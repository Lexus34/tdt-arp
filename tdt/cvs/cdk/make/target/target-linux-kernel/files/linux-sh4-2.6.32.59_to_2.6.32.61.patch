diff -Naur a/arch/alpha/kernel/sys_nautilus.c b/arch/alpha/kernel/sys_nautilus.c
--- a/arch/alpha/kernel/sys_nautilus.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/alpha/kernel/sys_nautilus.c	2013-11-01 18:44:42.489781908 +0200
@@ -189,6 +189,10 @@
 extern void free_reserved_mem(void *, void *);
 extern void pcibios_claim_one_bus(struct pci_bus *);
 
+static struct resource irongate_io = {
+	.name	= "Irongate PCI IO",
+	.flags	= IORESOURCE_IO,
+};
 static struct resource irongate_mem = {
 	.name	= "Irongate PCI MEM",
 	.flags	= IORESOURCE_MEM,
@@ -210,6 +214,7 @@
 
 	irongate = pci_get_bus_and_slot(0, 0);
 	bus->self = irongate;
+	bus->resource[0] = &irongate_io;
 	bus->resource[1] = &irongate_mem;
 
 	pci_bus_size_bridges(bus);
diff -Naur a/arch/arm/include/asm/signal.h b/arch/arm/include/asm/signal.h
--- a/arch/arm/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/arm/include/asm/signal.h	2013-11-01 18:44:42.709782993 +0200
@@ -127,6 +127,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/arm/kernel/sys_arm.c b/arch/arm/kernel/sys_arm.c
--- a/arch/arm/kernel/sys_arm.c	2013-11-01 20:18:03.197554310 +0200
+++ b/arch/arm/kernel/sys_arm.c	2013-11-01 18:44:42.733783112 +0200
@@ -240,7 +240,7 @@
 		  "Ir" (THREAD_START_SP - sizeof(regs)),
 		  "r" (&regs),
 		  "Ir" (sizeof(regs))
-		: "r0", "r1", "r2", "r3", "ip", "lr", "memory");
+		: "r0", "r1", "r2", "r3", "r8", "r9", "ip", "lr", "memory");
 
  out:
 	return ret;
diff -Naur a/arch/avr32/include/asm/signal.h b/arch/avr32/include/asm/signal.h
--- a/arch/avr32/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/avr32/include/asm/signal.h	2013-11-01 18:44:43.433786581 +0200
@@ -128,6 +128,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/cris/include/asm/signal.h b/arch/cris/include/asm/signal.h
--- a/arch/cris/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/cris/include/asm/signal.h	2013-11-01 18:44:43.837788583 +0200
@@ -122,6 +122,7 @@
 	void (*sa_restorer)(void);
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/h8300/include/asm/signal.h b/arch/h8300/include/asm/signal.h
--- a/arch/h8300/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/h8300/include/asm/signal.h	2013-11-01 18:44:44.065789714 +0200
@@ -121,6 +121,7 @@
 	void (*sa_restorer)(void);
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/ia64/include/asm/unistd.h b/arch/ia64/include/asm/unistd.h
--- a/arch/ia64/include/asm/unistd.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/ia64/include/asm/unistd.h	2013-11-01 18:44:44.161790193 +0200
@@ -311,11 +311,12 @@
 #define __NR_preadv			1319
 #define __NR_pwritev			1320
 #define __NR_rt_tgsigqueueinfo		1321
+#define __NR_accept4			1334
 
 #ifdef __KERNEL__
 
 
-#define NR_syscalls			298 /* length of syscall table */
+#define NR_syscalls			311 /* length of syscall table */
 
 /*
  * The following defines stop scripts/checksyscalls.sh from complaining about
diff -Naur a/arch/ia64/kernel/entry.S b/arch/ia64/kernel/entry.S
--- a/arch/ia64/kernel/entry.S	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/ia64/kernel/entry.S	2013-11-01 18:44:44.177790274 +0200
@@ -1806,6 +1806,19 @@
 	data8 sys_preadv
 	data8 sys_pwritev			// 1320
 	data8 sys_rt_tgsigqueueinfo
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall			// 1325
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall			// 1330
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_accept4
 
 	.org sys_call_table + 8*NR_syscalls	// guard against failures to increase NR_syscalls
 #endif /* __IA64_ASM_PARAVIRTUALIZED_NATIVE */
diff -Naur a/arch/ia64/kernel/irq_ia64.c b/arch/ia64/kernel/irq_ia64.c
--- a/arch/ia64/kernel/irq_ia64.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/ia64/kernel/irq_ia64.c	2013-11-01 18:44:44.185790312 +0200
@@ -24,7 +24,6 @@
 #include <linux/kernel_stat.h>
 #include <linux/slab.h>
 #include <linux/ptrace.h>
-#include <linux/random.h>	/* for rand_initialize_irq() */
 #include <linux/signal.h>
 #include <linux/smp.h>
 #include <linux/threads.h>
diff -Naur a/arch/ia64/kvm/kvm-ia64.c b/arch/ia64/kvm/kvm-ia64.c
--- a/arch/ia64/kvm/kvm-ia64.c	2013-11-01 20:18:03.245554546 +0200
+++ b/arch/ia64/kvm/kvm-ia64.c	2013-11-01 18:44:44.213790448 +0200
@@ -1185,6 +1185,11 @@
 
 #define PALE_RESET_ENTRY    0x80000000ffffffb0UL
 
+bool kvm_vcpu_compatible(struct kvm_vcpu *vcpu)
+{
+	return irqchip_in_kernel(vcpu->kvm) == (vcpu->arch.apic != NULL);
+}
+
 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 {
 	struct kvm_vcpu *v;
diff -Naur a/arch/m32r/include/asm/signal.h b/arch/m32r/include/asm/signal.h
--- a/arch/m32r/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/m32r/include/asm/signal.h	2013-11-01 18:44:44.289790824 +0200
@@ -123,6 +123,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/m68k/include/asm/signal.h b/arch/m68k/include/asm/signal.h
--- a/arch/m68k/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/m68k/include/asm/signal.h	2013-11-01 18:44:44.445791601 +0200
@@ -119,6 +119,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/mips/include/asm/thread_info.h b/arch/mips/include/asm/thread_info.h
--- a/arch/mips/include/asm/thread_info.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/mips/include/asm/thread_info.h	2013-11-01 18:44:44.837793543 +0200
@@ -60,6 +60,8 @@
 register struct thread_info *__current_thread_info __asm__("$28");
 #define current_thread_info()  __current_thread_info
 
+#endif /* !__ASSEMBLY__ */
+
 /* thread information allocation */
 #if defined(CONFIG_PAGE_SIZE_4KB) && defined(CONFIG_32BIT)
 #define THREAD_SIZE_ORDER (1)
@@ -93,8 +95,6 @@
 
 #define free_thread_info(info) kfree(info)
 
-#endif /* !__ASSEMBLY__ */
-
 #define PREEMPT_ACTIVE		0x10000000
 
 /*
diff -Naur a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
--- a/arch/mips/kernel/Makefile	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/mips/kernel/Makefile	2013-11-01 18:44:44.853793621 +0200
@@ -88,7 +88,7 @@
 obj-$(CONFIG_KEXEC)		+= machine_kexec.o relocate_kernel.o
 obj-$(CONFIG_EARLY_PRINTK)	+= early_printk.o
 
-CFLAGS_cpu-bugs64.o	= $(shell if $(CC) $(KBUILD_CFLAGS) -Wa,-mdaddi -c -o /dev/null -xc /dev/null >/dev/null 2>&1; then echo "-DHAVE_AS_SET_DADDI"; fi)
+CFLAGS_cpu-bugs64.o	= $(shell if $(CC) $(KBUILD_CFLAGS) -Wa,-mdaddi -c -o /dev/null -x c /dev/null >/dev/null 2>&1; then echo "-DHAVE_AS_SET_DADDI"; fi)
 
 obj-$(CONFIG_HAVE_STD_PC_SERIAL_PORT)	+= 8250-platform.o
 
diff -Naur a/arch/mips/kernel/vmlinux.lds.S b/arch/mips/kernel/vmlinux.lds.S
--- a/arch/mips/kernel/vmlinux.lds.S	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/mips/kernel/vmlinux.lds.S	2013-11-01 18:44:44.873793720 +0200
@@ -1,5 +1,6 @@
 #include <asm/asm-offsets.h>
 #include <asm/page.h>
+#include <asm/thread_info.h>
 #include <asm-generic/vmlinux.lds.h>
 
 #undef mips
@@ -70,7 +71,7 @@
 	.data : {	/* Data */
 		. = . + DATAOFFSET;		/* for CONFIG_MAPPED_KERNEL */
 
-		INIT_TASK_DATA(PAGE_SIZE)
+		INIT_TASK_DATA(THREAD_SIZE)
 		NOSAVE_DATA
 		CACHELINE_ALIGNED_DATA(1 << CONFIG_MIPS_L1_CACHE_SHIFT)
 		DATA_DATA
diff -Naur a/arch/mips/Makefile b/arch/mips/Makefile
--- a/arch/mips/Makefile	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/mips/Makefile	2013-11-01 18:44:44.573792241 +0200
@@ -657,7 +657,7 @@
 LDFLAGS			+= -m $(ld-emul)
 
 ifdef CONFIG_MIPS
-CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -xc /dev/null | \
+CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -x c /dev/null | \
 	egrep -vw '__GNUC_(|MINOR_|PATCHLEVEL_)_' | \
 	sed -e 's/^\#define /-D/' -e "s/ /='/" -e "s/$$/'/")
 ifdef CONFIG_64BIT
diff -Naur a/arch/mn10300/include/asm/signal.h b/arch/mn10300/include/asm/signal.h
--- a/arch/mn10300/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/mn10300/include/asm/signal.h	2013-11-01 18:44:44.993794316 +0200
@@ -131,6 +131,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/parisc/include/asm/atomic.h b/arch/parisc/include/asm/atomic.h
--- a/arch/parisc/include/asm/atomic.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/parisc/include/asm/atomic.h	2013-11-01 18:44:45.061794653 +0200
@@ -248,7 +248,7 @@
 
 #define atomic_sub_and_test(i,v)	(atomic_sub_return((i),(v)) == 0)
 
-#define ATOMIC_INIT(i)	((atomic_t) { (i) })
+#define ATOMIC_INIT(i)	{ (i) }
 
 #define smp_mb__before_atomic_dec()	smp_mb()
 #define smp_mb__after_atomic_dec()	smp_mb()
@@ -257,7 +257,7 @@
 
 #ifdef CONFIG_64BIT
 
-#define ATOMIC64_INIT(i) ((atomic64_t) { (i) })
+#define ATOMIC64_INIT(i) { (i) }
 
 static __inline__ int
 __atomic64_add_return(s64 i, atomic64_t *v)
diff -Naur a/arch/parisc/kernel/signal32.c b/arch/parisc/kernel/signal32.c
--- a/arch/parisc/kernel/signal32.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/parisc/kernel/signal32.c	2013-11-01 18:44:45.105794873 +0200
@@ -68,7 +68,8 @@
 {
 	compat_sigset_t s;
 
-	if (sz != sizeof *set) panic("put_sigset32()");
+	if (sz != sizeof *set)
+		return -EINVAL;
 	sigset_64to32(&s, set);
 
 	return copy_to_user(up, &s, sizeof s);
@@ -80,7 +81,8 @@
 	compat_sigset_t s;
 	int r;
 
-	if (sz != sizeof *set) panic("put_sigset32()");
+	if (sz != sizeof *set)
+		return -EINVAL;
 
 	if ((r = copy_from_user(&s, up, sz)) == 0) {
 		sigset_32to64(set, &s);
diff -Naur a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h
--- a/arch/powerpc/include/asm/reg.h	2013-11-01 20:18:03.293554787 +0200
+++ b/arch/powerpc/include/asm/reg.h	2013-11-01 18:44:45.361796150 +0200
@@ -870,7 +870,8 @@
 /* Macros for setting and retrieving special purpose registers */
 #ifndef __ASSEMBLY__
 #define mfmsr()		({unsigned long rval; \
-			asm volatile("mfmsr %0" : "=r" (rval)); rval;})
+			asm volatile("mfmsr %0" : "=r" (rval) : \
+						: "memory"); rval;})
 #ifdef CONFIG_PPC64
 #define __mtmsrd(v, l)	asm volatile("mtmsrd %0," __stringify(l) \
 				     : : "r" (v) : "memory")
diff -Naur a/arch/powerpc/include/asm/signal.h b/arch/powerpc/include/asm/signal.h
--- a/arch/powerpc/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/powerpc/include/asm/signal.h	2013-11-01 18:44:45.365796164 +0200
@@ -109,6 +109,7 @@
 	__sigrestore_t sa_restorer;
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/arch/powerpc/kernel/ftrace.c b/arch/powerpc/kernel/ftrace.c
--- a/arch/powerpc/kernel/ftrace.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/powerpc/kernel/ftrace.c	2013-11-01 18:44:45.393796309 +0200
@@ -244,9 +244,9 @@
 
 	/*
 	 * On PPC32 the trampoline looks like:
-	 *  0x3d, 0x60, 0x00, 0x00  lis r11,sym@ha
-	 *  0x39, 0x6b, 0x00, 0x00  addi r11,r11,sym@l
-	 *  0x7d, 0x69, 0x03, 0xa6  mtctr r11
+	 *  0x3d, 0x80, 0x00, 0x00  lis r12,sym@ha
+	 *  0x39, 0x8c, 0x00, 0x00  addi r12,r12,sym@l
+	 *  0x7d, 0x89, 0x03, 0xa6  mtctr r12
 	 *  0x4e, 0x80, 0x04, 0x20  bctr
 	 */
 
@@ -261,9 +261,9 @@
 	pr_devel(" %08x %08x ", jmp[0], jmp[1]);
 
 	/* verify that this is what we expect it to be */
-	if (((jmp[0] & 0xffff0000) != 0x3d600000) ||
-	    ((jmp[1] & 0xffff0000) != 0x396b0000) ||
-	    (jmp[2] != 0x7d6903a6) ||
+	if (((jmp[0] & 0xffff0000) != 0x3d800000) ||
+	    ((jmp[1] & 0xffff0000) != 0x398c0000) ||
+	    (jmp[2] != 0x7d8903a6) ||
 	    (jmp[3] != 0x4e800420)) {
 		printk(KERN_ERR "Not a trampoline\n");
 		return -EINVAL;
diff -Naur a/arch/powerpc/kernel/module_32.c b/arch/powerpc/kernel/module_32.c
--- a/arch/powerpc/kernel/module_32.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/powerpc/kernel/module_32.c	2013-11-01 18:44:45.409796389 +0200
@@ -187,8 +187,8 @@
 
 static inline int entry_matches(struct ppc_plt_entry *entry, Elf32_Addr val)
 {
-	if (entry->jump[0] == 0x3d600000 + ((val + 0x8000) >> 16)
-	    && entry->jump[1] == 0x396b0000 + (val & 0xffff))
+	if (entry->jump[0] == 0x3d800000 + ((val + 0x8000) >> 16)
+	    && entry->jump[1] == 0x398c0000 + (val & 0xffff))
 		return 1;
 	return 0;
 }
@@ -215,10 +215,9 @@
 		entry++;
 	}
 
-	/* Stolen from Paul Mackerras as well... */
-	entry->jump[0] = 0x3d600000+((val+0x8000)>>16);	/* lis r11,sym@ha */
-	entry->jump[1] = 0x396b0000 + (val&0xffff);	/* addi r11,r11,sym@l*/
-	entry->jump[2] = 0x7d6903a6;			/* mtctr r11 */
+	entry->jump[0] = 0x3d800000+((val+0x8000)>>16); /* lis r12,sym@ha */
+	entry->jump[1] = 0x398c0000 + (val&0xffff);     /* addi r12,r12,sym@l*/
+	entry->jump[2] = 0x7d8903a6;                    /* mtctr r12 */
 	entry->jump[3] = 0x4e800420;			/* bctr */
 
 	DEBUGP("Initialized plt for 0x%x at %p\n", val, entry);
diff -Naur a/arch/powerpc/platforms/powermac/smp.c b/arch/powerpc/platforms/powermac/smp.c
--- a/arch/powerpc/platforms/powermac/smp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/powerpc/platforms/powermac/smp.c	2013-11-01 18:44:45.597797314 +0200
@@ -402,7 +402,7 @@
 
 static void __init smp_psurge_setup_cpu(int cpu_nr)
 {
-	if (cpu_nr != 0)
+	if (cpu_nr != 0 || !psurge_start)
 		return;
 
 	/* reset the entry point so if we get another intr we won't
diff -Naur a/arch/s390/include/asm/signal.h b/arch/s390/include/asm/signal.h
--- a/arch/s390/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/s390/include/asm/signal.h	2013-11-01 18:44:45.689797769 +0200
@@ -131,6 +131,7 @@
         void (*sa_restorer)(void);
         sigset_t sa_mask;               /* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
         struct sigaction sa;
diff -Naur a/arch/sh/boards/Kconfig b/arch/sh/boards/Kconfig
--- a/arch/sh/boards/Kconfig	2013-11-01 20:19:18.045925472 +0200
+++ b/arch/sh/boards/Kconfig	2013-11-01 18:44:45.845798542 +0200
@@ -389,6 +389,14 @@
 	  Select B2069 if configuring for an
 	  STMicroelectronics STx7111 KC Reference Board
 
+config SH_ST_B2075
+	bool "B2075: STxH205-HDK Reference board"
+	depends on CPU_SUBTYPE_STXH205
+	default n
+	help
+	  Select SH_ST_B2075 if configuring for a
+	  STMicroelectronics STxH205-HDK Reference Board.
+
 config SH_ST_B2076
 	bool "B2076: STxH207-HVK (LiegeC) processor module board"
 	depends on CPU_SUBTYPE_STXH205
@@ -871,6 +879,8 @@
 source "arch/sh/boards/mach-rsk/Kconfig"
 source "arch/sh/boards/mach-b2039/Kconfig"
 source "arch/sh/boards/mach-b2057/Kconfig"
+source "arch/sh/boards/mach-b2064/Kconfig"
+source "arch/sh/boards/mach-b2067/Kconfig"
 source "arch/sh/boards/mach-b2076/Kconfig"
 source "arch/sh/boards/mach-eud7141/Kconfig"
 source "arch/sh/boards/mach-mb628/Kconfig"
diff -Naur a/arch/sh/boards/mach-b2039/setup.c b/arch/sh/boards/mach-b2039/setup.c
--- a/arch/sh/boards/mach-b2039/setup.c	2013-11-01 20:19:18.049925485 +0200
+++ b/arch/sh/boards/mach-b2039/setup.c	2013-11-01 18:44:45.853798588 +0200
@@ -22,6 +22,7 @@
 #include <linux/spi/spi.h>
 #include <linux/spi/flash.h>
 #include <linux/stm/platform.h>
+#include <linux/stm/nand_devices.h>
 #include <linux/stm/stxh205.h>
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
@@ -113,7 +114,11 @@
 	},
 };
 
-/* NAND Flash (via b2006a/b2007a VPMEM module) */
+/*
+ * NAND Flash
+ *	b2006a/b2007a VPMEM module
+ *	J66 should be 1-2, or open (i.e. 'VPMEM_notWP' not connected)
+ */
 static struct stm_nand_bank_data b2039_nand_flash = {
 	.csn		= 0,
 	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
@@ -129,17 +134,11 @@
 			.size	= MTDPART_SIZ_FULL
 		},
 	},
-	.timing_data	=  &(struct stm_nand_timing_data) {
-		.sig_setup	= 50,		/* times in ns */
-		.sig_hold	= 50,
-		.CE_deassert	= 0,
-		.WE_to_RBn	= 100,
-		.wr_on		= 10,
-		.wr_off		= 40,
-		.rd_on		= 10,
-		.rd_off		= 40,
-		.chip_delay	= 30,		/* in us */
-	},
+	/* Timing parameters specified for the Samsung K9F2G08U0C device.
+	 * Please update according to mounted device (numerous population
+	 * options available).
+	 */
+	.timing_spec	= &NAND_TSPEC_SAMSUNG_K9F2G08U0C,
 };
 
 
diff -Naur a/arch/sh/boards/mach-b2057/setup.c b/arch/sh/boards/mach-b2057/setup.c
--- a/arch/sh/boards/mach-b2057/setup.c	2013-11-01 20:19:18.053925502 +0200
+++ b/arch/sh/boards/mach-b2057/setup.c	2013-11-01 18:44:45.853798588 +0200
@@ -26,6 +26,7 @@
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
 
+#define B2057_GPIO_FLASH_WP		stm_gpio(6, 2)
 #define B2057_GPIO_POWER_ON_ETH		stm_gpio(2, 5)
 #define B2057_MII1_TXER			stm_gpio(0, 4)
 #define B2057_POWER_ON			stm_gpio(3, 7)
@@ -147,33 +148,26 @@
 	},
 };
 
-/* NAND Flash */
+/*
+ * NAND Flash: Micron MT29F8G08ABABAWP
+ *  - Requires 4-bit ECC
+ *  - ONFI compliant: timing parameters retrieved during device probe
+ */
 static struct stm_nand_bank_data b2057_nand_flash = {
-	.csn		= 1,	/* Controlled by JF3 */
+	.csn		= 0,	/* Rev A/B : set JF3 2-3 (EMI_CS0 -> NAND_CS) */
 	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
 	.nr_partitions	= 2,
 	.partitions	= (struct mtd_partition []) {
 		{
 			.name	= "NAND Flash 1",
 			.offset	= 0,
-			.size	= 0x00800000
+			.size	= 0x04000000
 		}, {
 			.name	= "NAND Flash 2",
 			.offset = MTDPART_OFS_NXTBLK,
 			.size	= MTDPART_SIZ_FULL
 		},
 	},
-	.timing_data	=  &(struct stm_nand_timing_data) {
-		.sig_setup	= 50,		/* times in ns */
-		.sig_hold	= 50,
-		.CE_deassert	= 0,
-		.WE_to_RBn	= 100,
-		.wr_on		= 10,
-		.wr_off		= 40,
-		.rd_on		= 10,
-		.rd_off		= 40,
-		.chip_delay	= 30,		/* in us */
-	},
 };
 
 static int b2057_phy_reset(void *bus)
@@ -296,11 +290,18 @@
 			.emmc = 0,
 		});
 
+	/*
+	 * NAND MTD has no concept of write-protect, so permanently disable WP
+	 */
+	gpio_request(B2057_GPIO_FLASH_WP, "FLASH_WP");
+	gpio_direction_output(B2057_GPIO_FLASH_WP, 1);
+
 	stxh205_configure_nand(&(struct stm_nand_config) {
 			.driver = stm_nand_bch,
 			.nr_banks = 1,
 			.banks = &b2057_nand_flash,
-			.rbn.flex_connected = 1,});
+			.rbn.flex_connected = 1,
+			.bch_ecc_cfg = BCH_ECC_CFG_AUTO});
 
 	stxh205_configure_spifsm(&b2057_serial_flash);
 
diff -Naur a/arch/sh/boards/mach-b2064/Kconfig b/arch/sh/boards/mach-b2064/Kconfig
--- a/arch/sh/boards/mach-b2064/Kconfig	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/boards/mach-b2064/Kconfig	2013-11-01 18:44:45.853798588 +0200
@@ -0,0 +1,30 @@
+if SH_ST_B2064
+
+menu "B2064: STxH239-HDK board options"
+
+choice
+	prompt  "B2064: Reference Board Version selection"
+	default SH_ST_B2064B_BOARD
+	help
+	  Select the appropriate version of the board which you will be using.
+	  This controls which PIO ports will be used for PHY reset.
+
+config SH_ST_B2064A_BOARD
+	bool "B2064A Board"
+	help
+	  B2064A Board for CUT1.0
+
+config SH_ST_B2064B_BOARD
+	bool "B2064B Board"
+	help
+	  B2064B Board for CUT1.0
+
+config SH_ST_B2064C_BOARD
+	bool "B2064C Board"
+	help
+	  B2064C Board for CUT2.0
+endchoice
+
+endmenu
+
+endif
diff -Naur a/arch/sh/boards/mach-b2064/setup.c b/arch/sh/boards/mach-b2064/setup.c
--- a/arch/sh/boards/mach-b2064/setup.c	2013-11-01 20:19:18.053925502 +0200
+++ b/arch/sh/boards/mach-b2064/setup.c	2013-11-01 18:44:45.853798588 +0200
@@ -26,8 +26,14 @@
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
 
+#define B2064_GPIO_FLASH_WP		stm_gpio(6, 2)
+#ifndef CONFIG_SH_ST_B2064C_BOARD
 #define B2064_GPIO_POWER_ON_ETH		stm_gpio(2, 5)
+#else
+#define B2064_GPIO_POWER_ON_ETH		stm_gpio(3, 3)
+#endif
 #define B2064_MII1_TXER			stm_gpio(0, 4)
+#define B2064_POWER_ON			stm_gpio(3, 7)
 
 static void __init b2064_setup(char **cmdline_p)
 {
@@ -158,17 +164,17 @@
 		/* Capabilities may be overriden by SoC configuration */
 		.dual_mode = 1,
 		.quad_mode = 1,
-		/*
-		 * Reset signal can be routed to UM7 (SO16 option) by fitting
-		 * RM52 (default is DNF)
-		 */
-		.reset_signal = 0,
+		.reset_signal = 0, /* Reset signal can be routed to UD16 if RD21
+				    * fitted (default is DNF)
+				    */
 	},
 };
 
 /* NAND Flash */
 static struct stm_nand_bank_data b2064_nand_flash = {
-	.csn		= 1,	/* Controlled by SW4 */
+	.csn		= 0,	/* Rev A/B : set SW4 2-3 (EMI_CS0 -> NAND_CS)
+				 * Rev C   : EMI_CS0 hardwired to NAND_CS
+				 */
 	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
 	.nr_partitions	= 2,
 	.partitions	= (struct mtd_partition []) {
@@ -230,6 +236,9 @@
 	gpio_request(B2064_GPIO_POWER_ON_ETH, "POWER_ON_ETH");
 	gpio_direction_output(B2064_GPIO_POWER_ON_ETH, 0);
 
+	gpio_request(B2064_POWER_ON, "POWER_ON");
+	gpio_direction_output(B2064_POWER_ON, 1);
+
 	stxh205_configure_ethernet(&(struct stxh205_ethernet_config) {
 			.mode = stxh205_ethernet_mode_mii,
 			.ext_clk = 1,
@@ -287,11 +296,18 @@
 			.no_mmc_boot_data_error = 1,
 		});
 
+	/*
+	 * NAND MTD has no concept of write-protect, so permanently disable WP
+	 */
+	gpio_request(B2064_GPIO_FLASH_WP, "FLASH_WP");
+	gpio_direction_output(B2064_GPIO_FLASH_WP, 1);
+
 	stxh205_configure_nand(&(struct stm_nand_config) {
-			.driver = stm_nand_flex,
+			.driver = stm_nand_bch,
 			.nr_banks = 1,
 			.banks = &b2064_nand_flash,
-			.rbn.flex_connected = 1,});
+			.rbn.flex_connected = 1,
+			.bch_ecc_cfg = BCH_ECC_CFG_AUTO});
 
 	stxh205_configure_spifsm(&b2064_serial_flash);
 
diff -Naur a/arch/sh/boards/mach-b2067/Kconfig b/arch/sh/boards/mach-b2067/Kconfig
--- a/arch/sh/boards/mach-b2067/Kconfig	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/boards/mach-b2067/Kconfig	2013-11-01 18:44:45.853798588 +0200
@@ -0,0 +1,30 @@
+if SH_ST_B2067
+
+menu "B2067: STxH238-HDK board options"
+
+choice
+	prompt  "B2067: Reference Board Version selection"
+	default SH_ST_B2067B_BOARD
+	help
+	  Select the appropriate version of the board which you will be using.
+	  This controls which PIO ports will be used for PHY reset.
+
+config SH_ST_B2067A_BOARD
+	bool "B2067A Board"
+	help
+	  B2067A Board for CUT1.0
+
+config SH_ST_B2067B_BOARD
+	bool "B2067B Board"
+	help
+	  B2067B Board for CUT1.0
+
+config SH_ST_B2067C_BOARD
+	bool "B2067C Board"
+	help
+	  B2067C Board for CUT2.0
+endchoice
+
+endmenu
+
+endif
diff -Naur a/arch/sh/boards/mach-b2067/setup.c b/arch/sh/boards/mach-b2067/setup.c
--- a/arch/sh/boards/mach-b2067/setup.c	2013-11-01 20:19:18.057925524 +0200
+++ b/arch/sh/boards/mach-b2067/setup.c	2013-11-01 18:44:45.853798588 +0200
@@ -26,8 +26,14 @@
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
 
+#define B2067_GPIO_FLASH_WP		stm_gpio(6, 2)
+#ifndef CONFIG_SH_ST_B2067C_BOARD
 #define B2067_GPIO_POWER_ON_ETH		stm_gpio(2, 5)
+#else
+#define B2067_GPIO_POWER_ON_ETH		stm_gpio(3, 3)
+#endif
 #define B2067_MII1_TXER			stm_gpio(0, 4)
+#define B2067_POWER_ON			stm_gpio(3, 7)
 
 static void __init b2067_setup(char **cmdline_p)
 {
@@ -138,19 +144,24 @@
 	.capabilities = {
 		/* Capabilities may be overriden by SoC configuration */
 		.dual_mode = 1,
-		.quad_mode = 1,
-		/*
-		 * Reset signal can be routed to U4 and U12 by fitting
-		 * RM52 (default is DNF).
-		 * Note rev A boards misconnected reset and hold signals.
-		 */
+#ifdef CONFIG_SH_ST_B2067A_BOARD
+		/* HOLD and RESET misconnected on Rev A boards*/
+		.quad_mode = 0,
 		.reset_signal = 0,
+#else
+		.quad_mode = 1,
+		.reset_signal = 0,  /* Reset signal can be routed to U4 and U12
+				     * by fitting RM52 (default is DNF)
+				     */
+#endif
 	},
 };
 
 /* NAND Flash */
 static struct stm_nand_bank_data b2067_nand_flash = {
-	.csn		= 1,	/* Controlled by JF3 */
+	.csn		= 0,	/* Rev A/B : set JF3 2-3 (EMI_CS0 -> NAND_CS)
+				 * Rev C   : EMI_CS0 hardwired to NAND_CS
+				 */
 	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
 	.nr_partitions	= 2,
 	.partitions	= (struct mtd_partition []) {
@@ -211,6 +222,9 @@
 	gpio_request(B2067_GPIO_POWER_ON_ETH, "POWER_ON_ETH");
 	gpio_direction_output(B2067_GPIO_POWER_ON_ETH, 0);
 
+	gpio_request(B2067_POWER_ON, "POWER_ON");
+	gpio_direction_output(B2067_POWER_ON, 0);
+
 	stxh205_configure_ethernet(&(struct stxh205_ethernet_config) {
 			.mode = stxh205_ethernet_mode_mii,
 			.ext_clk = 1,
@@ -271,12 +285,18 @@
 			.emmc = 0,
 			.no_mmc_boot_data_error = 1,
 		});
+	/*
+	 * NAND MTD has no concept of write-protect, so permanently disable WP
+	 */
+	gpio_request(B2067_GPIO_FLASH_WP, "FLASH_WP");
+	gpio_direction_output(B2067_GPIO_FLASH_WP, 1);
 
 	stxh205_configure_nand(&(struct stm_nand_config) {
-			.driver = stm_nand_flex,
+			.driver = stm_nand_bch,
 			.nr_banks = 1,
 			.banks = &b2067_nand_flash,
-			.rbn.flex_connected = 1,});
+			.rbn.flex_connected = 1,
+			.bch_ecc_cfg = BCH_ECC_CFG_AUTO});
 
 	stxh205_configure_spifsm(&b2067_serial_flash);
 
diff -Naur a/arch/sh/boards/mach-b2075/Makefile b/arch/sh/boards/mach-b2075/Makefile
--- a/arch/sh/boards/mach-b2075/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/boards/mach-b2075/Makefile	2013-11-01 18:44:45.857798602 +0200
@@ -0,0 +1,5 @@
+#
+# Makefile for STMicroelectronics B2075(STxH205-HDK) board
+#
+
+obj-y := setup.o
diff -Naur a/arch/sh/boards/mach-b2075/setup.c b/arch/sh/boards/mach-b2075/setup.c
--- a/arch/sh/boards/mach-b2075/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/boards/mach-b2075/setup.c	2013-11-01 18:44:45.857798602 +0200
@@ -0,0 +1,328 @@
+/*
+ * arch/sh/boards/mach-b2075/setup.c
+ *
+ * Copyright (C) 2011 STMicroelectronics Limited
+ * Author: Stuart Menefy (stuart.menefy@st.com)
+ *
+ * May be copied or modified under the terms of the GNU General Public
+ * License.  See linux/COPYING for more information.
+ */
+
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/phy.h>
+#include <linux/gpio.h>
+#include <linux/gpio_keys.h>
+#include <linux/leds.h>
+#include <linux/tm1668.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/nand.h>
+#include <linux/spi/spi.h>
+#include <linux/spi/flash.h>
+#include <linux/stm/platform.h>
+#include <linux/stm/stxh205.h>
+#include <linux/stm/sysconf.h>
+#include <asm/irq-ilc.h>
+
+#define B2075_GPIO_FLASH_WP		stm_gpio(6, 2)
+#define B2075_GPIO_POWER_ON_ETH		stm_gpio(3, 3)
+#define B2075_MII1_TXER			stm_gpio(0, 4)
+#define B2075_POWER_ON			stm_gpio(3, 7)
+
+static void __init b2075_setup(char **cmdline_p)
+{
+	printk(KERN_INFO "STMicroelectronics B2075 board initialisation\n");
+
+	stxh205_early_device_init();
+
+	/*
+	 * Socket CN32 DB9-1 connector (no flow control)
+	 */
+	stxh205_configure_asc(STXH205_ASC(10), &(struct stxh205_asc_config) {
+			.hw_flow_control = 0,
+			.is_console = 1, });
+	/*
+	 * Header JD7 (no flow control)
+	 * also Socket CN29 as FSK UART (with flow control)
+	 */
+	stxh205_configure_asc(STXH205_ASC(1), &(struct stxh205_asc_config) {
+			.hw_flow_control = 0, });
+}
+
+static struct platform_device b2075_leds = {
+	.name = "leds-gpio",
+	.id = -1,
+	.dev.platform_data = &(struct gpio_led_platform_data) {
+		.num_leds = 2,
+		.leds = (struct gpio_led[]) {
+						{
+				.name = "GREEN",
+				.gpio = stm_gpio(3, 0),
+			},{
+				.name = "RED",
+				.default_trigger = "heartbeat",
+				.gpio = stm_gpio(3, 1),
+			},
+		},
+	},
+};
+
+static struct tm1668_key b2075_front_panel_keys[] = {
+	{ 0x00001000, KEY_UP, "Up (SWF2)" },
+	{ 0x00800000, KEY_DOWN, "Down (SWF7)" },
+	{ 0x00008000, KEY_LEFT, "Left (SWF6)" },
+	{ 0x00000010, KEY_RIGHT, "Right (SWF5)" },
+	{ 0x00000080, KEY_OK, "Menu/OK (SWF1)" },
+	{ 0x00100000, KEY_BACK, "Back (SWF4)" },
+	{ 0x80000000, KEY_TV, "DOXTV (SWF9)" },
+};
+
+static struct tm1668_character b2075_front_panel_characters[] = {
+	TM1668_7_SEG_HEX_DIGITS,
+	TM1668_7_SEG_SEGMENTS,
+	TM1668_7_SEG_LETTERS
+};
+
+static struct platform_device b2075_front_panel = {
+	.name = "tm1668",
+	.id = -1,
+	.dev.platform_data = &(struct tm1668_platform_data) {
+		.gpio_dio = stm_gpio(15, 4),
+		.gpio_sclk = stm_gpio(14, 7),
+		.gpio_stb = stm_gpio(14, 4),
+		.config = tm1668_config_6_digits_12_segments,
+
+		.keys_num = ARRAY_SIZE(b2075_front_panel_keys),
+		.keys = b2075_front_panel_keys,
+		.keys_poll_period = DIV_ROUND_UP(HZ, 5),
+
+		.brightness = 8,
+		.characters_num = ARRAY_SIZE(b2075_front_panel_characters),
+		.characters = b2075_front_panel_characters,
+		.text = "H205",
+	},
+};
+
+/*
+ * Serial Flash (Contrary to schematics, board is fitted with Spansion
+ * S25FL256SAGBHIY0 device.)
+ */
+static struct stm_plat_spifsm_data b2075_serial_flash =  {
+	.name		= "s25fl256s1",
+	.nr_parts	= 3,
+	.parts = (struct mtd_partition []) {
+		{
+			.name = "Serial Flash 1",
+			.size = 0x00800000,
+			.offset = 0,
+		}, {
+			.name = "Serial Flash 2",
+			.size = 0x01000000,
+			.offset = MTDPART_OFS_NXTBLK,
+		}, {
+			.name = "Serial Flash 3",
+			.size = MTDPART_SIZ_FULL,
+			.offset = MTDPART_OFS_NXTBLK,
+		},
+	},
+	.capabilities = {
+		/* Capabilities may be overridden by SoC configuration */
+		.dual_mode = 1,
+		.quad_mode = 1,
+		.reset_signal = 0, /* Reset signal can be routed to UD16 if RD21
+				    * fitted (default is DNF)
+				    */
+	},
+};
+
+/* NAND Flash */
+static struct stm_nand_bank_data b2075_nand_flash = {
+	.csn		= 0,
+	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
+	.nr_partitions	= 3,
+	.partitions	= (struct mtd_partition []) {
+		{
+			.name	= "NAND Flash 1",
+			.offset	= 0,
+			.size	= 0x01000000,
+		}, {
+			.name	= "NAND Flash 2",
+			.offset = MTDPART_OFS_NXTBLK,
+			.size	= 0x01000000,
+		}, {
+			.name	= "NAND Flash 3",
+			.offset = MTDPART_OFS_NXTBLK,
+			.size	= MTDPART_SIZ_FULL,
+
+		},
+	},
+	.timing_data	=  &(struct stm_nand_timing_data) {
+		.sig_setup	= 50,		/* times in ns */
+		.sig_hold	= 50,
+		.CE_deassert	= 0,
+		.WE_to_RBn	= 100,
+		.wr_on		= 10,
+		.wr_off		= 40,
+		.rd_on		= 10,
+		.rd_off		= 40,
+		.chip_delay	= 30,		/* in us */
+	},
+};
+
+static int b2075_phy_reset(void *bus)
+{
+	/*
+	 * IC+ IP101 datasheet specifies 10mS low period and device usable
+	 * 2.5mS after rising edge. However experimentally it appear
+	 * 10mS is required for reliable functioning.
+	 */
+	gpio_set_value(B2075_GPIO_POWER_ON_ETH, 0);
+	mdelay(10);
+	gpio_set_value(B2075_GPIO_POWER_ON_ETH, 1);
+	mdelay(10);
+
+	return 1;
+}
+
+static struct stmmac_mdio_bus_data stmmac_mdio_bus = {
+	.bus_id = 0,
+	.phy_reset = b2075_phy_reset,
+	.phy_mask = 0,
+	.probed_phy_irq = ILC_IRQ(25), /* MDINT */
+};
+
+static struct platform_device *b2075_devices[] __initdata = {
+	&b2075_leds,
+	&b2075_front_panel,
+};
+
+static int __init device_init(void)
+{
+	/* The "POWER_ON_ETH" line should be rather called "PHY_RESET",
+	 * but it isn't... ;-) */
+	gpio_request(B2075_GPIO_POWER_ON_ETH, "POWER_ON_ETH");
+	gpio_direction_output(B2075_GPIO_POWER_ON_ETH, 0);
+
+	gpio_request(B2075_POWER_ON, "POWER_ON");
+	gpio_direction_output(B2075_POWER_ON, 0);
+
+	stxh205_configure_ethernet(&(struct stxh205_ethernet_config) {
+			.mode = stxh205_ethernet_mode_mii,
+			.ext_clk = 1,
+			.phy_bus = 0,
+			.phy_addr = -1,
+			.mdio_bus_data = &stmmac_mdio_bus,
+		});
+
+	/* PHY IRQ has to be triggered LOW */
+	set_irq_type(ILC_IRQ(25), IRQ_TYPE_LEVEL_LOW);
+
+	stxh205_configure_miphy(&(struct stxh205_miphy_config){
+			.mode = SATA_MODE,
+			.iface = UPORT_IF,
+		});
+
+	stxh205_configure_sata();
+
+	stxh205_configure_usb(0);
+
+	stxh205_configure_usb(1);
+
+	/* SSC1: NIM3 */
+	stxh205_configure_ssc_i2c(STXH205_SSC(1), &(struct stxh205_ssc_config) {
+			.routing.ssc1.sclk = stxh205_ssc1_sclk_pio12_0,
+			.routing.ssc1.mtsr = stxh205_ssc1_mtsr_pio12_1, });
+
+	/* SSC3: STV6440, EEPROM */
+	stxh205_configure_ssc_i2c(STXH205_SSC(3), &(struct stxh205_ssc_config) {
+			.routing.ssc3.sclk = stxh205_ssc3_sclk_pio15_5,
+			.routing.ssc3.mtsr = stxh205_ssc3_mtsr_pio15_6, });
+	/* SSC11: HDMI */
+	stxh205_configure_ssc_i2c(STXH205_SSC(11), NULL);
+
+	stxh205_configure_lirc(&(struct stxh205_lirc_config) {
+#ifdef CONFIG_LIRC_STM_UHF
+			.rx_mode = stxh205_lirc_rx_mode_uhf, });
+#else
+			.rx_mode = stxh205_lirc_rx_mode_ir, });
+#endif
+
+	stxh205_configure_pwm(&(struct stxh205_pwm_config) {
+			/*
+			 * PWM10 is connected to 12V->1.2V power supply
+			 * for "debug purposes". Enable at your own risk!
+			 */
+			.out10_enabled = 0 });
+
+	stxh205_configure_mmc(&(struct stxh205_mmc_config) {
+			.emmc = 0,
+			.no_mmc_boot_data_error = 1,
+		});
+	/*
+	 * NAND MTD has no concept of write-protect, so permanently disable WP
+	 */
+	gpio_request(B2075_GPIO_FLASH_WP, "FLASH_WP");
+	gpio_direction_output(B2075_GPIO_FLASH_WP, 1);
+
+	stxh205_configure_nand(&(struct stm_nand_config) {
+			.driver = stm_nand_bch,
+			.nr_banks = 1,
+			.banks = &b2075_nand_flash,
+			.rbn.flex_connected = 1,
+			.bch_ecc_cfg = BCH_ECC_CFG_AUTO});
+
+	stxh205_configure_spifsm(&b2075_serial_flash);
+
+	return platform_add_devices(b2075_devices,
+			ARRAY_SIZE(b2075_devices));
+}
+arch_initcall(device_init);
+
+static void __iomem *b2075_ioport_map(unsigned long port, unsigned int size)
+{
+	/* If we have PCI then this should never be called because we
+	 * are using the generic iomap implementation. If we don't
+	 * have PCI then there are no IO mapped devices, so it still
+	 * shouldn't be called. */
+	BUG();
+	return NULL;
+}
+
+struct sh_machine_vector mv_b2075 __initmv = {
+	.mv_name = "b2075",
+	.mv_setup = b2075_setup,
+	.mv_nr_irqs = NR_IRQS,
+	.mv_ioport_map = b2075_ioport_map,
+};
+
+#if defined(CONFIG_HIBERNATION_ON_MEMORY)
+
+#include "../../kernel/cpu/sh4/stm_hom.h"
+
+static int b2075_board_freeze(void)
+{
+	gpio_set_value(B2075_GPIO_POWER_ON_ETH, 0);
+	return 0;
+}
+
+static int b2075_board_defrost(void)
+{
+	b2075_phy_reset(NULL);
+	return 0;
+}
+
+static struct stm_hom_board b2075_hom = {
+	.freeze = b2075_board_freeze,
+	.restore = b2075_board_defrost,
+};
+
+static int __init b2075_hom_register(void)
+{
+	return stm_hom_board_register(&b2075_hom);
+}
+
+module_init(b2075_hom_register);
+#endif
+
diff -Naur a/arch/sh/boards/mach-b2076/setup.c b/arch/sh/boards/mach-b2076/setup.c
--- a/arch/sh/boards/mach-b2076/setup.c	2013-11-01 20:19:18.061925551 +0200
+++ b/arch/sh/boards/mach-b2076/setup.c	2013-11-01 18:44:45.857798602 +0200
@@ -114,7 +114,11 @@
 	},
 };
 
-/* NAND Flash (via b2006a/b2007a VPMEM module) */
+/*
+ * NAND Flash
+ *	b2006a/b2007a VPMEM module
+ *	J70 should be 1-2, or open (i.e. 'VPMEM_notWP' not connected)
+ */
 static struct stm_nand_bank_data b2076_nand_flash = {
 	.csn		= 0,
 	.options	= NAND_NO_AUTOINCR | NAND_USE_FLASH_BBT,
diff -Naur a/arch/sh/boards/mach-hdk7105/setup.c b/arch/sh/boards/mach-hdk7105/setup.c
--- a/arch/sh/boards/mach-hdk7105/setup.c	2013-11-01 20:19:18.077925629 +0200
+++ b/arch/sh/boards/mach-hdk7105/setup.c	2013-11-01 18:44:45.869798662 +0200
@@ -23,6 +23,8 @@
 #include <linux/stm/stx7105.h>
 #include <linux/stm/pci-glue.h>
 #include <linux/stm/emi.h>
+#include <linux/stm/nand.h>
+#include <linux/stm/nand_devices.h>
 #include <linux/mtd/mtd.h>
 #include <linux/mtd/physmap.h>
 #include <linux/mtd/nand.h>
@@ -222,17 +224,7 @@
 			.size	= MTDPART_SIZ_FULL
 		},
 	},
-	.timing_data		= &(struct stm_nand_timing_data) {
-		.sig_setup	= 50,		/* times in ns */
-		.sig_hold	= 50,
-		.CE_deassert	= 0,
-		.WE_to_RBn	= 100,
-		.wr_on		= 10,
-		.wr_off		= 40,
-		.rd_on		= 10,
-		.rd_off		= 40,
-		.chip_delay	= 30,		/* in us */
-	},
+	.timing_spec	= &NAND_TSPEC_HYNIX_HY27UH08AG5B,
 };
 
 /* Serial Flash */
@@ -240,7 +232,7 @@
 	.modalias       = "m25p80",
 	.bus_num        = 0,
 	.chip_select    = stm_gpio(2, 4),
-	.max_speed_hz   = 7000000,
+	.max_speed_hz   = 3000000,
 	.mode           = SPI_MODE_3,
 	.platform_data  = &(struct flash_platform_data) {
 		.name = "m25p80",
@@ -412,7 +404,7 @@
 			.driver = stm_nand_flex,
 			.nr_banks = 1,
 			.banks = &hdk7105_nand_flash,
-			.rbn.flex_connected = -1,});
+			.rbn.flex_connected = 1,});
 
 	spi_register_board_info(&hdk7105_serial_flash, 1);
 
diff -Naur a/arch/sh/boards/mach-hdk7108/setup.c b/arch/sh/boards/mach-hdk7108/setup.c
--- a/arch/sh/boards/mach-hdk7108/setup.c	2013-11-01 20:19:18.081925640 +0200
+++ b/arch/sh/boards/mach-hdk7108/setup.c	2013-11-01 18:44:45.869798662 +0200
@@ -25,6 +25,7 @@
 #include <linux/spi/spi_gpio.h>
 #include <linux/spi/flash.h>
 #include <linux/stm/nand.h>
+#include <linux/stm/nand_devices.h>
 #include <linux/stm/emi.h>
 #include <linux/stm/pci-glue.h>
 #include <linux/stm/platform.h>
@@ -91,6 +92,7 @@
 #define HDK7108_GPIO_MII_SPEED_SEL stm_gpio(21, 7)
 #define HDK7108_GPIO_SPI_HOLD stm_gpio(2, 2)
 #define HDK7108_GPIO_SPI_WRITE_PRO stm_gpio(2, 3)
+#define HDK7108_GPIO_LPM	stm_gpio(26, 7)
 
 static void __init hdk7108_setup(char **cmdline_p)
 {
@@ -283,17 +285,7 @@
 			.size	= MTDPART_SIZ_FULL
 		},
 	},
-	.timing_data = &(struct stm_nand_timing_data) {
-		.sig_setup      = 10,           /* times in ns */
-		.sig_hold       = 10,
-		.CE_deassert    = 0,
-		.WE_to_RBn      = 100,
-		.wr_on          = 10,
-		.wr_off         = 30,
-		.rd_on          = 10,
-		.rd_off         = 30,
-		.chip_delay     = 30,           /* in us */
-	},
+	.timing_spec = &NAND_TSPEC_ST_NAND08GW3B2CN6,
 };
 
 
@@ -553,6 +545,16 @@
 				});
 #endif
 
+#if !defined(CONFIG_SH_ST_HDK7108_VER1_BOARD) && \
+	!defined(CONFIG_SH_ST_HDK7108_VER1_1_BOARD)
+
+	stx7108_configure_lpm_i2c_interface(&(struct stx7108_lpm_i2c_config) {
+					.number_i2c = 2,
+					.number_gpio = HDK7108_GPIO_LPM,
+				});
+
+#endif
+
 
 #ifdef CONFIG_SH_ST_HDK7108_STMMAC0
 	stx7108_configure_ethernet(0, &(struct stx7108_ethernet_config) {
diff -Naur a/arch/sh/configs/7102isdb_defconfig b/arch/sh/configs/7102isdb_defconfig
--- a/arch/sh/configs/7102isdb_defconfig	2013-11-01 20:19:18.169926087 +0200
+++ b/arch/sh/configs/7102isdb_defconfig	2013-11-01 18:44:45.921798926 +0200
@@ -1628,7 +1628,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/adi7108_defconfig b/arch/sh/configs/adi7108_defconfig
--- a/arch/sh/configs/adi7108_defconfig	2013-11-01 20:19:18.173926101 +0200
+++ b/arch/sh/configs/adi7108_defconfig	2013-11-01 18:44:45.921798926 +0200
@@ -1560,7 +1560,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/b2064_defconfig b/arch/sh/configs/b2064_defconfig
--- a/arch/sh/configs/b2064_defconfig	2013-11-01 20:19:18.185926165 +0200
+++ b/arch/sh/configs/b2064_defconfig	2013-11-01 18:44:45.925798942 +0200
@@ -1,7 +1,7 @@
 #
 # Automatically generated make config: don't edit
-# Linux kernel version: 2.6.32.57
-# Fri Jul 20 19:10:38 2012
+# Linux kernel version: 2.6.32.59
+# Thu Aug  2 15:46:28 2012
 #
 CONFIG_SUPERH=y
 CONFIG_SUPERH32=y
@@ -255,6 +255,7 @@
 CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
 CONFIG_BPA2=y
 # CONFIG_BPA2_ALLOC_TRACE is not set
+# CONFIG_MIN_FREE_KBYTES is not set
 
 #
 # Cache configuration
@@ -294,6 +295,7 @@
 # CONFIG_SH_ST_B2039 is not set
 # CONFIG_SH_ST_B2057 is not set
 CONFIG_SH_ST_B2064=y
+# CONFIG_SH_ST_B2067 is not set
 # CONFIG_SH_ST_B2076 is not set
 
 #
@@ -555,12 +557,10 @@
 # CONFIG_MTD_NAND_NANDSIM is not set
 # CONFIG_MTD_NAND_PLATFORM is not set
 # CONFIG_MTD_ALAUDA is not set
-# CONFIG_MTD_NAND_STM_BCH is not set
+CONFIG_MTD_NAND_STM_BCH=y
+# CONFIG_STM_NAND_BCH_DEBUG is not set
 # CONFIG_MTD_NAND_STM_EMI is not set
-CONFIG_MTD_NAND_STM_FLEX=y
-# CONFIG_STM_NAND_FLEX_CACHED is not set
-# CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT is not set
-CONFIG_STM_NAND_FLEX_BOOTPARTITION="Boot firmware"
+# CONFIG_MTD_NAND_STM_FLEX is not set
 # CONFIG_MTD_NAND_STM_AFM is not set
 # CONFIG_MTD_ONENAND is not set
 
diff -Naur a/arch/sh/configs/b2066_defconfig b/arch/sh/configs/b2066_defconfig
--- a/arch/sh/configs/b2066_defconfig	2013-11-01 20:19:18.189926176 +0200
+++ b/arch/sh/configs/b2066_defconfig	2013-11-01 18:44:45.929798958 +0200
@@ -1581,7 +1581,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/b2067_defconfig b/arch/sh/configs/b2067_defconfig
--- a/arch/sh/configs/b2067_defconfig	2013-11-01 20:19:18.193926197 +0200
+++ b/arch/sh/configs/b2067_defconfig	2013-11-01 18:44:45.929798958 +0200
@@ -1,7 +1,7 @@
 #
 # Automatically generated make config: don't edit
-# Linux kernel version: 2.6.32.57
-# Mon Jul 23 17:29:52 2012
+# Linux kernel version: 2.6.32.59
+# Fri Aug  3 12:07:41 2012
 #
 CONFIG_SUPERH=y
 CONFIG_SUPERH32=y
@@ -255,6 +255,7 @@
 CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
 CONFIG_BPA2=y
 # CONFIG_BPA2_ALLOC_TRACE is not set
+# CONFIG_MIN_FREE_KBYTES is not set
 
 #
 # Cache configuration
@@ -302,6 +303,13 @@
 #
 
 #
+# B2067: STxH238-HDK Reference board options
+#
+CONFIG_SH_ST_B2067A_BOARD=y
+# CONFIG_SH_ST_B2067B_BOARD is not set
+# CONFIG_SH_ST_B2067C_BOARD is not set
+
+#
 # Timer and clock configuration
 #
 CONFIG_SH_TIMER_TMU=y
@@ -556,12 +564,10 @@
 # CONFIG_MTD_NAND_NANDSIM is not set
 # CONFIG_MTD_NAND_PLATFORM is not set
 # CONFIG_MTD_ALAUDA is not set
-# CONFIG_MTD_NAND_STM_BCH is not set
+CONFIG_MTD_NAND_STM_BCH=y
+# CONFIG_STM_NAND_BCH_DEBUG is not set
 # CONFIG_MTD_NAND_STM_EMI is not set
-CONFIG_MTD_NAND_STM_FLEX=y
-# CONFIG_STM_NAND_FLEX_CACHED is not set
-# CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT is not set
-CONFIG_STM_NAND_FLEX_BOOTPARTITION="Boot firmware"
+# CONFIG_MTD_NAND_STM_FLEX is not set
 # CONFIG_MTD_NAND_STM_AFM is not set
 # CONFIG_MTD_ONENAND is not set
 
diff -Naur a/arch/sh/configs/b2068_defconfig b/arch/sh/configs/b2068_defconfig
--- a/arch/sh/configs/b2068_defconfig	2013-11-01 20:19:18.197926225 +0200
+++ b/arch/sh/configs/b2068_defconfig	2013-11-01 18:44:45.929798958 +0200
@@ -1574,7 +1574,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/b2069_defconfig b/arch/sh/configs/b2069_defconfig
--- a/arch/sh/configs/b2069_defconfig	2013-11-01 20:19:18.201926241 +0200
+++ b/arch/sh/configs/b2069_defconfig	2013-11-01 18:44:45.929798958 +0200
@@ -1482,7 +1482,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/b2075_defconfig b/arch/sh/configs/b2075_defconfig
--- a/arch/sh/configs/b2075_defconfig	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/configs/b2075_defconfig	2013-11-01 18:44:45.929798958 +0200
@@ -0,0 +1,1493 @@
+#
+# Automatically generated make config: don't edit
+# Linux kernel version: 2.6.32.59
+# Mon Nov  5 16:12:14 2012
+#
+CONFIG_SUPERH=y
+CONFIG_SUPERH32=y
+# CONFIG_SUPERH64 is not set
+CONFIG_ARCH_DEFCONFIG="arch/sh/configs/shx3_defconfig"
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+CONFIG_GENERIC_BUG=y
+CONFIG_GENERIC_FIND_NEXT_BIT=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_IRQ_PER_CPU=y
+CONFIG_GENERIC_GPIO=y
+CONFIG_GENERIC_TIME=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_SYS_SUPPORTS_HUGETLBFS=y
+CONFIG_SYS_SUPPORTS_TMU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_HAVE_LATENCYTOP_SUPPORT=y
+# CONFIG_ARCH_HAS_ILOG2_U32 is not set
+# CONFIG_ARCH_HAS_ILOG2_U64 is not set
+CONFIG_ARCH_NO_VIRT_TO_BUS=y
+CONFIG_ARCH_HAS_DEFAULT_IDLE=y
+CONFIG_ARCH_HAS_CPU_IDLE_WAIT=y
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_CONSTRUCTORS=y
+
+#
+# General setup
+#
+CONFIG_EXPERIMENTAL=y
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_LOCK_KERNEL=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_LOCALVERSION="-b2075"
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_BZIP2=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_BZIP2 is not set
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_LZO is not set
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+CONFIG_POSIX_MQUEUE=y
+CONFIG_POSIX_MQUEUE_SYSCTL=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+# CONFIG_AUDIT is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TREE_RCU=y
+# CONFIG_TREE_PREEMPT_RCU is not set
+# CONFIG_RCU_TRACE is not set
+CONFIG_RCU_FANOUT=32
+# CONFIG_RCU_FANOUT_EXACT is not set
+# CONFIG_TREE_RCU_TRACE is not set
+CONFIG_IKCONFIG=y
+CONFIG_IKCONFIG_PROC=y
+CONFIG_LOG_BUF_SHIFT=14
+# CONFIG_CGROUPS is not set
+# CONFIG_SYSFS_DEPRECATED_V2 is not set
+# CONFIG_RELAY is not set
+# CONFIG_NAMESPACES is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+CONFIG_CC_OPTIMIZE_FOR_SIZE=y
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_EMBEDDED=y
+CONFIG_UID16=y
+CONFIG_SYSCTL_SYSCALL=y
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_EXTRA_PASS is not set
+CONFIG_HOTPLUG=y
+CONFIG_PRINTK=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_HAVE_PERF_EVENTS=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+# CONFIG_PERF_COUNTERS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLOB is not set
+# CONFIG_KPROBES is not set
+CONFIG_HAVE_IOREMAP_PROT=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+
+#
+# GCOV-based kernel profiling
+#
+# CONFIG_GCOV_KERNEL is not set
+# CONFIG_SLOW_WORK is not set
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+CONFIG_LKM_ELF_HASH=y
+# CONFIG_MODULES_BPA2 is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+# CONFIG_BLK_DEV_BSG is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_AS=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_AS=y
+# CONFIG_DEFAULT_DEADLINE is not set
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="anticipatory"
+CONFIG_FREEZER=y
+
+#
+# System type
+#
+CONFIG_CPU_SH4=y
+CONFIG_CPU_SUBTYPE_ST40=y
+CONFIG_CPU_ST40_300=y
+# CONFIG_CPU_SUBTYPE_SH7619 is not set
+# CONFIG_CPU_SUBTYPE_SH7201 is not set
+# CONFIG_CPU_SUBTYPE_SH7203 is not set
+# CONFIG_CPU_SUBTYPE_SH7206 is not set
+# CONFIG_CPU_SUBTYPE_SH7263 is not set
+# CONFIG_CPU_SUBTYPE_MXG is not set
+# CONFIG_CPU_SUBTYPE_SH7705 is not set
+# CONFIG_CPU_SUBTYPE_SH7706 is not set
+# CONFIG_CPU_SUBTYPE_SH7707 is not set
+# CONFIG_CPU_SUBTYPE_SH7708 is not set
+# CONFIG_CPU_SUBTYPE_SH7709 is not set
+# CONFIG_CPU_SUBTYPE_SH7710 is not set
+# CONFIG_CPU_SUBTYPE_SH7712 is not set
+# CONFIG_CPU_SUBTYPE_SH7720 is not set
+# CONFIG_CPU_SUBTYPE_SH7721 is not set
+# CONFIG_CPU_SUBTYPE_SH7750 is not set
+# CONFIG_CPU_SUBTYPE_SH7091 is not set
+# CONFIG_CPU_SUBTYPE_SH7750R is not set
+# CONFIG_CPU_SUBTYPE_SH7750S is not set
+# CONFIG_CPU_SUBTYPE_SH7751 is not set
+# CONFIG_CPU_SUBTYPE_SH7751R is not set
+# CONFIG_CPU_SUBTYPE_SH7760 is not set
+# CONFIG_CPU_SUBTYPE_SH4_202 is not set
+# CONFIG_CPU_SUBTYPE_FLI75XX is not set
+# CONFIG_CPU_SUBTYPE_ST40STB1 is not set
+# CONFIG_CPU_SUBTYPE_STX5197 is not set
+# CONFIG_CPU_SUBTYPE_STX5206 is not set
+# CONFIG_CPU_SUBTYPE_STX7100 is not set
+# CONFIG_CPU_SUBTYPE_STX7105 is not set
+# CONFIG_CPU_SUBTYPE_STX7108 is not set
+# CONFIG_CPU_SUBTYPE_STX7111 is not set
+# CONFIG_CPU_SUBTYPE_STX7141 is not set
+# CONFIG_CPU_SUBTYPE_STX7200 is not set
+CONFIG_CPU_SUBTYPE_STXH205=y
+# CONFIG_CPU_SUBTYPE_SH7723 is not set
+# CONFIG_CPU_SUBTYPE_SH7724 is not set
+# CONFIG_CPU_SUBTYPE_SH7757 is not set
+# CONFIG_CPU_SUBTYPE_SH7763 is not set
+# CONFIG_CPU_SUBTYPE_SH7770 is not set
+# CONFIG_CPU_SUBTYPE_SH7780 is not set
+# CONFIG_CPU_SUBTYPE_SH7785 is not set
+# CONFIG_CPU_SUBTYPE_SH7786 is not set
+# CONFIG_CPU_SUBTYPE_SHX3 is not set
+# CONFIG_CPU_SUBTYPE_SH7343 is not set
+# CONFIG_CPU_SUBTYPE_SH7722 is not set
+# CONFIG_CPU_SUBTYPE_SH7366 is not set
+
+#
+# Memory management options
+#
+CONFIG_QUICKLIST=y
+CONFIG_MMU=y
+CONFIG_PAGE_OFFSET=0x80000000
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_MEMORY_START=0x40000000
+CONFIG_MEMORY_SIZE=0x08000000
+# CONFIG_29BIT is not set
+CONFIG_32BIT=y
+CONFIG_SUPPORTS_32BIT=y
+CONFIG_PMB_ENABLE=y
+CONFIG_PMB=y
+# CONFIG_PMB_FIXED is not set
+# CONFIG_PMB_64M_TILES is not set
+# CONFIG_VSYSCALL is not set
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_ARCH_SPARSEMEM_ENABLE=y
+CONFIG_ARCH_SPARSEMEM_DEFAULT=y
+CONFIG_MAX_ACTIVE_REGIONS=1
+CONFIG_ARCH_POPULATES_NODE_MAP=y
+CONFIG_ARCH_SELECT_MEMORY_MODEL=y
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_SELECT_MEMORY_MODEL=y
+CONFIG_FLATMEM_MANUAL=y
+# CONFIG_DISCONTIGMEM_MANUAL is not set
+# CONFIG_SPARSEMEM_MANUAL is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_SPARSEMEM_STATIC=y
+CONFIG_PAGEFLAGS_EXTENDED=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+CONFIG_ZONE_DMA_FLAG=0
+CONFIG_NR_QUICK=2
+CONFIG_HAVE_MLOCK=y
+CONFIG_HAVE_MLOCKED_PAGE_BIT=y
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_BPA2=y
+# CONFIG_BPA2_ALLOC_TRACE is not set
+# CONFIG_MIN_FREE_KBYTES is not set
+
+#
+# Cache configuration
+#
+CONFIG_CACHE_WRITEBACK=y
+# CONFIG_CACHE_WRITETHROUGH is not set
+# CONFIG_CACHE_OFF is not set
+CONFIG_STM_L2_CACHE=y
+# CONFIG_STM_L2_CACHE_BYPASSED is not set
+# CONFIG_STM_L2_CACHE_WRITETHROUGH is not set
+CONFIG_STM_L2_CACHE_WRITEBACK=y
+
+#
+# Processor features
+#
+CONFIG_CPU_LITTLE_ENDIAN=y
+# CONFIG_CPU_BIG_ENDIAN is not set
+CONFIG_SH_FPU=y
+# CONFIG_SH_STORE_QUEUES is not set
+CONFIG_CPU_HAS_INTEVT=y
+CONFIG_CPU_HAS_SR_RB=y
+CONFIG_CPU_HAS_FPU=y
+
+#
+# Board support
+#
+
+#
+# ST Main Boards
+#
+# CONFIG_SH_ST_HARP_IRQ is not set
+# CONFIG_SH_ST_EPLD is not set
+# CONFIG_SH_ST_STEM is not set
+# CONFIG_SH_ST_STPM_HD_V1 is not set
+# CONFIG_SH_ST_STPM_HD_V2 is not set
+# CONFIG_SH_ST_STPM_SD is not set
+# CONFIG_SH_ST_B2039 is not set
+# CONFIG_SH_ST_B2057 is not set
+# CONFIG_SH_ST_B2064 is not set
+# CONFIG_SH_ST_B2067 is not set
+CONFIG_SH_ST_B2075=y
+# CONFIG_SH_ST_B2076 is not set
+
+#
+# ST Peripheral Boards
+#
+
+#
+# Timer and clock configuration
+#
+CONFIG_SH_TIMER_TMU=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_SH_PCLK_FREQ=66000000
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+CONFIG_GENERIC_CLOCKEVENTS_BUILD=y
+
+#
+# CPU Frequency scaling
+#
+# CONFIG_CPU_FREQ is not set
+
+#
+# DMA support
+#
+
+#
+# Companion Chips
+#
+
+#
+# Additional SuperH Device Drivers
+#
+# CONFIG_HEARTBEAT is not set
+# CONFIG_PUSH_SWITCH is not set
+# CONFIG_PINMUX_GPIO is not set
+
+#
+# Kernel features
+#
+# CONFIG_HZ_100 is not set
+CONFIG_HZ_250=y
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=250
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+# CONFIG_SECCOMP is not set
+# CONFIG_PREEMPT_NONE is not set
+# CONFIG_PREEMPT_VOLUNTARY is not set
+CONFIG_PREEMPT=y
+CONFIG_GUSA=y
+CONFIG_GUSA_RB=y
+# CONFIG_SPARSE_IRQ is not set
+# CONFIG_CC_STACKPROTECTOR is not set
+
+#
+# Boot options
+#
+CONFIG_ZERO_PAGE_OFFSET=0x00001000
+CONFIG_BOOT_LINK_OFFSET=0x00800000
+CONFIG_ENTRY_OFFSET=0x00001000
+# CONFIG_UBC_WAKEUP is not set
+# CONFIG_CMDLINE_OVERWRITE is not set
+# CONFIG_CMDLINE_EXTEND is not set
+
+#
+# Bus options
+#
+# CONFIG_SH_ST_ST40RA_PCI is not set
+# CONFIG_ARCH_SUPPORTS_MSI is not set
+# CONFIG_PCCARD is not set
+
+#
+# Executable file formats
+#
+CONFIG_BINFMT_ELF=y
+# CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+
+#
+# Power management options (EXPERIMENTAL)
+#
+CONFIG_PM=y
+# CONFIG_PM_DEBUG is not set
+CONFIG_PM_SLEEP=y
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATION_NVS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_HIBERNATION_ON_MEMORY=y
+CONFIG_HOM_TAG_VIRTUAL_ADDRESS=0x80001800
+# CONFIG_HOM_DEBUG is not set
+CONFIG_PM_RUNTIME=y
+# CONFIG_CPU_IDLE is not set
+CONFIG_NET=y
+
+#
+# Networking options
+#
+# CONFIG_PACKET is not set
+CONFIG_UNIX=y
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+# CONFIG_IP_MULTICAST is not set
+# CONFIG_IP_ADVANCED_ROUTER is not set
+CONFIG_IP_FIB_HASH=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE is not set
+# CONFIG_ARPD is not set
+# CONFIG_SYN_COOKIES is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+# CONFIG_INET_LRO is not set
+# CONFIG_INET_DIAG is not set
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_DEFAULT_TCP_CONG="cubic"
+# CONFIG_TCP_MD5SIG is not set
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_NET_DSA is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_ECONET is not set
+# CONFIG_WAN_ROUTER is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_NET_9P is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_UEVENT_HELPER_PATH="/sbin/hotplug"
+# CONFIG_DEVTMPFS is not set
+CONFIG_STANDALONE=y
+CONFIG_PREVENT_FIRMWARE_BUILD=y
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_DEBUG is not set
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_CONCAT is not set
+CONFIG_MTD_PARTITIONS=y
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_CHAR=y
+# CONFIG_MTD_BLKDEVS is not set
+# CONFIG_MTD_BLOCK is not set
+# CONFIG_MTD_BLOCK_RO is not set
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_MTD_OOPS is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_M25P80 is not set
+CONFIG_MTD_STM_SPI_FSM=y
+# CONFIG_MTD_SST25L is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOC2000 is not set
+# CONFIG_MTD_DOC2001 is not set
+# CONFIG_MTD_DOC2001PLUS is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_VERIFY_WRITE is not set
+# CONFIG_MTD_NAND_ECC_SMC is not set
+# CONFIG_MTD_NAND_MUSEUM_IDS is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_ALAUDA is not set
+CONFIG_MTD_NAND_STM_BCH=y
+# CONFIG_STM_NAND_BCH_DEBUG is not set
+# CONFIG_MTD_NAND_STM_EMI is not set
+# CONFIG_MTD_NAND_STM_FLEX is not set
+# CONFIG_MTD_NAND_STM_AFM is not set
+CONFIG_STM_NAND_SAFE_MOUNT=y
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR flash memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+
+#
+# UBI - Unsorted block images
+#
+CONFIG_MTD_UBI=y
+CONFIG_MTD_UBI_WL_THRESHOLD=4096
+CONFIG_MTD_UBI_BEB_RESERVE=1
+# CONFIG_MTD_UBI_GLUEBI is not set
+
+#
+# UBI debugging options
+#
+# CONFIG_MTD_UBI_DEBUG is not set
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_NBD is not set
+# CONFIG_BLK_DEV_UB is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=4096
+# CONFIG_BLK_DEV_XIP is not set
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_BLK_DEV_HD is not set
+# CONFIG_MISC_DEVICES is not set
+CONFIG_HAVE_IDE=y
+# CONFIG_IDE is not set
+
+#
+# SCSI device support
+#
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_DMA=y
+# CONFIG_SCSI_TGT is not set
+# CONFIG_SCSI_NETLINK is not set
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+# CONFIG_SCSI_MULTI_LUN is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+CONFIG_SCSI_WAIT_SCAN=m
+
+#
+# SCSI Transports
+#
+# CONFIG_SCSI_SPI_ATTRS is not set
+# CONFIG_SCSI_FC_ATTRS is not set
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_LIBSAS is not set
+# CONFIG_SCSI_SRP_ATTRS is not set
+CONFIG_SCSI_LOWLEVEL=y
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_LIBFC is not set
+# CONFIG_LIBFCOE is not set
+# CONFIG_SCSI_DEBUG is not set
+# CONFIG_SCSI_DH is not set
+# CONFIG_SCSI_OSD_INITIATOR is not set
+CONFIG_ATA=y
+# CONFIG_ATA_NONSTANDARD is not set
+CONFIG_ATA_VERBOSE_ERROR=y
+CONFIG_SATA_PMP=y
+CONFIG_SATA_AHCI_PLATFORM=y
+# CONFIG_ATA_SFF is not set
+# CONFIG_MD is not set
+CONFIG_NETDEVICES=y
+# CONFIG_DUMMY is not set
+# CONFIG_BONDING is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_TUN is not set
+# CONFIG_VETH is not set
+CONFIG_NWHW_CONFIG=y
+CONFIG_PHYLIB=y
+
+#
+# MII PHY device drivers
+#
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+CONFIG_ICPLUS_PHY=y
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_FIXED_PHY is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_NET_ETHERNET is not set
+CONFIG_MII=y
+CONFIG_NETDEV_1000=y
+CONFIG_STMMAC_ETH=y
+CONFIG_STMMAC_PLATFORM=y
+# CONFIG_STMMAC_PCI is not set
+# CONFIG_STMMAC_DEBUG_FS is not set
+# CONFIG_STMMAC_DA is not set
+# CONFIG_STMMAC_TIMER is not set
+CONFIG_STMMAC_RING=y
+# CONFIG_STMMAC_CHAINED is not set
+# CONFIG_NETDEV_10000 is not set
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+
+#
+# USB Network Adapters
+#
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_USBNET is not set
+# CONFIG_WAN is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_ISDN is not set
+# CONFIG_PHONE is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+CONFIG_INPUT_EVBUG=y
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ATKBD is not set
+# CONFIG_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+CONFIG_KEYBOARD_GPIO=y
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_LM8323 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_SH_KEYSC is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_ATI_REMOTE is not set
+# CONFIG_INPUT_ATI_REMOTE2 is not set
+# CONFIG_INPUT_KEYSPAN_REMOTE is not set
+# CONFIG_INPUT_POWERMATE is not set
+# CONFIG_INPUT_YEALINK is not set
+# CONFIG_INPUT_CM109 is not set
+# CONFIG_INPUT_UINPUT is not set
+# CONFIG_INPUT_GPIO_ROTARY_ENCODER is not set
+CONFIG_INPUT_TM1668=y
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+# CONFIG_SERIO_I8042 is not set
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_LIBPS2 is not set
+# CONFIG_SERIO_RAW is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+# CONFIG_VT_CONSOLE is not set
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_DEVKMEM=y
+# CONFIG_SERIAL_NONSTANDARD is not set
+
+#
+# Serial drivers
+#
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_SH_SCI is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+CONFIG_SERIAL_STM_ASC=y
+CONFIG_SERIAL_STM_ASC_CONSOLE=y
+CONFIG_UNIX98_PTYS=y
+# CONFIG_DEVPTS_MULTIPLE_INSTANCES is not set
+# CONFIG_LEGACY_PTYS is not set
+
+#
+# Linux InfraRed Controller
+#
+# CONFIG_LIRC_SUPPORT is not set
+# CONFIG_IPMI_HANDLER is not set
+CONFIG_HW_RANDOM=y
+# CONFIG_HW_RANDOM_TIMERIOMEM is not set
+CONFIG_HW_RANDOM_STM=y
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=y
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_DESIGNWARE is not set
+# CONFIG_I2C_GPIO is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_SH_MOBILE is not set
+# CONFIG_I2C_SIMTEC is not set
+CONFIG_I2C_STM=y
+# CONFIG_I2C_STM_GLITCH_SUPPORT is not set
+# CONFIG_I2C_STM_HW_GLITCH is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_TAOS_EVM is not set
+# CONFIG_I2C_TINY_USB is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_STUB is not set
+
+#
+# Miscellaneous I2C Chip support
+#
+# CONFIG_DS1682 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_I2C_DEBUG_CHIP is not set
+CONFIG_SPI=y
+CONFIG_SPI_MASTER=y
+
+#
+# SPI Master Controller Drivers
+#
+CONFIG_SPI_BITBANG=y
+# CONFIG_SPI_GPIO is not set
+# CONFIG_SPI_SH_SCI is not set
+CONFIG_SPI_STM=y
+
+#
+# SPI Protocol Masters
+#
+# CONFIG_SPI_SPIDEV is not set
+# CONFIG_SPI_TLE62X0 is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+CONFIG_ARCH_REQUIRE_GPIOLIB=y
+CONFIG_GPIOLIB=y
+CONFIG_GPIO_SYSFS=y
+
+#
+# Memory mapped GPIO expanders:
+#
+
+#
+# I2C GPIO expanders:
+#
+# CONFIG_GPIO_MAX732X is not set
+# CONFIG_GPIO_PCA953X is not set
+# CONFIG_GPIO_PCF857X is not set
+
+#
+# PCI GPIO expanders:
+#
+
+#
+# SPI GPIO expanders:
+#
+# CONFIG_GPIO_MAX7301 is not set
+# CONFIG_GPIO_MCP23S08 is not set
+# CONFIG_GPIO_MC33880 is not set
+
+#
+# AC97 GPIO expanders:
+#
+# CONFIG_W1 is not set
+# CONFIG_POWER_SUPPLY is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_TPS65010 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_MC13783 is not set
+# CONFIG_AB3100_CORE is not set
+# CONFIG_EZX_PCAP is not set
+# CONFIG_REGULATOR is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_VGASTATE is not set
+# CONFIG_VIDEO_OUTPUT_CONTROL is not set
+# CONFIG_FB is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+
+#
+# Display device support
+#
+# CONFIG_DISPLAY_SUPPORT is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_SOUND is not set
+# CONFIG_HID_SUPPORT is not set
+CONFIG_USB_SUPPORT=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB_ARCH_HAS_OHCI=y
+CONFIG_USB_ARCH_HAS_EHCI=y
+CONFIG_USB=y
+CONFIG_USB_DEBUG=y
+CONFIG_USB_ANNOUNCE_NEW_DEVICES=y
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEVICEFS=y
+# CONFIG_USB_DEVICE_CLASS is not set
+# CONFIG_USB_DYNAMIC_MINORS is not set
+# CONFIG_USB_SUSPEND is not set
+# CONFIG_USB_OTG is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_OTG_BLACKLIST_HUB is not set
+# CONFIG_USB_MON is not set
+# CONFIG_USB_WUSB is not set
+# CONFIG_USB_WUSB_CBAF is not set
+
+#
+# USB Host Controller Drivers
+#
+# CONFIG_USB_C67X00_HCD is not set
+CONFIG_USB_EHCI_HCD=y
+# CONFIG_USB_EHCI_ROOT_HUB_TT is not set
+# CONFIG_USB_EHCI_TT_NEWSCHED is not set
+# CONFIG_USB_OXU210HP_HCD is not set
+# CONFIG_USB_ISP116X_HCD is not set
+# CONFIG_USB_ISP1760_HCD is not set
+# CONFIG_USB_ISP1362_HCD is not set
+CONFIG_USB_OHCI_HCD=y
+# CONFIG_USB_OHCI_BIG_ENDIAN_DESC is not set
+# CONFIG_USB_OHCI_BIG_ENDIAN_MMIO is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SL811_HCD is not set
+# CONFIG_USB_R8A66597_HCD is not set
+# CONFIG_USB_HWA_HCD is not set
+CONFIG_USB_STM_COMMON=y
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+# CONFIG_USB_WDM is not set
+# CONFIG_USB_TMC is not set
+
+#
+# NOTE: USB_STORAGE depends on SCSI but BLK_DEV_SD may
+#
+
+#
+# also be needed; see USB_STORAGE Help for more info
+#
+CONFIG_USB_STORAGE=y
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_USBAT is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+# CONFIG_USB_STORAGE_ALAUDA is not set
+# CONFIG_USB_STORAGE_ONETOUCH is not set
+# CONFIG_USB_STORAGE_KARMA is not set
+# CONFIG_USB_STORAGE_CYPRESS_ATACB is not set
+# CONFIG_USB_LIBUSUAL is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+
+#
+# USB port drivers
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_ADUTUX is not set
+# CONFIG_USB_SEVSEG is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_BERRY_CHARGE is not set
+# CONFIG_USB_LED is not set
+# CONFIG_USB_CYPRESS_CY7C63 is not set
+# CONFIG_USB_CYTHERM is not set
+# CONFIG_USB_IDMOUSE is not set
+# CONFIG_USB_FTDI_ELAN is not set
+# CONFIG_USB_APPLEDISPLAY is not set
+# CONFIG_USB_SISUSBVGA is not set
+# CONFIG_USB_LD is not set
+# CONFIG_USB_TRANCEVIBRATOR is not set
+# CONFIG_USB_IOWARRIOR is not set
+# CONFIG_USB_TEST is not set
+# CONFIG_USB_ISIGHTFW is not set
+# CONFIG_USB_VST is not set
+# CONFIG_USB_GADGET is not set
+
+#
+# OTG and related infrastructure
+#
+# CONFIG_USB_GPIO_VBUS is not set
+# CONFIG_NOP_USB_XCEIV is not set
+CONFIG_MMC=y
+# CONFIG_MMC_DEBUG is not set
+# CONFIG_MMC_UNSAFE_RESUME is not set
+
+#
+# MMC/SD/SDIO Card Drivers
+#
+CONFIG_MMC_BLOCK=y
+CONFIG_MMC_BLOCK_MINORS=8
+CONFIG_MMC_BLOCK_BOUNCE=y
+# CONFIG_SDIO_UART is not set
+# CONFIG_MMC_TEST is not set
+
+#
+# MMC/SD/SDIO Host Controller Drivers
+#
+CONFIG_MMC_SDHCI=y
+CONFIG_MMC_SDHCI_PLTFM=y
+# CONFIG_MMC_SPI is not set
+# CONFIG_MMC_SH_MMCIF is not set
+# CONFIG_MMC_USHC is not set
+# CONFIG_MEMSTICK is not set
+CONFIG_NEW_LEDS=y
+CONFIG_LEDS_CLASS=y
+
+#
+# LED drivers
+#
+# CONFIG_LEDS_PCA9532 is not set
+CONFIG_LEDS_GPIO=y
+CONFIG_LEDS_GPIO_PLATFORM=y
+# CONFIG_LEDS_LP3944 is not set
+# CONFIG_LEDS_PCA955X is not set
+# CONFIG_LEDS_DAC124S085 is not set
+# CONFIG_LEDS_BD2802 is not set
+
+#
+# LED Triggers
+#
+CONFIG_LEDS_TRIGGERS=y
+# CONFIG_LEDS_TRIGGER_TIMER is not set
+CONFIG_LEDS_TRIGGER_HEARTBEAT=y
+# CONFIG_LEDS_TRIGGER_BACKLIGHT is not set
+# CONFIG_LEDS_TRIGGER_GPIO is not set
+# CONFIG_LEDS_TRIGGER_DEFAULT_ON is not set
+
+#
+# iptables trigger is under Netfilter config (LED target)
+#
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+
+#
+# TI VLYNQ
+#
+# CONFIG_STAGING is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_STM_DRIVERS=y
+
+#
+# STM specific devices
+#
+CONFIG_STM_MIPHY=y
+# CONFIG_STM_MIPHY_TAP is not set
+CONFIG_STM_MIPHY_PCIE_MP=y
+# CONFIG_STM_MIPHY_DUMMY is not set
+CONFIG_STM_MIPHYA40X=y
+# CONFIG_STM_MIPHY365X is not set
+# CONFIG_STPIO is not set
+# CONFIG_STM_DMA is not set
+# CONFIG_STM_RNG is not set
+# CONFIG_PMS is not set
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+# CONFIG_EXT2_FS_XATTR is not set
+# CONFIG_EXT2_FS_XIP is not set
+CONFIG_EXT3_FS=y
+# CONFIG_EXT3_DEFAULTS_TO_ORDERED is not set
+CONFIG_EXT3_FS_XATTR=y
+# CONFIG_EXT3_FS_POSIX_ACL is not set
+# CONFIG_EXT3_FS_SECURITY is not set
+# CONFIG_EXT4_FS is not set
+CONFIG_JBD=y
+# CONFIG_JBD_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_FS_POSIX_ACL is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_QUOTA is not set
+# CONFIG_AUTOFS_FS is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+CONFIG_JOLIET=y
+# CONFIG_ZISOFS is not set
+CONFIG_UDF_FS=y
+CONFIG_UDF_NLS=y
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_VFAT_NO_CREATE_WITH_LONGNAMES is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_KCORE=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_HUGETLBFS is not set
+# CONFIG_HUGETLB_PAGE is not set
+# CONFIG_CONFIGFS_FS is not set
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+CONFIG_UBIFS_FS=y
+# CONFIG_UBIFS_FS_XATTR is not set
+# CONFIG_UBIFS_FS_ADVANCED_COMPR is not set
+CONFIG_UBIFS_FS_LZO=y
+CONFIG_UBIFS_FS_ZLIB=y
+# CONFIG_UBIFS_FS_DEBUG is not set
+CONFIG_CRAMFS=y
+CONFIG_SQUASHFS=y
+# CONFIG_SQUASHFS_EMBEDDED is not set
+CONFIG_SQUASHFS_FRAGMENT_CACHE_SIZE=3
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+CONFIG_ROMFS_FS=y
+CONFIG_ROMFS_BACKED_BY_BLOCK=y
+# CONFIG_ROMFS_BACKED_BY_MTD is not set
+# CONFIG_ROMFS_BACKED_BY_BOTH is not set
+CONFIG_ROMFS_ON_BLOCK=y
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+# CONFIG_NFS_V4 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFSD is not set
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+# CONFIG_RPCSEC_GSS_KRB5 is not set
+# CONFIG_RPCSEC_GSS_SPKM3 is not set
+# CONFIG_SMB_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+
+#
+# Partition Types
+#
+# CONFIG_PARTITION_ADVANCED is not set
+CONFIG_MSDOS_PARTITION=y
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+# CONFIG_PRINTK_TIME is not set
+CONFIG_ENABLE_WARN_DEPRECATED=y
+CONFIG_ENABLE_MUST_CHECK=y
+CONFIG_FRAME_WARN=1024
+# CONFIG_MAGIC_SYSRQ is not set
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+CONFIG_DEBUG_FS=y
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_KERNEL is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+# CONFIG_DEBUG_BUGVERBOSE is not set
+# CONFIG_DEBUG_MEMORY_INIT is not set
+# CONFIG_RCU_CPU_STALL_DETECTOR is not set
+# CONFIG_LATENCYTOP is not set
+# CONFIG_SYSCTL_SYSCALL_CHECK is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_FUNCTION_TRACE_MCOUNT_TEST=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_KPTRACE=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+# CONFIG_KPTRACE is not set
+
+#
+# Profilers
+#
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_DYNAMIC_DEBUG is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_SH_STANDARD_BIOS is not set
+# CONFIG_EARLY_SCIF_CONSOLE is not set
+# CONFIG_DWARF_UNWINDER is not set
+
+#
+# Security options
+#
+# CONFIG_KEYS is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+# CONFIG_SECURITY_FILE_CAPABILITIES is not set
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+# CONFIG_CRYPTO_FIPS is not set
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=m
+# CONFIG_CRYPTO_MANAGER is not set
+# CONFIG_CRYPTO_MANAGER2 is not set
+# CONFIG_CRYPTO_GF128MUL is not set
+# CONFIG_CRYPTO_NULL is not set
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+# CONFIG_CRYPTO_CCM is not set
+# CONFIG_CRYPTO_GCM is not set
+# CONFIG_CRYPTO_SEQIV is not set
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+# CONFIG_CRYPTO_CTR is not set
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_HMAC is not set
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+# CONFIG_CRYPTO_CRC32C is not set
+# CONFIG_CRYPTO_GHASH is not set
+# CONFIG_CRYPTO_MD4 is not set
+# CONFIG_CRYPTO_MD5 is not set
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+# CONFIG_CRYPTO_SHA1 is not set
+# CONFIG_CRYPTO_SHA256 is not set
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=m
+# CONFIG_CRYPTO_ANUBIS is not set
+# CONFIG_CRYPTO_ARC4 is not set
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+# CONFIG_CRYPTO_ZLIB is not set
+CONFIG_CRYPTO_LZO=y
+
+#
+# Random Number Generation
+#
+CONFIG_CRYPTO_ANSI_CPRNG=m
+CONFIG_CRYPTO_HW=y
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_GENERIC_FIND_LAST_BIT=y
+# CONFIG_CRC_CCITT is not set
+CONFIG_CRC16=y
+# CONFIG_CRC_T10DIF is not set
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC7 is not set
+# CONFIG_LIBCRC32C is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT=y
+CONFIG_HAS_DMA=y
+CONFIG_HAVE_LMB=y
+CONFIG_NLATTR=y
+CONFIG_GENERIC_ATOMIC64=y
diff -Naur a/arch/sh/configs/dtt5250_defconfig b/arch/sh/configs/dtt5250_defconfig
--- a/arch/sh/configs/dtt5250_defconfig	2013-11-01 20:19:18.209926279 +0200
+++ b/arch/sh/configs/dtt5250_defconfig	2013-11-01 18:44:45.933798980 +0200
@@ -1546,7 +1546,7 @@
 CONFIG_CRC32=y
 # CONFIG_CRC7 is not set
 # CONFIG_LIBCRC32C is not set
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/eud7141_defconfig b/arch/sh/configs/eud7141_defconfig
--- a/arch/sh/configs/eud7141_defconfig	2013-11-01 20:19:18.213926305 +0200
+++ b/arch/sh/configs/eud7141_defconfig	2013-11-01 18:44:45.937799007 +0200
@@ -1439,7 +1439,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/fldb_defconfig b/arch/sh/configs/fldb_defconfig
--- a/arch/sh/configs/fldb_defconfig	2013-11-01 20:19:18.217926318 +0200
+++ b/arch/sh/configs/fldb_defconfig	2013-11-01 18:44:45.937799007 +0200
@@ -1741,7 +1741,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/fudb_defconfig b/arch/sh/configs/fudb_defconfig
--- a/arch/sh/configs/fudb_defconfig	2013-11-01 20:19:18.225926355 +0200
+++ b/arch/sh/configs/fudb_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1744,7 +1744,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk5250_defconfig b/arch/sh/configs/hdk5250_defconfig
--- a/arch/sh/configs/hdk5250_defconfig	2013-11-01 20:19:18.229926383 +0200
+++ b/arch/sh/configs/hdk5250_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1548,7 +1548,7 @@
 CONFIG_CRC32=y
 # CONFIG_CRC7 is not set
 # CONFIG_LIBCRC32C is not set
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk5289_defconfig b/arch/sh/configs/hdk5289_defconfig
--- a/arch/sh/configs/hdk5289_defconfig	2013-11-01 20:19:18.229926383 +0200
+++ b/arch/sh/configs/hdk5289_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1563,7 +1563,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk7105_defconfig b/arch/sh/configs/hdk7105_defconfig
--- a/arch/sh/configs/hdk7105_defconfig	2013-11-01 20:19:18.233926399 +0200
+++ b/arch/sh/configs/hdk7105_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1549,7 +1549,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk7106_defconfig b/arch/sh/configs/hdk7106_defconfig
--- a/arch/sh/configs/hdk7106_defconfig	2013-11-01 20:19:18.237926415 +0200
+++ b/arch/sh/configs/hdk7106_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1645,7 +1645,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk7108_defconfig b/arch/sh/configs/hdk7108_defconfig
--- a/arch/sh/configs/hdk7108_defconfig	2013-11-01 20:19:18.241926437 +0200
+++ b/arch/sh/configs/hdk7108_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1693,7 +1693,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk7111_defconfig b/arch/sh/configs/hdk7111_defconfig
--- a/arch/sh/configs/hdk7111_defconfig	2013-11-01 20:19:18.245926464 +0200
+++ b/arch/sh/configs/hdk7111_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1495,7 +1495,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdk7197_defconfig b/arch/sh/configs/hdk7197_defconfig
--- a/arch/sh/configs/hdk7197_defconfig	2013-11-01 20:19:18.249926477 +0200
+++ b/arch/sh/configs/hdk7197_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1600,7 +1600,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdkh225_defconfig b/arch/sh/configs/hdkh225_defconfig
--- a/arch/sh/configs/hdkh225_defconfig	2013-11-01 20:19:18.253926494 +0200
+++ b/arch/sh/configs/hdkh225_defconfig	2013-11-01 18:44:45.941799020 +0200
@@ -1601,7 +1601,7 @@
 CONFIG_CRC32=y
 # CONFIG_CRC7 is not set
 # CONFIG_LIBCRC32C is not set
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdkh246_defconfig b/arch/sh/configs/hdkh246_defconfig
--- a/arch/sh/configs/hdkh246_defconfig	2013-11-01 20:19:18.257926516 +0200
+++ b/arch/sh/configs/hdkh246_defconfig	2013-11-01 18:44:45.945799037 +0200
@@ -1638,7 +1638,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdkh251_defconfig b/arch/sh/configs/hdkh251_defconfig
--- a/arch/sh/configs/hdkh251_defconfig	2013-11-01 20:19:18.257926516 +0200
+++ b/arch/sh/configs/hdkh251_defconfig	2013-11-01 18:44:45.945799037 +0200
@@ -1619,7 +1619,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hdref_defconfig b/arch/sh/configs/hdref_defconfig
--- a/arch/sh/configs/hdref_defconfig	2013-11-01 20:19:18.261926543 +0200
+++ b/arch/sh/configs/hdref_defconfig	2013-11-01 18:44:45.945799037 +0200
@@ -1533,7 +1533,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hmp7100_defconfig b/arch/sh/configs/hmp7100_defconfig
--- a/arch/sh/configs/hmp7100_defconfig	2013-11-01 20:19:18.265926556 +0200
+++ b/arch/sh/configs/hmp7100_defconfig	2013-11-01 18:44:45.945799037 +0200
@@ -1509,7 +1509,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hmp7105_defconfig b/arch/sh/configs/hmp7105_defconfig
--- a/arch/sh/configs/hmp7105_defconfig	2013-11-01 20:19:18.269926573 +0200
+++ b/arch/sh/configs/hmp7105_defconfig	2013-11-01 18:44:45.949799059 +0200
@@ -1598,7 +1598,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/hms1_defconfig b/arch/sh/configs/hms1_defconfig
--- a/arch/sh/configs/hms1_defconfig	2013-11-01 20:19:18.273926595 +0200
+++ b/arch/sh/configs/hms1_defconfig	2013-11-01 18:44:45.949799059 +0200
@@ -1481,7 +1481,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/iptv7105_defconfig b/arch/sh/configs/iptv7105_defconfig
--- a/arch/sh/configs/iptv7105_defconfig	2013-11-01 20:19:18.277926622 +0200
+++ b/arch/sh/configs/iptv7105_defconfig	2013-11-01 18:44:45.949799059 +0200
@@ -1475,7 +1475,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb411_defconfig b/arch/sh/configs/mb411_defconfig
--- a/arch/sh/configs/mb411_defconfig	2013-11-01 20:19:18.277926622 +0200
+++ b/arch/sh/configs/mb411_defconfig	2013-11-01 18:44:45.953799086 +0200
@@ -1317,7 +1317,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb442_defconfig b/arch/sh/configs/mb442_defconfig
--- a/arch/sh/configs/mb442_defconfig	2013-11-01 20:19:18.281926636 +0200
+++ b/arch/sh/configs/mb442_defconfig	2013-11-01 18:44:45.953799086 +0200
@@ -1593,7 +1593,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb448_defconfig b/arch/sh/configs/mb448_defconfig
--- a/arch/sh/configs/mb448_defconfig	2013-11-01 20:19:18.285926654 +0200
+++ b/arch/sh/configs/mb448_defconfig	2013-11-01 18:44:45.953799086 +0200
@@ -1314,7 +1314,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb519_mb520_defconfig b/arch/sh/configs/mb519_mb520_defconfig
--- a/arch/sh/configs/mb519_mb520_defconfig	2013-11-01 20:19:18.289926674 +0200
+++ b/arch/sh/configs/mb519_mb520_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1383,7 +1383,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb602_defconfig b/arch/sh/configs/mb602_defconfig
--- a/arch/sh/configs/mb602_defconfig	2013-11-01 20:19:18.293926700 +0200
+++ b/arch/sh/configs/mb602_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1678,7 +1678,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb618_defconfig b/arch/sh/configs/mb618_defconfig
--- a/arch/sh/configs/mb618_defconfig	2013-11-01 20:19:18.297926711 +0200
+++ b/arch/sh/configs/mb618_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1639,7 +1639,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb628_defconfig b/arch/sh/configs/mb628_defconfig
--- a/arch/sh/configs/mb628_defconfig	2013-11-01 20:19:18.297926711 +0200
+++ b/arch/sh/configs/mb628_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1611,7 +1611,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb671_defconfig b/arch/sh/configs/mb671_defconfig
--- a/arch/sh/configs/mb671_defconfig	2013-11-01 20:19:18.301926732 +0200
+++ b/arch/sh/configs/mb671_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1598,7 +1598,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb680_defconfig b/arch/sh/configs/mb680_defconfig
--- a/arch/sh/configs/mb680_defconfig	2013-11-01 20:19:18.305926760 +0200
+++ b/arch/sh/configs/mb680_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1636,7 +1636,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb704_defconfig b/arch/sh/configs/mb704_defconfig
--- a/arch/sh/configs/mb704_defconfig	2013-11-01 20:19:18.309926775 +0200
+++ b/arch/sh/configs/mb704_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1453,7 +1453,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb796_defconfig b/arch/sh/configs/mb796_defconfig
--- a/arch/sh/configs/mb796_defconfig	2013-11-01 20:19:18.313926795 +0200
+++ b/arch/sh/configs/mb796_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1343,7 +1343,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb837_defconfig b/arch/sh/configs/mb837_defconfig
--- a/arch/sh/configs/mb837_defconfig	2013-11-01 20:19:18.317926820 +0200
+++ b/arch/sh/configs/mb837_defconfig	2013-11-01 18:44:45.957799099 +0200
@@ -1532,7 +1532,7 @@
 # CONFIG_LIBCRC32C is not set
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/mb839_defconfig b/arch/sh/configs/mb839_defconfig
--- a/arch/sh/configs/mb839_defconfig	2013-11-01 20:19:18.317926820 +0200
+++ b/arch/sh/configs/mb839_defconfig	2013-11-01 18:44:45.961799116 +0200
@@ -1453,7 +1453,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/ngb7167_defconfig b/arch/sh/configs/ngb7167_defconfig
--- a/arch/sh/configs/ngb7167_defconfig	2013-11-01 20:19:18.325926849 +0200
+++ b/arch/sh/configs/ngb7167_defconfig	2013-11-01 18:44:45.961799116 +0200
@@ -1637,7 +1637,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/configs/sat7111_defconfig b/arch/sh/configs/sat7111_defconfig
--- a/arch/sh/configs/sat7111_defconfig	2013-11-01 20:19:18.329926878 +0200
+++ b/arch/sh/configs/sat7111_defconfig	2013-11-01 18:44:45.965799138 +0200
@@ -1449,7 +1449,7 @@
 CONFIG_ZLIB_INFLATE=y
 CONFIG_ZLIB_DEFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
-CONFIG_LIBELF=y
+CONFIG_LIBELF_32=y
 CONFIG_HAS_IOMEM=y
 CONFIG_HAS_IOPORT=y
 CONFIG_HAS_DMA=y
diff -Naur a/arch/sh/include/asm/restart.h b/arch/sh/include/asm/restart.h
--- a/arch/sh/include/asm/restart.h	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/include/asm/restart.h	2013-11-01 18:44:46.017799397 +0200
@@ -0,0 +1,17 @@
+#ifndef _ASM_SH_RESTART_H
+#define _ASM_SH_RESTART_H
+
+#ifdef __KERNEL__
+
+#include <linux/list.h>
+
+struct restart_prep_handler {
+	struct list_head list;
+	void (*prepare_restart)(void);
+};
+
+/* Register a function to be run immediately before a restart. */
+void register_prepare_restart_handler(void (*prepare_restart)(void));
+
+#endif /* __KERNEL__ */
+#endif /* _ASM_SH_RESTART_H */
diff -Naur a/arch/sh/include/asm/sections.h b/arch/sh/include/asm/sections.h
--- a/arch/sh/include/asm/sections.h	2013-11-01 20:19:18.357927018 +0200
+++ b/arch/sh/include/asm/sections.h	2013-11-01 18:44:46.017799397 +0200
@@ -5,7 +5,7 @@
 
 extern long __nosave_begin, __nosave_end;
 extern long __machvec_start, __machvec_end;
-extern char __uncached_start, __uncached_end;
+extern char __uncached_start[], __uncached_end[];
 extern char _ebss[];
 extern char __start_eh_frame[], __stop_eh_frame[];
 
diff -Naur a/arch/sh/Kconfig.debug b/arch/sh/Kconfig.debug
--- a/arch/sh/Kconfig.debug	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/sh/Kconfig.debug	2013-11-01 18:44:45.845798542 +0200
@@ -140,4 +140,13 @@
 	depends on SUPERH32
 	depends on STACK_DEBUG || FUNCTION_TRACER
 
+config COUNT_EXCEPTIONS
+	bool "Count all exceptions"
+	depends on CPU_SH4
+	default n
+	help
+	  Add additional code to the exception handling path to count
+	  the number of every exception type. The output is visible
+	  in /sys/kernel/debug/sh/exceptions.
+
 endmenu
diff -Naur a/arch/sh/kernel/cpu/irq/ilc3.c b/arch/sh/kernel/cpu/irq/ilc3.c
--- a/arch/sh/kernel/cpu/irq/ilc3.c	2013-11-01 20:19:18.389927177 +0200
+++ b/arch/sh/kernel/cpu/irq/ilc3.c	2013-11-01 18:44:46.329800940 +0200
@@ -617,6 +617,16 @@
 #define ilc_restore		NULL
 #endif
 
+static int ilc_suspend(void)
+{
+	struct irq_desc *desc;
+	int irq;
+	for_each_irq_desc(irq, desc)
+		if (desc->status & IRQ_WAKEUP && desc->chip == &ilc_chip)
+			unmask_ilc_irq(irq);
+	return 0;
+}
+
 static struct stm_system stm_ilc_system = {
 	.name = "ilc3",
 	.priority = 0x1000, /* higher enough to be restored after:
@@ -624,6 +634,7 @@
 			     * - sysconf
 			     * - gpio
 			     */
+	.suspend = ilc_suspend,
 	.restore = ilc_restore,
 };
 
diff -Naur a/arch/sh/kernel/cpu/sh4/count_exceptions.c b/arch/sh/kernel/cpu/sh4/count_exceptions.c
--- a/arch/sh/kernel/cpu/sh4/count_exceptions.c	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/kernel/cpu/sh4/count_exceptions.c	2013-11-01 18:44:46.345801022 +0200
@@ -0,0 +1,94 @@
+/*
+ * Support functions when CONFIG_COUNT_EXCEPTIONS is enabled.
+ *
+ * Copyright (C) 2013 STMicroelectronics Ltd.
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <asm/processor.h>
+#include <asm/uaccess.h>
+#include <asm/cache.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#define NR_EXCEPTIONS ((0x820/0x20)+1)
+
+unsigned long exception_count_table[NR_EXCEPTIONS];
+unsigned long exception_count_table2[NR_EXCEPTIONS];
+
+static char *exception_names[16] = {
+	"POR", "Man reset", "TLB miss (r)", "TLB miss (w)",
+	"Init page wr", "TLB prot (r)", "TLB prot (w)", "Addr err (r)",
+	"Addr err (w)", "FPU", "TLB multi-hit", "TRAPA",
+	"Illegal instr", "Slot illegal", "NMI", "User break"
+};
+
+static int exceptions_seq_show(struct seq_file *file, void *iter)
+{
+	int i;
+	char buf[10];
+	char *name;
+
+	seq_printf(file, "EXPEVT %10s %10s %10s\n", "Total", "asm", "C");
+	for (i = 0; i < NR_EXCEPTIONS; i++) {
+		if (exception_count_table[i] == 0)
+			continue;
+
+		if (i < 16) {
+			name = exception_names[i];
+		} else if (i == (0x800/32)) {
+			name = "FPU disabled";
+		} else if (i == (0x820/32)) {
+			name = "FPU disabled (slot)";
+		} else {
+			sprintf(buf, "IRQ %3d", i-16);
+			name = buf;
+		}
+
+		if (exception_count_table2[i])
+			seq_printf(file, "0x%03x: %10lu %10lu %10lu %s\n",
+				   i*32,
+				   exception_count_table2[i],
+				   exception_count_table2[i] -
+					exception_count_table[i],
+				   exception_count_table[i], name);
+		else
+			seq_printf(file, "0x%03x: %10lu %10s %10s %s\n",
+				   i*32,
+				   exception_count_table[i], "", "", name);
+	}
+
+	return 0;
+}
+
+static int exceptions_debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, exceptions_seq_show, inode->i_private);
+}
+
+static const struct file_operations exceptions_debugfs_fops = {
+	.owner		= THIS_MODULE,
+	.open		= exceptions_debugfs_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int __init exceptions_debugfs_init(void)
+{
+	struct dentry *dentry;
+
+	dentry = debugfs_create_file("exceptions", S_IRUSR, sh_debugfs_root,
+				     NULL, &exceptions_debugfs_fops);
+	if (!dentry)
+		return -ENOMEM;
+
+	return IS_ERR(dentry) ? PTR_ERR(dentry) : 0;
+}
+module_init(exceptions_debugfs_init);
diff -Naur a/arch/sh/kernel/cpu/sh4/entry.S b/arch/sh/kernel/cpu/sh4/entry.S
--- a/arch/sh/kernel/cpu/sh4/entry.S	2013-11-01 20:19:18.405927257 +0200
+++ b/arch/sh/kernel/cpu/sh4/entry.S	2013-11-01 18:44:46.345801022 +0200
@@ -247,7 +247,7 @@
 	shlr2	r8
 	shlr	r8
 
-#ifdef COUNT_EXCEPTIONS
+#ifdef CONFIG_COUNT_EXCEPTIONS
 	mov.l	3f, r9
 	add	r8, r9
 	mov.l	@r9, r10
@@ -266,7 +266,7 @@
 	.balign	32 /* d-cache align to only one line */
 1:	.long	EXPEVT
 2:	.long	ret_from_exception
-#ifdef COUNT_EXCEPTIONS
+#ifdef CONFIG_COUNT_EXCEPTIONS
 3:	.long	exception_count_table
 #endif
 998: 	.long	0x000080f0
@@ -289,9 +289,14 @@
 
 	.balign 	1024,0,1024
 tlb_miss:
-#ifdef COUNT_EXCEPTIONS
+#ifdef CONFIG_COUNT_EXCEPTIONS
 	! Increment the counts
+	mov.l	11f, k2
+	mov.l	@k2, k2
+	shlr2	k2
+	shlr	k2
 	mov.l	9f, k1
+	add	k2, k1
 	mov.l	@k1, k2
 	add	#1, k2
 	mov.l	k2, @k1
@@ -439,8 +444,9 @@
 5:	.long	_PAGE_PRESENT
 7:	.long	_PAGE_FLAGS_HARDWARE_MASK
 8:	.long	MMU_PTEH
-#ifdef COUNT_EXCEPTIONS
-9:	.long	exception_count_miss
+#ifdef CONFIG_COUNT_EXCEPTIONS
+9:	.long	exception_count_table2
+11:	.long	EXPEVT
 #endif
 
 	.balign 	512,0,512
diff -Naur a/arch/sh/kernel/cpu/sh4/hom-stx7108.c b/arch/sh/kernel/cpu/sh4/hom-stx7108.c
--- a/arch/sh/kernel/cpu/sh4/hom-stx7108.c	2013-11-01 20:19:18.409927269 +0200
+++ b/arch/sh/kernel/cpu/sh4/hom-stx7108.c	2013-11-01 18:44:46.345801022 +0200
@@ -186,3 +186,22 @@
 }
 
 module_init(hom_stx7108_setup);
+
+int platform_allow_pm_sysconf(struct device *dev, int reg_nr, int freezing)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	/*
+	 * Don't save and restore SYSCFG Bank0 SYSTEM_CONFIG0
+	 * "CPUs soft reset register" as this may cause the slave processors
+	 * for example the ST40 RT to reboot.
+	 */
+
+	if (pdev->id != 0)
+		return 1;
+
+	if (reg_nr != 4)
+		return 1;
+
+	return 0;
+}
diff -Naur a/arch/sh/kernel/cpu/sh4/Makefile b/arch/sh/kernel/cpu/sh4/Makefile
--- a/arch/sh/kernel/cpu/sh4/Makefile	2013-11-01 20:19:18.389927177 +0200
+++ b/arch/sh/kernel/cpu/sh4/Makefile	2013-11-01 18:44:46.341801004 +0200
@@ -4,9 +4,12 @@
 
 obj-y	:= probe.o common.o
 common-y	+= entry.o
+obj-$(CONFIG_COUNT_EXCEPTIONS)		+= count_exceptions.o
 
 swsusp-y				:= $(addprefix ../sh3/, swsusp.o)
+swsusp-$(CONFIG_CPU_SUBTYPE_STXH205)	+= swsusp-stxh205.o
 obj-$(CONFIG_HIBERNATION)		+= swsusp.o
+
 obj-$(CONFIG_SH_FPU)			+= fpu.o softfloat.o
 obj-$(CONFIG_SH_STORE_QUEUES)		+= sq.o
 
diff -Naur a/arch/sh/kernel/cpu/sh4/setup-stx7105.c b/arch/sh/kernel/cpu/sh4/setup-stx7105.c
--- a/arch/sh/kernel/cpu/sh4/setup-stx7105.c	2013-11-01 20:19:18.421927328 +0200
+++ b/arch/sh/kernel/cpu/sh4/setup-stx7105.c	2013-11-01 18:44:46.349801042 +0200
@@ -15,6 +15,8 @@
 #include <linux/stm/stx7105.h>
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
+#include <asm/restart.h>
+#include <linux/clk.h>
 
 
 
@@ -61,7 +63,49 @@
 }
 core_initcall(stx7105_sh4_devices_setup);
 
+/* Warm reboot --------------------------------------------------------- */
 
+void stx7105_prepare_restart(void)
+{
+	struct sysconf_field *sc1;
+	struct sysconf_field *sc2;
+	struct clk *sys_clk = NULL;
+	struct clk *osc_clk = NULL;
+
+	/* Ensure the reset period is short and that the reset is not masked */
+	sc1 = sysconf_claim(SYS_CFG, 9, 29, 29, "kernel");
+	sc2 = sysconf_claim(SYS_CFG, 9, 0, 25, "kernel");
+	sysconf_write(sc1, 0x0);
+	sysconf_write(sc2, 0x00000a8c);
+
+	/* Slow the EMI clock down. This clock is used to drive serial flash
+	 * at boot time, and some larger flash parts need to be driven as
+	 * slowly as 20MHz. Note that the SPI boot clock divider is reset to
+	 * 2 on watchdog reset. */
+	sys_clk = clk_get(NULL, "CLKA_EMI_MASTER");
+	osc_clk = clk_get(NULL, "CLKA_REF");
+	clk_set_parent(sys_clk, osc_clk);
+	clk_set_rate(sys_clk, clk_get_rate(osc_clk));
+}
+
+static int __init stx7105_reset_init(void)
+{
+	struct sysconf_field *sc;
+
+	/* Set the reset chain correctly */
+	sc = sysconf_claim(SYS_CFG, 9, 27, 28, "reset_chain");
+	sysconf_write(sc, 0);
+
+	/* Release the sysconf bits so the coprocessor driver can claim them */
+	sysconf_release(sc);
+
+	/* Add stx_7105_prepare_restart to the list of functions to be called
+	 * immediately before a warm reboot. */
+	register_prepare_restart_handler(stx7105_prepare_restart);
+
+	return 0;
+}
+arch_initcall(stx7105_reset_init);
 
 /* Interrupt initialisation ----------------------------------------------- */
 
diff -Naur a/arch/sh/kernel/cpu/sh4/setup-stxh205.c b/arch/sh/kernel/cpu/sh4/setup-stxh205.c
--- a/arch/sh/kernel/cpu/sh4/setup-stxh205.c	2013-11-01 20:19:18.425927349 +0200
+++ b/arch/sh/kernel/cpu/sh4/setup-stxh205.c	2013-11-01 18:44:46.353801068 +0200
@@ -15,6 +15,7 @@
 #include <linux/stm/stxh205.h>
 #include <linux/stm/sysconf.h>
 #include <asm/irq-ilc.h>
+#include <asm/restart.h>
 
 /* SH4-only resources ----------------------------------------------------- */
 
@@ -58,7 +59,26 @@
 }
 core_initcall(stxh205_sh4_devices_setup);
 
+/* Warm reboot --------------------------------------------------------- */
 
+void stxh205_prepare_restart(void)
+{
+	struct sysconf_field *sc;
+
+	sc = sysconf_claim(SYSCONF(498), 0, 0, "reset");
+	sysconf_write(sc, 0);
+
+	sc = sysconf_claim(SYSCONF(475), 2, 2, "reset");
+	sysconf_write(sc, 0);
+}
+
+static int __init stxh205_reset_init(void)
+{
+	register_prepare_restart_handler(stxh205_prepare_restart);
+
+	return 0;
+}
+arch_initcall(stxh205_reset_init);
 
 /* Interrupt initialisation ----------------------------------------------- */
 
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-fli75xx.c b/arch/sh/kernel/cpu/sh4/suspend-fli75xx.c
--- a/arch/sh/kernel/cpu/sh4/suspend-fli75xx.c	2013-11-01 20:19:18.433927389 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-fli75xx.c	2013-11-01 18:44:46.353801068 +0200
@@ -228,7 +228,7 @@
 	cfg_1 &= ~(0x3 << (2 * CLKA_IC_200_ID));
 
 #if 0
-	if (wkd.eth_phy_can_wakeup) {
+	if (wkd.stm_mac0_can_wakeup) {
 		/* Pll_0 on */
 		pwr &= ~1;
 		/* eth_phy_clk under pll0 */
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-stx5206.c b/arch/sh/kernel/cpu/sh4/suspend-stx5206.c
--- a/arch/sh/kernel/cpu/sh4/suspend-stx5206.c	2013-11-01 20:19:18.437927406 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-stx5206.c	2013-11-01 18:44:46.357801078 +0200
@@ -240,7 +240,7 @@
 		cfg_0 &=  ~(0x3 << (2 * CLKA_IC_IF_100_ID));
 		cfg_0 |= (0x2 << (2 * CLKA_IC_IF_100_ID));
 	}
-	if (wkd.eth_phy_can_wakeup) {
+	if (wkd.stm_mac0_can_wakeup) {
 		unsigned long pll_id;
 		/* identify the eth_phy_clk parent */
 		pll_id = (clk_get_parent(ca_eth_phy_clk) == ca_pll1_clk) ?
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-stx7105.c b/arch/sh/kernel/cpu/sh4/suspend-stx7105.c
--- a/arch/sh/kernel/cpu/sh4/suspend-stx7105.c	2013-11-01 20:19:18.441927428 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-stx7105.c	2013-11-01 18:44:46.357801078 +0200
@@ -234,7 +234,7 @@
 	iowrite32(0xfffff0ff, cga + CKGA_CLKOPSRC_SWITCH_CFG(0));
 	iowrite32(0x3, cga + CKGA_CLKOPSRC_SWITCH_CFG(1));
 
-	if (wkd.hdmi_can_wakeup || wkd.eth_phy_can_wakeup) {
+	if (wkd.hdmi_can_wakeup || wkd.stm_mac0_can_wakeup) {
 		unsigned long pwr = 0x3; /* Plls Off */
 		unsigned long cfg = 0xfffff0ff;
 
@@ -246,7 +246,7 @@
 			cfg &= ~(0x3 << (2 * CLKA_IC_IF_100_ID));
 			cfg |= (0x2 << (2 * CLKA_IC_IF_100_ID));
 		}
-		if (wkd.eth_phy_can_wakeup) {
+		if (wkd.stm_mac0_can_wakeup) {
 			unsigned long pll_id;
 			/* identify the eth_phy_clk parent */
 			pll_id = (clk_get_parent(ca_eth_phy_clk) ==
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-stx7108.c b/arch/sh/kernel/cpu/sh4/suspend-stx7108.c
--- a/arch/sh/kernel/cpu/sh4/suspend-stx7108.c	2013-11-01 20:19:18.441927428 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-stx7108.c	2013-11-01 18:44:46.357801078 +0200
@@ -259,7 +259,7 @@
 	 * as we don't care about the actual frequency as long as it has a
 	 * clock.
 	 */
-	if (wkd.eth1_phy_can_wakeup) {
+	if (wkd.stm_mac1_can_wakeup) {
 		unsigned long pll_id;
 		/* identify the eth_phy_clk parent */
 		pll_id = (clk_get_parent(ca0_eth_phy_clk) == ca0_pll1_clk) ?
@@ -272,7 +272,7 @@
 	}
 
 	iowrite32(cfg_a0_0, cga0 + CKGA_CLKOPSRC_SWITCH_CFG);
-	iowrite32(0xF3FFFFFF, cga1 + CKGA_CLKOPSRC_SWITCH_CFG);
+	iowrite32(0xF0FFFFFF, cga1 + CKGA_CLKOPSRC_SWITCH_CFG);
 
 	if (state == PM_SUSPEND_MEM) {
 		/* all the clocks off */
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-stx7111.c b/arch/sh/kernel/cpu/sh4/suspend-stx7111.c
--- a/arch/sh/kernel/cpu/sh4/suspend-stx7111.c	2013-11-01 20:19:18.445927455 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-stx7111.c	2013-11-01 18:44:46.357801078 +0200
@@ -232,7 +232,7 @@
 	cfg_1 = 0xf;
 	cfg_1 &= ~(0x3 << (2 * (CLKA_IC_IF_200_ID - 16)));
 
-	if (wkd.eth_phy_can_wakeup) {
+	if (wkd.stm_mac0_can_wakeup) {
 		unsigned long pll_id;
 
 		/* identify the eth_phy_clk */
diff -Naur a/arch/sh/kernel/cpu/sh4/suspend-stxh205.c b/arch/sh/kernel/cpu/sh4/suspend-stxh205.c
--- a/arch/sh/kernel/cpu/sh4/suspend-stxh205.c	2013-11-01 20:19:18.449927469 +0200
+++ b/arch/sh/kernel/cpu/sh4/suspend-stxh205.c	2013-11-01 18:44:46.361801099 +0200
@@ -154,7 +154,7 @@
 
 on_suspending:
 
-	cfg_0_0 = 0xf00fffcc;
+	cfg_0_0 = 0xc00fffcc;
 	cfg_0_1 = 0x3ffff;
 	cfg_1_0 = 0xffffffff;
 	cfg_1_1 = 0xfffffff;
@@ -182,7 +182,7 @@
 	 * - eth.phy_clk and eth1.mac_clk enabled
 	 * - eth.phy_clk @ 25 MHz
 	 */
-	if (stxh205_wkd.eth_phy_can_wakeup) {
+	if (stxh205_wkd.stm_mac0_can_wakeup) {
 		int pll_id = (a1_pll1_ls_clk == clk_get_parent(a1_eth_phy_clk) ?
 			2 : 1);
 		cfg_1_0 &= ~(0x3 << (CLK_A1_ETH_PHY * 2));
@@ -191,6 +191,14 @@
 		cfg_1_0 |= (pll_id << (CLK_A1_GMAC * 2));
 		pwr_1 &= ~pll_id;
 	}
+	/* WoL+ is supported so the MAC clk can be disabled */
+	if (stxh205_wkd.stm_phy_can_wakeup) {
+		int pll_id = (a1_pll1_ls_clk == clk_get_parent(a1_eth_phy_clk) ?
+			2 : 1);
+		cfg_1_0 &= ~(0x3 << (CLK_A1_ETH_PHY * 2));
+		cfg_1_0 |= (pll_id << (CLK_A1_ETH_PHY * 2));
+		pwr_1 &= ~pll_id;
+	}
 
 /*
  * The DDR subsystem uses an clock-channel coming direclty from A1.
diff -Naur a/arch/sh/kernel/cpu/sh4/swsusp-stxh205.c b/arch/sh/kernel/cpu/sh4/swsusp-stxh205.c
--- a/arch/sh/kernel/cpu/sh4/swsusp-stxh205.c	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/sh/kernel/cpu/sh4/swsusp-stxh205.c	2013-11-01 18:44:46.361801099 +0200
@@ -0,0 +1,25 @@
+/*
+ * -------------------------------------------------------------------------
+ * Copyright (C) 2012  STMicroelectronics
+ * Author: Francesco M. Virlinzi  <francesco.virlinzi@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public
+ * License V.2 ONLY.  See linux/COPYING for more information.
+ *
+ * -------------------------------------------------------------------------
+ */
+
+#include <linux/device.h>
+#include <linux/platform_device.h>
+
+int platform_allow_pm_sysconf(struct device *dev,
+	int reg_nr, int freezing)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+
+	if (pdev->id != 4)
+		return 1;
+	if (reg_nr < (2 * sizeof(long)))
+		return 1;
+	return 0;
+}
diff -Naur a/arch/sh/kernel/kptrace.c b/arch/sh/kernel/kptrace.c
--- a/arch/sh/kernel/kptrace.c	2013-11-01 20:19:18.461927534 +0200
+++ b/arch/sh/kernel/kptrace.c	2013-11-01 18:44:46.401801301 +0200
@@ -97,8 +97,11 @@
 static size_t dropped;
 static size_t subbuf_size = 262144;
 static size_t n_subbufs = 4;
+static size_t overwrite_subbufs;
 #define KPTRACE_MAXSUBBUFSIZE 16777216
 #define KPTRACE_MAXSUBBUFS 256
+#define MAX_BUFFER_FULL_WARNINGS 10
+static int buffer_full_warning_ratelimit = MAX_BUFFER_FULL_WARNINGS;
 
 /* channel-management control files */
 static struct dentry *enabled_control;
@@ -106,19 +109,21 @@
 static struct dentry *subbuf_size_control;
 static struct dentry *n_subbufs_control;
 static struct dentry *dropped_control;
+static struct dentry *overwrite_control;
 
 /* produced/consumed control files */
 static struct dentry *produced_control;
 static struct dentry *consumed_control;
 
 /* control file fileop declarations */
-static struct file_operations enabled_fops;
-static struct file_operations create_fops;
-static struct file_operations subbuf_size_fops;
-static struct file_operations n_subbufs_fops;
-static struct file_operations dropped_fops;
-static struct file_operations produced_fops;
-static struct file_operations consumed_fops;
+static const struct file_operations enabled_fops;
+static const struct file_operations create_fops;
+static const struct file_operations subbuf_size_fops;
+static const struct file_operations n_subbufs_fops;
+static const struct file_operations dropped_fops;
+static const struct file_operations overwrite_fops;
+static const struct file_operations produced_fops;
+static const struct file_operations consumed_fops;
 
 /* forward declarations */
 static int create_controls(void);
@@ -774,6 +779,8 @@
 		}
 	}
 
+	buffer_full_warning_ratelimit = MAX_BUFFER_FULL_WARNINGS;
+
 	logging = 1;
 }
 
@@ -2287,6 +2294,16 @@
 
 /*
  * subbuf_start() relay callback.
+ *
+ * If all the sub-buffers are full, we don't overwrite them - no
+ * more trace is recorded until userspace has consumed some of the
+ * existing sub-buffers. The exception is in flight-recorder mode, where
+ * the whole point is that nothing is consumed until the end.
+ *
+ * We printk a warning if the buffer is full, as trace data is being lost
+ * (and a larger buffer would prevent it). Those messages can be frequent if
+ * the buffer fills, so we limit the number of warnings emitted per trace
+ * session.
  */
 static int subbuf_start_handler(struct rchan_buf *buf,
 				void *subbuf,
@@ -2295,6 +2312,18 @@
 	if (prev_subbuf)
 		*((unsigned *)prev_subbuf) = prev_padding;
 
+	if (!overwrite_subbufs && relay_buf_full(buf)) {
+		if (buffer_full_warning_ratelimit) {
+			printk(KERN_WARNING "kptrace: trace buffer full. "
+				"Consider increasing the buffer size.\n");
+			buffer_full_warning_ratelimit--;
+			if (!buffer_full_warning_ratelimit)
+				printk(KERN_WARNING "kptrace: disabling "
+						"buffer full warnings.\n");
+		}
+		return 0;
+	}
+
 	subbuf_start_reserve(buf, sizeof(unsigned int));
 
 	return 1;
@@ -2403,6 +2432,9 @@
 
 	if (dropped_control)
 		debugfs_remove(dropped_control);
+
+	if (overwrite_control)
+		debugfs_remove(overwrite_control);
 }
 
 /**
@@ -2448,6 +2480,14 @@
 		goto fail;
 	}
 
+	overwrite_control = debugfs_create_file("overwrite", 0, dir,
+					      NULL, &overwrite_fops);
+	if (!overwrite_control) {
+		printk(KERN_WARNING "Couldn't create relay control "
+					"file 'overwrite'.\n");
+		goto fail;
+	}
+
 	return 1;
 fail:
 	remove_controls();
@@ -2506,7 +2546,7 @@
  *
  *  toggles logging to the relay channel
  */
-static struct file_operations enabled_fops = {
+static const struct file_operations enabled_fops = {
 	.owner = THIS_MODULE,
 	.read = enabled_read,
 	.write = enabled_write,
@@ -2557,7 +2597,7 @@
  *
  *  creates/destroys the relay channel
  */
-static struct file_operations create_fops = {
+static const struct file_operations create_fops = {
 	.owner = THIS_MODULE,
 	.read = create_read,
 	.write = create_write,
@@ -2603,7 +2643,7 @@
  *
  *  gets/sets the subbuffer size to use in channel creation
  */
-static struct file_operations subbuf_size_fops = {
+static const struct file_operations subbuf_size_fops = {
 	.owner = THIS_MODULE,
 	.read = subbuf_size_read,
 	.write = subbuf_size_write,
@@ -2649,7 +2689,7 @@
  *
  *  gets/sets the number of subbuffers to use in channel creation
  */
-static struct file_operations n_subbufs_fops = {
+static const struct file_operations n_subbufs_fops = {
 	.owner = THIS_MODULE,
 	.read = n_subbufs_read,
 	.write = n_subbufs_write,
@@ -2665,12 +2705,38 @@
 	return simple_read_from_buffer(buffer, count, ppos, buf, strlen(buf));
 }
 
+static ssize_t overwrite_write(struct file *filp, const char __user *buffer,
+			       size_t count, loff_t *ppos)
+{
+	char buf;
+
+	if (count > 1)
+		return -EINVAL;
+
+	if (copy_from_user(&buf, buffer, count))
+		return -EFAULT;
+
+	if (buf == '0')
+		overwrite_subbufs = 0;
+	else if (buf == '1')
+		overwrite_subbufs = 1;
+	else
+		return -EINVAL;
+
+	return count;
+}
+
+static const struct file_operations overwrite_fops = {
+	.owner = THIS_MODULE,
+	.write = overwrite_write,
+};
+
 /*
  * 'dropped' file operations - r
  *
  *  gets the number of dropped events seen
  */
-static struct file_operations dropped_fops = {
+static const struct file_operations dropped_fops = {
 	.owner = THIS_MODULE,
 	.read = dropped_read,
 };
@@ -2703,7 +2769,7 @@
  *  Reading a .produced file returns the number of sub-buffers so far
  *  produced for the associated relay buffer.
  */
-static struct file_operations produced_fops = {
+static const struct file_operations produced_fops = {
 	.owner = THIS_MODULE,
 	.open = produced_open,
 	.read = produced_read
@@ -2749,7 +2815,7 @@
  *  Reading a .consumed file returns the number of sub-buffers so far
  *  consumed for the associated relay buffer.
  */
-static struct file_operations consumed_fops = {
+static const struct file_operations consumed_fops = {
 	.owner = THIS_MODULE,
 	.open = consumed_open,
 	.read = consumed_read,
diff -Naur a/arch/sh/kernel/process_32.c b/arch/sh/kernel/process_32.c
--- a/arch/sh/kernel/process_32.c	2013-11-01 20:19:18.465927547 +0200
+++ b/arch/sh/kernel/process_32.c	2013-11-01 18:44:46.401801301 +0200
@@ -25,6 +25,7 @@
 #include <linux/fs.h>
 #include <linux/ftrace.h>
 #include <linux/preempt.h>
+#include <linux/list.h>
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/pgalloc.h>
@@ -34,6 +35,7 @@
 #include <asm/watchdog.h>
 #include <asm/syscalls.h>
 #include <asm/watchdog.h>
+#include <asm/restart.h>
 
 #ifdef CONFIG_CC_STACKPROTECTOR
 unsigned long __stack_chk_guard __read_mostly;
@@ -48,8 +50,30 @@
 	sh_wdt_write_csr(0xC2);
 }
 
+LIST_HEAD(restart_prep_handler_list);
+
+void register_prepare_restart_handler(void (*prepare_restart)(void))
+{
+	struct restart_prep_handler *s = (struct restart_prep_handler *)
+				kmalloc(sizeof(struct restart_prep_handler),
+				GFP_KERNEL);
+	s->prepare_restart = prepare_restart;
+	list_add(&(s->list), &(restart_prep_handler_list));
+}
+
 void machine_restart(char * __unused)
 {
+	struct restart_prep_handler *tmp;
+	struct list_head *pos, *q;
+
+	/* Run any "prepare restart" handlers */
+	list_for_each_safe(pos, q, &restart_prep_handler_list) {
+		tmp = list_entry(pos, struct restart_prep_handler, list);
+		tmp->prepare_restart();
+		list_del(pos);
+		kfree(tmp);
+	}
+
 	local_irq_disable();
 
 	/* Use watchdog timer to trigger reset */
diff -Naur a/arch/sh/Makefile b/arch/sh/Makefile
--- a/arch/sh/Makefile	2013-11-01 20:19:18.041925445 +0200
+++ b/arch/sh/Makefile	2013-11-01 18:44:45.845798542 +0200
@@ -160,6 +160,7 @@
 machdir-$(CONFIG_SH_ST_B2067)			+= mach-b2067
 machdir-$(CONFIG_SH_ST_B2068)			+= mach-b2068
 machdir-$(CONFIG_SH_ST_B2069)			+= mach-b2069
+machdir-$(CONFIG_SH_ST_B2075)			+= mach-b2075
 machdir-$(CONFIG_SH_ST_B2076)			+= mach-b2076
 machdir-$(CONFIG_SH_ST_CAB5197)			+= mach-cab5197
 machdir-$(CONFIG_SH_ST_EUD7141)			+= mach-eud7141
diff -Naur a/arch/sh/mm/Kconfig b/arch/sh/mm/Kconfig
--- a/arch/sh/mm/Kconfig	2013-11-01 20:19:18.473927584 +0200
+++ b/arch/sh/mm/Kconfig	2013-11-01 18:44:46.429801446 +0200
@@ -157,6 +157,22 @@
 	  fill in holes in the virtual address space when PMB_64M_TILES
 	  is enabled.
 
+config PMB_LARGE_UNCACHED_MAPPING
+	bool "Map all of kernel memory uncached using the PMB"
+	depends on PMB
+	help
+	  Normally when the kernel boots it maps the entire kernel logical
+	  memory region into the kernel's address space using the PMB.
+	  A small uncached region is also created to map some key functions
+	  which must be executed from uncached code. In some circumstances
+	  it might be useful to have this uncached region expanded to cover
+	  the entire kernel memory space, for example if the P1/P2 portion
+	  of the address space has very little free space, and it is known
+	  that this uncached mapping will be needed later.
+
+	  Note that on systems with more than 512MB kernel memory this will
+	  prevent the system booting, so should not be enabled.
+
 config X2TLB
 	bool "Enable extended TLB mode"
 	depends on (CPU_SHX2 || CPU_SHX3) && MMU && EXPERIMENTAL
diff -Naur a/arch/sh/mm/pmb.c b/arch/sh/mm/pmb.c
--- a/arch/sh/mm/pmb.c	2013-11-01 20:19:18.481927627 +0200
+++ b/arch/sh/mm/pmb.c	2013-11-01 18:44:46.437801478 +0200
@@ -94,6 +94,22 @@
 	return mk_pmb_entry(entry) | PMB_DATA;
 }
 
+static __always_inline unsigned long pmb_size(unsigned long data)
+{
+	switch(data & PMB_SZ_MASK) {
+	case PMB_SZ_16M:
+		return 16 * 1024 * 1024;
+	case PMB_SZ_64M:
+		return 64 * 1024 * 1024;
+	case PMB_SZ_128M:
+		return 128 * 1024 * 1024;
+	case PMB_SZ_512M:
+		return 512 * 1024 * 1024;
+	default:
+		return 0;
+	}
+}
+
 static __always_inline void __set_pmb_entry(unsigned long vpn,
 	unsigned long ppn, unsigned long flags, int pos)
 {
@@ -126,7 +142,8 @@
 	ctrl_barrier();
 	*vpn   = ctrl_inl(mk_pmb_addr(pos)) & PMB_VPN;
 	*ppn   = ctrl_inl(mk_pmb_data(pos)) & PMB_PPN;
-	*flags = ctrl_inl(mk_pmb_data(pos)) & (PMB_SZ_MASK|PMB_C|PMB_WT|PMB_UB);
+	*flags = ctrl_inl(mk_pmb_data(pos)) &
+	     (PMB_SZ_MASK|PMB_C|PMB_WT|PMB_UB|PMB_V);
 	ctrl_barrier();
 }
 
@@ -249,7 +266,7 @@
  * address which accomodates the mapping we're interested in.
  */
 static struct pmb_mapping* pmb_calc(unsigned long phys, unsigned long size,
-				    unsigned long req_virt, int *req_pos,
+				    unsigned long req_virt, int req_pos,
 				    unsigned long pmb_flags)
 {
 	struct pmb_mapping *new_mapping;
@@ -308,7 +325,8 @@
 
 	DPRINTK("found space at %08lx to %08lx\n", new_start, new_end);
 
-	BUG_ON(req_pos && (*req_pos != PMB_VIRT2POS(new_start)));
+	BUG_ON((req_pos != PMB_NO_ENTRY) &&
+	       (req_pos != PMB_VIRT2POS(new_start)));
 
 	phys &= ~(pmb_size - 1);
 	new_start &= ~(pmb_size - 1);
@@ -360,7 +378,7 @@
 };
 
 static struct pmb_mapping* pmb_calc(unsigned long phys, unsigned long size,
-				    unsigned long req_virt, int *req_pos,
+				    unsigned long req_virt, int req_pos,
 				    unsigned long pmb_flags)
 {
 	unsigned long orig_phys = phys;
@@ -417,7 +435,8 @@
 		if (entry == NULL) {
 			int pos;
 
-			pos = pmb_alloc(req_pos ? *req_pos++ : PMB_NO_ENTRY);
+			pos = pmb_alloc((req_pos != PMB_NO_ENTRY) ?
+					req_pos++ : PMB_NO_ENTRY);
 			if (pos == PMB_NO_ENTRY)
 				goto failed_give_up;
 			entry = &pmbe[pos];
@@ -588,7 +607,7 @@
 		write_unlock(&pmb_lock);
 		return 0;
 	} else {
-		mapping = pmb_calc(phys, size, 0, NULL, pmb_flags);
+		mapping = pmb_calc(phys, size, 0, PMB_NO_ENTRY, pmb_flags);
 		if (!mapping) {
 			write_unlock(&pmb_lock);
 			return 0;
@@ -652,10 +671,38 @@
 static void noinline __uses_jump_to_uncached
 apply_boot_mappings(struct pmb_mapping *uc_mapping, struct pmb_mapping *ram_mapping)
 {
-	register int i __asm__("r1");
-	register unsigned long c2uc __asm__("r2");
-	register struct pmb_entry *entry __asm__("r3");
-	register unsigned long flags __asm__("r4");
+	int i;
+	unsigned long c2uc;
+	struct pmb_entry *entry;
+	unsigned long flags;
+	unsigned int trash;
+
+	/*
+	 * We are currenly running with the mappings set up by the
+	 * boot loader. These may be excessive, so indentify the
+	 * minimum subset needed to map the kernel text uncached and
+	 * delete the rest.
+	 */
+	trash = 0;
+	for (i=0; i<NR_PMB_ENTRIES; i++) {
+		unsigned long addr, data;
+		unsigned int size;
+		char *start, *end;
+
+		addr = ctrl_inl(mk_pmb_addr(i));
+		data = ctrl_inl(mk_pmb_data(i));
+		if (! (addr & PMB_V))
+			continue;
+
+		size = pmb_size(data);
+		start = (char*)(addr & ~(size-1));
+		end = start + size;
+
+		if ((end <= __uncached_start) || (start >= __uncached_end))
+			__clear_pmb_entry(i);
+		else
+			trash |= 1<<i;
+	}
 
 	/* We can execute this directly, as the current PMB is uncached */
 	if (uc_mapping)
@@ -669,6 +716,7 @@
 		__ocbwb(((void *)pmbe) + i);
 
 	jump_to_uncached();
+	__asm__ __volatile__("add	%0, r15" : : "r"(cached_to_uncached));
 
 	/*
 	 * We have to be cautious here, as we will temporarily lose access to
@@ -681,8 +729,11 @@
 	entry = ram_mapping->entries;
 	flags = ram_mapping->flags;
 
-	for (i=0; i<NR_PMB_ENTRIES-1; i++)
+	for (i=0; i<NR_PMB_ENTRIES; i++) {
+		if (!(trash & (1<<i)))
+			continue;
 		__clear_pmb_entry(i);
+	}
 
 	do {
 		entry = (struct pmb_entry*)(((unsigned long)entry) + c2uc);
@@ -697,15 +748,36 @@
 	ctrl_outl(i, MMUCR);
 
 	back_to_cached();
+	__asm__ __volatile__("sub	%0, r15" : : "r"(cached_to_uncached));
 }
 
 struct pmb_mapping *uc_mapping, *ram_mapping
 	__attribute__ ((__section__ (".uncached.data")));
+unsigned int uc_stack[128]
+	__attribute__ ((__section__ (".uncached.data")));
+
+static void call_apply_boot_mappings(struct pmb_mapping *uc_mapping,
+		struct pmb_mapping *ram_mapping)
+{
+	register struct pmb_mapping *p1 asm("r4") = uc_mapping;
+	register struct pmb_mapping *p2 asm("r5") = ram_mapping;
+
+	asm volatile(
+		"mov	r15, r8;"
+		"jsr	@%1;"
+		" mov	%0, r15;"
+		"mov	r8, r15;"
+		:
+		: "r"(&uc_stack[ARRAY_SIZE(uc_stack)]),
+		  "r"(&apply_boot_mappings),
+		  "r"(p1), "r"(p2)
+		: "r0", "r1", "r2", "r3", "r8", "t");
+}
 
 void __init pmb_init(void)
 {
 	int i;
-	int entry;
+	struct pmb_entry *entry;
 	unsigned long uc_vpn, uc_ppn, uc_flags;
 	int uc_mapping_present;
 
@@ -720,10 +792,15 @@
 		pmbe[i].pos = i;
 
 	/* Create the initial mappings */
-	entry = NR_PMB_ENTRIES-1;
-	uc_mapping = pmb_calc(__pa(&__uncached_start), &__uncached_end - &__uncached_start,
-		 P3SEG-pmb_sizes[0].size, &entry, PMB_WT | PMB_UB);
-	ram_mapping = pmb_calc(__MEMORY_START, __MEMORY_SIZE, P1SEG, 0, PMB_C);
+#ifdef CONFIG_PMB_LARGE_UNCACHED_MAPPING
+	uc_mapping = pmb_calc(__MEMORY_START, __MEMORY_SIZE, P2SEG,
+			      8, PMB_WT | PMB_UB);
+#else
+	uc_mapping = pmb_calc(__pa(__uncached_start), __uncached_end - __uncached_start,
+		P3SEG-pmb_sizes[0].size, NR_PMB_ENTRIES-1, PMB_WT | PMB_UB);
+#endif
+	ram_mapping = pmb_calc(__MEMORY_START, __MEMORY_SIZE, P1SEG,
+			       PMB_NO_ENTRY, PMB_C);
 
 	/*
 	 * If we already have the uncached mapping there is no need to set
@@ -731,18 +808,21 @@
 	 * restarting after a kexec, and so the main ram mapping could be
 	 * cached, and it wouldn't be safe to manipulate the PMB directly.
 	 */
-	entry = NR_PMB_ENTRIES-1;
-	__get_pmb_entry(&uc_vpn, &uc_ppn, &uc_flags, entry);
-	uc_mapping_present = ((uc_mapping->virt == uc_vpn) &&
-	     (uc_mapping->phys == uc_ppn) &&
-	     (uc_mapping->flags == uc_flags));
+	uc_mapping_present = 1;
+	for (entry = uc_mapping->entries; entry; entry=entry->next) {
+	     __get_pmb_entry(&uc_vpn, &uc_ppn, &uc_flags, entry->pos);
+	     if (((entry->vpn != uc_vpn) ||
+		  (entry->ppn != uc_ppn) ||
+		  (entry->flags != uc_flags)))
+		  uc_mapping_present = 0;
+	}
 
 	cached_to_uncached = uc_mapping->virt -
 		(((unsigned long)&__uncached_start) &
 		 ~(uc_mapping->entries->size-1));
 
-	apply_boot_mappings(uc_mapping_present ? NULL : uc_mapping,
-			    ram_mapping);
+	call_apply_boot_mappings(uc_mapping_present ? NULL : uc_mapping,
+				 ram_mapping);
 }
 
 int pmb_virt_to_phys(void *addr, unsigned long *phys, unsigned long *flags)
@@ -790,22 +870,16 @@
 	for (i = 0; i < NR_PMB_ENTRIES; i++) {
 		unsigned long addr, data;
 		unsigned int size;
-		char *sz_str = NULL;
 
 		addr = ctrl_inl(mk_pmb_addr(i));
 		data = ctrl_inl(mk_pmb_data(i));
-
-		size = data & PMB_SZ_MASK;
-		sz_str = (size == PMB_SZ_16M)  ? " 16MB":
-			 (size == PMB_SZ_64M)  ? " 64MB":
-			 (size == PMB_SZ_128M) ? "128MB":
-					         "512MB";
+		size = pmb_size(data);
 
 		/* 02: V 0x88 0x08 128MB C CB  B */
-		seq_printf(file, "%02d: %c 0x%02lx 0x%02lx %s %c %s %s\n",
+		seq_printf(file, "%02d: %c 0x%02lx 0x%02lx %3dMB %c %s %s\n",
 			   i, ((addr & PMB_V) && (data & PMB_V)) ? 'V' : ' ',
 			   (addr >> 24) & 0xff, (data >> 24) & 0xff,
-			   sz_str, (data & PMB_C) ? 'C' : ' ',
+			   size/(1024*1024), (data & PMB_C) ? 'C' : ' ',
 			   (data & PMB_WT) ? "WT" : "CB",
 			   (data & PMB_UB) ? "UB" : " B");
 	}
@@ -887,7 +961,7 @@
 
 void __uses_jump_to_uncached stm_hom_pmb_init(void)
 {
-	apply_boot_mappings(uc_mapping, ram_mapping);
+	call_apply_boot_mappings(uc_mapping, ram_mapping);
 
 	/* Now I can call the pmb_sysdev_resume */
 	pmb_sysdev_suspend(NULL, PMSG_ON);
diff -Naur a/arch/sparc/include/asm/signal.h b/arch/sparc/include/asm/signal.h
--- a/arch/sparc/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/sparc/include/asm/signal.h	2013-11-01 18:44:46.497801773 +0200
@@ -191,6 +191,7 @@
 	unsigned long		sa_flags;
 	void			(*sa_restorer)(void);  /* not used by Linux/SPARC yet */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 typedef struct sigaltstack {
 	void			__user *ss_sp;
diff -Naur a/arch/sparc/kernel/ds.c b/arch/sparc/kernel/ds.c
--- a/arch/sparc/kernel/ds.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/sparc/kernel/ds.c	2013-11-01 18:44:46.521801892 +0200
@@ -1242,4 +1242,4 @@
 	return vio_register_driver(&ds_driver);
 }
 
-subsys_initcall(ds_init);
+fs_initcall(ds_init);
diff -Naur a/arch/sparc/kernel/rtrap_64.S b/arch/sparc/kernel/rtrap_64.S
--- a/arch/sparc/kernel/rtrap_64.S	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/sparc/kernel/rtrap_64.S	2013-11-01 18:44:46.577802179 +0200
@@ -20,11 +20,6 @@
 
 		.text
 		.align			32
-__handle_softirq:
-		call			do_softirq
-		 nop
-		ba,a,pt			%xcc, __handle_softirq_continue
-		 nop
 __handle_preemption:
 		call			schedule
 		 wrpr			%g0, RTRAP_PSTATE, %pstate
@@ -159,9 +154,7 @@
 		cmp			%l1, 0
 
 		/* mm/ultra.S:xcall_report_regs KNOWS about this load. */
-		bne,pn			%icc, __handle_softirq
 		 ldx			[%sp + PTREGS_OFF + PT_V9_TSTATE], %l1
-__handle_softirq_continue:
 rtrap_xcall:
 		sethi			%hi(0xf << 20), %l4
 		and			%l1, %l4, %l4
diff -Naur a/arch/sparc/Makefile b/arch/sparc/Makefile
--- a/arch/sparc/Makefile	2013-11-01 20:18:03.369555163 +0200
+++ b/arch/sparc/Makefile	2013-11-01 18:44:46.441801498 +0200
@@ -31,7 +31,7 @@
 
 #KBUILD_CFLAGS += -g -pipe -fcall-used-g5 -fcall-used-g7
 KBUILD_CFLAGS += -m32 -pipe -mno-fpu -fcall-used-g5 -fcall-used-g7
-KBUILD_AFLAGS += -m32
+KBUILD_AFLAGS += -m32 -Wa,-Av8
 
 #LDFLAGS_vmlinux = -N -Ttext 0xf0004000
 #  Since 2.5.40, the first stage is left not btfix-ed.
diff -Naur a/arch/x86/include/asm/archrandom.h b/arch/x86/include/asm/archrandom.h
--- a/arch/x86/include/asm/archrandom.h	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/x86/include/asm/archrandom.h	2013-11-01 18:44:47.073804633 +0200
@@ -0,0 +1,75 @@
+/*
+ * This file is part of the Linux kernel.
+ *
+ * Copyright (c) 2011, Intel Corporation
+ * Authors: Fenghua Yu <fenghua.yu@intel.com>,
+ *          H. Peter Anvin <hpa@linux.intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifndef ASM_X86_ARCHRANDOM_H
+#define ASM_X86_ARCHRANDOM_H
+
+#include <asm/processor.h>
+#include <asm/cpufeature.h>
+#include <asm/alternative.h>
+#include <asm/nops.h>
+
+#define RDRAND_RETRY_LOOPS	10
+
+#define RDRAND_INT	".byte 0x0f,0xc7,0xf0"
+#ifdef CONFIG_X86_64
+# define RDRAND_LONG	".byte 0x48,0x0f,0xc7,0xf0"
+#else
+# define RDRAND_LONG	RDRAND_INT
+#endif
+
+#ifdef CONFIG_ARCH_RANDOM
+
+#define GET_RANDOM(name, type, rdrand, nop)			\
+static inline int name(type *v)					\
+{								\
+	int ok;							\
+	alternative_io("movl $0, %0\n\t"			\
+		       nop,					\
+		       "\n1: " rdrand "\n\t"			\
+		       "jc 2f\n\t"				\
+		       "decl %0\n\t"                            \
+		       "jnz 1b\n\t"                             \
+		       "2:",                                    \
+		       X86_FEATURE_RDRAND,                      \
+		       ASM_OUTPUT2("=r" (ok), "=a" (*v)),       \
+		       "0" (RDRAND_RETRY_LOOPS));		\
+	return ok;						\
+}
+
+#ifdef CONFIG_X86_64
+
+GET_RANDOM(arch_get_random_long, unsigned long, RDRAND_LONG, ASM_NOP5);
+GET_RANDOM(arch_get_random_int, unsigned int, RDRAND_INT, ASM_NOP4);
+
+#else
+
+GET_RANDOM(arch_get_random_long, unsigned long, RDRAND_LONG, ASM_NOP3);
+GET_RANDOM(arch_get_random_int, unsigned int, RDRAND_INT, ASM_NOP3);
+
+#endif /* CONFIG_X86_64 */
+
+#endif  /* CONFIG_ARCH_RANDOM */
+
+extern void x86_init_rdrand(struct cpuinfo_x86 *c);
+
+#endif /* ASM_X86_ARCHRANDOM_H */
diff -Naur a/arch/x86/include/asm/cpufeature.h b/arch/x86/include/asm/cpufeature.h
--- a/arch/x86/include/asm/cpufeature.h	2013-11-01 20:18:03.477555699 +0200
+++ b/arch/x86/include/asm/cpufeature.h	2013-11-01 18:44:47.077804660 +0200
@@ -124,6 +124,8 @@
 #define X86_FEATURE_XSAVE	(4*32+26) /* XSAVE/XRSTOR/XSETBV/XGETBV */
 #define X86_FEATURE_OSXSAVE	(4*32+27) /* "" XSAVE enabled in the OS */
 #define X86_FEATURE_AVX		(4*32+28) /* Advanced Vector Extensions */
+#define X86_FEATURE_F16C	(4*32+29) /* 16-bit fp conversions */
+#define X86_FEATURE_RDRAND	(4*32+30) /* The RDRAND instruction */
 #define X86_FEATURE_HYPERVISOR	(4*32+31) /* Running on a hypervisor */
 
 /* VIA/Cyrix/Centaur-defined CPU features, CPUID level 0xC0000001, word 5 */
diff -Naur a/arch/x86/include/asm/k8.h b/arch/x86/include/asm/k8.h
--- a/arch/x86/include/asm/k8.h	2013-11-01 20:18:03.485555743 +0200
+++ b/arch/x86/include/asm/k8.h	2013-11-01 18:44:47.089804712 +0200
@@ -1,11 +1,13 @@
 #ifndef _ASM_X86_K8_H
 #define _ASM_X86_K8_H
 
+#include <linux/ioport.h>
 #include <linux/pci.h>
 
 extern struct pci_device_id k8_nb_ids[];
 
 extern int early_is_k8_nb(u32 value);
+extern struct resource *amd_get_mmconfig_range(struct resource *res);
 extern struct pci_dev **k8_northbridges;
 extern int num_k8_northbridges;
 extern int cache_k8_northbridges(void);
diff -Naur a/arch/x86/include/asm/kvm_emulate.h b/arch/x86/include/asm/kvm_emulate.h
--- a/arch/x86/include/asm/kvm_emulate.h	2013-11-01 20:18:03.485555743 +0200
+++ b/arch/x86/include/asm/kvm_emulate.h	2013-11-01 18:44:47.093804739 +0200
@@ -109,6 +109,8 @@
 				unsigned int bytes,
 				struct kvm_vcpu *vcpu);
 
+	bool (*get_cpuid)(struct x86_emulate_ctxt *ctxt,
+			 u32 *eax, u32 *ebx, u32 *ecx, u32 *edx);
 };
 
 /* Type, address-of, and value of an instruction's operand. */
@@ -190,6 +192,19 @@
 #define X86EMUL_MODE_HOST X86EMUL_MODE_PROT64
 #endif
 
+/* CPUID vendors */
+#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx 0x68747541
+#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx 0x444d4163
+#define X86EMUL_CPUID_VENDOR_AuthenticAMD_edx 0x69746e65
+
+#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx 0x69444d41
+#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx 0x21726574
+#define X86EMUL_CPUID_VENDOR_AMDisbetterI_edx 0x74656273
+
+#define X86EMUL_CPUID_VENDOR_GenuineIntel_ebx 0x756e6547
+#define X86EMUL_CPUID_VENDOR_GenuineIntel_ecx 0x6c65746e
+#define X86EMUL_CPUID_VENDOR_GenuineIntel_edx 0x49656e69
+
 int x86_decode_insn(struct x86_emulate_ctxt *ctxt,
 		    struct x86_emulate_ops *ops);
 int x86_emulate_insn(struct x86_emulate_ctxt *ctxt,
diff -Naur a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
--- a/arch/x86/include/asm/pgtable.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/include/asm/pgtable.h	2013-11-01 18:44:47.105804791 +0200
@@ -130,6 +130,11 @@
 	return (pmd_val(pmd) & PTE_PFN_MASK) >> PAGE_SHIFT;
 }
 
+static inline unsigned long pud_pfn(pud_t pud)
+{
+	return (pud_val(pud) & PTE_PFN_MASK) >> PAGE_SHIFT;
+}
+
 #define pte_page(pte)	pfn_to_page(pte_pfn(pte))
 
 static inline int pmd_large(pmd_t pte)
diff -Naur a/arch/x86/include/asm/ptrace.h b/arch/x86/include/asm/ptrace.h
--- a/arch/x86/include/asm/ptrace.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/include/asm/ptrace.h	2013-11-01 18:44:47.109804818 +0200
@@ -2,6 +2,7 @@
 #define _ASM_X86_PTRACE_H
 
 #include <linux/compiler.h>	/* For __user */
+#include <linux/linkage.h>	/* For asmregparm */
 #include <asm/ptrace-abi.h>
 #include <asm/processor-flags.h>
 
@@ -142,8 +143,8 @@
 			 int error_code, int si_code);
 void signal_fault(struct pt_regs *regs, void __user *frame, char *where);
 
-extern long syscall_trace_enter(struct pt_regs *);
-extern void syscall_trace_leave(struct pt_regs *);
+extern asmregparm long syscall_trace_enter(struct pt_regs *);
+extern asmregparm void syscall_trace_leave(struct pt_regs *);
 
 static inline unsigned long regs_return_value(struct pt_regs *regs)
 {
diff -Naur a/arch/x86/include/asm/signal.h b/arch/x86/include/asm/signal.h
--- a/arch/x86/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/include/asm/signal.h	2013-11-01 18:44:47.117804848 +0200
@@ -125,6 +125,8 @@
 extern void do_notify_resume(struct pt_regs *, void *, __u32);
 # endif /* __KERNEL__ */
 
+#define __ARCH_HAS_SA_RESTORER
+
 #ifdef __i386__
 # ifdef __KERNEL__
 struct old_sigaction {
diff -Naur a/arch/x86/include/asm/timer.h b/arch/x86/include/asm/timer.h
--- a/arch/x86/include/asm/timer.h	2013-11-01 20:18:03.497555806 +0200
+++ b/arch/x86/include/asm/timer.h	2013-11-01 18:44:47.121804871 +0200
@@ -63,14 +63,10 @@
 
 static inline unsigned long long __cycles_2_ns(unsigned long long cyc)
 {
-	unsigned long long quot;
-	unsigned long long rem;
 	int cpu = smp_processor_id();
 	unsigned long long ns = per_cpu(cyc2ns_offset, cpu);
-	quot = (cyc >> CYC2NS_SCALE_FACTOR);
-	rem = cyc & ((1ULL << CYC2NS_SCALE_FACTOR) - 1);
-	ns += quot * per_cpu(cyc2ns, cpu) +
-		((rem * per_cpu(cyc2ns, cpu)) >> CYC2NS_SCALE_FACTOR);
+	ns += mult_frac(cyc, per_cpu(cyc2ns, cpu),
+			(1UL << CYC2NS_SCALE_FACTOR));
 	return ns;
 }
 
diff -Naur a/arch/x86/Kconfig b/arch/x86/Kconfig
--- a/arch/x86/Kconfig	2013-11-01 20:18:03.449555568 +0200
+++ b/arch/x86/Kconfig	2013-11-01 18:44:46.985804198 +0200
@@ -1428,6 +1428,15 @@
 	def_bool y
 	depends on X86_PAT
 
+config ARCH_RANDOM
+	def_bool y
+	prompt "x86 architectural random number generator" if EMBEDDED
+	---help---
+	  Enable the x86 architectural RDRAND instruction
+	  (Intel Bull Mountain technology) to generate random numbers.
+	  If supported, this is a high bandwidth, cryptographically
+	  secure hardware random number generator.
+
 config EFI
 	bool "EFI runtime service support"
 	depends on ACPI
diff -Naur a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
--- a/arch/x86/kernel/apic/io_apic.c	2013-11-01 20:18:03.517555898 +0200
+++ b/arch/x86/kernel/apic/io_apic.c	2013-11-01 18:44:47.169805109 +0200
@@ -4262,6 +4262,7 @@
 void __init mp_register_ioapic(int id, u32 address, u32 gsi_base)
 {
 	int idx = 0;
+	int entries;
 
 	if (bad_ioapic(address))
 		return;
@@ -4280,10 +4281,14 @@
 	 * Build basic GSI lookup table to facilitate gsi->io_apic lookups
 	 * and to prevent reprogramming of IOAPIC pins (PCI GSIs).
 	 */
+	entries = io_apic_get_redir_entries(idx);
 	mp_gsi_routing[idx].gsi_base = gsi_base;
-	mp_gsi_routing[idx].gsi_end = gsi_base +
-	    io_apic_get_redir_entries(idx);
+	mp_gsi_routing[idx].gsi_end = gsi_base + entries;
 
+	/*
+	 * The number of IO-APIC IRQ registers (== #pins):
+	 */
+	nr_ioapic_registers[idx] = entries + 1;
 	printk(KERN_INFO "IOAPIC[%d]: apic_id %d, version %d, address 0x%x, "
 	       "GSI %d-%d\n", idx, mp_ioapics[idx].apicid,
 	       mp_ioapics[idx].apicver, mp_ioapics[idx].apicaddr,
diff -Naur a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
--- a/arch/x86/kernel/cpu/common.c	2013-11-01 20:18:03.525555937 +0200
+++ b/arch/x86/kernel/cpu/common.c	2013-11-01 18:44:47.181805164 +0200
@@ -15,6 +15,7 @@
 #include <asm/stackprotector.h>
 #include <asm/perf_event.h>
 #include <asm/mmu_context.h>
+#include <asm/archrandom.h>
 #include <asm/hypervisor.h>
 #include <asm/processor.h>
 #include <asm/sections.h>
@@ -815,6 +816,7 @@
 #endif
 
 	init_hypervisor(c);
+	x86_init_rdrand(c);
 
 	/*
 	 * Clear/Set all flags overriden by options, need do it
diff -Naur a/arch/x86/kernel/cpu/Makefile b/arch/x86/kernel/cpu/Makefile
--- a/arch/x86/kernel/cpu/Makefile	2013-11-01 20:18:03.521555925 +0200
+++ b/arch/x86/kernel/cpu/Makefile	2013-11-01 18:44:47.177805148 +0200
@@ -14,6 +14,7 @@
 obj-y			:= intel_cacheinfo.o addon_cpuid_features.o
 obj-y			+= proc.o capflags.o powerflags.o common.o
 obj-y			+= vmware.o hypervisor.o sched.o
+obj-y			+= rdrand.o
 
 obj-$(CONFIG_X86_32)	+= bugs.o cmpxchg.o
 obj-$(CONFIG_X86_64)	+= bugs_64.o
diff -Naur a/arch/x86/kernel/cpu/mcheck/mce.c b/arch/x86/kernel/cpu/mcheck/mce.c
--- a/arch/x86/kernel/cpu/mcheck/mce.c	2013-11-01 20:18:03.533555981 +0200
+++ b/arch/x86/kernel/cpu/mcheck/mce.c	2013-11-01 18:44:47.193805228 +0200
@@ -431,6 +431,13 @@
 	if (regs && (m->mcgstatus & (MCG_STATUS_RIPV|MCG_STATUS_EIPV))) {
 		m->ip = regs->ip;
 		m->cs = regs->cs;
+		/*
+		 * When in VM86 mode make the cs look like ring 3
+		 * always. This is a lie, but it's better than passing
+		 * the additional vm86 bit around everywhere.
+		 */
+		if (v8086_mode(regs))
+			m->cs |= 3;
 	} else {
 		m->ip = 0;
 		m->cs = 0;
@@ -968,6 +975,7 @@
 		 */
 		add_taint(TAINT_MACHINE_CHECK);
 
+		mce_get_rip(&m, regs);
 		severity = mce_severity(&m, tolerant, NULL);
 
 		/*
@@ -1006,7 +1014,6 @@
 		if (severity == MCE_AO_SEVERITY && mce_usable_address(&m))
 			mce_ring_add(m.addr >> PAGE_SHIFT);
 
-		mce_get_rip(&m, regs);
 		mce_log(&m);
 
 		if (severity > worst) {
diff -Naur a/arch/x86/kernel/cpu/rdrand.c b/arch/x86/kernel/cpu/rdrand.c
--- a/arch/x86/kernel/cpu/rdrand.c	1970-01-01 03:00:00.000000000 +0300
+++ b/arch/x86/kernel/cpu/rdrand.c	2013-11-01 18:44:47.201805273 +0200
@@ -0,0 +1,73 @@
+/*
+ * This file is part of the Linux kernel.
+ *
+ * Copyright (c) 2011, Intel Corporation
+ * Authors: Fenghua Yu <fenghua.yu@intel.com>,
+ *          H. Peter Anvin <hpa@linux.intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include <asm/processor.h>
+#include <asm/archrandom.h>
+#include <asm/sections.h>
+
+static int __init x86_rdrand_setup(char *s)
+{
+	setup_clear_cpu_cap(X86_FEATURE_RDRAND);
+	return 1;
+}
+__setup("nordrand", x86_rdrand_setup);
+
+/* We can't use arch_get_random_long() here since alternatives haven't run */
+static inline int rdrand_long(unsigned long *v)
+{
+	int ok;
+	asm volatile("1: " RDRAND_LONG "\n\t"
+		     "jc 2f\n\t"
+		     "decl %0\n\t"
+		     "jnz 1b\n\t"
+		     "2:"
+		     : "=r" (ok), "=a" (*v)
+		     : "0" (RDRAND_RETRY_LOOPS));
+	return ok;
+}
+
+/*
+ * Force a reseed cycle; we are architecturally guaranteed a reseed
+ * after no more than 512 128-bit chunks of random data.  This also
+ * acts as a test of the CPU capability.
+ */
+#define RESEED_LOOP ((512*128)/sizeof(unsigned long))
+
+void __cpuinit x86_init_rdrand(struct cpuinfo_x86 *c)
+{
+#ifdef CONFIG_ARCH_RANDOM
+	unsigned long tmp;
+	int i, count, ok;
+
+	if (!cpu_has(c, X86_FEATURE_RDRAND))
+		return;		/* Nothing to do */
+
+	for (count = i = 0; i < RESEED_LOOP; i++) {
+		ok = rdrand_long(&tmp);
+		if (ok)
+			count++;
+	}
+
+	if (count != RESEED_LOOP)
+		clear_cpu_cap(c, X86_FEATURE_RDRAND);
+#endif
+}
diff -Naur a/arch/x86/kernel/efi.c b/arch/x86/kernel/efi.c
--- a/arch/x86/kernel/efi.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/kernel/efi.c	2013-11-01 18:44:47.209805305 +0200
@@ -459,9 +459,6 @@
 	x86_platform.set_wallclock = efi_set_rtc_mmss;
 #endif
 
-	/* Setup for EFI runtime service */
-	reboot_type = BOOT_EFI;
-
 #if EFI_DEBUG
 	print_efi_memmap();
 #endif
diff -Naur a/arch/x86/kernel/k8.c b/arch/x86/kernel/k8.c
--- a/arch/x86/kernel/k8.c	2013-11-01 20:18:03.549556056 +0200
+++ b/arch/x86/kernel/k8.c	2013-11-01 18:44:47.225805385 +0200
@@ -87,6 +87,37 @@
 	return 0;
 }
 
+struct resource *amd_get_mmconfig_range(struct resource *res)
+{
+	u32 address;
+	u64 base, msr;
+	unsigned segn_busn_bits;
+
+	if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
+		return NULL;
+
+	/* assume all cpus from fam10h have mmconfig */
+	if (boot_cpu_data.x86 < 0x10)
+		return NULL;
+
+	address = MSR_FAM10H_MMIO_CONF_BASE;
+	rdmsrl(address, msr);
+
+	/* mmconfig is not enabled */
+	if (!(msr & FAM10H_MMIO_CONF_ENABLE))
+		return NULL;
+
+	base = msr & (FAM10H_MMIO_CONF_BASE_MASK<<FAM10H_MMIO_CONF_BASE_SHIFT);
+
+	segn_busn_bits = (msr >> FAM10H_MMIO_CONF_BUSRANGE_SHIFT) &
+                         FAM10H_MMIO_CONF_BUSRANGE_MASK;
+
+	res->flags = IORESOURCE_MEM;
+	res->start = base;
+	res->end = base + (1ULL<<(segn_busn_bits + 20)) - 1;
+	return res;
+}
+
 void k8_flush_garts(void)
 {
 	int flushed, i;
diff -Naur a/arch/x86/kernel/msr.c b/arch/x86/kernel/msr.c
--- a/arch/x86/kernel/msr.c	2013-11-01 20:18:03.557556100 +0200
+++ b/arch/x86/kernel/msr.c	2013-11-01 18:44:47.233805433 +0200
@@ -176,6 +176,9 @@
 	struct cpuinfo_x86 *c = &cpu_data(cpu);
 	int ret = 0;
 
+	if (!capable(CAP_SYS_RAWIO))
+		return -EPERM;
+
 	lock_kernel();
 	cpu = iminor(file->f_path.dentry->d_inode);
 
diff -Naur a/arch/x86/kernel/tls.c b/arch/x86/kernel/tls.c
--- a/arch/x86/kernel/tls.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/kernel/tls.c	2013-11-01 18:44:47.261805565 +0200
@@ -163,7 +163,7 @@
 {
 	const struct desc_struct *tls;
 
-	if (pos > GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||
+	if (pos >= GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||
 	    (pos % sizeof(struct user_desc)) != 0 ||
 	    (count % sizeof(struct user_desc)) != 0)
 		return -EINVAL;
@@ -198,7 +198,7 @@
 	struct user_desc infobuf[GDT_ENTRY_TLS_ENTRIES];
 	const struct user_desc *info;
 
-	if (pos > GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||
+	if (pos >= GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||
 	    (pos % sizeof(struct user_desc)) != 0 ||
 	    (count % sizeof(struct user_desc)) != 0)
 		return -EINVAL;
diff -Naur a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c
--- a/arch/x86/kernel/tsc.c	2013-11-01 20:18:03.581556219 +0200
+++ b/arch/x86/kernel/tsc.c	2013-11-01 18:44:47.265805592 +0200
@@ -623,7 +623,8 @@
 
 	if (cpu_khz) {
 		*scale = (NSEC_PER_MSEC << CYC2NS_SCALE_FACTOR)/cpu_khz;
-		*offset = ns_now - (tsc_now * *scale >> CYC2NS_SCALE_FACTOR);
+		*offset = ns_now - mult_frac(tsc_now, *scale,
+					     (1UL << CYC2NS_SCALE_FACTOR));
 	}
 
 	sched_clock_idle_wakeup_event(0);
diff -Naur a/arch/x86/kvm/emulate.c b/arch/x86/kvm/emulate.c
--- a/arch/x86/kvm/emulate.c	2013-11-01 20:18:03.585556236 +0200
+++ b/arch/x86/kvm/emulate.c	2013-11-01 18:44:47.273805622 +0200
@@ -1495,20 +1495,73 @@
 	ss->present = 1;
 }
 
+static bool em_syscall_is_enabled(struct x86_emulate_ctxt *ctxt,
+				  struct x86_emulate_ops *ops)
+{
+	u32 eax, ebx, ecx, edx;
+
+	/*
+	 * syscall should always be enabled in longmode - so only become
+	 * vendor specific (cpuid) if other modes are active...
+	 */
+	if (ctxt->mode == X86EMUL_MODE_PROT64)
+		return true;
+
+	eax = 0x00000000;
+	ecx = 0x00000000;
+	if (ops->get_cpuid(ctxt, &eax, &ebx, &ecx, &edx)) {
+		/*
+		 * Intel ("GenuineIntel")
+		 * remark: Intel CPUs only support "syscall" in 64bit
+		 * longmode. Also an 64bit guest with a
+		 * 32bit compat-app running will #UD !! While this
+		 * behaviour can be fixed (by emulating) into AMD
+		 * response - CPUs of AMD can't behave like Intel.
+		 */
+		if (ebx == X86EMUL_CPUID_VENDOR_GenuineIntel_ebx &&
+		    ecx == X86EMUL_CPUID_VENDOR_GenuineIntel_ecx &&
+		    edx == X86EMUL_CPUID_VENDOR_GenuineIntel_edx)
+			return false;
+
+		/* AMD ("AuthenticAMD") */
+		if (ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx &&
+		    ecx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx &&
+		    edx == X86EMUL_CPUID_VENDOR_AuthenticAMD_edx)
+			return true;
+
+		/* AMD ("AMDisbetter!") */
+		if (ebx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx &&
+		    ecx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx &&
+		    edx == X86EMUL_CPUID_VENDOR_AMDisbetterI_edx)
+			return true;
+	}
+
+	/* default: (not Intel, not AMD), apply Intel's stricter rules... */
+	return false;
+}
+
 static int
-emulate_syscall(struct x86_emulate_ctxt *ctxt)
+emulate_syscall(struct x86_emulate_ctxt *ctxt, struct x86_emulate_ops *ops)
 {
 	struct decode_cache *c = &ctxt->decode;
 	struct kvm_segment cs, ss;
 	u64 msr_data;
+	u64 efer = 0;
 
 	/* syscall is not available in real mode */
 	if (c->lock_prefix || ctxt->mode == X86EMUL_MODE_REAL
 	    || ctxt->mode == X86EMUL_MODE_VM86)
 		return -1;
 
+	if (!(em_syscall_is_enabled(ctxt, ops)))
+		return -1;
+
+	kvm_x86_ops->get_msr(ctxt->vcpu, MSR_EFER, &efer);
 	setup_syscalls_segments(ctxt, &cs, &ss);
 
+	if (!(efer & EFER_SCE))
+		return -1;
+
 	kvm_x86_ops->get_msr(ctxt->vcpu, MSR_STAR, &msr_data);
 	msr_data >>= 32;
 	cs.selector = (u16)(msr_data & 0xfffc);
@@ -2342,7 +2395,7 @@
 		}
 		break;
 	case 0x05: 		/* syscall */
-		if (emulate_syscall(ctxt) == -1)
+		if (emulate_syscall(ctxt, ops) == -1)
 			goto cannot_emulate;
 		else
 			goto writeback;
diff -Naur a/arch/x86/kvm/i8254.c b/arch/x86/kvm/i8254.c
--- a/arch/x86/kvm/i8254.c	2013-11-01 20:18:03.585556236 +0200
+++ b/arch/x86/kvm/i8254.c	2013-11-01 18:44:47.277805644 +0200
@@ -277,11 +277,15 @@
 	.is_periodic = kpit_is_periodic,
 };
 
-static void create_pit_timer(struct kvm_kpit_state *ps, u32 val, int is_period)
+static void create_pit_timer(struct kvm *kvm, u32 val, int is_period)
 {
+	struct kvm_kpit_state *ps = &kvm->arch.vpit->pit_state;
 	struct kvm_timer *pt = &ps->pit_timer;
 	s64 interval;
 
+	if (!irqchip_in_kernel(kvm))
+		return;
+
 	interval = muldiv64(val, NSEC_PER_SEC, KVM_PIT_FREQ);
 
 	pr_debug("pit: create pit timer, interval is %llu nsec\n", interval);
@@ -333,13 +337,13 @@
         /* FIXME: enhance mode 4 precision */
 	case 4:
 		if (!(ps->flags & KVM_PIT_FLAGS_HPET_LEGACY)) {
-			create_pit_timer(ps, val, 0);
+			create_pit_timer(kvm, val, 0);
 		}
 		break;
 	case 2:
 	case 3:
 		if (!(ps->flags & KVM_PIT_FLAGS_HPET_LEGACY)){
-			create_pit_timer(ps, val, 1);
+			create_pit_timer(kvm, val, 1);
 		}
 		break;
 	default:
diff -Naur a/arch/x86/kvm/irq.h b/arch/x86/kvm/irq.h
--- a/arch/x86/kvm/irq.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/kvm/irq.h	2013-11-01 18:44:47.277805644 +0200
@@ -85,7 +85,11 @@
 
 static inline int irqchip_in_kernel(struct kvm *kvm)
 {
-	return pic_irqchip(kvm) != NULL;
+	int ret;
+
+	ret = (pic_irqchip(kvm) != NULL);
+	smp_rmb();
+	return ret;
 }
 
 void kvm_pic_reset(struct kvm_kpic_state *s);
diff -Naur a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
--- a/arch/x86/kvm/x86.c	2013-11-01 20:18:03.609556355 +0200
+++ b/arch/x86/kvm/x86.c	2013-11-01 18:44:47.293805723 +0200
@@ -925,6 +925,12 @@
 		/* ...but clean it before doing the actual write */
 		vcpu->arch.time_offset = data & ~(PAGE_MASK | 1);
 
+		/* Check that address+len does not cross page boundary */
+		if ((vcpu->arch.time_offset +
+			sizeof(struct pvclock_vcpu_time_info) - 1)
+			& PAGE_MASK)
+			break;
+
 		vcpu->arch.time_page =
 				gfn_to_page(vcpu->kvm, data >> PAGE_SHIFT);
 
@@ -2273,25 +2279,42 @@
 		if (r)
 			goto out;
 		break;
-	case KVM_CREATE_IRQCHIP:
+	case KVM_CREATE_IRQCHIP: {
+		struct kvm_pic *vpic;
+
+		mutex_lock(&kvm->lock);
+		r = -EEXIST;
+		if (kvm->arch.vpic)
+			goto create_irqchip_unlock;
+		r = -EINVAL;
+		if (atomic_read(&kvm->online_vcpus))
+			goto create_irqchip_unlock;
 		r = -ENOMEM;
-		kvm->arch.vpic = kvm_create_pic(kvm);
-		if (kvm->arch.vpic) {
+		vpic = kvm_create_pic(kvm);
+		if (vpic) {
 			r = kvm_ioapic_init(kvm);
 			if (r) {
-				kfree(kvm->arch.vpic);
-				kvm->arch.vpic = NULL;
-				goto out;
+				kfree(vpic);
+				goto create_irqchip_unlock;
 			}
 		} else
-			goto out;
+			goto create_irqchip_unlock;
+		smp_wmb();
+		kvm->arch.vpic = vpic;
+		smp_wmb();
 		r = kvm_setup_default_irq_routing(kvm);
 		if (r) {
+			mutex_lock(&kvm->irq_lock);
 			kfree(kvm->arch.vpic);
 			kfree(kvm->arch.vioapic);
-			goto out;
+			kvm->arch.vpic = NULL;
+			kvm->arch.vioapic = NULL;
+			mutex_unlock(&kvm->irq_lock);
 		}
+	create_irqchip_unlock:
+		mutex_unlock(&kvm->lock);
 		break;
+	}
 	case KVM_CREATE_PIT:
 		u.pit_config.flags = KVM_PIT_SPEAKER_DUMMY;
 		goto create_pit;
@@ -2871,12 +2894,35 @@
 }
 EXPORT_SYMBOL_GPL(kvm_report_emulation_failure);
 
+static bool emulator_get_cpuid(struct x86_emulate_ctxt *ctxt,
+			       u32 *eax, u32 *ebx, u32 *ecx, u32 *edx)
+{
+	struct kvm_cpuid_entry2 *cpuid = NULL;
+
+	if (eax && ecx)
+		cpuid = kvm_find_cpuid_entry(ctxt->vcpu,
+					    *eax, *ecx);
+
+	if (cpuid) {
+		*eax = cpuid->eax;
+		*ecx = cpuid->ecx;
+		if (ebx)
+			*ebx = cpuid->ebx;
+		if (edx)
+			*edx = cpuid->edx;
+		return true;
+	}
+
+	return false;
+}
+
 static struct x86_emulate_ops emulate_ops = {
 	.read_std            = kvm_read_guest_virt_system,
 	.fetch               = kvm_fetch_guest_virt,
 	.read_emulated       = emulator_read_emulated,
 	.write_emulated      = emulator_write_emulated,
 	.cmpxchg_emulated    = emulator_cmpxchg_emulated,
+	.get_cpuid           = emulator_get_cpuid,
 };
 
 static void cache_all_regs(struct kvm_vcpu *vcpu)
@@ -4673,6 +4719,9 @@
 	int pending_vec, max_bits;
 	struct descriptor_table dt;
 
+	if (sregs->cr4 & X86_CR4_OSXSAVE)
+		return -EINVAL;
+
 	vcpu_load(vcpu);
 
 	dt.limit = sregs->idt.limit;
@@ -4990,6 +5039,11 @@
 	kvm_x86_ops->check_processor_compatibility(rtn);
 }
 
+bool kvm_vcpu_compatible(struct kvm_vcpu *vcpu)
+{
+	return irqchip_in_kernel(vcpu->kvm) == (vcpu->arch.apic != NULL);
+}
+
 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 {
 	struct page *page;
diff -Naur a/arch/x86/lib/delay.c b/arch/x86/lib/delay.c
--- a/arch/x86/lib/delay.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/lib/delay.c	2013-11-01 18:44:47.301805764 +0200
@@ -48,9 +48,9 @@
 }
 
 /* TSC based delay: */
-static void delay_tsc(unsigned long loops)
+static void delay_tsc(unsigned long __loops)
 {
-	unsigned long bclock, now;
+	u32 bclock, now, loops = __loops;
 	int cpu;
 
 	preempt_disable();
diff -Naur a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
--- a/arch/x86/mm/fault.c	2013-11-01 20:18:03.613556374 +0200
+++ b/arch/x86/mm/fault.c	2013-11-01 18:44:47.333805922 +0200
@@ -223,15 +223,14 @@
 	     address >= TASK_SIZE && address < FIXADDR_TOP;
 	     address += PMD_SIZE) {
 
-		unsigned long flags;
 		struct page *page;
 
-		spin_lock_irqsave(&pgd_lock, flags);
+		spin_lock(&pgd_lock);
 		list_for_each_entry(page, &pgd_list, lru) {
 			if (!vmalloc_sync_one(page_address(page), address))
 				break;
 		}
-		spin_unlock_irqrestore(&pgd_lock, flags);
+		spin_unlock(&pgd_lock);
 	}
 }
 
@@ -331,13 +330,12 @@
 	     address += PGDIR_SIZE) {
 
 		const pgd_t *pgd_ref = pgd_offset_k(address);
-		unsigned long flags;
 		struct page *page;
 
 		if (pgd_none(*pgd_ref))
 			continue;
 
-		spin_lock_irqsave(&pgd_lock, flags);
+		spin_lock(&pgd_lock);
 		list_for_each_entry(page, &pgd_list, lru) {
 			pgd_t *pgd;
 			pgd = (pgd_t *)page_address(page) + pgd_index(address);
@@ -346,7 +344,7 @@
 			else
 				BUG_ON(pgd_page_vaddr(*pgd) != pgd_page_vaddr(*pgd_ref));
 		}
-		spin_unlock_irqrestore(&pgd_lock, flags);
+		spin_unlock(&pgd_lock);
 	}
 }
 
@@ -378,10 +376,12 @@
 	if (pgd_none(*pgd_ref))
 		return -1;
 
-	if (pgd_none(*pgd))
+	if (pgd_none(*pgd)) {
 		set_pgd(pgd, *pgd_ref);
-	else
+		arch_flush_lazy_mmu_mode();
+	} else {
 		BUG_ON(pgd_page_vaddr(*pgd) != pgd_page_vaddr(*pgd_ref));
+	}
 
 	/*
 	 * Below here mismatches are bugs because these lower tables
diff -Naur a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
--- a/arch/x86/mm/init_64.c	2013-11-01 20:18:03.613556374 +0200
+++ b/arch/x86/mm/init_64.c	2013-11-01 18:44:47.337805941 +0200
@@ -839,6 +839,9 @@
 	if (pud_none(*pud))
 		return 0;
 
+	if (pud_large(*pud))
+		return pfn_valid(pud_pfn(*pud));
+
 	pmd = pmd_offset(pud, addr);
 	if (pmd_none(*pmd))
 		return 0;
diff -Naur a/arch/x86/mm/pageattr.c b/arch/x86/mm/pageattr.c
--- a/arch/x86/mm/pageattr.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/mm/pageattr.c	2013-11-01 18:44:47.349805999 +0200
@@ -56,12 +56,10 @@
 
 void update_page_count(int level, unsigned long pages)
 {
-	unsigned long flags;
-
 	/* Protect against CPA */
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 	direct_pages_count[level] += pages;
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 }
 
 static void split_page_count(int level)
@@ -354,7 +352,7 @@
 try_preserve_large_page(pte_t *kpte, unsigned long address,
 			struct cpa_data *cpa)
 {
-	unsigned long nextpage_addr, numpages, pmask, psize, flags, addr, pfn;
+	unsigned long nextpage_addr, numpages, pmask, psize, addr, pfn;
 	pte_t new_pte, old_pte, *tmp;
 	pgprot_t old_prot, new_prot;
 	int i, do_split = 1;
@@ -363,7 +361,7 @@
 	if (cpa->force_split)
 		return 1;
 
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 	/*
 	 * Check for races, another CPU might have split this page
 	 * up already:
@@ -458,14 +456,14 @@
 	}
 
 out_unlock:
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 
 	return do_split;
 }
 
 static int split_large_page(pte_t *kpte, unsigned long address)
 {
-	unsigned long flags, pfn, pfninc = 1;
+	unsigned long pfn, pfninc = 1;
 	unsigned int i, level;
 	pte_t *pbase, *tmp;
 	pgprot_t ref_prot;
@@ -479,7 +477,7 @@
 	if (!base)
 		return -ENOMEM;
 
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 	/*
 	 * Check for races, another CPU might have split this page
 	 * up for us already:
@@ -551,7 +549,7 @@
 	 */
 	if (base)
 		__free_page(base);
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 
 	return 0;
 }
diff -Naur a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c
--- a/arch/x86/mm/pgtable.c	2013-11-01 20:18:03.617556401 +0200
+++ b/arch/x86/mm/pgtable.c	2013-11-01 18:44:47.349805999 +0200
@@ -110,14 +110,12 @@
 
 static void pgd_dtor(pgd_t *pgd)
 {
-	unsigned long flags; /* can be called from interrupt context */
-
 	if (SHARED_KERNEL_PMD)
 		return;
 
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 	pgd_list_del(pgd);
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 }
 
 /*
@@ -248,7 +246,6 @@
 {
 	pgd_t *pgd;
 	pmd_t *pmds[PREALLOCATED_PMDS];
-	unsigned long flags;
 
 	pgd = (pgd_t *)__get_free_page(PGALLOC_GFP);
 
@@ -268,12 +265,12 @@
 	 * respect to anything walking the pgd_list, so that they
 	 * never see a partially populated pgd.
 	 */
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 
 	pgd_ctor(pgd);
 	pgd_prepopulate_pmd(mm, pgd, pmds);
 
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 
 	return pgd;
 
diff -Naur a/arch/x86/oprofile/backtrace.c b/arch/x86/oprofile/backtrace.c
--- a/arch/x86/oprofile/backtrace.c	2013-11-01 20:18:03.617556401 +0200
+++ b/arch/x86/oprofile/backtrace.c	2013-11-01 18:44:47.353806027 +0200
@@ -71,9 +71,9 @@
 		offset = addr & (PAGE_SIZE - 1);
 		size = min(PAGE_SIZE - offset, n - len);
 
-		map = kmap_atomic(page, KM_USER0);
+		map = kmap_atomic(page, KM_NMI);
 		memcpy(to, map+offset, size);
-		kunmap_atomic(map, KM_USER0);
+		kunmap_atomic(map, KM_NMI);
 		put_page(page);
 
 		len  += size;
diff -Naur a/arch/x86/pci/amd_bus.c b/arch/x86/pci/amd_bus.c
--- a/arch/x86/pci/amd_bus.c	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/pci/amd_bus.c	2013-11-01 18:44:47.361806059 +0200
@@ -3,6 +3,7 @@
 #include <linux/topology.h>
 #include <linux/cpu.h>
 #include <asm/pci_x86.h>
+#include <asm/k8.h>
 
 #ifdef CONFIG_X86_64
 #include <asm/pci-direct.h>
@@ -190,34 +191,6 @@
 	{ 0, 0x18, PCI_VENDOR_ID_AMD, 0x1300 },
 };
 
-static u64 __initdata fam10h_mmconf_start;
-static u64 __initdata fam10h_mmconf_end;
-static void __init get_pci_mmcfg_amd_fam10h_range(void)
-{
-	u32 address;
-	u64 base, msr;
-	unsigned segn_busn_bits;
-
-	/* assume all cpus from fam10h have mmconf */
-        if (boot_cpu_data.x86 < 0x10)
-		return;
-
-	address = MSR_FAM10H_MMIO_CONF_BASE;
-	rdmsrl(address, msr);
-
-	/* mmconfig is not enable */
-	if (!(msr & FAM10H_MMIO_CONF_ENABLE))
-		return;
-
-	base = msr & (FAM10H_MMIO_CONF_BASE_MASK<<FAM10H_MMIO_CONF_BASE_SHIFT);
-
-	segn_busn_bits = (msr >> FAM10H_MMIO_CONF_BUSRANGE_SHIFT) &
-			 FAM10H_MMIO_CONF_BUSRANGE_MASK;
-
-	fam10h_mmconf_start = base;
-	fam10h_mmconf_end = base + (1ULL<<(segn_busn_bits + 20)) - 1;
-}
-
 /**
  * early_fill_mp_bus_to_node()
  * called before pcibios_scan_root and pci_scan_bus
@@ -243,6 +216,9 @@
 	struct res_range range[RANGE_NUM];
 	u64 val;
 	u32 address;
+	struct resource fam10h_mmconf_res, *fam10h_mmconf;
+	u64 fam10h_mmconf_start;
+	u64 fam10h_mmconf_end;
 
 	if (!early_pci_allowed())
 		return -1;
@@ -367,11 +343,16 @@
 		update_range(range, 0, end - 1);
 
 	/* get mmconfig */
-	get_pci_mmcfg_amd_fam10h_range();
+	fam10h_mmconf = amd_get_mmconfig_range(&fam10h_mmconf_res);
 	/* need to take out mmconf range */
-	if (fam10h_mmconf_end) {
-		printk(KERN_DEBUG "Fam 10h mmconf [%llx, %llx]\n", fam10h_mmconf_start, fam10h_mmconf_end);
+	if (fam10h_mmconf) {
+		printk(KERN_DEBUG "Fam 10h mmconf %pR\n", fam10h_mmconf);
+		fam10h_mmconf_start = fam10h_mmconf->start;
+		fam10h_mmconf_end = fam10h_mmconf->end;
 		update_range(range, fam10h_mmconf_start, fam10h_mmconf_end);
+	} else {
+		fam10h_mmconf_start = 0;
+		fam10h_mmconf_end = 0;
 	}
 
 	/* mmio resource */
diff -Naur a/arch/x86/xen/enlighten.c b/arch/x86/xen/enlighten.c
--- a/arch/x86/xen/enlighten.c	2013-11-01 20:18:03.625556427 +0200
+++ b/arch/x86/xen/enlighten.c	2013-11-01 18:44:47.377806138 +0200
@@ -776,7 +776,16 @@
 
 	native_write_cr4(cr4);
 }
-
+#ifdef CONFIG_X86_64
+static inline unsigned long xen_read_cr8(void)
+{
+	return 0;
+}
+static inline void xen_write_cr8(unsigned long val)
+{
+	BUG_ON(val);
+}
+#endif
 static int xen_write_msr_safe(unsigned int msr, unsigned low, unsigned high)
 {
 	int ret;
@@ -942,13 +951,23 @@
 	.read_cr4_safe = native_read_cr4_safe,
 	.write_cr4 = xen_write_cr4,
 
+#ifdef CONFIG_X86_64
+	.read_cr8 = xen_read_cr8,
+	.write_cr8 = xen_write_cr8,
+#endif
+
 	.wbinvd = native_wbinvd,
 
 	.read_msr = native_read_msr_safe,
+	.rdmsr_regs = native_rdmsr_safe_regs,
 	.write_msr = xen_write_msr_safe,
+	.wrmsr_regs = native_wrmsr_safe_regs,
+
 	.read_tsc = native_read_tsc,
 	.read_pmc = native_read_pmc,
 
+	.read_tscp = native_read_tscp,
+
 	.iret = xen_iret,
 	.irq_enable_sysexit = xen_sysexit,
 #ifdef CONFIG_X86_64
diff -Naur a/arch/x86/xen/mmu.c b/arch/x86/xen/mmu.c
--- a/arch/x86/xen/mmu.c	2013-11-01 20:18:03.629556457 +0200
+++ b/arch/x86/xen/mmu.c	2013-11-01 18:44:47.381806160 +0200
@@ -987,10 +987,9 @@
  */
 void xen_mm_pin_all(void)
 {
-	unsigned long flags;
 	struct page *page;
 
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 
 	list_for_each_entry(page, &pgd_list, lru) {
 		if (!PagePinned(page)) {
@@ -999,7 +998,7 @@
 		}
 	}
 
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 }
 
 /*
@@ -1100,10 +1099,9 @@
  */
 void xen_mm_unpin_all(void)
 {
-	unsigned long flags;
 	struct page *page;
 
-	spin_lock_irqsave(&pgd_lock, flags);
+	spin_lock(&pgd_lock);
 
 	list_for_each_entry(page, &pgd_list, lru) {
 		if (PageSavePinned(page)) {
@@ -1113,7 +1111,7 @@
 		}
 	}
 
-	spin_unlock_irqrestore(&pgd_lock, flags);
+	spin_unlock(&pgd_lock);
 }
 
 void xen_activate_mm(struct mm_struct *prev, struct mm_struct *next)
diff -Naur a/arch/x86/xen/xen-asm_32.S b/arch/x86/xen/xen-asm_32.S
--- a/arch/x86/xen/xen-asm_32.S	2013-11-01 20:18:03.633556474 +0200
+++ b/arch/x86/xen/xen-asm_32.S	2013-11-01 18:44:47.385806187 +0200
@@ -88,11 +88,11 @@
 	 */
 #ifdef CONFIG_SMP
 	GET_THREAD_INFO(%eax)
-	movl TI_cpu(%eax), %eax
-	movl __per_cpu_offset(,%eax,4), %eax
-	mov per_cpu__xen_vcpu(%eax), %eax
+	movl %ss:TI_cpu(%eax), %eax
+	movl %ss:__per_cpu_offset(,%eax,4), %eax
+	mov %ss:per_cpu__xen_vcpu(%eax), %eax
 #else
-	movl per_cpu__xen_vcpu, %eax
+	movl %ss:per_cpu__xen_vcpu, %eax
 #endif
 
 	/* check IF state we're restoring */
@@ -105,11 +105,11 @@
 	 * resuming the code, so we don't have to be worried about
 	 * being preempted to another CPU.
 	 */
-	setz XEN_vcpu_info_mask(%eax)
+	setz %ss:XEN_vcpu_info_mask(%eax)
 xen_iret_start_crit:
 
 	/* check for unmasked and pending */
-	cmpw $0x0001, XEN_vcpu_info_pending(%eax)
+	cmpw $0x0001, %ss:XEN_vcpu_info_pending(%eax)
 
 	/*
 	 * If there's something pending, mask events again so we can
@@ -117,7 +117,7 @@
 	 * touch XEN_vcpu_info_mask.
 	 */
 	jne 1f
-	movb $1, XEN_vcpu_info_mask(%eax)
+	movb $1, %ss:XEN_vcpu_info_mask(%eax)
 
 1:	popl %eax
 
diff -Naur a/arch/x86/xen/xen-asm.S b/arch/x86/xen/xen-asm.S
--- a/arch/x86/xen/xen-asm.S	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/x86/xen/xen-asm.S	2013-11-01 18:44:47.385806187 +0200
@@ -96,7 +96,7 @@
 
 	/* check for unmasked and pending */
 	cmpw $0x0001, PER_CPU_VAR(xen_vcpu_info) + XEN_vcpu_info_pending
-	jz 1f
+	jnz 1f
 2:	call check_events
 1:
 ENDPATCH(xen_restore_fl_direct)
diff -Naur a/arch/xtensa/include/asm/signal.h b/arch/xtensa/include/asm/signal.h
--- a/arch/xtensa/include/asm/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/arch/xtensa/include/asm/signal.h	2013-11-01 18:44:47.449806498 +0200
@@ -133,6 +133,7 @@
 	void (*sa_restorer)(void);
 	sigset_t sa_mask;		/* mask last for extensibility */
 };
+#define __ARCH_HAS_SA_RESTORER
 
 struct k_sigaction {
 	struct sigaction sa;
diff -Naur a/block/blk-core.c b/block/blk-core.c
--- a/block/blk-core.c	2013-11-01 20:18:03.641556520 +0200
+++ b/block/blk-core.c	2013-11-01 18:44:47.525806874 +0200
@@ -865,6 +865,9 @@
 {
 	struct request *rq;
 
+	if (unlikely(test_bit(QUEUE_FLAG_DEAD, &q->queue_flags)))
+		return NULL;
+
 	BUG_ON(rw != READ && rw != WRITE);
 
 	spin_lock_irq(q->queue_lock);
@@ -1149,7 +1152,7 @@
  */
 static inline bool queue_should_plug(struct request_queue *q)
 {
-	return !(blk_queue_nonrot(q) && blk_queue_queuing(q));
+	return !(blk_queue_nonrot(q) && blk_queue_tagged(q));
 }
 
 static int __make_request(struct request_queue *q, struct bio *bio)
@@ -1861,15 +1864,8 @@
 	 * and to it is freed is accounted as io that is in progress at
 	 * the driver side.
 	 */
-	if (blk_account_rq(rq)) {
+	if (blk_account_rq(rq))
 		q->in_flight[rq_is_sync(rq)]++;
-		/*
-		 * Mark this device as supporting hardware queuing, if
-		 * we have more IOs in flight than 4.
-		 */
-		if (!blk_queue_queuing(q) && queue_in_flight(q) > 4)
-			set_bit(QUEUE_FLAG_CQ, &q->queue_flags);
-	}
 }
 
 /**
diff -Naur a/block/blk-exec.c b/block/blk-exec.c
--- a/block/blk-exec.c	2009-12-03 05:51:21.000000000 +0200
+++ b/block/blk-exec.c	2013-11-01 18:44:47.525806874 +0200
@@ -50,6 +50,13 @@
 {
 	int where = at_head ? ELEVATOR_INSERT_FRONT : ELEVATOR_INSERT_BACK;
 
+	if (unlikely(test_bit(QUEUE_FLAG_DEAD, &q->queue_flags))) {
+		rq->errors = -ENXIO;
+		if (rq->end_io)
+			rq->end_io(rq, rq->errors);
+		return;
+	}
+
 	rq->rq_disk = bd_disk;
 	rq->end_io = done;
 	WARN_ON(irqs_disabled());
diff -Naur a/block/blk-ioc.c b/block/blk-ioc.c
--- a/block/blk-ioc.c	2009-12-03 05:51:21.000000000 +0200
+++ b/block/blk-ioc.c	2013-11-01 18:44:47.529806893 +0200
@@ -66,22 +66,22 @@
 }
 
 /* Called by the exitting task */
-void exit_io_context(void)
+void exit_io_context(struct task_struct *task)
 {
 	struct io_context *ioc;
 
-	task_lock(current);
-	ioc = current->io_context;
-	current->io_context = NULL;
-	task_unlock(current);
+	task_lock(task);
+	ioc = task->io_context;
+	task->io_context = NULL;
+	task_unlock(task);
 
 	if (atomic_dec_and_test(&ioc->nr_tasks)) {
 		if (ioc->aic && ioc->aic->exit)
 			ioc->aic->exit(ioc->aic);
 		cfq_exit(ioc);
 
-		put_io_context(ioc);
 	}
+	put_io_context(ioc);
 }
 
 struct io_context *alloc_io_context(gfp_t gfp_flags, int node)
diff -Naur a/block/scsi_ioctl.c b/block/scsi_ioctl.c
--- a/block/scsi_ioctl.c	2013-11-01 20:18:03.653556576 +0200
+++ b/block/scsi_ioctl.c	2013-11-01 18:44:47.541806951 +0200
@@ -720,11 +720,14 @@
 		break;
 	}
 
+	if (capable(CAP_SYS_RAWIO))
+		return 0;
+
 	/* In particular, rule out all resets and host-specific ioctls.  */
 	printk_ratelimited(KERN_WARNING
 			   "%s: sending ioctl %x to a partition!\n", current->comm, cmd);
 
-	return capable(CAP_SYS_RAWIO) ? 0 : -ENOTTY;
+	return -ENOTTY;
 }
 EXPORT_SYMBOL(scsi_verify_blk_ioctl);
 
diff -Naur a/crypto/cryptd.c b/crypto/cryptd.c
--- a/crypto/cryptd.c	2009-12-03 05:51:21.000000000 +0200
+++ b/crypto/cryptd.c	2013-11-01 18:44:47.565807070 +0200
@@ -116,13 +116,18 @@
 	struct crypto_async_request *req, *backlog;
 
 	cpu_queue = container_of(work, struct cryptd_cpu_queue, work);
-	/* Only handle one request at a time to avoid hogging crypto
-	 * workqueue. preempt_disable/enable is used to prevent
-	 * being preempted by cryptd_enqueue_request() */
+	/*
+	 * Only handle one request at a time to avoid hogging crypto workqueue.
+	 * preempt_disable/enable is used to prevent being preempted by
+	 * cryptd_enqueue_request(). local_bh_disable/enable is used to prevent
+	 * cryptd_enqueue_request() being accessed from software interrupts.
+	 */
+	local_bh_disable();
 	preempt_disable();
 	backlog = crypto_get_backlog(&cpu_queue->queue);
 	req = crypto_dequeue_request(&cpu_queue->queue);
 	preempt_enable();
+	local_bh_enable();
 
 	if (!req)
 		return;
diff -Naur a/crypto/sha512_generic.c b/crypto/sha512_generic.c
--- a/crypto/sha512_generic.c	2013-11-01 20:18:03.657556593 +0200
+++ b/crypto/sha512_generic.c	2013-11-01 18:44:47.609807287 +0200
@@ -174,7 +174,7 @@
 	index = sctx->count[0] & 0x7f;
 
 	/* Update number of bytes */
-	if (!(sctx->count[0] += len))
+	if ((sctx->count[0] += len) < len)
 		sctx->count[1]++;
 
         part_len = 128 - index;
diff -Naur a/Documentation/kernel-parameters.txt b/Documentation/kernel-parameters.txt
--- a/Documentation/kernel-parameters.txt	2013-11-01 20:19:18.021925344 +0200
+++ b/Documentation/kernel-parameters.txt	2013-11-01 18:44:42.121780082 +0200
@@ -1727,6 +1727,11 @@
 
 	noresidual	[PPC] Don't use residual data on PReP machines.
 
+	nordrand	[X86] Disable the direct use of the RDRAND
+			instruction even if it is supported by the
+			processor.  RDRAND is still available to user
+			space applications.
+
 	noresume	[SWSUSP] Disables resume and restores original swap
 			space.
 
diff -Naur a/Documentation/stable_kernel_rules.txt b/Documentation/stable_kernel_rules.txt
--- a/Documentation/stable_kernel_rules.txt	2013-11-01 20:18:03.169554172 +0200
+++ b/Documentation/stable_kernel_rules.txt	2013-11-01 18:44:42.313781035 +0200
@@ -12,6 +12,12 @@
    marked CONFIG_BROKEN), an oops, a hang, data corruption, a real
    security issue, or some "oh, that's not good" issue.  In short, something
    critical.
+ - Serious issues as reported by a user of a distribution kernel may also
+   be considered if they fix a notable performance or interactivity issue.
+   As these fixes are not as obvious and have a higher risk of a subtle
+   regression they should only be submitted by a distribution kernel
+   maintainer and include an addendum linking to a bugzilla entry if it
+   exists and additional information on the user-visible impact.
  - New device IDs and quirks are also accepted.
  - No "theoretical race condition" issues, unless an explanation of how the
    race can be exploited is also provided.
diff -Naur a/drivers/acpi/ac.c b/drivers/acpi/ac.c
--- a/drivers/acpi/ac.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/acpi/ac.c	2013-11-01 18:44:47.641807455 +0200
@@ -287,7 +287,9 @@
 	ac->charger.properties = ac_props;
 	ac->charger.num_properties = ARRAY_SIZE(ac_props);
 	ac->charger.get_property = get_ac_property;
-	power_supply_register(&ac->device->dev, &ac->charger);
+	result = power_supply_register(&ac->device->dev, &ac->charger);
+	if (result)
+		goto end;
 #endif
 
 	printk(KERN_INFO PREFIX "%s [%s] (%s)\n",
diff -Naur a/drivers/acpi/processor_idle.c b/drivers/acpi/processor_idle.c
--- a/drivers/acpi/processor_idle.c	2013-11-01 20:18:03.669556651 +0200
+++ b/drivers/acpi/processor_idle.c	2013-11-01 18:44:47.761808050 +0200
@@ -1071,6 +1071,9 @@
 		return -EINVAL;
 	}
 
+	if (!dev)
+		return -EINVAL;
+
 	dev->cpu = pr->id;
 	for (i = 0; i < CPUIDLE_STATE_MAX; i++) {
 		dev->states[i].name[0] = '\0';
diff -Naur a/drivers/ata/libata-scsi.c b/drivers/ata/libata-scsi.c
--- a/drivers/ata/libata-scsi.c	2013-11-01 20:18:03.689556758 +0200
+++ b/drivers/ata/libata-scsi.c	2013-11-01 18:44:47.789808183 +0200
@@ -338,7 +338,8 @@
 	struct ata_port *ap = ata_shost_to_port(sdev->host);
 	struct ata_device *atadev = ata_scsi_find_dev(ap, sdev);
 
-	if (ap->ops->sw_activity_show && (ap->flags & ATA_FLAG_SW_ACTIVITY))
+	if (atadev && ap->ops->sw_activity_show &&
+	    (ap->flags & ATA_FLAG_SW_ACTIVITY))
 		return ap->ops->sw_activity_show(atadev, buf);
 	return -EINVAL;
 }
@@ -353,7 +354,8 @@
 	enum sw_activity val;
 	int rc;
 
-	if (ap->ops->sw_activity_store && (ap->flags & ATA_FLAG_SW_ACTIVITY)) {
+	if (atadev && ap->ops->sw_activity_store &&
+	    (ap->flags & ATA_FLAG_SW_ACTIVITY)) {
 		val = simple_strtoul(buf, NULL, 0);
 		switch (val) {
 		case OFF: case BLINK_ON: case BLINK_OFF:
diff -Naur a/drivers/base/bus.c b/drivers/base/bus.c
--- a/drivers/base/bus.c	2013-11-01 20:19:18.517927813 +0200
+++ b/drivers/base/bus.c	2013-11-01 18:44:47.901808736 +0200
@@ -289,7 +289,7 @@
 	struct device *dev;
 	int error = 0;
 
-	if (!bus)
+	if (!bus || !bus->p)
 		return -EINVAL;
 
 	klist_iter_init_node(&bus->p->klist_devices, &i,
@@ -323,7 +323,7 @@
 	struct klist_iter i;
 	struct device *dev;
 
-	if (!bus)
+	if (!bus || !bus->p)
 		return NULL;
 
 	klist_iter_init_node(&bus->p->klist_devices, &i,
diff -Naur a/drivers/block/cciss_scsi.c b/drivers/block/cciss_scsi.c
--- a/drivers/block/cciss_scsi.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/block/cciss_scsi.c	2013-11-01 18:44:47.941808942 +0200
@@ -747,17 +747,7 @@
 		{
 			case CMD_TARGET_STATUS:
 				/* Pass it up to the upper layers... */
-				if( ei->ScsiStatus)
-                		{
-#if 0
-                    			printk(KERN_WARNING "cciss: cmd %p "
-					"has SCSI Status = %x\n",
-                        			cp,  
-						ei->ScsiStatus); 
-#endif
-					cmd->result |= (ei->ScsiStatus < 1);
-                		}
-				else {  /* scsi status is zero??? How??? */
+				if (!ei->ScsiStatus) {
 					
 	/* Ordinarily, this case should never happen, but there is a bug
 	   in some released firmware revisions that allows it to happen
diff -Naur a/drivers/block/sx8.c b/drivers/block/sx8.c
--- a/drivers/block/sx8.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/block/sx8.c	2013-11-01 18:44:47.973809093 +0200
@@ -1116,7 +1116,7 @@
 			break;
 		case MISC_GET_FW_VER: {
 			struct carm_fw_ver *ver = (struct carm_fw_ver *)
-				mem + sizeof(struct carm_msg_get_fw_ver);
+				(mem + sizeof(struct carm_msg_get_fw_ver));
 			if (!error) {
 				host->fw_ver = le32_to_cpu(ver->version);
 				host->flags |= (ver->features & FL_FW_VER_MASK);
diff -Naur a/drivers/bluetooth/btusb.c b/drivers/bluetooth/btusb.c
--- a/drivers/bluetooth/btusb.c	2013-11-01 20:18:03.733556969 +0200
+++ b/drivers/bluetooth/btusb.c	2013-11-01 18:44:47.989809180 +0200
@@ -470,15 +470,10 @@
 
 	pipe = usb_rcvisocpipe(data->udev, data->isoc_rx_ep->bEndpointAddress);
 
-	urb->dev      = data->udev;
-	urb->pipe     = pipe;
-	urb->context  = hdev;
-	urb->complete = btusb_isoc_complete;
-	urb->interval = data->isoc_rx_ep->bInterval;
+	usb_fill_int_urb(urb, data->udev, pipe, buf, size, btusb_isoc_complete,
+				hdev, data->isoc_rx_ep->bInterval);
 
 	urb->transfer_flags  = URB_FREE_BUFFER | URB_ISO_ASAP;
-	urb->transfer_buffer = buf;
-	urb->transfer_buffer_length = size;
 
 	__fill_isoc_descriptor(urb, size,
 			le16_to_cpu(data->isoc_rx_ep->wMaxPacketSize));
diff -Naur a/drivers/bluetooth/hci_ldisc.c b/drivers/bluetooth/hci_ldisc.c
--- a/drivers/bluetooth/hci_ldisc.c	2013-11-01 20:18:03.733556969 +0200
+++ b/drivers/bluetooth/hci_ldisc.c	2013-11-01 18:44:47.993809191 +0200
@@ -312,9 +312,11 @@
 			hci_uart_close(hdev);
 
 		if (test_and_clear_bit(HCI_UART_PROTO_SET, &hu->flags)) {
+			if (hdev) {
+				hci_unregister_dev(hdev);
+				hci_free_dev(hdev);
+			}
 			hu->proto->close(hu);
-			hci_unregister_dev(hdev);
-			hci_free_dev(hdev);
 		}
 	}
 }
diff -Naur a/drivers/char/ipmi/ipmi_bt_sm.c b/drivers/char/ipmi/ipmi_bt_sm.c
--- a/drivers/char/ipmi/ipmi_bt_sm.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/char/ipmi/ipmi_bt_sm.c	2013-11-01 18:44:48.065809559 +0200
@@ -95,9 +95,9 @@
 	enum bt_states	state;
 	unsigned char	seq;		/* BT sequence number */
 	struct si_sm_io	*io;
-	unsigned char	write_data[IPMI_MAX_MSG_LENGTH];
+	unsigned char	write_data[IPMI_MAX_MSG_LENGTH + 2]; /* +2 for memcpy */
 	int		write_count;
-	unsigned char	read_data[IPMI_MAX_MSG_LENGTH];
+	unsigned char	read_data[IPMI_MAX_MSG_LENGTH + 2]; /* +2 for memcpy */
 	int		read_count;
 	int		truncated;
 	long		timeout;	/* microseconds countdown */
diff -Naur a/drivers/char/random.c b/drivers/char/random.c
--- a/drivers/char/random.c	2013-11-01 20:19:18.569928068 +0200
+++ b/drivers/char/random.c	2013-11-01 18:44:48.157810013 +0200
@@ -125,20 +125,32 @@
  * The current exported interfaces for gathering environmental noise
  * from the devices are:
  *
+ *	void add_device_randomness(const void *buf, unsigned int size);
  * 	void add_input_randomness(unsigned int type, unsigned int code,
  *                                unsigned int value);
- * 	void add_interrupt_randomness(int irq);
+ *	void add_interrupt_randomness(int irq, int irq_flags);
+ * 	void add_disk_randomness(struct gendisk *disk);
+ *
+ * add_device_randomness() is for adding data to the random pool that
+ * is likely to differ between two devices (or possibly even per boot).
+ * This would be things like MAC addresses or serial numbers, or the
+ * read-out of the RTC. This does *not* add any actual entropy to the
+ * pool, but it initializes the pool to different values for devices
+ * that might otherwise be identical and have very little entropy
+ * available to them (particularly common in the embedded world).
  *
  * add_input_randomness() uses the input layer interrupt timing, as well as
  * the event type information from the hardware.
  *
- * add_interrupt_randomness() uses the inter-interrupt timing as random
- * inputs to the entropy pool.  Note that not all interrupts are good
- * sources of randomness!  For example, the timer interrupts is not a
- * good choice, because the periodicity of the interrupts is too
- * regular, and hence predictable to an attacker.  Disk interrupts are
- * a better measure, since the timing of the disk interrupts are more
- * unpredictable.
+ * add_interrupt_randomness() uses the interrupt timing as random
+ * inputs to the entropy pool. Using the cycle counters and the irq source
+ * as inputs, it feeds the randomness roughly once a second.
+ *
+ * add_disk_randomness() uses what amounts to the seek time of block
+ * layer request events, on a per-disk_devt basis, as input to the
+ * entropy pool. Note that high-speed solid state drives with very low
+ * seek times do not make for good sources of entropy, as their seek
+ * times are usually fairly consistent.
  *
  * All of these routines try to estimate how many bits of randomness a
  * particular randomness source.  They do this by keeping track of the
@@ -241,6 +253,8 @@
 #include <linux/percpu.h>
 #include <linux/cryptohash.h>
 #include <linux/fips.h>
+#include <linux/ptrace.h>
+#include <linux/kmemcheck.h>
 
 #ifdef CONFIG_GENERIC_HARDIRQS
 # include <linux/irq.h>
@@ -249,6 +263,7 @@
 #include <asm/processor.h>
 #include <asm/uaccess.h>
 #include <asm/irq.h>
+#include <asm/irq_regs.h>
 #include <asm/io.h>
 
 /*
@@ -257,6 +272,9 @@
 #define INPUT_POOL_WORDS 128
 #define OUTPUT_POOL_WORDS 32
 #define SEC_XFER_SIZE 512
+#define EXTRACT_SIZE 10
+
+#define LONGS(x) (((x) + sizeof(unsigned long) - 1)/sizeof(unsigned long))
 
 /*
  * The minimum number of bits of entropy before we wake up a read on
@@ -406,15 +424,17 @@
 	struct poolinfo *poolinfo;
 	__u32 *pool;
 	const char *name;
-	int limit;
 	struct entropy_store *pull;
+	int limit;
 
 	/* read-write data: */
 	spinlock_t lock;
 	unsigned add_ptr;
+	unsigned input_rotate;
 	int entropy_count;
-	int input_rotate;
-	__u8 *last_data;
+	int entropy_total;
+	unsigned int initialized:1;
+	__u8 last_data[EXTRACT_SIZE];
 };
 
 static __u32 input_pool_data[INPUT_POOL_WORDS];
@@ -446,6 +466,10 @@
 	.pool = nonblocking_pool_data
 };
 
+static __u32 const twist_table[8] = {
+	0x00000000, 0x3b6e20c8, 0x76dc4190, 0x4db26158,
+	0xedb88320, 0xd6d6a3e8, 0x9b64c2b0, 0xa00ae278 };
+
 /*
  * This function adds bytes into the entropy "pool".  It does not
  * update the entropy estimate.  The caller should call
@@ -456,29 +480,24 @@
  * it's cheap to do so and helps slightly in the expected case where
  * the entropy is concentrated in the low-order bits.
  */
-static void mix_pool_bytes_extract(struct entropy_store *r, const void *in,
-				   int nbytes, __u8 out[64])
+static void __mix_pool_bytes(struct entropy_store *r, const void *in,
+			     int nbytes, __u8 out[64])
 {
-	static __u32 const twist_table[8] = {
-		0x00000000, 0x3b6e20c8, 0x76dc4190, 0x4db26158,
-		0xedb88320, 0xd6d6a3e8, 0x9b64c2b0, 0xa00ae278 };
 	unsigned long i, j, tap1, tap2, tap3, tap4, tap5;
 	int input_rotate;
 	int wordmask = r->poolinfo->poolwords - 1;
 	const char *bytes = in;
 	__u32 w;
-	unsigned long flags;
 
-	/* Taps are constant, so we can load them without holding r->lock.  */
 	tap1 = r->poolinfo->tap1;
 	tap2 = r->poolinfo->tap2;
 	tap3 = r->poolinfo->tap3;
 	tap4 = r->poolinfo->tap4;
 	tap5 = r->poolinfo->tap5;
 
-	spin_lock_irqsave(&r->lock, flags);
-	input_rotate = r->input_rotate;
-	i = r->add_ptr;
+	smp_rmb();
+	input_rotate = ACCESS_ONCE(r->input_rotate);
+	i = ACCESS_ONCE(r->add_ptr);
 
 	/* mix one byte at a time to simplify size handling and churn faster */
 	while (nbytes--) {
@@ -505,19 +524,53 @@
 		input_rotate += i ? 7 : 14;
 	}
 
-	r->input_rotate = input_rotate;
-	r->add_ptr = i;
+	ACCESS_ONCE(r->input_rotate) = input_rotate;
+	ACCESS_ONCE(r->add_ptr) = i;
+	smp_wmb();
 
 	if (out)
 		for (j = 0; j < 16; j++)
 			((__u32 *)out)[j] = r->pool[(i - j) & wordmask];
+}
 
+static void mix_pool_bytes(struct entropy_store *r, const void *in,
+			     int nbytes, __u8 out[64])
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&r->lock, flags);
+	__mix_pool_bytes(r, in, nbytes, out);
 	spin_unlock_irqrestore(&r->lock, flags);
 }
 
-static void mix_pool_bytes(struct entropy_store *r, const void *in, int bytes)
+struct fast_pool {
+	__u32		pool[4];
+	unsigned long	last;
+	unsigned short	count;
+	unsigned char	rotate;
+	unsigned char	last_timer_intr;
+};
+
+/*
+ * This is a fast mixing routine used by the interrupt randomness
+ * collector.  It's hardcoded for an 128 bit pool and assumes that any
+ * locks that might be needed are taken by the caller.
+ */
+static void fast_mix(struct fast_pool *f, const void *in, int nbytes)
 {
-       mix_pool_bytes_extract(r, in, bytes, NULL);
+	const char	*bytes = in;
+	__u32		w;
+	unsigned	i = f->count;
+	unsigned	input_rotate = f->rotate;
+
+	while (nbytes--) {
+		w = rol32(*bytes++, input_rotate & 31) ^ f->pool[i & 3] ^
+			f->pool[(i + 1) & 3];
+		f->pool[i & 3] = (w >> 3) ^ twist_table[w & 7];
+		input_rotate += (i++ & 3) ? 7 : 14;
+	}
+	f->count = i;
+	f->rotate = input_rotate;
 }
 
 /*
@@ -525,30 +578,34 @@
  */
 static void credit_entropy_bits(struct entropy_store *r, int nbits)
 {
-	unsigned long flags;
-	int entropy_count;
+	int entropy_count, orig;
 
 	if (!nbits)
 		return;
 
-	spin_lock_irqsave(&r->lock, flags);
-
 	DEBUG_ENT("added %d entropy credits to %s\n", nbits, r->name);
-	entropy_count = r->entropy_count;
+retry:
+	entropy_count = orig = ACCESS_ONCE(r->entropy_count);
 	entropy_count += nbits;
 	if (entropy_count < 0) {
 		DEBUG_ENT("negative entropy/overflow\n");
 		entropy_count = 0;
 	} else if (entropy_count > r->poolinfo->POOLBITS)
 		entropy_count = r->poolinfo->POOLBITS;
-	r->entropy_count = entropy_count;
+	if (cmpxchg(&r->entropy_count, orig, entropy_count) != orig)
+		goto retry;
+
+	if (!r->initialized && nbits > 0) {
+		r->entropy_total += nbits;
+		if (r->entropy_total > 128)
+			r->initialized = 1;
+	}
 
 	/* should we wake readers? */
 	if (r == &input_pool && entropy_count >= random_read_wakeup_thresh) {
 		wake_up_interruptible(&random_read_wait);
 		kill_fasync(&fasync, SIGIO, POLL_IN);
 	}
-	spin_unlock_irqrestore(&r->lock, flags);
 }
 
 /*********************************************************************
@@ -564,42 +621,24 @@
 	unsigned dont_count_entropy:1;
 };
 
-#ifndef CONFIG_GENERIC_HARDIRQS
-
-static struct timer_rand_state *irq_timer_state[NR_IRQS];
-
-static struct timer_rand_state *get_timer_rand_state(unsigned int irq)
-{
-	return irq_timer_state[irq];
-}
-
-static void set_timer_rand_state(unsigned int irq,
-				 struct timer_rand_state *state)
-{
-	irq_timer_state[irq] = state;
-}
-
-#else
-
-static struct timer_rand_state *get_timer_rand_state(unsigned int irq)
-{
-	struct irq_desc *desc;
-
-	desc = irq_to_desc(irq);
-
-	return desc->timer_rand_state;
-}
-
-static void set_timer_rand_state(unsigned int irq,
-				 struct timer_rand_state *state)
+/*
+ * Add device- or boot-specific data to the input and nonblocking
+ * pools to help initialize them to unique values.
+ *
+ * None of this adds any entropy, it is meant to avoid the
+ * problem of the nonblocking pool having similar initial state
+ * across largely identical devices.
+ */
+void add_device_randomness(const void *buf, unsigned int size)
 {
-	struct irq_desc *desc;
+	unsigned long time = get_cycles() ^ jiffies;
 
-	desc = irq_to_desc(irq);
-
-	desc->timer_rand_state = state;
+	mix_pool_bytes(&input_pool, buf, size, NULL);
+	mix_pool_bytes(&input_pool, &time, sizeof(time), NULL);
+	mix_pool_bytes(&nonblocking_pool, buf, size, NULL);
+	mix_pool_bytes(&nonblocking_pool, &time, sizeof(time), NULL);
 }
-#endif
+EXPORT_SYMBOL(add_device_randomness);
 
 static struct timer_rand_state input_timer_state;
 
@@ -616,8 +655,8 @@
 static void add_timer_randomness(struct timer_rand_state *state, unsigned num)
 {
 	struct {
-		cycles_t cycles;
 		long jiffies;
+		unsigned cycles;
 		unsigned num;
 	} sample;
 	long delta, delta2, delta3;
@@ -631,7 +670,7 @@
 	sample.jiffies = jiffies;
 	sample.cycles = get_cycles();
 	sample.num = num;
-	mix_pool_bytes(&input_pool, &sample, sizeof(sample));
+	mix_pool_bytes(&input_pool, &sample, sizeof(sample), NULL);
 
 	/*
 	 * Calculate number of bits of randomness we probably added.
@@ -688,17 +727,48 @@
 }
 EXPORT_SYMBOL_GPL(add_input_randomness);
 
-void add_interrupt_randomness(int irq)
+static DEFINE_PER_CPU(struct fast_pool, irq_randomness);
+
+void add_interrupt_randomness(int irq, int irq_flags)
 {
-	struct timer_rand_state *state;
+	struct entropy_store	*r;
+	struct fast_pool	*fast_pool = &__get_cpu_var(irq_randomness);
+	struct pt_regs		*regs = get_irq_regs();
+	unsigned long		now = jiffies;
+	__u32			input[4], cycles = get_cycles();
+
+	input[0] = cycles ^ jiffies;
+	input[1] = irq;
+	if (regs) {
+		__u64 ip = instruction_pointer(regs);
+		input[2] = ip;
+		input[3] = ip >> 32;
+	}
 
-	state = get_timer_rand_state(irq);
+	fast_mix(fast_pool, input, sizeof(input));
 
-	if (state == NULL)
+	if ((fast_pool->count & 1023) &&
+	    !time_after(now, fast_pool->last + HZ))
 		return;
 
-	DEBUG_ENT("irq event %d\n", irq);
-	add_timer_randomness(state, 0x100 + irq);
+	fast_pool->last = now;
+
+	r = nonblocking_pool.initialized ? &input_pool : &nonblocking_pool;
+	__mix_pool_bytes(r, &fast_pool->pool, sizeof(fast_pool->pool), NULL);
+	/*
+	 * If we don't have a valid cycle counter, and we see
+	 * back-to-back timer interrupts, then skip giving credit for
+	 * any entropy.
+	 */
+	if (cycles == 0) {
+		if (irq_flags & __IRQF_TIMER) {
+			if (fast_pool->last_timer_intr)
+				return;
+			fast_pool->last_timer_intr = 1;
+		} else
+			fast_pool->last_timer_intr = 0;
+	}
+	credit_entropy_bits(r, 1);
 }
 
 #ifdef CONFIG_BLOCK
@@ -722,7 +792,7 @@
 /* Note that <count> parameter is in BITS                         */
 void add_random_data(const char* rdata, int count)
 {
-	mix_pool_bytes(&input_pool, (const __u32 *)rdata, count);
+     mix_pool_bytes(&input_pool, (const __u32 *)rdata, count, NULL);
 	credit_entropy_bits(&input_pool, count*8);
 
 	if(input_pool.entropy_count >= random_read_wakeup_thresh)
@@ -748,7 +818,7 @@
  */
 static void xfer_secondary_pool(struct entropy_store *r, size_t nbytes)
 {
-	__u32 tmp[OUTPUT_POOL_WORDS];
+	__u32	tmp[OUTPUT_POOL_WORDS];
 
 	if (r->pull && r->entropy_count < nbytes * 8 &&
 	    r->entropy_count < r->poolinfo->POOLBITS) {
@@ -767,7 +837,7 @@
 
 		bytes = extract_entropy(r->pull, tmp, bytes,
 					random_read_wakeup_thresh / 8, rsvd);
-		mix_pool_bytes(r, tmp, bytes);
+		mix_pool_bytes(r, tmp, bytes, NULL);
 		credit_entropy_bits(r, bytes*8);
 	}
 }
@@ -826,13 +896,19 @@
 static void extract_buf(struct entropy_store *r, __u8 *out)
 {
 	int i;
-	__u32 hash[5], workspace[SHA_WORKSPACE_WORDS];
+	union {
+		__u32 w[5];
+		unsigned long l[LONGS(EXTRACT_SIZE)];
+	} hash;
+	__u32 workspace[SHA_WORKSPACE_WORDS];
 	__u8 extract[64];
+	unsigned long flags;
 
 	/* Generate a hash across the pool, 16 words (512 bits) at a time */
-	sha_init(hash);
+	sha_init(hash.w);
+	spin_lock_irqsave(&r->lock, flags);
 	for (i = 0; i < r->poolinfo->poolwords; i += 16)
-		sha_transform(hash, (__u8 *)(r->pool + i), workspace);
+		sha_transform(hash.w, (__u8 *)(r->pool + i), workspace);
 
 	/*
 	 * We mix the hash back into the pool to prevent backtracking
@@ -843,13 +919,14 @@
 	 * brute-forcing the feedback as hard as brute-forcing the
 	 * hash.
 	 */
-	mix_pool_bytes_extract(r, hash, sizeof(hash), extract);
+	__mix_pool_bytes(r, hash.w, sizeof(hash.w), extract);
+	spin_unlock_irqrestore(&r->lock, flags);
 
 	/*
 	 * To avoid duplicates, we atomically extract a portion of the
 	 * pool while mixing, and hash one final time.
 	 */
-	sha_transform(hash, extract, workspace);
+	sha_transform(hash.w, extract, workspace);
 	memset(extract, 0, sizeof(extract));
 	memset(workspace, 0, sizeof(workspace));
 
@@ -858,19 +935,30 @@
 	 * pattern, we fold it in half. Thus, we always feed back
 	 * twice as much data as we output.
 	 */
-	hash[0] ^= hash[3];
-	hash[1] ^= hash[4];
-	hash[2] ^= rol32(hash[2], 16);
-	memcpy(out, hash, EXTRACT_SIZE);
-	memset(hash, 0, sizeof(hash));
+	hash.w[0] ^= hash.w[3];
+	hash.w[1] ^= hash.w[4];
+	hash.w[2] ^= rol32(hash.w[2], 16);
+
+	/*
+	 * If we have a architectural hardware random number
+	 * generator, mix that in, too.
+	 */
+	for (i = 0; i < LONGS(EXTRACT_SIZE); i++) {
+		unsigned long v;
+		if (!arch_get_random_long(&v))
+			break;
+		hash.l[i] ^= v;
+	}
+
+	memcpy(out, &hash, EXTRACT_SIZE);
+	memset(&hash, 0, sizeof(hash));
 }
 
 static ssize_t extract_entropy(struct entropy_store *r, void *buf,
-			       size_t nbytes, int min, int reserved)
+				 size_t nbytes, int min, int reserved)
 {
 	ssize_t ret = 0, i;
 	__u8 tmp[EXTRACT_SIZE];
-	unsigned long flags;
 
 	xfer_secondary_pool(r, nbytes);
 	nbytes = account(r, nbytes, min, reserved);
@@ -878,7 +966,9 @@
 	while (nbytes) {
 		extract_buf(r, tmp);
 
-		if (r->last_data) {
+		if (fips_enabled) {
+			unsigned long flags;
+
 			spin_lock_irqsave(&r->lock, flags);
 			if (!memcmp(tmp, r->last_data, EXTRACT_SIZE))
 				panic("Hardware RNG duplicated output!\n");
@@ -937,8 +1027,9 @@
 
 /*
  * This function is the exported kernel interface.  It returns some
- * number of good random numbers, suitable for seeding TCP sequence
- * numbers, etc.
+ * number of good random numbers, suitable for key generation, seeding
+ * TCP sequence numbers, etc.  It does not use the hw random number
+ * generator, if available; use get_random_bytes_arch() for that.
  */
 void get_random_bytes(void *buf, int nbytes)
 {
@@ -947,6 +1038,38 @@
 EXPORT_SYMBOL(get_random_bytes);
 
 /*
+ * This function will use the architecture-specific hardware random
+ * number generator if it is available.  The arch-specific hw RNG will
+ * almost certainly be faster than what we can do in software, but it
+ * is impossible to verify that it is implemented securely (as
+ * opposed, to, say, the AES encryption of a sequence number using a
+ * key known by the NSA).  So it's useful if we need the speed, but
+ * only if we're willing to trust the hardware manufacturer not to
+ * have put in a back door.
+ */
+void get_random_bytes_arch(void *buf, int nbytes)
+{
+	char *p = buf;
+
+	while (nbytes) {
+		unsigned long v;
+		int chunk = min(nbytes, (int)sizeof(unsigned long));
+
+		if (!arch_get_random_long(&v))
+			break;
+
+		memcpy(p, &v, chunk);
+		p += chunk;
+		nbytes -= chunk;
+	}
+
+	if (nbytes)
+		extract_entropy(&nonblocking_pool, p, nbytes, 0, 0);
+}
+EXPORT_SYMBOL(get_random_bytes_arch);
+
+
+/*
  * init_std_data - initialize pool with system data
  *
  * @r: pool to initialize
@@ -957,21 +1080,31 @@
  */
 static void init_std_data(struct entropy_store *r)
 {
-	ktime_t now;
-	unsigned long flags;
+	int i;
+	ktime_t now = ktime_get_real();
+	unsigned long rv;
 
-	spin_lock_irqsave(&r->lock, flags);
 	r->entropy_count = 0;
-	spin_unlock_irqrestore(&r->lock, flags);
-
-	now = ktime_get_real();
-	mix_pool_bytes(r, &now, sizeof(now));
-	mix_pool_bytes(r, utsname(), sizeof(*(utsname())));
-	/* Enable continuous test in fips mode */
-	if (fips_enabled)
-		r->last_data = kmalloc(EXTRACT_SIZE, GFP_KERNEL);
+	r->entropy_total = 0;
+	mix_pool_bytes(r, &now, sizeof(now), NULL);
+	for (i = r->poolinfo->POOLBYTES; i > 0; i -= sizeof(rv)) {
+		if (!arch_get_random_long(&rv))
+			break;
+		mix_pool_bytes(r, &rv, sizeof(rv), NULL);
+	}
+	mix_pool_bytes(r, utsname(), sizeof(*(utsname())), NULL);
 }
 
+/*
+ * Note that setup_arch() may call add_device_randomness()
+ * long before we get here. This allows seeding of the pools
+ * with some platform dependent data very early in the boot
+ * process. But it limits our options here. We must use
+ * statically allocated structures that already have all
+ * initializations complete at compile time. We should also
+ * take care not to overwrite the precious per platform data
+ * we were given.
+ */
 static int rand_initialize(void)
 {
 	init_std_data(&input_pool);
@@ -981,24 +1114,6 @@
 }
 module_init(rand_initialize);
 
-void rand_initialize_irq(int irq)
-{
-	struct timer_rand_state *state;
-
-	state = get_timer_rand_state(irq);
-
-	if (state)
-		return;
-
-	/*
-	 * If kzalloc returns null, we just won't use that entropy
-	 * source.
-	 */
-	state = kzalloc(sizeof(struct timer_rand_state), GFP_KERNEL);
-	if (state)
-		set_timer_rand_state(irq, state);
-}
-
 #ifdef CONFIG_BLOCK
 void rand_initialize_disk(struct gendisk *disk)
 {
@@ -1106,7 +1221,7 @@
 		count -= bytes;
 		p += bytes;
 
-		mix_pool_bytes(r, buf, bytes);
+		mix_pool_bytes(r, buf, bytes, NULL);
 		cond_resched();
 	}
 
@@ -1247,10 +1362,15 @@
 	uuid = table->data;
 	if (!uuid) {
 		uuid = tmp_uuid;
-		uuid[8] = 0;
-	}
-	if (uuid[8] == 0)
 		generate_random_uuid(uuid);
+	} else {
+		static DEFINE_SPINLOCK(bootid_spinlock);
+
+		spin_lock(&bootid_spinlock);
+		if (!uuid[8])
+			generate_random_uuid(uuid);
+		spin_unlock(&bootid_spinlock);
+	}
 
 	sprintf(buf, "%02x%02x%02x%02x-%02x%02x-%02x%02x-%02x%02x-"
 		"%02x%02x%02x%02x%02x%02x",
@@ -1373,9 +1493,14 @@
 DEFINE_PER_CPU(__u32 [MD5_DIGEST_WORDS], get_random_int_hash);
 unsigned int get_random_int(void)
 {
-	__u32 *hash = get_cpu_var(get_random_int_hash);
+	__u32 *hash;
 	unsigned int ret;
 
+	if (arch_get_random_int(&ret))
+		return ret;
+
+	hash = get_cpu_var(get_random_int_hash);
+
 	hash[0] += current->pid + jiffies + get_cycles();
 	md5_transform(hash, random_int_secret);
 	ret = hash[0];
diff -Naur a/drivers/char/tty_audit.c b/drivers/char/tty_audit.c
--- a/drivers/char/tty_audit.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/char/tty_audit.c	2013-11-01 18:44:48.225810346 +0200
@@ -94,8 +94,10 @@
 {
 	if (buf->valid == 0)
 		return;
-	if (audit_enabled == 0)
+	if (audit_enabled == 0) {
+		buf->valid = 0;
 		return;
+	}
 	tty_audit_log("tty", tsk, loginuid, sessionid, buf->major, buf->minor,
 		      buf->data, buf->valid);
 	buf->valid = 0;
diff -Naur a/drivers/dma/ioat/dma_v2.c b/drivers/dma/ioat/dma_v2.c
--- a/drivers/dma/ioat/dma_v2.c	2013-11-01 20:18:03.821557409 +0200
+++ b/drivers/dma/ioat/dma_v2.c	2013-11-01 18:44:48.281810622 +0200
@@ -51,48 +51,40 @@
 
 void __ioat2_issue_pending(struct ioat2_dma_chan *ioat)
 {
-	void * __iomem reg_base = ioat->base.reg_base;
+	struct ioat_chan_common *chan = &ioat->base;
 
-	ioat->pending = 0;
 	ioat->dmacount += ioat2_ring_pending(ioat);
 	ioat->issued = ioat->head;
 	/* make descriptor updates globally visible before notifying channel */
 	wmb();
-	writew(ioat->dmacount, reg_base + IOAT_CHAN_DMACOUNT_OFFSET);
-	dev_dbg(to_dev(&ioat->base),
+	writew(ioat->dmacount, chan->reg_base + IOAT_CHAN_DMACOUNT_OFFSET);
+	dev_dbg(to_dev(chan),
 		"%s: head: %#x tail: %#x issued: %#x count: %#x\n",
 		__func__, ioat->head, ioat->tail, ioat->issued, ioat->dmacount);
 }
 
-void ioat2_issue_pending(struct dma_chan *chan)
+void ioat2_issue_pending(struct dma_chan *c)
 {
-	struct ioat2_dma_chan *ioat = to_ioat2_chan(chan);
+	struct ioat2_dma_chan *ioat = to_ioat2_chan(c);
 
-	spin_lock_bh(&ioat->ring_lock);
-	if (ioat->pending == 1)
+	if (ioat2_ring_pending(ioat)) {
+		spin_lock_bh(&ioat->ring_lock);
 		__ioat2_issue_pending(ioat);
-	spin_unlock_bh(&ioat->ring_lock);
+		spin_unlock_bh(&ioat->ring_lock);
+	}
 }
 
 /**
  * ioat2_update_pending - log pending descriptors
  * @ioat: ioat2+ channel
  *
- * set pending to '1' unless pending is already set to '2', pending == 2
- * indicates that submission is temporarily blocked due to an in-flight
- * reset.  If we are already above the ioat_pending_level threshold then
- * just issue pending.
- *
- * called with ring_lock held
+ * Check if the number of unsubmitted descriptors has exceeded the
+ * watermark.  Called with ring_lock held
  */
 static void ioat2_update_pending(struct ioat2_dma_chan *ioat)
 {
-	if (unlikely(ioat->pending == 2))
-		return;
-	else if (ioat2_ring_pending(ioat) > ioat_pending_level)
+	if (ioat2_ring_pending(ioat) > ioat_pending_level)
 		__ioat2_issue_pending(ioat);
-	else
-		ioat->pending = 1;
 }
 
 static void __ioat2_start_null_desc(struct ioat2_dma_chan *ioat)
@@ -546,7 +538,6 @@
 	ioat->head = 0;
 	ioat->issued = 0;
 	ioat->tail = 0;
-	ioat->pending = 0;
 	ioat->alloc_order = order;
 	spin_unlock_bh(&ioat->ring_lock);
 
@@ -815,7 +806,6 @@
 
 	chan->last_completion = 0;
 	chan->completion_dma = 0;
-	ioat->pending = 0;
 	ioat->dmacount = 0;
 }
 
diff -Naur a/drivers/dma/ioat/dma_v2.h b/drivers/dma/ioat/dma_v2.h
--- a/drivers/dma/ioat/dma_v2.h	2013-11-01 20:18:03.821557409 +0200
+++ b/drivers/dma/ioat/dma_v2.h	2013-11-01 18:44:48.281810622 +0200
@@ -47,7 +47,6 @@
  * @head: allocated index
  * @issued: hardware notification point
  * @tail: cleanup index
- * @pending: lock free indicator for issued != head
  * @dmacount: identical to 'head' except for occasionally resetting to zero
  * @alloc_order: log2 of the number of allocated descriptors
  * @ring: software ring buffer implementation of hardware ring
@@ -61,7 +60,6 @@
 	u16 tail;
 	u16 dmacount;
 	u16 alloc_order;
-	int pending;
 	struct ioat_ring_ent **ring;
 	spinlock_t ring_lock;
 };
diff -Naur a/drivers/firmware/dmi_scan.c b/drivers/firmware/dmi_scan.c
--- a/drivers/firmware/dmi_scan.c	2013-11-01 20:18:03.841557498 +0200
+++ b/drivers/firmware/dmi_scan.c	2013-11-01 18:44:48.329810860 +0200
@@ -6,6 +6,7 @@
 #include <linux/efi.h>
 #include <linux/bootmem.h>
 #include <linux/slab.h>
+#include <linux/random.h>
 #include <asm/dmi.h>
 
 /*
@@ -111,6 +112,8 @@
 
 	dmi_table(buf, dmi_len, dmi_num, decode, NULL);
 
+	add_device_randomness(buf, dmi_len);
+
 	dmi_iounmap(buf, dmi_len);
 	return 0;
 }
diff -Naur a/drivers/gpu/drm/i915/intel_display.c b/drivers/gpu/drm/i915/intel_display.c
--- a/drivers/gpu/drm/i915/intel_display.c	2013-11-01 20:18:03.889557736 +0200
+++ b/drivers/gpu/drm/i915/intel_display.c	2013-11-01 18:44:48.385811144 +0200
@@ -4355,17 +4355,18 @@
 		dev_priv->display.update_wm = g4x_update_wm;
 	else if (IS_I965G(dev))
 		dev_priv->display.update_wm = i965_update_wm;
-	else if (IS_I9XX(dev) || IS_MOBILE(dev)) {
+	else if (IS_I9XX(dev)) {
 		dev_priv->display.update_wm = i9xx_update_wm;
 		dev_priv->display.get_fifo_size = i9xx_get_fifo_size;
+	} else if (IS_I85X(dev)) {
+		dev_priv->display.update_wm = i9xx_update_wm;
+		dev_priv->display.get_fifo_size = i85x_get_fifo_size;
 	} else {
-		if (IS_I85X(dev))
-			dev_priv->display.get_fifo_size = i85x_get_fifo_size;
-		else if (IS_845G(dev))
+		dev_priv->display.update_wm = i830_update_wm;
+		if (IS_845G(dev))
 			dev_priv->display.get_fifo_size = i845_get_fifo_size;
 		else
 			dev_priv->display.get_fifo_size = i830_get_fifo_size;
-		dev_priv->display.update_wm = i830_update_wm;
 	}
 }
 
diff -Naur a/drivers/hwmon/stm-temp.c b/drivers/hwmon/stm-temp.c
--- a/drivers/hwmon/stm-temp.c	2013-11-01 20:19:18.581928127 +0200
+++ b/drivers/hwmon/stm-temp.c	2013-11-01 18:44:48.545811931 +0200
@@ -48,9 +48,7 @@
 
 	overflow |= sysconf_read(sensor->overflow);
 
-	data = (data + 20) * 1000;
-
-	*temperature = data;
+	*temperature = (data + sensor->plat_data->correction_factor) * 1000;
 
 	return overflow;
 }
diff -Naur a/drivers/infiniband/ulp/ipoib/ipoib_main.c b/drivers/infiniband/ulp/ipoib/ipoib_main.c
--- a/drivers/infiniband/ulp/ipoib/ipoib_main.c	2013-11-01 20:18:04.021558397 +0200
+++ b/drivers/infiniband/ulp/ipoib/ipoib_main.c	2013-11-01 18:44:49.601817174 +0200
@@ -157,7 +157,7 @@
 
 	netif_stop_queue(dev);
 
-	ipoib_ib_dev_down(dev, 0);
+	ipoib_ib_dev_down(dev, 1);
 	ipoib_ib_dev_stop(dev, 0);
 
 	if (!test_bit(IPOIB_FLAG_SUBINTERFACE, &priv->flags)) {
diff -Naur a/drivers/infiniband/ulp/ipoib/ipoib_multicast.c b/drivers/infiniband/ulp/ipoib/ipoib_multicast.c
--- a/drivers/infiniband/ulp/ipoib/ipoib_multicast.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/infiniband/ulp/ipoib/ipoib_multicast.c	2013-11-01 18:44:49.601817174 +0200
@@ -188,7 +188,9 @@
 
 	mcast->mcmember = *mcmember;
 
-	/* Set the cached Q_Key before we attach if it's the broadcast group */
+	/* Set the multicast MTU and cached Q_Key before we attach if it's
+	 * the broadcast group.
+	 */
 	if (!memcmp(mcast->mcmember.mgid.raw, priv->dev->broadcast + 4,
 		    sizeof (union ib_gid))) {
 		spin_lock_irq(&priv->lock);
@@ -196,10 +198,17 @@
 			spin_unlock_irq(&priv->lock);
 			return -EAGAIN;
 		}
+		priv->mcast_mtu = IPOIB_UD_MTU(ib_mtu_enum_to_int(priv->broadcast->mcmember.mtu));
 		priv->qkey = be32_to_cpu(priv->broadcast->mcmember.qkey);
 		spin_unlock_irq(&priv->lock);
 		priv->tx_wr.wr.ud.remote_qkey = priv->qkey;
 		set_qkey = 1;
+
+		if (!ipoib_cm_admin_enabled(dev)) {
+			rtnl_lock();
+			dev_set_mtu(dev, min(priv->mcast_mtu, priv->admin_mtu));
+			rtnl_unlock();
+		}
 	}
 
 	if (!test_bit(IPOIB_MCAST_FLAG_SENDONLY, &mcast->flags)) {
@@ -588,14 +597,6 @@
 		return;
 	}
 
-	priv->mcast_mtu = IPOIB_UD_MTU(ib_mtu_enum_to_int(priv->broadcast->mcmember.mtu));
-
-	if (!ipoib_cm_admin_enabled(dev)) {
-		rtnl_lock();
-		dev_set_mtu(dev, min(priv->mcast_mtu, priv->admin_mtu));
-		rtnl_unlock();
-	}
-
 	ipoib_dbg_mcast(priv, "successfully joined all multicast groups\n");
 
 	clear_bit(IPOIB_MCAST_RUN, &priv->flags);
diff -Naur a/drivers/input/joystick/xpad.c b/drivers/input/joystick/xpad.c
--- a/drivers/input/joystick/xpad.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/input/joystick/xpad.c	2013-11-01 18:44:49.625817285 +0200
@@ -111,6 +111,7 @@
 	{ 0x045e, 0x0285, "Microsoft X-Box pad (Japan)", MAP_DPAD_TO_AXES, XTYPE_XBOX },
 	{ 0x045e, 0x0287, "Microsoft Xbox Controller S", MAP_DPAD_TO_AXES, XTYPE_XBOX },
 	{ 0x045e, 0x0719, "Xbox 360 Wireless Receiver", MAP_DPAD_TO_BUTTONS, XTYPE_XBOX360W },
+	{ 0x045e, 0x0291, "Xbox 360 Wireless Receiver", MAP_DPAD_TO_BUTTONS, XTYPE_XBOX360W },
 	{ 0x0c12, 0x8809, "RedOctane Xbox Dance Pad", MAP_DPAD_TO_BUTTONS, XTYPE_XBOX },
 	{ 0x044f, 0x0f07, "Thrustmaster, Inc. Controller", MAP_DPAD_TO_AXES, XTYPE_XBOX },
 	{ 0x046d, 0xc242, "Logitech Chillstream Controller", MAP_DPAD_TO_AXES, XTYPE_XBOX360 },
@@ -421,6 +422,8 @@
 	case -ECONNRESET:
 	case -ENOENT:
 	case -ESHUTDOWN:
+	case -EPIPE:
+	case -EPROTO:
 		/* this urb is terminated, clean up */
 		dbg("%s - urb shutting down with status: %d",
 			__func__, status);
@@ -481,6 +484,8 @@
 	case -ECONNRESET:
 	case -ENOENT:
 	case -ESHUTDOWN:
+	case -EPIPE:
+	case -EPROTO:
 		/* this urb is terminated, clean up */
 		dbg("%s - urb shutting down with status: %d", __func__, status);
 		return;
diff -Naur a/drivers/isdn/isdnloop/isdnloop.c b/drivers/isdn/isdnloop/isdnloop.c
--- a/drivers/isdn/isdnloop/isdnloop.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/isdn/isdnloop/isdnloop.c	2013-11-01 18:44:49.817818245 +0200
@@ -15,7 +15,6 @@
 #include <linux/sched.h>
 #include "isdnloop.h"
 
-static char *revision = "$Revision: 1.11.6.7 $";
 static char *isdnloop_id = "loop0";
 
 MODULE_DESCRIPTION("ISDN4Linux: Pseudo Driver that simulates an ISDN card");
@@ -1493,17 +1492,6 @@
 static int __init
 isdnloop_init(void)
 {
-	char *p;
-	char rev[10];
-
-	if ((p = strchr(revision, ':'))) {
-		strcpy(rev, p + 1);
-		p = strchr(rev, '$');
-		*p = 0;
-	} else
-		strcpy(rev, " ??? ");
-	printk(KERN_NOTICE "isdnloop-ISDN-driver Rev%s\n", rev);
-
 	if (isdnloop_id)
 		return (isdnloop_addcard(isdnloop_id));
 
diff -Naur a/drivers/mfd/wm831x-otp.c b/drivers/mfd/wm831x-otp.c
--- a/drivers/mfd/wm831x-otp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mfd/wm831x-otp.c	2013-11-01 18:44:50.821823219 +0200
@@ -18,6 +18,7 @@
 #include <linux/bcd.h>
 #include <linux/delay.h>
 #include <linux/mfd/core.h>
+#include <linux/random.h>
 
 #include <linux/mfd/wm831x/core.h>
 #include <linux/mfd/wm831x/otp.h>
@@ -66,6 +67,7 @@
 
 int wm831x_otp_init(struct wm831x *wm831x)
 {
+	char uuid[WM831X_UNIQUE_ID_LEN];
 	int ret;
 
 	ret = device_create_file(wm831x->dev, &dev_attr_unique_id);
@@ -73,6 +75,12 @@
 		dev_err(wm831x->dev, "Unique ID attribute not created: %d\n",
 			ret);
 
+	ret = wm831x_unique_id_read(wm831x, uuid);
+	if (ret == 0)
+		add_device_randomness(uuid, sizeof(uuid));
+	else
+		dev_err(wm831x->dev, "Failed to read UUID: %d\n", ret);
+
 	return ret;
 }
 
diff -Naur a/drivers/mtd/devices/Kconfig b/drivers/mtd/devices/Kconfig
--- a/drivers/mtd/devices/Kconfig	2013-11-01 20:19:18.737928897 +0200
+++ b/drivers/mtd/devices/Kconfig	2013-11-01 18:44:50.905823640 +0200
@@ -115,6 +115,13 @@
 	  This provides a MTD device driver for the ST Microelectronics SPI
 	  FSM Serial Flash Controller, and connected Serial Flash device.
 
+config STM_SPI_FSM_DEBUG
+	bool "STM SPI FSM debug support"
+	depends on MTD_STM_SPI_FSM
+	default n
+	help
+	  Display debug messages on the console.
+
 config MTD_SST25L
 	tristate "Support SST25L (non JEDEC) SPI Flash chips"
 	depends on SPI_MASTER
diff -Naur a/drivers/mtd/devices/m25p80.c b/drivers/mtd/devices/m25p80.c
--- a/drivers/mtd/devices/m25p80.c	2013-11-01 20:19:18.737928897 +0200
+++ b/drivers/mtd/devices/m25p80.c	2013-11-01 18:44:50.909823651 +0200
@@ -671,6 +671,7 @@
 
 	/* Numonyx devices */
 	{ "n25q128", 0x20ba18, 0, 64 * 1024, 256, },
+	{ "n25q64", 0x20ba17, 0, 64 * 1024, 128, },
 
 	/* Winbond -- w25x "blocks" are 64K, "sectors" are 4KiB */
 	{ "w25x10", 0xef3011, 0, 64 * 1024, 2, SECT_4K, },
diff -Naur a/drivers/mtd/devices/stm_spi_fsm.c b/drivers/mtd/devices/stm_spi_fsm.c
--- a/drivers/mtd/devices/stm_spi_fsm.c	2013-11-01 20:19:18.741928916 +0200
+++ b/drivers/mtd/devices/stm_spi_fsm.c	2013-11-01 18:44:50.917823700 +0200
@@ -25,8 +25,6 @@
 
 #define NAME		"stm-spi-fsm"
 
-/* #define DEBUG_SPI_FSM_SEQS */
-
 #define FLASH_PROBE_FREQ	10		/* Probe freq. (MHz) */
 #define FLASH_PAGESIZE		256
 #define FLASH_MAX_BUSY_WAIT	(10 * HZ)	/* Maximum erase time */
@@ -37,8 +35,9 @@
  */
 #define CFG_READ_TOGGLE32BITADDR		0x00000001
 #define CFG_WRITE_TOGGLE32BITADDR		0x00000002
-#define CFG_WRITE_EX32BITADDR_DELAY		0x00000004
 #define CFG_ERASESEC_TOGGLE32BITADDR		0x00000008
+#define CFG_S25FL_CHECK_ERROR_FLAGS		0x00000010
+#define CFG_N25Q_CHECK_ERROR_FLAGS		0x00000020
 
 
 /*
@@ -74,8 +73,6 @@
 #define FLASH_CMD_SE_32K	0x52
 #define FLASH_CMD_SE		0xd8
 #define FLASH_CMD_CHIPERASE	0xc7
-#define FLASH_CMD_WRVCR		0x81
-#define FLASH_CMD_RDVCR		0x85
 
 #define FLASH_CMD_READ		0x03	/* READ */
 #define FLASH_CMD_READ_FAST	0x0b	/* FAST READ */
@@ -93,22 +90,51 @@
 #define FLASH_CMD_EN4B_ADDR	0xb7	/* Enter 4-byte address mode */
 #define FLASH_CMD_EX4B_ADDR	0xe9	/* Exit 4-byte address mode */
 
+
+/* READ commands with 32-bit addressing (N25Q256 and S25FLxxxS) */
+#define FLASH_CMD_READ4		0x13
+#define FLASH_CMD_READ4_FAST	0x0c
+#define FLASH_CMD_READ4_1_1_2	0x3c
+#define FLASH_CMD_READ4_1_2_2	0xbc
+#define FLASH_CMD_READ4_1_1_4	0x6c
+#define FLASH_CMD_READ4_1_4_4	0xec
+
 /* N25Q Commands */
-/*	- READ with 32-bit addressing */
-#define N25Q_CMD_READ4			0x13
-#define N25Q_CMD_READ4_FAST		0x0c
-#define N25Q_CMD_READ4_1_1_2		0x3c
-#define N25Q_CMD_READ4_1_2_2		0xbc
-#define N25Q_CMD_READ4_1_1_4		0x6c
-#define N25Q_CMD_READ4_1_4_4		0xec
 /*	- READ/CLEAR Flags Status register */
-#define N25Q_CMD_RFSR			0x70
-#define N25Q_CMD_CLFSR			0x50
+#define N25Q_CMD_RFSR		0x70
+#define N25Q_CMD_CLFSR		0x50
+#define N25Q_CMD_WRVCR		0x81
+#define N25Q_CMD_RDVCR		0x85
+#define N25Q_CMD_RDVECR		0x65
+#define N25Q_CMD_RDNVCR		0xb5
+#define N25Q_CMD_WRNVCR		0xb1
+
+/* N25Q Flags Status Register: Error Flags */
+#define N25Q_FLAGS_ERR_ERASE	(1 << 5)
+#define N25Q_FLAGS_ERR_PROG	(1 << 4)
+#define N25Q_FLAGS_ERR_VPP	(1 << 3)
+#define N25Q_FLAGS_ERR_PROT	(1 << 1)
+#define N25Q_FLAGS_ERROR	(N25Q_FLAGS_ERR_ERASE	| \
+				 N25Q_FLAGS_ERR_PROG	| \
+				 N25Q_FLAGS_ERR_VPP	| \
+				 N25Q_FLAGS_ERR_PROT)
 
 /* MX25 Commands */
 /*	- Read Security Register (home of '4BYTE' status bit!) */
-#define MX25_CMD_RDSCUR			0x2B
+#define MX25_CMD_RDSCUR		0x2B
 
+/* S25FLxxxS commands */
+/*	- WRITE/ERASE 32-bit address commands */
+#define S25FL_CMD_WRITE4	0x12	/* Note, opcode shared with clashes with
+					 * 'FLASH_CMD_WRITE_1_4_4', as found on
+					 * N25Qxxx devices! */
+#define S25FL_CMD_WRITE4_1_1_4	0x34
+#define S25FL_CMD_SE4		0xdc
+/*	- Clear status register flags */
+#define S25FL_CMD_CLSR		0x30
+/*	- Read/Write 'DYB' lock bit */
+#define S25FL_CMD_DYBWR		0xe1
+#define S25FL_CMD_DYBRD		0xe0
 
 /* Status register */
 #define FLASH_STATUS_BUSY	0x01
@@ -116,9 +142,13 @@
 #define FLASH_STATUS_BP0	0x04
 #define FLASH_STATUS_BP1	0x08
 #define FLASH_STATUS_BP2	0x10
-#define FLASH_STATUS_TB		0x20
-#define FLASH_STATUS_SP		0x40
 #define FLASH_STATUS_SRWP0	0x80
+/*	- S25FL Error Flags */
+#define S25FL_STATUS_E_ERR	0x20
+#define S25FL_STATUS_P_ERR	0x40
+/*	- Timeout status */
+#define FLASH_STATUS_TIMEOUT	0xff
+
 
 /* Capabilities */
 #define FLASH_CAPS_SINGLE	0x000000ff
@@ -129,6 +159,7 @@
 #define FLASH_CAPS_CE		0x00000010
 #define FLASH_CAPS_32BITADDR	0x00000020
 #define FLASH_CAPS_RESET	0x00000040
+#define FLASH_CAPS_DYB_LOCKING	0x00000080
 
 #define FLASH_CAPS_DUAL		0x0000ff00
 #define FLASH_CAPS_READ_1_1_2	0x00000100
@@ -222,23 +253,6 @@
 		    SEQ_CFG_STARTSEQ),
 };
 
-static struct fsm_seq fsm_seq_wrvcr = {
-	.seq_opc[0] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
-		       SEQ_OPC_OPCODE(FLASH_CMD_WREN) | SEQ_OPC_CSDEASSERT),
-	.seq_opc[1] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
-		       SEQ_OPC_OPCODE(FLASH_CMD_WRVCR)),
-	.seq = {
-		FSM_INST_CMD1,
-		FSM_INST_CMD2,
-		FSM_INST_STA_WR1,
-		FSM_INST_STOP,
-	},
-	.seq_cfg = (SEQ_CFG_PADS_1 |
-		    SEQ_CFG_READNOTWRITE |
-		    SEQ_CFG_CSDEASSERT |
-		    SEQ_CFG_STARTSEQ),
-};
-
 static struct fsm_seq fsm_seq_erase_sector = {
 	/* 'addr_cfg' configured during initialisation */
 	.seq_opc = {
@@ -303,7 +317,7 @@
 /*
  * Debug code for examining FSM sequences
  */
-#ifdef DEBUG_SPI_FSM_SEQS
+#ifdef CONFIG_STM_SPI_FSM_DEBUG
 char *flash_cmd_strs[256] = {
 	[FLASH_CMD_WREN]	= "WREN",
 	[FLASH_CMD_WRDI]	= "WRDI",
@@ -315,7 +329,6 @@
 	[FLASH_CMD_SE_4K]	= "SE_4K",
 	[FLASH_CMD_SE_32K]	= "SE_32K",
 	[FLASH_CMD_CHIPERASE]	= "CHIPERASE",
-	[FLASH_CMD_WRVCR]	= "WRVCR",
 	[FLASH_CMD_READ]	= "READ",
 	[FLASH_CMD_READ_FAST]	= "READ_FAST",
 	[FLASH_CMD_READ_1_1_2]	= "READ_1_1_2",
@@ -326,15 +339,16 @@
 	[FLASH_CMD_WRITE_1_1_2]	= "WRITE_1_1_2",
 	[FLASH_CMD_WRITE_1_2_2]	= "WRITE_1_2_2",
 	[FLASH_CMD_WRITE_1_1_4]	= "WRITE_1_1_4",
-	[FLASH_CMD_WRITE_1_4_4] = "WRITE_1_4_4",
+	[FLASH_CMD_WRITE_1_4_4] = "WRITE_1_4_4", /* Note, opcode shared with
+						  * 'S25FL_CMD_WRITE4' */
 	[FLASH_CMD_EN4B_ADDR]	= "EN4B_ADDR",
 	[FLASH_CMD_EX4B_ADDR]	= "EX4B_ADDR",
-	[N25Q_CMD_READ4]	= "READ4",
-	[N25Q_CMD_READ4_FAST]	= "READ4_FAST",
-	[N25Q_CMD_READ4_1_1_2]	= "READ4_1_1_2",
-	[N25Q_CMD_READ4_1_2_2]	= "READ4_1_2_2",
-	[N25Q_CMD_READ4_1_1_4]	= "READ4_1_1_4",
-	[N25Q_CMD_READ4_1_4_4]	= "READ4_1_4_4",
+	[FLASH_CMD_READ4]	= "READ4",
+	[FLASH_CMD_READ4_FAST]	= "READ4_FAST",
+	[FLASH_CMD_READ4_1_1_2]	= "READ4_1_1_2",
+	[FLASH_CMD_READ4_1_2_2]	= "READ4_1_2_2",
+	[FLASH_CMD_READ4_1_1_4]	= "READ4_1_1_4",
+	[FLASH_CMD_READ4_1_4_4]	= "READ4_1_4_4",
 };
 
 char *fsm_inst_strs[256] = {
@@ -385,7 +399,7 @@
 	for (i = 0; i < 5; i++) {
 		if (seq->seq_opc[i] == 0x00000000) {
 			printk(KERN_INFO "\tSEQ_OPC%d   : 0x%08x\n",
-			       i, seq->seq_opc[i]);
+			       i + 1, seq->seq_opc[i]);
 		} else {
 			cmd = (uint8_t)(seq->seq_opc[i] & 0xff);
 			str = flash_cmd_strs[cmd];
@@ -393,7 +407,7 @@
 				str = "UNKNOWN";
 			printk(KERN_INFO "\tSEQ_OPC%d   : 0x%08x  "
 			       "[ 0x%02x/%-12s %d(x%d)%11s ]\n",
-			       i, seq->seq_opc[i], cmd, str,
+			       i + 1, seq->seq_opc[i], cmd, str,
 			       (seq->seq_opc[i] >> 8) & 0x3f,
 			       ((seq->seq_opc[i] >> 14) & 0x3) + 1,
 			       ((seq->seq_opc[i] >> 16) & 0x1) ?
@@ -459,7 +473,7 @@
 	printk(KERN_INFO "\t-------------------------------------------------"
 	       "--------------\n");
 }
-#endif /* DEBUG_SPI_FSM_SEQS */
+#endif /* CONFIG_STM_SPI_FSM_DEBUG */
 
 /*
  * SPI Flash Device Table
@@ -494,6 +508,7 @@
 static int w25q_config(struct stm_spi_fsm *fsm, struct flash_info *info);
 static int n25q_config(struct stm_spi_fsm *fsm, struct flash_info *info);
 static int mx25_config(struct stm_spi_fsm *fsm, struct flash_info *info);
+static int s25fl_config(struct stm_spi_fsm *fsm, struct flash_info *info);
 
 static struct flash_info __devinitdata flash_types[] = {
 
@@ -515,19 +530,28 @@
 	{ "m25px32", 0x207116, 0,  64 * 1024,  64, M25PX_CAPS, 75, NULL},
 	{ "m25px64", 0x207117, 0,  64 * 1024, 128, M25PX_CAPS, 75, NULL},
 
+	/* Macronix MX25xxx
+	 *     - Support for 'FLASH_CAPS_WRITE_1_4_4' is omitted for devices
+	 *       where operating frequency must be reduced.
+	 */
 #define MX25_CAPS (FLASH_CAPS_READ_WRITE	| \
 		   FLASH_CAPS_READ_FAST		| \
 		   FLASH_CAPS_READ_1_1_2	| \
 		   FLASH_CAPS_READ_1_2_2	| \
 		   FLASH_CAPS_READ_1_1_4	| \
 		   FLASH_CAPS_READ_1_4_4	| \
-		   FLASH_CAPS_WRITE_1_4_4	| \
 		   FLASH_CAPS_SE_4K		| \
 		   FLASH_CAPS_SE_32K)
+	{ "mx25l3255e",  0xc29e16, 0, 64 * 1024, 64,
+	  (MX25_CAPS | FLASH_CAPS_WRITE_1_4_4), 86, mx25_config},
 	{ "mx25l25635e", 0xc22019, 0, 64*1024, 512,
 	  (MX25_CAPS | FLASH_CAPS_32BITADDR | FLASH_CAPS_RESET),
 	  70, mx25_config},
+	{ "mx25l25655e", 0xc22619, 0, 64*1024, 512,
+	  (MX25_CAPS | FLASH_CAPS_32BITADDR | FLASH_CAPS_RESET),
+	  70, mx25_config},
 
+/* Micron N25Qxxx */
 #define N25Q_CAPS (FLASH_CAPS_READ_WRITE	| \
 		   FLASH_CAPS_READ_FAST		| \
 		   FLASH_CAPS_READ_1_1_2	| \
@@ -539,8 +563,67 @@
 		   FLASH_CAPS_WRITE_1_1_4	| \
 		   FLASH_CAPS_WRITE_1_4_4)
 	{ "n25q128", 0x20ba18, 0, 64 * 1024,  256, N25Q_CAPS, 108, n25q_config},
-	{ "n25q256", 0x20ba19, 0, 64 * 1024,  512,
-	  N25Q_CAPS | FLASH_CAPS_32BITADDR, 108, n25q_config},
+
+	/* Micron N25Q256/N25Q512/N25Q00A (32-bit ADDR devices)
+	 *
+	 * Versions are available with or without a dedicated RESET# pin
+	 * (e.g. N25Q512A83GSF40G vs. N25Q512A13GSF40G).  To complicate matters,
+	 * the versions that include a RESET# pin (Feature Set = 8) require a
+	 * different opcode for the FLASH_CMD_WRITE_1_4_4 command.
+	 * Unfortunately it is not possible to determine easily at run-time
+	 * which version is being used.  We therefore remove support for
+	 * FLASH_CAPS_WRITE_1_4_4 (falling back to FLASH_CAPS_WRITE_1_1_4), and
+	 * defer overall support for RESET# to the board-level platform/Device
+	 * Tree property "reset-signal".
+	 */
+#define N25Q_32BITADDR_CAPS	((N25Q_CAPS		| \
+				  FLASH_CAPS_32BITADDR	| \
+				  FLASH_CAPS_RESET)	& \
+				 ~FLASH_CAPS_WRITE_1_4_4)
+	{ "n25q256", 0x20ba19,      0, 64 * 1024,   512,
+	  N25Q_32BITADDR_CAPS, 108, n25q_config},
+	{ "n25q512", 0x20ba20, 0x1000, 64 * 1024,  1024,
+	  N25Q_32BITADDR_CAPS, 108, n25q_config},
+	{ "n25q00a", 0x20ba21, 0x1000, 64 * 1024,  2048,
+	  N25Q_32BITADDR_CAPS, 108, n25q_config},
+
+
+	/* Spansion S25FLxxxP
+	 *     - 256KiB and 64KiB sector variants (identified by ext. JEDEC)
+	 */
+#define S25FLXXXP_CAPS (FLASH_CAPS_READ_WRITE	| \
+			FLASH_CAPS_READ_1_1_2	| \
+			FLASH_CAPS_READ_1_2_2	| \
+			FLASH_CAPS_READ_1_1_4	| \
+			FLASH_CAPS_READ_1_4_4	| \
+			FLASH_CAPS_WRITE_1_1_4	| \
+			FLASH_CAPS_READ_FAST)
+	{ "s25fl032p",  0x010215, 0x4d00,  64 * 1024,  64, S25FLXXXP_CAPS, 80,
+	  s25fl_config},
+	{ "s25fl129p0", 0x012018, 0x4d00, 256 * 1024,  64, S25FLXXXP_CAPS, 80,
+	  s25fl_config},
+	{ "s25fl129p1", 0x012018, 0x4d01,  64 * 1024, 256, S25FLXXXP_CAPS, 80,
+	  s25fl_config},
+
+	/* Spansion S25FLxxxS
+	 *     - 256KiB and 64KiB sector variants (identified by ext. JEDEC)
+	 *     - RESET# signal supported by die but not bristled out on all
+	 *       package types.  The package type is a function of board design,
+	 *       so this information is captured in the board's capabilities.
+	 *     - Supports 'DYB' sector protection. Depending on variant, sectors
+	 *       may default to locked state on power-on.
+	 */
+#define S25FLXXXS_CAPS (S25FLXXXP_CAPS		| \
+			FLASH_CAPS_RESET	| \
+			FLASH_CAPS_DYB_LOCKING)
+	{ "s25fl128s0", 0x012018, 0x0300,  256 * 1024, 64, S25FLXXXS_CAPS, 80,
+	  s25fl_config},
+	{ "s25fl128s1", 0x012018, 0x0301,  64 * 1024, 256, S25FLXXXS_CAPS, 80,
+	  s25fl_config},
+	{ "s25fl256s0", 0x010219, 0x4d00, 256 * 1024, 128,
+	  S25FLXXXS_CAPS | FLASH_CAPS_32BITADDR, 80, s25fl_config},
+	{ "s25fl256s1", 0x010219, 0x4d01,  64 * 1024, 512,
+	  S25FLXXXS_CAPS | FLASH_CAPS_32BITADDR, 80, s25fl_config},
 
 	/* Winbond -- w25x "blocks" are 64K, "sectors" are 4KiB */
 #define W25X_CAPS (FLASH_CAPS_READ_WRITE	| \
@@ -752,13 +835,6 @@
 	return 0;
 }
 
-static int fsm_read_status(struct stm_spi_fsm *fsm, uint8_t cmd,
-			   uint8_t *status);
-static int fsm_write_status(struct stm_spi_fsm *fsm, uint16_t status,
-			    int sta_bytes);
-static int fsm_wrvcr(struct stm_spi_fsm *fsm, uint8_t data);
-static int fsm_enter_32bitaddr(struct stm_spi_fsm *fsm, int enter);
-
 /* [DEFAULT] Configure READ/WRITE/ERASE sequences */
 static int fsm_config_rwe_seqs_default(struct stm_spi_fsm *fsm,
 				      struct flash_info *info)
@@ -796,30 +872,305 @@
 	return 0;
 }
 
-/* [W25Qxxx] Configure READ/WRITE sequences */
-#define W25Q_STATUS_QE			(0x1 << 9)
+static int fsm_read_status(struct stm_spi_fsm *fsm, uint8_t cmd,
+			   uint8_t *data, int bytes);
+static int fsm_write_status(struct stm_spi_fsm *fsm, uint8_t cmd,
+			    uint16_t status, int bytes, int wait_busy);
+static int fsm_enter_32bitaddr(struct stm_spi_fsm *fsm, int enter);
+static uint8_t fsm_wait_busy(struct stm_spi_fsm *fsm);
+static int fsm_write_fifo(struct stm_spi_fsm *fsm,
+			  const uint32_t *buf, const uint32_t size);
+static int fsm_read_fifo(struct stm_spi_fsm *fsm,
+			 uint32_t *buf, const uint32_t size);
+static inline void fsm_load_seq(struct stm_spi_fsm *fsm,
+				const struct fsm_seq *const seq);
+static int fsm_wait_seq(struct stm_spi_fsm *fsm);
+
+/*
+ * [W25Qxxx] Configuration
+ */
+#define W25Q_STATUS_QE			(0x1 << 1)
+
 static int w25q_config(struct stm_spi_fsm *fsm, struct flash_info *info)
 {
 	uint32_t data_pads;
-	uint8_t sta1, sta2;
-	uint16_t sta_wr;
+	uint8_t sr1, sr2;
+	uint16_t sr_wr;
+	int update_sr;
 
 	if (fsm_config_rwe_seqs_default(fsm, info) != 0)
 		return 1;
 
-	/* If using QUAD mode, set QE STATUS bit */
+	/* Check status of 'QE' bit, update if required. */
 	data_pads = ((fsm_seq_read.seq_cfg >> 16) & 0x3) + 1;
+	fsm_read_status(fsm, FLASH_CMD_RDSR2, &sr2, 1);
+	update_sr = 0;
 	if (data_pads == 4) {
-		fsm_read_status(fsm, FLASH_CMD_RDSR, &sta1);
-		fsm_read_status(fsm, FLASH_CMD_RDSR2, &sta2);
+		if (!(sr2 & W25Q_STATUS_QE)) {
+			/* Set 'QE' */
+			sr2 |= W25Q_STATUS_QE;
+			update_sr = 1;
+		}
+	} else {
+		if (sr2 & W25Q_STATUS_QE) {
+			/* Clear 'QE' */
+			sr2 &= ~W25Q_STATUS_QE;
+			update_sr = 1;
+		}
+	}
+	if (update_sr) {
+		/* Write status register */
+		fsm_read_status(fsm, FLASH_CMD_RDSR, &sr1, 1);
+		sr_wr = ((uint16_t)sr2 << 8) | sr1;
+		fsm_write_status(fsm, FLASH_CMD_WRSR, sr_wr, 2, 1);
+	}
+
+	return 0;
+}
+
+/*
+ *[S25FLxxx] Configuration
+ */
+#define S25FL_CONFIG_QE			(0x1 << 1)
+
+/*
+ * S25FLxxxS devices provide three ways of supporting 32-bit addressing: Bank
+ * Register, Extended Address Modes, and a 32-bit address command set.  The
+ * 32-bit address command set is used here, since it avoids any problems with
+ * entering a state that is incompatible with the SPIBoot Controller.
+ */
+static struct seq_rw_config s25fl_read4_configs[] = {
+	{FLASH_CAPS_READ_1_4_4,  FLASH_CMD_READ4_1_4_4,  0, 4, 4, 0x00, 2, 4},
+	{FLASH_CAPS_READ_1_1_4,  FLASH_CMD_READ4_1_1_4,  0, 1, 4, 0x00, 0, 8},
+	{FLASH_CAPS_READ_1_2_2,  FLASH_CMD_READ4_1_2_2,  0, 2, 2, 0x00, 4, 0},
+	{FLASH_CAPS_READ_1_1_2,  FLASH_CMD_READ4_1_1_2,  0, 1, 2, 0x00, 0, 8},
+	{FLASH_CAPS_READ_FAST,   FLASH_CMD_READ4_FAST,   0, 1, 1, 0x00, 0, 8},
+	{FLASH_CAPS_READ_WRITE,  FLASH_CMD_READ4,        0, 1, 1, 0x00, 0, 0},
+	{0x00,                   0,                      0, 0, 0, 0x00, 0, 0},
+};
+
+static struct seq_rw_config s25fl_write4_configs[] = {
+	{FLASH_CAPS_WRITE_1_1_4, S25FL_CMD_WRITE4_1_1_4, 1, 1, 4, 0x00, 0, 0},
+	{FLASH_CAPS_READ_WRITE,  S25FL_CMD_WRITE4,       1, 1, 1, 0x00, 0, 0},
+	{0x00,                   0,                      0, 0, 0, 0x00, 0, 0},
+};
+
+static int s25fl_configure_erasesec_seq_32(struct fsm_seq *seq)
+{
+	seq->seq_opc[1] = (SEQ_OPC_PADS_1 |
+			   SEQ_OPC_CYCLES(8) |
+			   SEQ_OPC_OPCODE(S25FL_CMD_SE4));
+
+	seq->addr_cfg = (ADR_CFG_CYCLES_ADD1(16) |
+			 ADR_CFG_PADS_1_ADD1 |
+			 ADR_CFG_CYCLES_ADD2(16) |
+			 ADR_CFG_PADS_1_ADD2 |
+			 ADR_CFG_CSDEASSERT_ADD2);
+	return 0;
+}
+
+static int s25fl_read_dyb(struct stm_spi_fsm *fsm, uint32_t offs, uint8_t *dby)
+{
+	struct fsm_seq seq = {
+		.data_size = TRANSFER_SIZE(4),
+		.seq_opc[0] = (SEQ_OPC_PADS_1 |
+			       SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(S25FL_CMD_DYBRD)),
+		.addr_cfg = (ADR_CFG_CYCLES_ADD1(16) |
+			     ADR_CFG_PADS_1_ADD1 |
+			     ADR_CFG_CYCLES_ADD2(16) |
+			     ADR_CFG_PADS_1_ADD2),
+		.addr1 = (offs >> 16) & 0xffff,
+		.addr2 = offs & 0xffff,
+		.seq = {
+			FSM_INST_CMD1,
+			FSM_INST_ADD1,
+			FSM_INST_ADD2,
+			FSM_INST_DATA_READ,
+			FSM_INST_STOP,
+		},
+		.seq_cfg = (SEQ_CFG_PADS_1 |
+			    SEQ_CFG_READNOTWRITE |
+			    SEQ_CFG_CSDEASSERT |
+			    SEQ_CFG_STARTSEQ),
+	};
+	uint32_t tmp;
+
+	fsm_load_seq(fsm, &seq);
+
+	fsm_read_fifo(fsm, &tmp, 4);
+
+	*dby = (uint8_t)(tmp >> 24);
+
+	fsm_wait_seq(fsm);
+
+	return 0;
+}
+
+static int s25fl_write_dyb(struct stm_spi_fsm *fsm, uint32_t offs, uint8_t dby)
+{
+	struct fsm_seq seq = {
+		.seq_opc[0] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(FLASH_CMD_WREN) |
+			       SEQ_OPC_CSDEASSERT),
+		.seq_opc[1] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(S25FL_CMD_DYBWR)),
+		.addr_cfg = (ADR_CFG_CYCLES_ADD1(16) |
+			     ADR_CFG_PADS_1_ADD1 |
+			     ADR_CFG_CYCLES_ADD2(16) |
+			     ADR_CFG_PADS_1_ADD2),
+		.status = (uint32_t)dby | STA_PADS_1 | STA_CSDEASSERT,
+		.addr1 = (offs >> 16) & 0xffff,
+		.addr2 = offs & 0xffff,
+		.seq = {
+			FSM_INST_CMD1,
+			FSM_INST_CMD2,
+			FSM_INST_ADD1,
+			FSM_INST_ADD2,
+			FSM_INST_STA_WR1,
+			FSM_INST_STOP,
+		},
+		.seq_cfg = (SEQ_CFG_PADS_1 |
+			    SEQ_CFG_READNOTWRITE |
+			    SEQ_CFG_CSDEASSERT |
+			    SEQ_CFG_STARTSEQ),
+	};
+
+	fsm_load_seq(fsm, &seq);
+	fsm_wait_seq(fsm);
+
+	fsm_wait_busy(fsm);
+
+	return 0;
+}
+
+static int s25fl_clear_status_reg(struct stm_spi_fsm *fsm)
+{
+	struct fsm_seq seq = {
+		.seq_opc[0] = (SEQ_OPC_PADS_1 |
+			       SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(S25FL_CMD_CLSR) |
+			       SEQ_OPC_CSDEASSERT),
+		.seq_opc[1] = (SEQ_OPC_PADS_1 |
+			       SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(FLASH_CMD_WRDI) |
+			       SEQ_OPC_CSDEASSERT),
+		.seq = {
+			FSM_INST_CMD1,
+			FSM_INST_CMD2,
+			FSM_INST_WAIT,
+			FSM_INST_STOP,
+		},
+		.seq_cfg = (SEQ_CFG_PADS_1 |
+			    SEQ_CFG_ERASE |
+			    SEQ_CFG_READNOTWRITE |
+			    SEQ_CFG_CSDEASSERT |
+			    SEQ_CFG_STARTSEQ),
+	};
+
+	fsm_load_seq(fsm, &seq);
+
+	fsm_wait_seq(fsm);
 
-		sta_wr = ((uint16_t)sta2 << 8) | sta1;
+	return 0;
+}
+
+static int s25fl_config(struct stm_spi_fsm *fsm, struct flash_info *info)
+{
+	uint32_t data_pads;
+	uint8_t sr1, cr1, dyb;
+	uint16_t sta_wr;
+	uint32_t capabilities = info->capabilities;
+	uint32_t offs;
+	int update_sr;
 
-		sta_wr |= W25Q_STATUS_QE;
+	/* Mask out-capabilities not supported by platform */
+	if (fsm->capabilities.quad_mode == 0)
+		capabilities &= ~FLASH_CAPS_QUAD;
+	if (fsm->capabilities.dual_mode == 0)
+		capabilities &= ~FLASH_CAPS_DUAL;
 
-		fsm_write_status(fsm, sta_wr, 2);
+	if (capabilities & FLASH_CAPS_32BITADDR) {
+		/*
+		 * Configure Read/Write/Erase sequences according to S25FLxxx
+		 * 32-bit address command set
+		 */
+		if (fsm_search_configure_rw_seq(fsm, &fsm_seq_read,
+						s25fl_read4_configs,
+						capabilities) != 0)
+			return 1;
+
+		if (fsm_search_configure_rw_seq(fsm, &fsm_seq_write,
+						s25fl_write4_configs,
+						capabilities) != 0)
+			return 1;
+		if (s25fl_configure_erasesec_seq_32(&fsm_seq_erase_sector) != 0)
+			return 1;
+
+	} else {
+		/* Use default configurations for 24-bit addressing */
+		if (fsm_config_rwe_seqs_default(fsm, info) != 0)
+			return 1;
+	}
+
+	/*
+	 * For devices that support 'DYB' sector locking, check lock status and
+	 * unlock sectors if necessary (some variants power-on with sectors
+	 * locked by default)
+	 */
+	if (capabilities & FLASH_CAPS_DYB_LOCKING) {
+		offs = 0;
+		for (offs = 0; offs < info->sector_size * info->n_sectors;) {
+			s25fl_read_dyb(fsm, offs, &dyb);
+			if (dyb == 0x00)
+				s25fl_write_dyb(fsm, offs, 0xff);
+
+			/* Handle bottom/top 4KiB parameter sectors */
+			if ((offs < info->sector_size * 2) ||
+			    (offs >= (info->sector_size - info->n_sectors * 4)))
+				offs += 0x1000;
+			else
+				offs += 0x10000;
+		}
+	}
+
+	/* Check status of 'QE' bit, update if required. */
+	data_pads = ((fsm_seq_read.seq_cfg >> 16) & 0x3) + 1;
+	fsm_read_status(fsm, FLASH_CMD_RDSR2, &cr1, 1);
+	update_sr = 0;
+	if (data_pads == 4) {
+		if (!(cr1 & S25FL_CONFIG_QE)) {
+			/* Set 'QE' */
+			cr1 |= S25FL_CONFIG_QE;
+			update_sr = 1;
+		}
+	} else {
+		if (cr1 & S25FL_CONFIG_QE) {
+			/* Clear 'QE' */
+			cr1 &= ~S25FL_CONFIG_QE;
+			update_sr = 1;
+		}
 	}
+	if (update_sr) {
+		fsm_read_status(fsm, FLASH_CMD_RDSR, &sr1, 1);
+		sta_wr = ((uint16_t)cr1  << 8) | sr1;
+		fsm_write_status(fsm, FLASH_CMD_WRSR, sta_wr, 2, 1);
+	}
+
+	/* S25FLxxx devices support Program and Error error flags.  Configure
+	 * driver to check flags and clear if necessary.
+	 */
+	fsm->configuration |= CFG_S25FL_CHECK_ERROR_FLAGS;
 
+#ifdef CONFIG_STM_SPI_FSM_DEBUG
+	/* Debug strings for S25FLxxx specific commands */
+	flash_cmd_strs[S25FL_CMD_WRITE4]	= "WRITE4";
+	flash_cmd_strs[S25FL_CMD_WRITE4_1_1_4]	= "WRITE4_1_1_4";
+	flash_cmd_strs[S25FL_CMD_SE4]		= "SE4";
+	flash_cmd_strs[S25FL_CMD_CLSR]		= "CLSR";
+	flash_cmd_strs[S25FL_CMD_DYBWR]		= "DYBWR";
+	flash_cmd_strs[S25FL_CMD_DYBRD]		= "DYBRD";
+#endif
 	return 0;
 }
 
@@ -851,12 +1202,6 @@
 	uint32_t data_pads;
 	uint8_t sta;
 
-	/* Disable support for 'WRITE_1_4_4' (limited to 20MHz which is of
-	 * marginal benefit on our hardware and doesn't justify implementing
-	 * different READ/WRITE frequencies).
-	 */
-	info->capabilities &= ~FLASH_CAPS_WRITE_1_4_4;
-
 	/*
 	 * Use default READ/WRITE sequences
 	 */
@@ -871,33 +1216,40 @@
 		mx25_configure_en32bitaddr_seq(&fsm_seq_en32bitaddr);
 
 		if (!fsm->capabilities.boot_from_spi ||
-		    can_handle_soc_reset(fsm, info)) {
+		    can_handle_soc_reset(fsm, info))
 			/* If we can handle SoC resets, we enable 32-bit address
 			 * mode pervasively */
 			fsm_enter_32bitaddr(fsm, 1);
-
-		} else {
+		else
 			/* Else, enable/disable 32-bit addressing before/after
 			 * each operation */
 			fsm->configuration = (CFG_READ_TOGGLE32BITADDR |
 					      CFG_WRITE_TOGGLE32BITADDR |
 					      CFG_ERASESEC_TOGGLE32BITADDR);
-			/* It seems a small delay is required after exiting
-			 * 32-bit mode following a write operation.  The issue
-			 * is under investigation.
-			 */
-			fsm->configuration |= CFG_WRITE_EX32BITADDR_DELAY;
-		}
 	}
 
-	/* For QUAD mode, set 'QE' STATUS bit */
+	/* Check status of 'QE' bit, update if required. */
 	data_pads = ((fsm_seq_read.seq_cfg >> 16) & 0x3) + 1;
+	fsm_read_status(fsm, FLASH_CMD_RDSR, &sta, 1);
 	if (data_pads == 4) {
-		fsm_read_status(fsm, FLASH_CMD_RDSR, &sta);
-		sta |= MX25_STATUS_QE;
-		fsm_write_status(fsm, sta, 1);
+		if (!(sta & MX25_STATUS_QE)) {
+			/* Set 'QE' */
+			sta |= MX25_STATUS_QE;
+			fsm_write_status(fsm, FLASH_CMD_WRSR, sta, 1, 1);
+		}
+	} else {
+		if (sta & MX25_STATUS_QE) {
+			/* Clear 'QE' */
+			sta &= ~MX25_STATUS_QE;
+			fsm_write_status(fsm, FLASH_CMD_WRSR, sta, 1, 1);
+		}
 	}
 
+#ifdef CONFIG_STM_SPI_FSM_DEBUG
+	/* Debug strings for MX25xxx specific commands */
+	flash_cmd_strs[MX25_CMD_RDSCUR]	= "RDSCUR";
+#endif
+
 	return 0;
 }
 
@@ -935,12 +1287,12 @@
  *	- 'FAST' variants configured for 8 dummy cycles (see note above.)
  */
 static struct seq_rw_config n25q_read4_configs[] = {
-	{FLASH_CAPS_READ_1_4_4, N25Q_CMD_READ4_1_4_4,	0, 4, 4, 0x00, 0, 8},
-	{FLASH_CAPS_READ_1_1_4, N25Q_CMD_READ4_1_1_4,	0, 1, 4, 0x00, 0, 8},
-	{FLASH_CAPS_READ_1_2_2, N25Q_CMD_READ4_1_2_2,	0, 2, 2, 0x00, 0, 8},
-	{FLASH_CAPS_READ_1_1_2, N25Q_CMD_READ4_1_1_2,	0, 1, 2, 0x00, 0, 8},
-	{FLASH_CAPS_READ_FAST,	N25Q_CMD_READ4_FAST,	0, 1, 1, 0x00, 0, 8},
-	{FLASH_CAPS_READ_WRITE, N25Q_CMD_READ4,		0, 1, 1, 0x00, 0, 0},
+	{FLASH_CAPS_READ_1_4_4, FLASH_CMD_READ4_1_4_4,	0, 4, 4, 0x00, 0, 8},
+	{FLASH_CAPS_READ_1_1_4, FLASH_CMD_READ4_1_1_4,	0, 1, 4, 0x00, 0, 8},
+	{FLASH_CAPS_READ_1_2_2, FLASH_CMD_READ4_1_2_2,	0, 2, 2, 0x00, 0, 8},
+	{FLASH_CAPS_READ_1_1_2, FLASH_CMD_READ4_1_1_2,	0, 1, 2, 0x00, 0, 8},
+	{FLASH_CAPS_READ_FAST,	FLASH_CMD_READ4_FAST,	0, 1, 1, 0x00, 0, 8},
+	{FLASH_CAPS_READ_WRITE, FLASH_CMD_READ4,	0, 1, 1, 0x00, 0, 0},
 	{0x00,			 0,			0, 0, 0, 0x00, 0, 0},
 };
 
@@ -966,9 +1318,33 @@
 	return 0;
 }
 
+static int n25q_clear_flags(struct stm_spi_fsm *fsm)
+{
+	struct fsm_seq seq = {
+		.seq_opc[0] = (SEQ_OPC_PADS_1 |
+			       SEQ_OPC_CYCLES(8) |
+			       SEQ_OPC_OPCODE(N25Q_CMD_CLFSR) |
+			       SEQ_OPC_CSDEASSERT),
+		.seq = {
+			FSM_INST_CMD1,
+			FSM_INST_STOP,
+		},
+		.seq_cfg = (SEQ_CFG_PADS_1 |
+			    SEQ_CFG_READNOTWRITE |
+			    SEQ_CFG_CSDEASSERT |
+			    SEQ_CFG_STARTSEQ),
+	};
+
+	fsm_load_seq(fsm, &seq);
+
+	fsm_wait_seq(fsm);
+
+	return 0;
+}
+
 static int n25q_config(struct stm_spi_fsm *fsm, struct flash_info *info)
 {
-	uint8_t vcr;
+	uint8_t vcr, sta;
 	int ret = 0;
 	uint32_t capabilities = info->capabilities;
 
@@ -1038,11 +1414,30 @@
 	}
 
 	/*
+	 * Check/Clear Error Flags
+	 */
+	fsm->configuration |= CFG_N25Q_CHECK_ERROR_FLAGS;
+	fsm_read_status(fsm, N25Q_CMD_RFSR, &sta, 1);
+	if (sta & N25Q_FLAGS_ERROR)
+		n25q_clear_flags(fsm);
+
+	/*
 	 * Configure device to use 8 dummy cycles
 	 */
 	vcr = (N25Q_VCR_DUMMY_CYCLES(8) | N25Q_VCR_XIP_DISABLED |
 	       N25Q_VCR_WRAP_CONT);
-	fsm_wrvcr(fsm, vcr);
+	fsm_write_status(fsm, N25Q_CMD_WRVCR, vcr, 1, 0);
+
+#ifdef CONFIG_STM_SPI_FSM_DEBUG
+	/* Debug strings for N25Qxxx specific commands */
+	flash_cmd_strs[N25Q_CMD_RFSR]	= "RFSR";
+	flash_cmd_strs[N25Q_CMD_CLFSR]	= "CLRFSR";
+	flash_cmd_strs[N25Q_CMD_RDVCR]	= "RDVCR";
+	flash_cmd_strs[N25Q_CMD_RDVECR]	= "RDVECR";
+	flash_cmd_strs[N25Q_CMD_WRVCR]	= "WRVCR";
+	flash_cmd_strs[N25Q_CMD_RDNVCR]	= "RDNVCR";
+	flash_cmd_strs[N25Q_CMD_WRNVCR]	= "WRNVCR";
+#endif
 
 	return ret;
 }
@@ -1084,19 +1479,85 @@
 	return 1;
 }
 
-static void fsm_clear_fifo(struct stm_spi_fsm *fsm)
+/* Dummy sequence to read one byte of data from flash into the FIFO */
+static const struct fsm_seq fsm_seq_load_fifo_byte = {
+	.data_size = TRANSFER_SIZE(1),
+	.seq_opc[0] = (SEQ_OPC_PADS_1 |
+		       SEQ_OPC_CYCLES(8) |
+		       SEQ_OPC_OPCODE(FLASH_CMD_RDID)),
+	.seq = {
+		FSM_INST_CMD1,
+		FSM_INST_DATA_READ,
+		FSM_INST_STOP,
+	},
+	.seq_cfg = (SEQ_CFG_PADS_1 |
+		    SEQ_CFG_READNOTWRITE |
+		    SEQ_CFG_CSDEASSERT |
+		    SEQ_CFG_STARTSEQ),
+};
+
+/*
+ * Clear the data FIFO
+ *
+ * Typically, this is only required during driver initialisation, where no
+ * assumptions can be made regarding the state of the FIFO.
+ *
+ * The process of clearing the FIFO is complicated by fact that while it is
+ * possible for the FIFO to contain an arbitrary number of bytes [1], the
+ * SPI_FAST_SEQ_STA register only reports the number of complete 32-bit words
+ * present.  Furthermore, data can only be drained from the FIFO by reading
+ * complete 32-bit words.
+ *
+ * With this in mind, a two stage process is used to the clear the FIFO:
+ *
+ *     1. Read any complete 32-bit words from the FIFO, as reported by the
+ *        SPI_FAST_SEQ_STA register.
+ *
+ *     2. Mop up any remaining bytes.  At this point, it is not known if there
+ *        are 0, 1, 2, or 3 bytes in the FIFO.  To handle all cases, a dummy FSM
+ *        sequence is used to load one byte at a time, until a complete 32-bit
+ *        word is formed; at most, 4 bytes will need to be loaded.
+ *
+ * [1] It is theoretically possible for the FIFO to contain an arbitrary number
+ *     of bits.  However, since there are no known use-cases that leave
+ *     incomplete bytes in the FIFO, only words and bytes are considered here.
+ */
+static int fsm_clear_fifo(struct stm_spi_fsm *fsm)
 {
-	uint32_t avail;
+	const struct fsm_seq *seq = &fsm_seq_load_fifo_byte;
+	uint32_t words;
+	int i;
 
-	while ((avail = fsm_fifo_available(fsm)) > 0) {
+	/* 1. Clear any 32-bit words */
+	words = fsm_fifo_available(fsm);
+	if (words) {
+		for (i = 0; i < words; i++)
+			readl(fsm->base + SPI_FAST_SEQ_DATA_REG);
+		dev_dbg(fsm->dev, "cleared %d words from FIFO\n", words);
+	}
 
-		dev_dbg(fsm->dev, "clearing %d bytes from FIFO\n", avail*4);
+	/* 2. Clear any remaining bytes
+	 *    - Load the FIFO, one byte at a time, until a complete 32-bit word
+	 *      is available.
+	 */
+	for (i = 0, words = 0; i < 4 && !words; i++) {
+		fsm_load_seq(fsm, seq);
+		fsm_wait_seq(fsm);
+		words = fsm_fifo_available(fsm);
+	}
 
-		while (avail) {
-			readl(fsm->base + SPI_FAST_SEQ_DATA_REG);
-			avail--;
-		}
+	/*    - A single word must be available now */
+	if (words != 1) {
+		dev_err(fsm->dev, "failed to clear bytes from the data FIFO\n");
+		return 1;
 	}
+
+	/*    - Read the 32-bit word */
+	readl(fsm->base + SPI_FAST_SEQ_DATA_REG);
+
+	dev_dbg(fsm->dev, "cleared %d byte(s) from the data FIFO\n", 4 - i);
+
+	return 0;
 }
 
 static int fsm_read_fifo(struct stm_spi_fsm *fsm,
@@ -1141,7 +1602,7 @@
 /*
  * Serial Flash operations
  */
-static int fsm_wait_busy(struct stm_spi_fsm *fsm)
+static uint8_t fsm_wait_busy(struct stm_spi_fsm *fsm)
 {
 	struct fsm_seq *seq = &fsm_seq_read_status_fifo;
 	unsigned long deadline;
@@ -1167,6 +1628,11 @@
 		if ((status[3] & FLASH_STATUS_BUSY) == 0)
 			return 0;
 
+		if ((fsm->configuration & CFG_S25FL_CHECK_ERROR_FLAGS) &&
+		    ((status[3] & S25FL_STATUS_P_ERR) ||
+		     (status[3] & S25FL_STATUS_E_ERR)))
+			return status[3];
+
 		/* Restart */
 		writel(seq->seq_cfg, fsm->base + SPI_FAST_SEQ_CFG);
 
@@ -1174,7 +1640,7 @@
 
 	dev_err(fsm->dev, "timeout on wait_busy\n");
 
-	return 1;
+	return FLASH_STATUS_TIMEOUT;
 }
 
 static int fsm_read_jedec(struct stm_spi_fsm *fsm, uint8_t *const jedec)
@@ -1192,60 +1658,57 @@
 }
 
 static int fsm_read_status(struct stm_spi_fsm *fsm, uint8_t cmd,
-			   uint8_t *status)
+			   uint8_t *data, int bytes)
 {
 	struct fsm_seq *seq = &fsm_seq_read_status_fifo;
 	uint32_t tmp;
+	uint8_t *t = (uint8_t *)&tmp;
+	int i;
 
-	dev_dbg(fsm->dev, "reading STA[%s]\n",
-		(cmd == FLASH_CMD_RDSR) ? "1" : "2");
+	dev_dbg(fsm->dev, "read 'status' register [0x%02x], %d byte(s)\n",
+		cmd, bytes);
 
-	seq->seq_opc[0] = (SEQ_OPC_PADS_1 |
-			   SEQ_OPC_CYCLES(8) |
+	BUG_ON(bytes != 1 && bytes != 2);
+
+	seq->seq_opc[0] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
 			   SEQ_OPC_OPCODE(cmd)),
 
 	fsm_load_seq(fsm, seq);
 
 	fsm_read_fifo(fsm, &tmp, 4);
 
-	*status = (uint8_t)(tmp >> 24);
+	for (i = 0; i < bytes; i++)
+		data[i] = t[i];
 
 	fsm_wait_seq(fsm);
 
 	return 0;
 }
 
-static int fsm_write_status(struct stm_spi_fsm *fsm, uint16_t status,
-			    int sta_bytes)
+static int fsm_write_status(struct stm_spi_fsm *fsm, uint8_t cmd,
+			    uint16_t data, int bytes, int wait_busy)
 {
 	struct fsm_seq *seq = &fsm_seq_write_status;
 
-	dev_dbg(fsm->dev, "writing STA[%s] 0x%04x\n",
-		(sta_bytes == 1) ? "1" : "1+2", status);
-
-	seq->status = (uint32_t)status | STA_PADS_1 | STA_CSDEASSERT;
-	seq->seq[2] = (sta_bytes == 1) ? FSM_INST_STA_WR1 : FSM_INST_STA_WR1_2;
+	dev_dbg(fsm->dev, "write 'status' register [0x%02x], %d byte(s), "
+		"0x%04x, %s wait-busy\n",
+		cmd, bytes, data, wait_busy ? "with" : "no");
 
-	fsm_load_seq(fsm, seq);
+	BUG_ON(bytes != 1 && bytes != 2);
 
-	fsm_wait_seq(fsm);
-
-	return 0;
-};
-
-static int fsm_wrvcr(struct stm_spi_fsm *fsm, uint8_t data)
-{
-	struct fsm_seq *seq = &fsm_seq_wrvcr;
-
-	dev_dbg(fsm->dev, "writing VCR 0x%02x\n", data);
+	seq->seq_opc[1] = (SEQ_OPC_PADS_1 | SEQ_OPC_CYCLES(8) |
+			   SEQ_OPC_OPCODE(cmd));
 
-	seq->status = (STA_DATA_BYTE1(data) |
-		       STA_PADS_1 | STA_CSDEASSERT);
+	seq->status = (uint32_t)data | STA_PADS_1 | STA_CSDEASSERT;
+	seq->seq[2] = (bytes == 1) ? FSM_INST_STA_WR1 : FSM_INST_STA_WR1_2;
 
 	fsm_load_seq(fsm, seq);
 
 	fsm_wait_seq(fsm);
 
+	if (wait_busy)
+		fsm_wait_busy(fsm);
+
 	return 0;
 }
 
@@ -1266,10 +1729,11 @@
 	return 0;
 }
 
-
 static int fsm_erase_sector(struct stm_spi_fsm *fsm, const uint32_t offset)
 {
 	struct fsm_seq *seq = &fsm_seq_erase_sector;
+	uint8_t sta;
+	int ret = 0;
 
 	dev_dbg(fsm->dev, "erasing sector at 0x%08x\n", offset);
 
@@ -1284,13 +1748,28 @@
 
 	fsm_wait_seq(fsm);
 
-	fsm_wait_busy(fsm);
+	/* Wait for completion */
+	sta = fsm_wait_busy(fsm);
+	if (sta != 0) {
+		ret = 1;
+		if (fsm->configuration & CFG_S25FL_CHECK_ERROR_FLAGS)
+			s25fl_clear_status_reg(fsm);
+	}
+
+	/* N25Q: Check/Clear Error Flags */
+	if (fsm->configuration & CFG_N25Q_CHECK_ERROR_FLAGS) {
+		fsm_read_status(fsm, N25Q_CMD_RFSR, &sta, 1);
+		if (sta & N25Q_FLAGS_ERROR) {
+			ret = 1;
+			n25q_clear_flags(fsm);
+		}
+	}
 
 	/* Exit 32-bit address mode, if required */
 	if (fsm->configuration & CFG_ERASESEC_TOGGLE32BITADDR)
 		fsm_enter_32bitaddr(fsm, 0);
 
-	return 0;
+	return ret;
 }
 
 static int fsm_erase_chip(struct stm_spi_fsm *fsm)
@@ -1327,7 +1806,7 @@
 	if (fsm->configuration & CFG_READ_TOGGLE32BITADDR)
 		fsm_enter_32bitaddr(fsm, 1);
 
-	/* Must read in multiples of 32 cycles (or 32*pads/8 bytes) */
+	/* Must read in multiples of 32 cycles (i.e. (32*pads)/8 bytes) */
 	data_pads = ((seq->seq_cfg >> 16) & 0x3) + 1;
 	read_mask = (data_pads << 2) - 1;
 
@@ -1360,8 +1839,6 @@
 	/* Wait for sequence to finish */
 	fsm_wait_seq(fsm);
 
-	fsm_clear_fifo(fsm);
-
 	/* Exit 32-bit address mode, if required */
 	if (fsm->configuration & CFG_READ_TOGGLE32BITADDR)
 		fsm_enter_32bitaddr(fsm, 0);
@@ -1383,6 +1860,8 @@
 	uint8_t *t = (uint8_t *)&tmp;
 	int i;
 	const uint8_t *p;
+	uint8_t sta;
+	int ret = 0;
 
 	dev_dbg(fsm->dev, "writing %d bytes to 0x%08x\n", size, offset);
 
@@ -1390,7 +1869,7 @@
 	if (fsm->configuration & CFG_WRITE_TOGGLE32BITADDR)
 		fsm_enter_32bitaddr(fsm, 1);
 
-	/* Must write in multiples of 32 cycles (or 32*pads/8 bytes) */
+	/* Must write in multiples of 32 cycles (i.e. (32*pads)/8 bytes) */
 	data_pads = ((seq->seq_cfg >> 16) & 0x3) + 1;
 	write_mask = (data_pads << 2) - 1;
 
@@ -1452,16 +1931,27 @@
 	fsm_wait_seq(fsm);
 
 	/* Wait for completion */
-	fsm_wait_busy(fsm);
+	sta = fsm_wait_busy(fsm);
+	if (sta != 0) {
+		ret = 1;
+		if (fsm->configuration & CFG_S25FL_CHECK_ERROR_FLAGS)
+			s25fl_clear_status_reg(fsm);
+	}
+
+	/* N25Q: Check/Clear Error Flags */
+	if (fsm->configuration & CFG_N25Q_CHECK_ERROR_FLAGS) {
+		fsm_read_status(fsm, N25Q_CMD_RFSR, &sta, 1);
+		if (sta & N25Q_FLAGS_ERROR) {
+			ret = 1;
+			n25q_clear_flags(fsm);
+		}
+	}
 
 	/* Exit 32-bit address mode, if required */
-	if (fsm->configuration & CFG_WRITE_TOGGLE32BITADDR) {
+	if (fsm->configuration & CFG_WRITE_TOGGLE32BITADDR)
 		fsm_enter_32bitaddr(fsm, 0);
-		if (fsm->configuration & CFG_WRITE_EX32BITADDR_DELAY)
-			udelay(1);
-	}
 
-	return 0;
+	return ret;
 }
 
 
@@ -1555,7 +2045,14 @@
 	       SPI_CFG_DATA_HOLD(0x00), fsm->base + SPI_CONFIGDATA);
 	writel(0x0016e360, fsm->base + SPI_STATUS_WR_TIME_REG);
 
-	/* Clear FIFO, just in case */
+	/*
+	 * Set the FSM 'WAIT' delay to the minimum workable value.  Note, for
+	 * our purposes, the WAIT instruction is used purely to achieve
+	 * "sequence validity" rather than actually implement a delay.
+	 */
+	writel(0x000001, fsm->base + SPI_PROGRAM_ERASE_TIME);
+
+	/* Clear the data FIFO */
 	fsm_clear_fifo(fsm);
 
 	return 0;
@@ -1627,6 +2124,7 @@
 	u32 page_offs;
 	u32 bytes;
 	uint8_t *b = (uint8_t *)buf;
+	int ret = 0;
 
 	dev_dbg(fsm->dev, "%s %s 0x%08x, len %zd\n", __func__,
 		"to", (u32)to, len);
@@ -1650,7 +2148,10 @@
 		/* write up to page boundary */
 		bytes = min(FLASH_PAGESIZE - page_offs, len);
 
-		fsm_write(fsm, b, bytes, to);
+		if (fsm_write(fsm, b, bytes, to) != 0) {
+			ret = -EIO;
+			goto out1;
+		}
 
 		b += bytes;
 		len -= bytes;
@@ -1664,9 +2165,10 @@
 
 	}
 
+ out1:
 	mutex_unlock(&fsm->lock);
 
-	return 0;
+	return ret;
 }
 
 /*
@@ -1863,10 +2365,10 @@
 
 	if (fsm->capabilities.boot_from_spi &&
 	    !can_handle_soc_reset(fsm, info))
-		dev_warn(&pdev->dev, "WARNING: no provision for SPI reset"
-			 "on boot-from-spi system\n");
+		dev_warn(&pdev->dev, "WARNING: no provision for SPI reset on "
+			 "boot-from-spi system\n");
 
-#ifdef DEBUG_SPI_FSM_SEQS
+#ifdef CONFIG_STM_SPI_FSM_DEBUG
 	fsm_dump_seq("FSM READ SEQ", &fsm_seq_read);
 	fsm_dump_seq("FSM WRITE_SEQ", &fsm_seq_write);
 	fsm_dump_seq("FSM ERASE_SECT_SEQ", &fsm_seq_erase_sector);
@@ -1888,6 +2390,7 @@
 	else
 		fsm->mtd.name = NAME;
 
+	fsm->mtd.dev.parent = &pdev->dev;
 	fsm->mtd.type = MTD_NORFLASH;
 	fsm->mtd.writesize = 4;
 	fsm->mtd.flags = MTD_CAP_NORFLASH;
@@ -1943,10 +2446,16 @@
 			}
 			fsm->partitioned = 1;
 
-			if (add_mtd_partitions(&fsm->mtd, parts, nr_parts)) {
-				ret = -ENODEV;
+			ret = add_mtd_partitions(&fsm->mtd, parts, nr_parts);
+
+			/* Free 'parts', if allocated by
+			 * parse_mtd_partitions()
+			 */
+			if (!data || (parts != data->parts))
+				kfree(parts);
+
+			if (ret != 0)
 				goto out5;
-			}
 
 			/* Success :-) */
 			return 0;
@@ -1996,6 +2505,8 @@
 	release_resource(fsm->region);
 	platform_set_drvdata(pdev, NULL);
 
+	kfree(fsm);
+
 	return 0;
 }
 
diff -Naur a/drivers/mtd/mtdcore.c b/drivers/mtd/mtdcore.c
--- a/drivers/mtd/mtdcore.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mtd/mtdcore.c	2013-11-01 18:44:50.937823791 +0200
@@ -291,6 +291,10 @@
 					       mtd->name);
 			}
 
+			/* Set MTD_SPANS_MASTER for non-slave MTD devices */
+			if (!(mtd->flags & MTD_SLAVE_PARTITION))
+				mtd->flags |= MTD_SPANS_MASTER;
+
 			/* Caller should have set dev.parent to match the
 			 * physical device.
 			 */
diff -Naur a/drivers/mtd/mtdpart.c b/drivers/mtd/mtdpart.c
--- a/drivers/mtd/mtdpart.c	2013-11-01 20:19:18.745928937 +0200
+++ b/drivers/mtd/mtdpart.c	2013-11-01 18:44:50.937823791 +0200
@@ -57,12 +57,13 @@
 		len = mtd->size - from;
 	res = part->master->read(part->master, from + part->offset,
 				   len, retlen, buf);
-	if (unlikely(res)) {
-		if (res == -EUCLEAN)
-			mtd->ecc_stats.corrected += part->master->ecc_stats.corrected - stats.corrected;
-		if (res == -EBADMSG)
-			mtd->ecc_stats.failed += part->master->ecc_stats.failed - stats.failed;
-	}
+	mtd->ecc_stats.corrected += part->master->ecc_stats.corrected -
+		stats.corrected;
+
+	if (unlikely(res) && res == -EBADMSG)
+		mtd->ecc_stats.failed += part->master->ecc_stats.failed -
+			stats.failed;
+
 	return res;
 }
 
@@ -101,20 +102,45 @@
 		struct mtd_oob_ops *ops)
 {
 	struct mtd_part *part = PART(mtd);
+	struct mtd_ecc_stats stats;
 	int res;
 
 	if (from >= mtd->size)
 		return -EINVAL;
 	if (ops->datbuf && from + ops->len > mtd->size)
 		return -EINVAL;
-	res = part->master->read_oob(part->master, from + part->offset, ops);
 
-	if (unlikely(res)) {
-		if (res == -EUCLEAN)
-			mtd->ecc_stats.corrected++;
-		if (res == -EBADMSG)
-			mtd->ecc_stats.failed++;
+	stats = part->master->ecc_stats;
+
+	/*
+	 * If OOB is also requested, make sure that we do not read past the end
+	 * of this partition.
+	 */
+	if (ops->oobbuf) {
+		size_t len, pages;
+		unsigned int page_shift = ffs(mtd->writesize) - 1;
+
+		if (ops->mode == MTD_OOB_AUTO)
+			len = mtd->oobavail;
+		else
+			len = mtd->oobsize;
+
+		pages = mtd->size >> page_shift;
+		pages -= from >> page_shift;
+
+		if (ops->ooboffs + ops->ooblen > pages * len)
+			return -EINVAL;
 	}
+
+	res = part->master->read_oob(part->master, from + part->offset, ops);
+
+	mtd->ecc_stats.corrected += part->master->ecc_stats.corrected -
+		stats.corrected;
+
+	if (unlikely(res) && res == -EBADMSG)
+		mtd->ecc_stats.failed += part->master->ecc_stats.failed -
+			stats.failed;
+
 	return res;
 }
 
@@ -356,6 +382,9 @@
 	slave->mtd.owner = master->owner;
 	slave->mtd.backing_dev_info = master->backing_dev_info;
 
+	/* Flag MTD device as a slave partition */
+	slave->mtd.flags |= MTD_SLAVE_PARTITION;
+
 	/* NOTE:  we don't arrange MTDs as a tree; it'd be error-prone
 	 * to have the same data be in two different partitions.
 	 */
@@ -496,6 +525,10 @@
 		}
 	}
 
+	/* Set MTD_SPANS_MASTER if slave MTD spans entire master MTD */
+	if (slave->offset == 0 && slave->mtd.size == master->size)
+		slave->mtd.flags |= MTD_SPANS_MASTER;
+
 out_register:
 	/* register our partition */
 	add_mtd_device(&slave->mtd);
@@ -533,15 +566,22 @@
 }
 EXPORT_SYMBOL(add_mtd_partitions);
 
-/* Retieve a master's MTD slave object for the partition named @name */
-struct mtd_info *get_mtd_partition_slave(struct mtd_info *master, char *name)
+/*
+ * Retrieve a master's MTD slave object for the partition named @name.  If
+ * found, returns a pointer the Slave's mtd_info structure, and sets the @offset
+ * parameter.  Else, returns NULL.
+ */
+struct mtd_info *get_mtd_partition_slave(struct mtd_info *master, char *name,
+					 uint64_t *offset)
 {
 	struct mtd_part *slave, *next;
 
 	list_for_each_entry_safe(slave, next, &mtd_partitions, list)
 		if (slave->master == master &&
-		    strcmp(slave->mtd.name, name) == 0)
+		    strcmp(slave->mtd.name, name) == 0) {
+			*offset = slave->offset;
 			return &slave->mtd;
+		}
 	return NULL;
 }
 EXPORT_SYMBOL(get_mtd_partition_slave);
diff -Naur a/drivers/mtd/nand/cafe_nand.c b/drivers/mtd/nand/cafe_nand.c
--- a/drivers/mtd/nand/cafe_nand.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mtd/nand/cafe_nand.c	2013-11-01 18:44:50.945823833 +0200
@@ -103,7 +103,7 @@
 static int cafe_device_ready(struct mtd_info *mtd)
 {
 	struct cafe_priv *cafe = mtd->priv;
-	int result = !!(cafe_readl(cafe, NAND_STATUS) | 0x40000000);
+	int result = !!(cafe_readl(cafe, NAND_STATUS) & 0x40000000);
 	uint32_t irqs = cafe_readl(cafe, NAND_IRQ);
 
 	cafe_writel(cafe, irqs, NAND_IRQ);
diff -Naur a/drivers/mtd/nand/Kconfig b/drivers/mtd/nand/Kconfig
--- a/drivers/mtd/nand/Kconfig	2013-11-01 20:19:18.745928937 +0200
+++ b/drivers/mtd/nand/Kconfig	2013-11-01 18:44:50.941823819 +0200
@@ -598,4 +598,16 @@
 	  Update the boot-mode ECC boundary from the PBL and apply to the
 	  specified NAND boot partition.
 
+config STM_NAND_SAFE_MOUNT
+	bool "STM NAND: Check for 'alien' BBTs when mounting NAND device"
+	depends on (MTD_NAND_STM_EMI || \
+		    MTD_NAND_STM_FLEX || \
+		    MTD_NAND_STM_AFM || \
+		    MTD_NAND_STM_BCH)
+	default y
+	help
+	  This option helps prevent corruption that might otherwise result from
+	  the presence of 'alien' BBTs (i.e. BBTs written by a driver different
+	  to that currently employed).
+
 endif # MTD_NAND
diff -Naur a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c
--- a/drivers/mtd/nand/nand_base.c	2013-11-01 20:19:18.753928975 +0200
+++ b/drivers/mtd/nand/nand_base.c	2013-11-01 18:44:50.949823852 +0200
@@ -441,13 +441,14 @@
  *
  * The function expects, that the device is already selected
  */
-static int nand_check_wp(struct mtd_info *mtd)
+int nand_check_wp(struct mtd_info *mtd)
 {
 	struct nand_chip *chip = mtd->priv;
 	/* Check the WP bit */
 	chip->cmdfunc(mtd, NAND_CMD_STATUS, -1, -1);
 	return (chip->read_byte(mtd) & NAND_STATUS_WP) ? 0 : 1;
 }
+EXPORT_SYMBOL_GPL(nand_check_wp);
 
 /**
  * nand_block_checkbad - [GENERIC] Check if a block is marked bad
@@ -480,8 +481,8 @@
  * Send an entire "SET FEATURES" command to NAND device. This includes
  * the feature address (FA), and the set of 4 parameters to use (P1,P2,P3,P4).
  */
-static int nand_get_features(struct mtd_info *mtd, int feature,
-			     uint8_t *parameters)
+static __maybe_unused int nand_get_features(struct mtd_info *mtd, int feature,
+					    uint8_t *parameters)
 {
 	struct nand_chip *chip = mtd->priv;
 
@@ -1036,10 +1037,15 @@
 		int stat;
 
 		stat = chip->ecc.correct(mtd, p, &ecc_code[i], &ecc_calc[i]);
-		if (stat < 0)
-			mtd->ecc_stats.failed++;
-		else
-			mtd->ecc_stats.corrected += stat;
+		if (stat) {
+			printk(KERN_CONT "sector %d, page %d (0x%012llx)]\n",
+			       chip->ecc.steps - eccsteps, page,
+			       (uint64_t)page << chip->page_shift);
+			if (stat < 0)
+				mtd->ecc_stats.failed++;
+			else
+				mtd->ecc_stats.corrected += stat;
+		}
 	}
 	return 0;
 }
@@ -1281,8 +1287,8 @@
  * @ops:	oob ops structure
  * @len:	size of oob to transfer
  */
-static uint8_t *nand_transfer_oob(struct nand_chip *chip, uint8_t *oob,
-				  struct mtd_oob_ops *ops, size_t len)
+uint8_t *nand_transfer_oob(struct nand_chip *chip, uint8_t *oob,
+			   struct mtd_oob_ops *ops, size_t len)
 {
 	switch(ops->mode) {
 
@@ -1321,6 +1327,7 @@
 	}
 	return NULL;
 }
+EXPORT_SYMBOL_GPL(nand_transfer_oob);
 
 /**
  * nand_do_read_ops - [Internal] Read data with ECC
@@ -2014,8 +2021,8 @@
  * @oob:	oob data buffer
  * @ops:	oob ops structure
  */
-static uint8_t *nand_fill_oob(struct nand_chip *chip, uint8_t *oob,
-				  struct mtd_oob_ops *ops)
+uint8_t *nand_fill_oob(struct nand_chip *chip, uint8_t *oob,
+		       struct mtd_oob_ops *ops)
 {
 	size_t len = ops->ooblen;
 
@@ -2056,6 +2063,7 @@
 	}
 	return NULL;
 }
+EXPORT_SYMBOL_GPL(nand_fill_oob);
 
 #define NOTALIGNED(x)	(x & (chip->subpagesize - 1)) != 0
 
@@ -2763,8 +2771,10 @@
 		}
 	}
 
-	if (i == 3)
+	if (i == 3) {
+		printk(KERN_INFO "No valid ONFI param page found (bad CRC)\n");
 		return 0;
+	}
 
 	/* check version */
 	val = le16_to_cpu(p->revision);
@@ -2867,9 +2877,9 @@
 	 * not match, ignore the device completely.
 	 */
 
+	/* Read entire ID string */
 	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
-
-	for (i = 0; i < 2; i++)
+	for (i = 0; i < 8; i++)
 		id_data[i] = chip->read_byte(mtd);
 
 	if (id_data[0] != *maf_id || id_data[1] != dev_id) {
@@ -2898,11 +2908,6 @@
 	if (!mtd->name)
 		mtd->name = type->name;
 
-	/* Read entire ID string */
-	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
-	for (i = 0; i < 8; i++)
-		id_data[i] = chip->read_byte(mtd);
-
 	/* Decode ID string */
 	if (nand_decode_id(mtd, chip, type, id_data, 8) != 0) {
 		printk(KERN_INFO "Failed to decode NAND READID "
@@ -2958,6 +2963,11 @@
 	else
 		chip->erase_cmd = single_erase_cmd;
 
+	/* Check for Micron '4-bit on-die ECC; device (ID4[1:0]) */
+	if (id_data[0] == NAND_MFR_MICRON && id_data[4] != NAND_MFR_MICRON &&
+	    (id_data[4] & 0x03) == 0x02)
+		chip->options |= NAND_MICRON_4BITONDIEECC;
+
 	/* Do not replace user supplied command function ! */
 	if (mtd->writesize > 512 && chip->cmdfunc == nand_command)
 		chip->cmdfunc = nand_command_lp;
@@ -3051,10 +3061,7 @@
 			chip->ecc.layout = &nand_oob_16;
 			break;
 		case 64:
-			if (chip->ecc.mode == NAND_ECC_4BITONDIE)
-				chip->ecc.layout = &nand_oob_64_4bitondie;
-			else
-				chip->ecc.layout = &nand_oob_64;
+			chip->ecc.layout = &nand_oob_64;
 			break;
 		case 128:
 			chip->ecc.layout = &nand_oob_128;
@@ -3070,6 +3077,13 @@
 		chip->write_page = nand_write_page;
 
 	/*
+	 * For Micron '4-bit on-die ECC' devices, use on-die ECC scheme instead
+	 * of default NAND_ECC_SOFT.
+	 */
+	if (chip->options & NAND_MICRON_4BITONDIEECC &&
+	    chip->ecc.mode == NAND_ECC_SOFT)
+		chip->ecc.mode = NAND_ECC_4BITONDIE;
+	/*
 	 * check ECC mode, default to software if 3byte/512byte hardware ECC is
 	 * selected and we have 256 byte pagesize fallback to software ECC
 	 */
@@ -3162,12 +3176,23 @@
 		break;
 
 	case NAND_ECC_4BITONDIE:
+		if (mtd->oobsize != 64) {
+			printk(KERN_WARNING "No 'Micron on-die ECC' layout for "
+			       "OOB size %d\n", mtd->oobsize);
+			BUG();
+		}
+		if (!(chip->options & NAND_USE_FLASH_BBT)) {
+			printk(KERN_WARNING "'Micron on-die ECC' device "
+			       "requires 'NAND_USE_FLASH_BBT' option");
+			BUG();
+		}
 		chip->ecc.read_page = nand_read_page_raw;
 		chip->ecc.write_page = nand_write_page_raw;
 		chip->ecc.read_page_raw = nand_read_page_raw;
 		chip->ecc.write_page_raw = nand_write_page_raw;
 		chip->ecc.read_oob = nand_read_oob_std;
 		chip->ecc.write_oob = nand_write_oob_std;
+		chip->ecc.layout = &nand_oob_64_4bitondie;
 		chip->ecc.size = 512;
 		chip->ecc.bytes = 8;
 
diff -Naur a/drivers/mtd/nand/nand_bbt.c b/drivers/mtd/nand/nand_bbt.c
--- a/drivers/mtd/nand/nand_bbt.c	2013-11-01 20:19:18.753928975 +0200
+++ b/drivers/mtd/nand/nand_bbt.c	2013-11-01 18:44:50.953823878 +0200
@@ -1275,3 +1275,6 @@
 
 EXPORT_SYMBOL(nand_scan_bbt);
 EXPORT_SYMBOL(nand_default_bbt);
+
+#include "stm_nand_bbt.c"
+
diff -Naur a/drivers/mtd/nand/nand_ids.c b/drivers/mtd/nand/nand_ids.c
--- a/drivers/mtd/nand/nand_ids.c	2013-11-01 20:19:18.757928989 +0200
+++ b/drivers/mtd/nand/nand_ids.c	2013-11-01 18:44:50.953823878 +0200
@@ -185,6 +185,171 @@
 EXPORT_SYMBOL(nand_flash_ids);
 
 /*
+ * ONFI NAND Timing Mode Specifications
+ *
+ * Note, 'tR' field (maximum page read time) is extracted from the ONFI
+ * parameter page during device probe.
+ */
+struct nand_timing_spec nand_onfi_timing_specs[] = {
+	/*
+	 * ONFI Timing Mode '0' (supported on all ONFI compliant devices)
+	 */
+	[0] = {
+		.tCLS	= 50,
+		.tCS	= 70,
+		.tALS	= 50,
+		.tDS	= 40,
+		.tWP	= 50,
+		.tCLH	= 20,
+		.tCH	= 20,
+		.tALH	= 20,
+		.tDH	= 20,
+		.tWB	= 200,
+		.tWH	= 30,
+		.tWC	= 100,
+		.tRP	= 50,
+		.tREH	= 30,
+		.tRC	= 100,
+		.tREA	= 40,
+		.tRHOH	= 0,
+		.tCEA	= 100,
+		.tCOH	= 0,
+		.tCHZ	= 100,
+	},
+
+	/*
+	 * ONFI Timing Mode '1'
+	 */
+	[1] = {
+		.tCLS	= 25,
+		.tCS	= 35,
+		.tALS	= 25,
+		.tDS	= 20,
+		.tWP	= 25,
+		.tCLH	= 10,
+		.tCH	= 10,
+		.tALH	= 10,
+		.tDH	= 10,
+		.tWB	= 100,
+		.tWH	= 15,
+		.tWC	= 45,
+		.tRP	= 25,
+		.tREH	= 15,
+		.tRC	= 50,
+		.tREA	= 30,
+		.tRHOH	= 15,
+		.tCEA	= 45,
+		.tCOH	= 15,
+		.tCHZ	= 50,
+	},
+
+	/*
+	 * ONFI Timing Mode '2'
+	 */
+	[2] = {
+		.tCLS	= 15,
+		.tCS	= 25,
+		.tALS	= 15,
+		.tDS	= 15,
+		.tWP	= 17,
+		.tCLH	= 10,
+		.tCH	= 10,
+		.tALH	= 10,
+		.tDH	= 5,
+		.tWB	= 100,
+		.tWH	= 15,
+		.tWC	= 35,
+		.tRP	= 17,
+		.tREH	= 16,
+		.tRC	= 35,
+		.tREA	= 25,
+		.tRHOH	= 15,
+		.tCEA	= 30,
+		.tCOH	= 15,
+		.tCHZ	= 50,
+	},
+
+	/*
+	 * ONFI Timing Mode '3'
+	 */
+	[3] = {
+		.tCLS	= 10,
+		.tCS	= 25,
+		.tALS	= 10,
+		.tDS	= 10,
+		.tWP	= 15,
+		.tCLH	= 5,
+		.tCH	= 5,
+		.tALH	= 5,
+		.tDH	= 5,
+		.tWB	= 100,
+		.tWH	= 10,
+		.tWC	= 30,
+		.tRP	= 15,
+		.tREH	= 10,
+		.tRC	= 30,
+		.tREA	= 20,
+		.tRHOH	= 15,
+		.tCEA	= 25,
+		.tCOH	= 15,
+		.tCHZ	= 50,
+	},
+
+	/*
+	 * ONFI Timing Mode '4' (EDO only)
+	 */
+	[4] = {
+		.tCLS	= 10,
+		.tCS	= 20,
+		.tALS	= 10,
+		.tDS	= 10,
+		.tWP	= 12,
+		.tCLH	= 5,
+		.tCH	= 5,
+		.tALH	= 5,
+		.tDH	= 5,
+		.tWB	= 100,
+		.tWH	= 10,
+		.tWC	= 25,
+		.tRP	= 12,
+		.tREH	= 10,
+		.tRC	= 25,
+		.tREA	= 20,
+		.tRHOH	= 15,
+		.tCEA	= 25,
+		.tCOH	= 15,
+		.tCHZ	= 30,
+	},
+
+	/*
+	 * ONFI Timing Mode '5' (EDO only)
+	 */
+	[5] = {
+		.tCLS	= 10,
+		.tCS	= 15,
+		.tALS	= 10,
+		.tDS	= 7,
+		.tWP	= 10,
+		.tCLH	= 5,
+		.tCH	= 5,
+		.tALH	= 5,
+		.tDH	= 5,
+		.tWB	= 100,
+		.tWH	= 7,
+		.tWC	= 20,
+		.tRP	= 10,
+		.tREH	= 7,
+		.tRC	= 20,
+		.tREA	= 16,
+		.tRHOH	= 15,
+		.tCEA	= 25,
+		.tCOH	= 15,
+		.tCHZ	= 30,
+	}
+};
+EXPORT_SYMBOL(nand_onfi_timing_specs);
+
+/*
  *	Decode READID data
  */
 
diff -Naur a/drivers/mtd/nand/stm_nand_afm.c b/drivers/mtd/nand/stm_nand_afm.c
--- a/drivers/mtd/nand/stm_nand_afm.c	2013-11-01 20:19:18.765929034 +0200
+++ b/drivers/mtd/nand/stm_nand_afm.c	2013-11-01 18:44:50.961823910 +0200
@@ -26,6 +26,7 @@
 #include <linux/mtd/nand_ecc.h>
 #include <linux/clk.h>
 #include <linux/stm/platform.h>
+#include <linux/stm/pm_sys.h>
 #include <linux/stm/nand.h>
 #include <linux/completion.h>
 #include <linux/interrupt.h>
@@ -33,6 +34,7 @@
 
 #include "stm_nand_ecc.h"
 #include "stm_nand_regs.h"
+#include "stm_nand_bbt.h"
 
 #define NAME	"stm-nand-afm"
 
@@ -93,7 +95,12 @@
 	struct mtd_info		mtd;
 
 	int			csn;
-	struct stm_nand_timing_data *timing_data;
+
+	uint32_t		ctl_timing;
+	uint32_t		wen_timing;
+	uint32_t		ren_timing;
+
+	uint32_t		afm_gen_cfg;
 
 	struct device		*dev;
 
@@ -458,24 +465,6 @@
 };
 #endif
 
-/* Pattern descriptors for scanning bad-block scanning - add support for AFM ECC
- * scheme */
-static uint8_t scan_ff_pattern[] = { 0xff, 0xff };
-static struct nand_bbt_descr bbt_scan_sp = {
-
-	.options = (NAND_BBT_SCAN2NDPAGE | NAND_BBT_SCANSTMAFMECC),
-	.offs = 5,
-	.len = 1,
-	.pattern = scan_ff_pattern
-};
-static struct nand_bbt_descr bbt_scan_lp = {
-	.options = (NAND_BBT_SCAN2NDPAGE | NAND_BBT_SCANSTMAFMECC),
-	.offs = 0,
-	.len = 2,
-	.pattern = scan_ff_pattern
-};
-
-
 /*
  * AFM Interrupts
  */
@@ -532,8 +521,8 @@
  * AFM Initialisation
  */
 
-/* AFM set generic config register */
-static void afm_generic_config(struct stm_nand_afm_controller *afm,
+/* Derive AFM_GEN_CFG data according to device probed */
+static uint32_t afm_gen_config(struct stm_nand_afm_controller *afm,
 			       uint32_t busw, uint32_t page_size,
 			       uint32_t chip_size)
 {
@@ -551,17 +540,20 @@
 			reg |= AFM_GEN_CFG_EXTRA_ADD_CYCLE;
 	} else if (chip_size > (32 << 20)) {
 		reg |= AFM_GEN_CFG_EXTRA_ADD_CYCLE;
-
 	}
 
-	dev_dbg(afm->dev, "setting AFM_GEN_CFG = 0x%08x\n", reg);
-
-	afm_writereg(reg, NANDHAM_AFM_GEN_CFG);
+	return reg;
 }
 
-/* AFM configure timing parameters */
-static void afm_set_timings(struct stm_nand_afm_controller *afm,
-			    struct stm_nand_timing_data *tm)
+/* Derive timing register values from 'stm_nand_timing_data' data.
+ *
+ * [DEPRECATED in favour of afm_calc_timing_registers() based on 'struct
+ * nand_timing_spec' data.]
+ */
+static void afm_calc_timing_registers_legacy(struct stm_nand_timing_data *tm,
+					      uint32_t *ctl_timing,
+					      uint32_t *wen_timing,
+					      uint32_t *ren_timing)
 {
 	uint32_t n;
 	uint32_t reg;
@@ -593,8 +585,7 @@
 	n = (tm->WE_to_RBn + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 24;
 
-	dev_dbg(afm->dev, "setting CTL_TIMING = 0x%08x\n", reg);
-	afm_writereg(reg, NANDHAM_CTL_TIMING);
+	*ctl_timing = reg;
 
 	/* WEN_TIMING */
 	n = (tm->wr_on + emi_t_ns - 1)/emi_t_ns;
@@ -603,8 +594,8 @@
 	n = (tm->wr_off + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 8;
 
-	dev_dbg(afm->dev, "setting WEN_TIMING = 0x%08x\n", reg);
-	afm_writereg(reg, NANDHAM_WEN_TIMING);
+	*wen_timing = reg;
+
 
 	/* REN_TIMING */
 	n = (tm->rd_on + emi_t_ns - 1)/emi_t_ns;
@@ -613,13 +604,149 @@
 	n = (tm->rd_off + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 8;
 
-	dev_dbg(afm->dev, "setting REN_TIMING = 0x%08x\n", reg);
-	afm_writereg(reg, NANDHAM_REN_TIMING);
+	*ren_timing = reg;
+}
+
+/* Derive timing register values from 'nand_timing_spec' data */
+static void afm_calc_timing_registers(struct nand_timing_spec *spec,
+				      int relax,
+				      uint32_t *ctl_timing,
+				      uint32_t *wen_timing,
+				      uint32_t *ren_timing)
+{
+	struct clk *emi_clk;
+	int tCLK;
+
+	int tMAX_HOLD;
+	int n_ctl_setup;
+	int n_ctl_hold;
+	int n_ctl_wb;
+
+	int tMAX_WEN_OFF;
+	int n_wen_on;
+	int n_wen_off;
+
+	int tMAX_REN_OFF;
+	int n_ren_on;
+	int n_ren_off;
+
+	/* Get EMI clock (default 100MHz) */
+	emi_clk = clk_get(NULL, "emi_clk");
+	if (!emi_clk || IS_ERR(emi_clk)) {
+		printk(KERN_WARNING NAME
+		       ": Failed to get EMI clock, assuming default 100MHz\n");
+		tCLK = 10;
+	} else {
+		tCLK = 1000000000 / clk_get_rate(emi_clk);
+	}
+
+	/*
+	 * CTL_TIMING
+	 */
+
+	/*	- SETUP */
+	n_ctl_setup = (spec->tCLS - spec->tWP + tCLK - 1)/tCLK;
+	if (n_ctl_setup < 1)
+		n_ctl_setup = 1;
+	n_ctl_setup += relax;
+
+	/*	- HOLD */
+	tMAX_HOLD = spec->tCLH;
+	if (spec->tCH > tMAX_HOLD)
+		tMAX_HOLD = spec->tCH;
+	if (spec->tALH > tMAX_HOLD)
+		tMAX_HOLD = spec->tALH;
+	if (spec->tDH > tMAX_HOLD)
+		tMAX_HOLD = spec->tDH;
+	n_ctl_hold = (tMAX_HOLD + tCLK - 1)/tCLK + relax;
+
+	/*	- CE_deassert_hold = 0 */
+
+	/*	- WE_high_to_RBn_low */
+	n_ctl_wb = (spec->tWB + tCLK - 1)/tCLK;
+
+	*ctl_timing = ((n_ctl_setup & 0xff) |
+		       (n_ctl_hold & 0xff) << 8 |
+		       (n_ctl_wb & 0xff) << 24);
+
+	/*
+	 * WEN_TIMING
+	 */
+
+	/*	- ON */
+	n_wen_on = (spec->tWH + tCLK - 1)/tCLK - 2;
+	if (n_wen_on < 1)
+		n_wen_on = 1;
+	n_wen_on += relax;
+
+	/*	- OFF */
+	tMAX_WEN_OFF = spec->tWC - spec->tWH;
+	if (spec->tWP > tMAX_WEN_OFF)
+		tMAX_WEN_OFF = spec->tWP;
+	n_wen_off = (tMAX_WEN_OFF + tCLK - 1)/tCLK + relax;
+
+	*wen_timing = ((n_wen_on & 0xff) |
+		       (n_wen_off & 0xff) << 8);
+
+
+	/*
+	 * REN_TIMING
+	 */
+
+	/*	- ON */
+	if (spec->tREH == 3 * tCLK) {
+		n_ren_on = 2;
+	} else {
+		n_ren_on = (spec->tREH + tCLK - 1)/tCLK - 1;
+		if (n_ren_on < 1)
+			n_ren_on = 1;
+	}
+	n_ren_on += relax;
+
+	/*	- OFF */
+	tMAX_REN_OFF = spec->tRC - spec->tREH;
+	if (spec->tRP > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tRP;
+	if (spec->tREA > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tREA;
+	n_ren_off = (tMAX_REN_OFF + tCLK - 1)/tCLK + 1 + relax;
+
+	*ren_timing = ((n_ren_on & 0xff) |
+		       (n_ren_off & 0xff) << 8);
+}
+
+static void afm_init_controller(struct stm_nand_afm_controller *afm)
+{
+	/* Stop AFM Controller, in case it's still running! */
+	afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
+	memset(afm->base + NANDHAM_AFM_SEQ_REG_1, 0, 32);
+
+	/* Reset AFM Controller */
+	afm_writereg((0x1 << 3), NANDHAM_FLEXMODE_CFG);
+	udelay(1);
+	afm_writereg(0x00, NANDHAM_FLEXMODE_CFG);
+
+	/* Disable boot_not_flex */
+	afm_writereg(0x00000000, NANDHAM_BOOTBANK_CFG);
+
+	/* Set Controller to AFM */
+	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
+
+	/* Enable Interrupts: individual interrupts enabled when needed! */
+	afm_writereg(0x0000007C, NANDHAM_INT_CLR);
+	afm_writereg(NAND_EDGE_CFG_RBN_RISING, NANDHAM_INT_EDGE_CFG);
+	afm_writereg(NAND_INT_ENABLE, NANDHAM_INT_EN);
+
+	/* Configure FLEX Data register for 1-byte Read/Write operation */
+	afm_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		     NANDHAM_FLEX_DATAREAD_CONFIG);
+	afm_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		     NANDHAM_FLEX_DATAWRITE_CONFIG);
 }
 
 /* Initialise the AFM NAND controller */
-static struct stm_nand_afm_controller * __init
-afm_init_controller(struct platform_device *pdev)
+static struct stm_nand_afm_controller * __devinit
+afm_init_resources(struct platform_device *pdev)
 {
 	struct stm_plat_nand_flex_data *pdata = pdev->dev.platform_data;
 	struct stm_nand_afm_controller *afm;
@@ -703,27 +830,12 @@
 
 	init_completion(&afm->rbn_completed);
 	init_completion(&afm->seq_completed);
-	afm->current_csn = -1;
 
-	/* Stop AFM Controller, in case it's still running! */
-	afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
-	memset(afm->base + NANDHAM_AFM_SEQ_REG_1, 0, 32);
-
-	/* Reset AFM Controller */
-	afm_writereg((0x1 << 3), NANDHAM_FLEXMODE_CFG);
-	udelay(1);
-	afm_writereg(0x00, NANDHAM_FLEXMODE_CFG);
-
-	/* Disable boot_not_flex */
-	afm_writereg(0x00000000, NANDHAM_BOOTBANK_CFG);
+	afm->current_csn = -1;
 
-	/* Set Controller to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
+	afm_init_controller(afm);
 
-	/* Enable Interrupts: individual interrupts enabled when needed! */
-	afm_writereg(0x0000007C, NANDHAM_INT_CLR);
-	afm_writereg(NAND_EDGE_CFG_RBN_RISING, NANDHAM_INT_EDGE_CFG);
-	afm_writereg(NAND_INT_ENABLE, NANDHAM_INT_EN);
+	platform_set_drvdata(pdev, afm);
 
 	/* Success :-) */
 	return afm;
@@ -745,10 +857,12 @@
 
 }
 
-static void __devexit afm_exit_controller(struct platform_device *pdev)
+static void afm_exit_controller(struct platform_device *pdev)
 {
 	struct stm_nand_afm_controller *afm = platform_get_drvdata(pdev);
 
+	platform_set_drvdata(pdev, NULL);
+
 	free_irq(afm->irq, afm);
 #ifdef CONFIG_STM_NAND_AFM_CACHED
 	iounmap(afm->fifo_cached);
@@ -828,69 +942,11 @@
 		}
 	}
 }
-
-/* Replicated from ../mtdpart.c: required here to get slave MTD offsets and
- * determine which ECC mode to use.
- */
-struct mtd_part {
-	struct mtd_info mtd;
-	struct mtd_info *master;
-	u_int32_t offset;
-	int index;
-	struct list_head list;
-	int registered;
-};
-
-#define PART(x)  ((struct mtd_part *)(x))
 #endif
 
-
-
 /*
  * Internal helper-functions for MTD Interface callbacks
  */
-static uint8_t *afm_transfer_oob(struct nand_chip *chip, uint8_t *oob,
-				 struct mtd_oob_ops *ops, size_t len)
-{
-	switch (ops->mode) {
-
-	case MTD_OOB_PLACE:
-	case MTD_OOB_RAW:
-		memcpy(oob, chip->oob_poi + ops->ooboffs, len);
-		return oob + len;
-
-	case MTD_OOB_AUTO: {
-		struct nand_oobfree *free = chip->ecc.layout->oobfree;
-		uint32_t boffs = 0, roffs = ops->ooboffs;
-		size_t bytes = 0;
-
-		for (; free->length && len; free++, len -= bytes) {
-			/* Read request not from offset 0 ? */
-			if (unlikely(roffs)) {
-				if (roffs >= free->length) {
-					roffs -= free->length;
-					continue;
-				}
-				boffs = free->offset + roffs;
-				bytes = min_t(size_t, len,
-					      (free->length - roffs));
-				roffs = 0;
-			} else {
-				bytes = min_t(size_t, len, free->length);
-				boffs = free->offset;
-			}
-			memcpy(oob, chip->oob_poi + boffs, bytes);
-			oob += bytes;
-		}
-
-		return oob;
-	}
-	default:
-		BUG();
-	}
-	return NULL;
-}
-
 static int afm_do_read_oob(struct mtd_info *mtd, loff_t from,
 			   struct mtd_oob_ops *ops)
 {
@@ -943,7 +999,7 @@
 		sndcmd = chip->ecc.read_oob(mtd, chip, page, sndcmd);
 
 		len = min(len, readlen);
-		buf = afm_transfer_oob(chip, buf, ops, len);
+		buf = nand_transfer_oob(chip, buf, ops, len);
 
 		if (!(chip->options & NAND_NO_READRDY)) {
 			/*
@@ -1047,7 +1103,8 @@
 
 			/* Transfer not aligned data */
 			if (!aligned) {
-				chip->pagebuf = realpage;
+				chip->pagebuf = (ops->mode == MTD_OOB_RAW) ?
+					-1 : realpage;
 				memcpy(buf, chip->buffers->databuf + col,
 				       bytes);
 			}
@@ -1061,16 +1118,16 @@
 					int toread = min(oobreadlen,
 						chip->ecc.layout->oobavail);
 					if (toread) {
-						oob = afm_transfer_oob(chip,
-								       oob,
-								       ops,
-								       toread);
+						oob = nand_transfer_oob(chip,
+									oob,
+									ops,
+									toread);
 						oobreadlen -= toread;
 					}
 				} else
-					buf = afm_transfer_oob(chip,
-							       buf, ops,
-							       mtd->oobsize);
+					buf = nand_transfer_oob(chip,
+								buf, ops,
+								mtd->oobsize);
 			}
 		} else {
 			memcpy(buf, chip->buffers->databuf + col, bytes);
@@ -1116,131 +1173,6 @@
 
 }
 
-static int afm_check_wp(struct mtd_info *mtd)
-{
-	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-	uint32_t status;
-
-	/* Switch to Flex Mode */
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
-
-	/* Read status register */
-	afm_writereg(FLEX_CMD(NAND_CMD_STATUS), NANDHAM_FLEX_CMD);
-	status = afm_readreg(NANDHAM_FLEX_DATA);
-
-	/* Switch back to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
-
-	return (status & NAND_STATUS_WP) ? 0 : 1;
-}
-
-static uint8_t *afm_fill_oob(struct nand_chip *chip, uint8_t *oob,
-			     struct mtd_oob_ops *ops)
-{
-	size_t len = ops->ooblen;
-
-	switch (ops->mode) {
-
-	case MTD_OOB_PLACE:
-	case MTD_OOB_RAW:
-		memcpy(chip->oob_poi + ops->ooboffs, oob, len);
-		return oob + len;
-
-	case MTD_OOB_AUTO: {
-		struct nand_oobfree *free = chip->ecc.layout->oobfree;
-		uint32_t boffs = 0, woffs = ops->ooboffs;
-		size_t bytes = 0;
-
-		for (; free->length && len; free++, len -= bytes) {
-			/* Write request not from offset 0 ? */
-			if (unlikely(woffs)) {
-				if (woffs >= free->length) {
-					woffs -= free->length;
-					continue;
-				}
-				boffs = free->offset + woffs;
-				bytes = min_t(size_t, len,
-					      (free->length - woffs));
-				woffs = 0;
-			} else {
-				bytes = min_t(size_t, len, free->length);
-				boffs = free->offset;
-			}
-			memcpy(chip->oob_poi + boffs, oob, bytes);
-			oob += bytes;
-		}
-		return oob;
-	}
-	default:
-		BUG();
-	}
-	return NULL;
-}
-
-static int afm_do_write_oob(struct mtd_info *mtd, loff_t to,
-			    struct mtd_oob_ops *ops)
-{
-	int chipnr, page, status, len;
-	struct nand_chip *chip = mtd->priv;
-
-	DEBUG(MTD_DEBUG_LEVEL3, "nand_write_oob: to = 0x%08x, len = %i\n",
-	      (unsigned int)to, (int)ops->ooblen);
-
-	if (ops->mode == MTD_OOB_AUTO)
-		len = chip->ecc.layout->oobavail;
-	else
-		len = mtd->oobsize;
-
-	/* Do not allow write past end of page */
-	if ((ops->ooboffs + ops->ooblen) > len) {
-		DEBUG(MTD_DEBUG_LEVEL0, "nand_write_oob: "
-		      "Attempt to write past end of page\n");
-		return -EINVAL;
-	}
-
-	if (unlikely(ops->ooboffs >= len)) {
-		DEBUG(MTD_DEBUG_LEVEL0, "nand_read_oob: "
-			"Attempt to start write outside oob\n");
-		return -EINVAL;
-	}
-
-	/* Do not allow reads past end of device */
-	if (unlikely(to >= mtd->size ||
-		     ops->ooboffs + ops->ooblen >
-			((mtd->size >> chip->page_shift) -
-			 (to >> chip->page_shift)) * len)) {
-		DEBUG(MTD_DEBUG_LEVEL0, "nand_read_oob: "
-			"Attempt write beyond end of device\n");
-		return -EINVAL;
-	}
-
-	chipnr = (int)(to >> chip->chip_shift);
-	chip->select_chip(mtd, chipnr);
-
-	/* Shift to get page */
-	page = (int)(to >> chip->page_shift);
-
-	/* Check, if it is write protected */
-	if (afm_check_wp(mtd))
-		return -EROFS;
-
-	/* Invalidate the page cache, if we write to the cached page */
-	if (page == chip->pagebuf)
-		chip->pagebuf = -1;
-
-	memset(chip->oob_poi, 0xff, mtd->oobsize);
-	afm_fill_oob(chip, ops->oobbuf, ops);
-	status = chip->ecc.write_oob(mtd, chip, page & chip->pagemask);
-	memset(chip->oob_poi, 0xff, mtd->oobsize);
-
-	if (status)
-		return status;
-
-	ops->oobretlen = ops->ooblen;
-
-	return 0;
-}
-
 static int afm_write_page(struct mtd_info *mtd, struct nand_chip *chip,
 			  const uint8_t *buf, int page, int cached, int raw)
 {
@@ -1294,7 +1226,7 @@
 	chip->select_chip(mtd, chipnr);
 
 	/* Check, if it is write protected */
-	if (afm_check_wp(mtd))
+	if (nand_check_wp(mtd))
 		return -EIO;
 
 	realpage = (int)(to >> chip->page_shift);
@@ -1332,7 +1264,7 @@
 		}
 
 		if (unlikely(oob))
-			oob = afm_fill_oob(chip, oob, ops);
+			oob = nand_fill_oob(chip, oob, ops);
 
 		ret = chip->write_page(mtd, chip, wbuf, page, cached,
 				       (ops->mode == MTD_OOB_RAW));
@@ -1427,7 +1359,7 @@
 		chip->ops.oobbuf = buf;
 		chip->ops.ooboffs = chip->badblockpos & ~0x01;
 
-		ret = afm_do_write_oob(mtd, offs, &chip->ops);
+		ret = nand_do_write_oob(mtd, offs, &chip->ops);
 		nand_release_device(mtd);
 	}
 	if (ret == 0)
@@ -1560,7 +1492,7 @@
 	}
 
 	if (!ops->datbuf)
-		ret = afm_do_write_oob(mtd, to, ops);
+		ret = nand_do_write_oob(mtd, to, ops);
 	else
 		ret = afm_do_write_ops(mtd, to, ops);
 
@@ -1569,45 +1501,12 @@
 	return ret;
 }
 
-/* MTD Interface - Sync (just wait for chip ready, then release) */
-static void afm_sync(struct mtd_info *mtd)
-{
-	struct nand_chip *chip = mtd->priv;
-
-	DEBUG(MTD_DEBUG_LEVEL3, "nand_sync: called\n");
-
-	/* Grab the lock and see if the device is available */
-	nand_get_device(chip, mtd, FL_SYNCING);
-	/* Release it and go back */
-	nand_release_device(mtd);
-}
-
-/* MTD Interface - Suspend (wait for chip ready, then suspend) */
-static int afm_suspend(struct mtd_info *mtd)
-{
-	struct nand_chip *chip = mtd->priv;
-
-	return nand_get_device(chip, mtd, FL_PM_SUSPENDED);
-}
-
-/* MTD Interface - Resume (release device) */
-static void afm_resume(struct mtd_info *mtd)
-{
-	struct nand_chip *chip = mtd->priv;
-
-	if (chip->state == FL_PM_SUSPENDED)
-		nand_release_device(mtd);
-	else
-		printk(KERN_ERR "afm_resume() called for a chip which is not "
-		       "in suspended state\n");
-}
-
 /*
  * AFM data transfer routines
  */
 
 #ifdef CONFIG_STM_NAND_AFM_CACHED
-static void afm_read_buf_cached(struct mtd_info *mtd, uint8_t *buf, int len)
+static void afm_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
 {
 	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
 
@@ -1675,6 +1574,9 @@
 
 	afm->status = 0;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Initialise Seq interrupts */
 	INIT_COMPLETION(afm->seq_completed);
 	afm_enable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -1696,7 +1598,7 @@
 	/* Wait for sequence to finish */
 	ret = wait_for_completion_timeout(&afm->seq_completed, 2*HZ);
 	if (!ret) {
-		dev_warn(afm->dev, "sequence timeout, force exit!\n");
+		dev_warn(afm->dev, "%s: Seq timeout, force exit!\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -1711,26 +1613,6 @@
 	afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
 }
 
-static int afm_correct_ecc(struct mtd_info *mtd, unsigned char *buf,
-			   unsigned char *read_ecc, unsigned char *calc_ecc)
-{
-	/* No error */
-	if ((read_ecc[0] ^ calc_ecc[0]) == 0 &&
-	    (read_ecc[1] ^ calc_ecc[1]) == 0 &&
-	    (read_ecc[2] ^ calc_ecc[2]) == 0)
-		return 0;
-
-	/* Special test for freshly erased page */
-	if (read_ecc[0] == 0xff && calc_ecc[0] == 0x00 &&
-	    read_ecc[1] == 0xff && calc_ecc[1] == 0x00 &&
-	    read_ecc[2] == 0xff && calc_ecc[2] == 0x00)
-		return 0;
-
-	/* Use nand_ecc.c:nand_correct_data() function */
-	return nand_correct_data(mtd, buf, read_ecc, calc_ecc);
-
-}
-
 /* AFM: Read Page and OOB Data with ECC */
 static int afm_read_page_ecc(struct mtd_info *mtd, struct nand_chip *chip,
 			     uint8_t *buf, int page)
@@ -1792,12 +1674,17 @@
 		p += eccsize;
 	}
 
+	/* Check for empty page before attempting ECC fixes */
+	if (stmnand_test_empty_page(ecc_code, ecc_calc, eccsteps, eccbytes,
+				    buf, NULL, mtd->writesize, 0, 1))
+		return 0;
+
 	/* Detect/Correct ECC errors */
 	p = buf;
 	for (i = 0 ; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
 		int stat;
 
-		stat = afm_correct_ecc(mtd, p, &ecc_code[i], &ecc_calc[i]);
+		stat = nand_correct_data(mtd, p, &ecc_code[i], &ecc_calc[i]);
 
 		if (stat == -1) {
 			mtd->ecc_stats.failed++;
@@ -1823,6 +1710,9 @@
 	uint32_t reg;
 	int ret;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Select AFM program */
 	prog = (mtd->writesize == 512) ?
 		&afm_prog_read_raw_sp :
@@ -1848,14 +1738,14 @@
 	/* Wait for data to become available */
 	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "RBn timeout, force exit\n");
+		dev_err(afm->dev, "%s: RBn timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm_disable_interrupts(afm, NAND_INT_RBN);
 		return 1;
 	}
 	/* Read page data and OOB (SmallPage: +48 bytes dummy data) */
-	chip->read_buf(mtd, buf, mtd->writesize);
-	chip->read_buf(mtd, chip->oob_poi, 64);
+	afm_read_buf(mtd, buf, mtd->writesize);
+	afm_read_buf(mtd, chip->oob_poi, 64);
 
 	/* Disable RBn interrupts */
 	afm_disable_interrupts(afm, NAND_INT_RBN);
@@ -1872,6 +1762,9 @@
 	uint32_t reg;
 	int ret;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Select AFM program */
 	prog = (mtd->writesize == 512) ?
 		&afm_prog_read_oob_sp :
@@ -1899,14 +1792,14 @@
 	/* Wait for data to become available */
 	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "RBn timeout, force exit\n");
+		dev_err(afm->dev, "%s: RBn timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm_disable_interrupts(afm, NAND_INT_RBN);
 		return 1;
 	}
 
 	/* Read OOB data to chip->oob_poi buffer */
-	chip->read_buf(mtd, chip->oob_poi, 64);
+	afm_read_buf(mtd, chip->oob_poi, 64);
 
 	/* Disable RBn Interrupts */
 	afm_disable_interrupts(afm, NAND_INT_RBN);
@@ -1927,7 +1820,10 @@
 
 	afm->status = 0;
 
-	/* 1. Write page data to chip's page buffer */
+	/* 1. Use AFM to write page data to chip's page buffer */
+
+	/*    Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
 
 	/*    Initialise Seq interrupt */
 	INIT_COMPLETION(afm->seq_completed);
@@ -1945,12 +1841,12 @@
 	memcpy_toio(afm->base + NANDHAM_AFM_SEQ_REG_1, prog, 32);
 
 	/*    Write page data */
-	chip->write_buf(mtd, buf, mtd->writesize);
+	afm_write_buf(mtd, buf, mtd->writesize);
 
 	/*    Wait for the sequence to terminate */
 	ret = wait_for_completion_timeout(&afm->seq_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "seq timeout, force exit\n");
+		dev_err(afm->dev, "%s: Seq timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -1960,8 +1856,9 @@
 	/*    Disable Seq interrupt */
 	afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
 
-	/* 2. Write OOB data */
-	/*    Populate OOB with ECC data  */
+	/* 2. Use FLEX Mode to write OOB data */
+
+	/*    Collect AFM ECC from Controller and populate OOB  */
 	ecc_afm = afm_readreg(NANDHAM_AFM_ECC_REG_3);
 	chip->oob_poi[0] = ecc_afm & 0xff; ecc_afm >>= 8;
 	chip->oob_poi[1] = ecc_afm & 0xff; ecc_afm >>= 8;
@@ -1971,10 +1868,12 @@
 	chip->oob_poi[5] = 'M';
 	chip->oob_poi[6] = stm_afm_lp1617(buf);
 
-	/*    Switch to FLEX mode for writing OOB */
+	/*    Enable FLEX mode */
+	afm_writereg(CFG_ENABLE_FLEX, NANDHAM_FLEXMODE_CFG);
+
+	/*    Initialise RBn interrupt */
 	INIT_COMPLETION(afm->rbn_completed);
 	afm_enable_interrupts(afm, NAND_INT_RBN);
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
 
 	/*    Write OOB data */
 	afm_writereg(FLEX_DATA_CFG_BEATS_4 | FLEX_DATA_CFG_CSN,
@@ -1989,16 +1888,14 @@
 	/*    Wait for page program operation to complete */
 	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
 	if (!ret)
-		dev_err(afm->dev, "RBn timeout, force exit\n");
+		dev_err(afm->dev, "%s: RBn timeout, force exit\n", __func__);
 
-	/*     Get status */
+	/*    Get status */
 	afm_writereg(FLEX_CMD(NAND_CMD_STATUS), NANDHAM_FLEX_CMD);
 	afm->status = afm_readreg(NANDHAM_FLEX_DATA);
 
+	/*    Disable RBn Interrupt */
 	afm_disable_interrupts(afm, NAND_INT_RBN);
-
-	/* 3. Switch back to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
 }
 
 
@@ -2022,6 +1919,9 @@
 
 	afm->status = 0;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Calc S/W ECC LP1617, insert into OOB area with 'AFM' signature */
 	p = buf;
 	for (i = 0; i < eccsteps; i++) {
@@ -2048,13 +1948,13 @@
 	memcpy_toio(afm->base + NANDHAM_AFM_SEQ_REG_1, prog, 32);
 
 	/* Write page and oob data */
-	chip->write_buf(mtd, buf, mtd->writesize);
-	chip->write_buf(mtd, chip->oob_poi, 64);
+	afm_write_buf(mtd, buf, mtd->writesize);
+	afm_write_buf(mtd, chip->oob_poi, 64);
 
 	/* Wait for sequence to complete */
 	ret = wait_for_completion_timeout(&afm->seq_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "seq timeout, force exit\n");
+		dev_err(afm->dev, "%s: Seq timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -2080,6 +1980,9 @@
 
 	afm->status = 0;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Initialise Seq Interrupts */
 	INIT_COMPLETION(afm->seq_completed);
 	afm_enable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -2091,13 +1994,13 @@
 	memcpy_toio(afm->base + NANDHAM_AFM_SEQ_REG_1, prog, 32);
 
 	/* Write page and OOB data */
-	chip->write_buf(mtd, buf, 2048);
-	chip->write_buf(mtd, chip->oob_poi, 64);
+	afm_write_buf(mtd, buf, mtd->writesize);
+	afm_write_buf(mtd, chip->oob_poi, 64);
 
 	/* Wait for sequence to complete */
 	ret = wait_for_completion_timeout(&afm->seq_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "seq timeout, force exit\n");
+		dev_err(afm->dev, "%s: Seq timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -2123,24 +2026,35 @@
 
 	afm->status = 0;
 
-	/* Enable sequence interrupts */
+	/* 1. Use AFM to write page data to chip's page buffer */
+
+	/*    Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
+	/*    Initialise Seq interrupt */
 	INIT_COMPLETION(afm->seq_completed);
 	afm_enable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
 
-	/* 1. Write page data to chip's page buffer */
+	/*    Set page address */
 	prog->addr_reg	= afm->page << 8;
+
+	/*    Copy program to controller, and start sequence */
 	memcpy_toio(afm->base + NANDHAM_AFM_SEQ_REG_1, prog, 32);
 
-	chip->write_buf(mtd, buf, mtd->writesize);
+	/*    Wite page data */
+	afm_write_buf(mtd, buf, mtd->writesize);
 
+	/*    Wait for the sequence to terminate */
 	ret = wait_for_completion_timeout(&afm->seq_completed, HZ/2);
 	if (!ret) {
-		dev_err(afm->dev, "seq timeout, force exit\n");
+		dev_err(afm->dev, "%s: Seq timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
 		return;
 	}
+
+	/*    Disable Seq interrupt */
 	afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
 
 	reg = afm_readreg(NANDHAM_AFM_SEQ_STA);
@@ -2150,10 +2064,14 @@
 		return;
 	}
 
-	/* 2. Switch to FLEX mode and write OOB data */
+	/* 2. Use FLEX Mode to write OOB data */
+
+	/*    Enable FLEX Mode */
+	afm_writereg(CFG_ENABLE_FLEX, NANDHAM_FLEXMODE_CFG);
+
+	/*    Initialise RBn interrupt */
 	INIT_COMPLETION(afm->rbn_completed);
 	afm_enable_interrupts(afm, NAND_INT_RBN);
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
 
 	/*    Send OOB pointer operation */
 	afm_writereg(FLEX_CMD(NAND_CMD_READOOB),  NANDHAM_FLEX_CMD);
@@ -2183,7 +2101,7 @@
 	/* Wait for page program operation to complete */
 	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
 	if (!ret)
-		dev_err(afm->dev, "RBn timeout!\n");
+		dev_err(afm->dev, "%s: RBn timeout!\n", __func__);
 
 	/*     Get status */
 	afm_writereg(FLEX_CMD(NAND_CMD_STATUS), NANDHAM_FLEX_CMD);
@@ -2191,8 +2109,6 @@
 
 	afm_disable_interrupts(afm, NAND_INT_RBN);
 
-	/* 3. Switch back to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
 }
 
 /* AFM: Write OOB Data [LargePage] */
@@ -2206,6 +2122,9 @@
 
 	afm->status = 0;
 
+	/* Enable AFM */
+	afm_writereg(CFG_ENABLE_AFM, NANDHAM_FLEXMODE_CFG);
+
 	/* Enable sequence interrupts */
 	INIT_COMPLETION(afm->seq_completed);
 	afm_enable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -2215,12 +2134,12 @@
 	memcpy_toio(afm->base + NANDHAM_AFM_SEQ_REG_1, prog, 32);
 
 	/* Write OOB */
-	chip->write_buf(mtd, chip->oob_poi, 64);
+	afm_write_buf(mtd, chip->oob_poi, 64);
 
 	/* Wait for sequence to complete */
 	ret = wait_for_completion_timeout(&afm->seq_completed, HZ);
 	if (!ret) {
-		dev_err(afm->dev, "seq timeout, force exit\n");
+		dev_err(afm->dev, "%s: Seq timeout, force exit\n", __func__);
 		afm_writereg(0x00000000, NANDHAM_AFM_SEQ_CFG);
 		afm->status = NAND_STATUS_FAIL;
 		afm_disable_interrupts(afm, NANDHAM_INT_SEQ_DREQ);
@@ -2248,13 +2167,13 @@
 
 	afm->status = 0;
 
+	/* Enable FLEX Mode */
+	afm_writereg(CFG_ENABLE_FLEX, NANDHAM_FLEXMODE_CFG);
+
 	/* Initialise interrupts */
 	INIT_COMPLETION(afm->rbn_completed);
 	afm_enable_interrupts(afm, NAND_INT_RBN);
 
-	/* Switch to Flex Mode */
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
-
 	/* Pointer Operation */
 	afm_writereg(FLEX_CMD(NAND_CMD_READOOB), NANDHAM_FLEX_CMD);
 
@@ -2287,7 +2206,7 @@
 	/* Wait for page program operation to complete */
 	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
 	if (!ret)
-		dev_err(afm->dev, "RBn timeout\n");
+		dev_err(afm->dev, "%s: RBn timeout\n", __func__);
 
 	/* Get status */
 	afm_writereg(FLEX_CMD(NAND_CMD_STATUS), NANDHAM_FLEX_CMD);
@@ -2295,67 +2214,12 @@
 
 	afm->status = 0xff & status;
 
-	/* Switch back to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
-
 	/* Disable RBn interrupts */
 	afm_disable_interrupts(afm, NAND_INT_RBN);
 
 	return status & NAND_STATUS_FAIL ? -EIO : 0;
 }
 
-/* Read the device electronic signature */
-static int afm_read_sig(struct mtd_info *mtd,
-		       int *maf_id, int *dev_id,
-		       uint8_t *cellinfo, uint8_t *extid)
-{
-	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-	uint32_t ret, reg;
-
-	/* Enable RBn interrupts */
-	INIT_COMPLETION(afm->rbn_completed);
-	afm_enable_interrupts(afm, NAND_INT_RBN);
-
-	/* Switch to Flex Mode */
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
-
-	/* Issue NAND reset */
-	afm_writereg(FLEX_CMD(NAND_CMD_RESET), NANDHAM_FLEX_CMD);
-
-	/* Wait for reset to complete */
-	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
-	if (!ret)
-		dev_err(afm->dev, "RBn timeout\n");
-
-	/* Read electronic signature */
-	afm_writereg(FLEX_CMD(NAND_CMD_READID), NANDHAM_FLEX_CMD);
-
-	reg = (0x00 | FLEX_ADDR_BEATS_1 | FLEX_ADDR_RBN | FLEX_ADDR_CSN);
-	afm_writereg(reg, NANDHAM_FLEX_ADD);
-
-	afm_writereg(FLEX_DATA_CFG_BEATS_4 | FLEX_DATA_CFG_CSN,
-		     NANDHAM_FLEX_DATAREAD_CONFIG);
-	reg = afm_readreg(NANDHAM_FLEX_DATA);
-	afm_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
-		      NANDHAM_FLEX_DATAREAD_CONFIG);
-
-	/* Extract manufacturer and device ID */
-	*maf_id = reg & 0xff;
-	*dev_id = (reg >> 8) & 0xff;
-
-	/* Newer devices have all the information in additional id bytes */
-	*cellinfo = (reg >> 16) & 0xff;
-	*extid = (reg >> 24) & 0xff;
-
-	/* Switch back to AFM Mode */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
-
-	/* Disable RBn interrupts */
-	afm_disable_interrupts(afm, NAND_INT_RBN);
-
-	return 0;
-}
-
 #ifdef CONFIG_STM_NAND_AFM_BOOTMODESUPPORT
 /* For boot-mode, we use software ECC with AFM raw read/write commands */
 static int boot_calc_ecc(struct mtd_info *mtd, const unsigned char *buf,
@@ -2405,6 +2269,11 @@
 	eccsteps = chip->ecc.steps;
 	p = buf;
 
+	/* Check for empty page before attempting ECC fixes */
+	if (stmnand_test_empty_page(ecc_code, ecc_calc, eccsteps, eccbytes,
+				    buf, NULL, mtd->writesize, 0, 1))
+		return 0;
+
 	for (i = 0 ; eccsteps; eccsteps--, i += eccbytes, p += eccsize) {
 		int stat;
 
@@ -2469,8 +2338,22 @@
 		afm->current_csn = data->csn;
 		afm_writereg(0x1 << data->csn, NANDHAM_FLEX_MUXCTRL);
 
-		/* Set up timing parameters */
-		afm_set_timings(afm, data->timing_data);
+		/* Update AFM_GEN_CFG */
+		dev_dbg(afm->dev, "updating generic configuration [0x%08x]\n",
+			data->afm_gen_cfg);
+		afm_writereg(data->afm_gen_cfg, NANDHAM_AFM_GEN_CFG);
+
+		/* Configure timing registers */
+		if (data->ctl_timing) {
+			dev_dbg(afm->dev, "updating timing configuration "
+				"[0x%08x, 0x%08x, 0x%08x]\n",
+				data->ctl_timing,
+				data->wen_timing,
+				data->ren_timing);
+			afm_writereg(data->ctl_timing, NANDHAM_CTL_TIMING);
+			afm_writereg(data->wen_timing, NANDHAM_WEN_TIMING);
+			afm_writereg(data->ren_timing, NANDHAM_REN_TIMING);
+		}
 	} else {
 		dev_err(afm->dev, "attempt to select chipnr = %d\n", chipnr);
 	}
@@ -2478,253 +2361,245 @@
 	return;
 }
 
-/* The low-level AFM chip operations wait internally, and set the status field.
- * All that is left to do here is return the status */
-static int afm_wait(struct mtd_info *mtd, struct nand_chip *chip)
-{
-	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-
-	return afm->status;
-}
-
 /*
- * afm_command() and afm_read_byte() are treated as special cases here.  We need
- * to support nand_base.c:nand_erase_nand() because this is called directly by
- * nand_bbt.c (why is it not a callback?).  However, nand_erase_nand() calls
- * nand_check_wp() which in turn calls chip->cmdfunc() and chip->read_byte() in
- * order to check the status register.  Since nand_check_wp() is the only
- * function that uses these callbacks, we can implement specialised versions
- * such that afm_command() is empty, and afm_read_byte() queries and returns the
- * status register.
+ * Partial implementation of 'chip->cmdfunc' interface, based on Hamming-FLEX
+ * operation.
  *
- * Need to track updates to nand_base.c to ensure these assumptions remain valid
- * in the future!
+ * Allows us to make use of nand_base.c functions where possible
+ * (e.g. nand_scan_ident() and friends).
  */
-static void afm_command(struct mtd_info *mtd, unsigned int command,
-			 int column, int page_addr)
+static int flex_wait_rbn(struct stm_nand_afm_controller *afm)
 {
+	int ret;
 
+	ret = wait_for_completion_timeout(&afm->rbn_completed, HZ/2);
+	if (!ret)
+		dev_err(afm->dev, "%s: FLEX RBn timeout\n", __func__);
+
+	return ret;
 }
 
-static uint8_t afm_read_byte(struct mtd_info *mtd)
+static void flex_cmd(struct stm_nand_afm_controller *afm, uint8_t cmd)
 {
-	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-	uint32_t reg;
-
-	/* Switch to Flex Mode */
-	afm_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
-
-	/* Write STATUS command (do not set FLEX_CMD_RBN!) */
-	reg = (NAND_CMD_STATUS | FLEX_CMD_BEATS_1 | FLEX_CMD_CSN);
-	afm_writereg(reg, NANDHAM_FLEX_CMD);
+	uint32_t val;
 
-	reg = afm_readreg(NANDHAM_FLEX_DATA);
+	val = (FLEX_CMD_CSN | FLEX_CMD_BEATS_1 | cmd);
 
-	/* Switch back to AFM */
-	afm_writereg(0x00000002, NANDHAM_FLEXMODE_CFG);
-
-	return reg & 0xff;
+	afm_writereg(val, NANDHAM_FLEX_CMD);
 }
 
-static int afm_verify_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+static void flex_addr(struct stm_nand_afm_controller *afm,
+		      uint32_t addr, int cycles)
 {
-	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
-	BUG();
+	addr &= 0x00ffffff;
 
-	return 0;
-}
+	BUG_ON(cycles < 1);
+	BUG_ON(cycles > 3);
 
-static u16 afm_read_word(struct mtd_info *mtd)
-{
-	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
-	BUG();
+	addr |= (FLEX_ADDR_CSN | FLEX_ADDR_ADD8_VALID);
+	addr |= (cycles & 0x3) << 28;
 
-	return 0xff;
+	afm_writereg(addr, NANDHAM_FLEX_ADD);
 }
 
-/*
- * AFM scan/probe NAND routines
- */
-
-/* Set AFM generic call-backs (not chip-specific) */
-static void afm_set_defaults(struct nand_chip *chip, int busw)
+static uint8_t flex_read_byte(struct mtd_info *mtd)
 {
-	chip->chip_delay = 0;
-	chip->cmdfunc = afm_command;
-	chip->waitfunc = afm_wait;
-	chip->select_chip = afm_select_chip;
-	chip->read_byte = afm_read_byte;
-	chip->read_word = afm_read_word;
-	chip->block_bad = NULL;
-	chip->block_markbad = NULL;
-	chip->write_buf = afm_write_buf;
-	chip->verify_buf = afm_verify_buf;
-	chip->scan_bbt = nand_default_bbt;
-#ifdef CONFIG_STM_NAND_AFM_CACHED
-	chip->read_buf = afm_read_buf_cached;
-#else
-	chip->read_buf = afm_read_buf;
-#endif
-}
+	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
 
+	return (uint8_t)(afm_readreg(NANDHAM_FLEX_DATA) & 0xff);
+}
 
-/* Determine the NAND device paramters
- * [cf nand_base.c:nand_get_flash_type()] */
-static struct nand_flash_dev *afm_get_flash_type(struct mtd_info *mtd,
-						 struct nand_chip *chip,
-						 int busw, int *maf_id)
+static void flex_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
 {
 	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-	struct nand_flash_dev *type = NULL;
-	int i, dev_id, maf_idx;
-	uint8_t cellinfo;
-	uint8_t extid;
+	int aligned;
 
-	/* Select the device */
-	chip->select_chip(mtd, 0);
+	/* Read bytes until buf is 4-byte aligned */
+	while (len && ((unsigned int)buf & 0x3)) {
+		*buf++ = (uint8_t)(readl(afm->base + NANDHAM_FLEX_DATA)
+				   & 0xff);
+		len--;
+	};
 
-	/* Read the electronic signature */
-	afm_read_sig(mtd, maf_id, &dev_id, &cellinfo, &extid);
+	/* Use 'BEATS_4'/readsl */
+	if (len > 8) {
+		aligned = len & ~0x3;
+		writel(FLEX_DATA_CFG_BEATS_4 | FLEX_DATA_CFG_CSN,
+		       afm->base + NANDHAM_FLEX_DATAREAD_CONFIG);
 
-	/* Lookup device */
-	for (i = 0; nand_flash_ids[i].name != NULL; i++) {
-		if (dev_id == nand_flash_ids[i].id) {
-			type =  &nand_flash_ids[i];
-			break;
-		}
-	}
+		readsl(afm->base + NANDHAM_FLEX_DATA, buf, aligned >> 2);
 
-	if (!type)
-		return ERR_PTR(-ENODEV);
+		buf += aligned;
+		len -= aligned;
 
-	if (!mtd->name)
-		mtd->name = type->name;
+		writel(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		       afm->base + NANDHAM_FLEX_DATAREAD_CONFIG);
+	}
 
-	chip->chipsize = type->chipsize << 20;
+	/* Mop up remaining bytes */
+	while (len > 0) {
+		*buf++ = (uint8_t)(readl(afm->base + NANDHAM_FLEX_DATA)
+				   & 0xff);
+		len--;
+	}
+}
 
-	if (!type->pagesize) {
-		/* New devices use the extended chip info... */
-		chip->cellinfo = cellinfo;
+static void flex_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
+	int aligned;
 
-		/* Calc pagesize */
-		mtd->writesize = 1024 << (extid & 0x3);
-		extid >>= 2;
+	/* Write bytes until buf is 4-byte aligned */
+	while (len && ((unsigned int)buf & 0x3)) {
+		writel(*buf++, afm->base + NANDHAM_FLEX_DATA);
+		len--;
+	};
 
-		/* Calc oobsize */
-		mtd->oobsize = (8 << (extid & 0x01)) * (mtd->writesize >> 9);
-		extid >>= 2;
+	/* USE 'BEATS_4/writesl */
+	if (len > 8) {
+		aligned = len & ~0x3;
+		writel(FLEX_DATA_CFG_BEATS_4 | FLEX_DATA_CFG_CSN,
+		       afm->base + NANDHAM_FLEX_DATAWRITE_CONFIG);
+		writesl(afm->base + NANDHAM_FLEX_DATA, buf, aligned >> 2);
+		buf += aligned;
+		len -= aligned;
+		writel(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		       afm->base + NANDHAM_FLEX_DATAWRITE_CONFIG);
+	}
 
-		/* Calc blocksize. Blocksize is multiples of 64KiB */
-		mtd->erasesize = (64 * 1024) << (extid & 0x03);
-		extid >>= 2;
+	/* Mop up remaining bytes */
+	while (len > 0) {
+		writel(*buf++, afm->base + NANDHAM_FLEX_DATA);
+		len--;
+	}
+}
 
-		/* Get buswidth information */
-		busw = (extid & 0x01) ? NAND_BUSWIDTH_16 : 0;
+/* Wait for device to become ready, and return the status register */
+static int afm_wait(struct mtd_info *mtd, struct nand_chip *chip)
+{
+	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
+	int status;
+
+	if (afm_readreg(NANDHAM_FLEXMODE_CFG) & CFG_ENABLE_AFM) {
+		/* All AFM-based routines employ their own wait function,
+		 * so all that remains is to return the saved status */
+		status = afm->status;
 	} else {
-		/* Old devices have chip data hardcoded in device id table */
-		mtd->erasesize = type->erasesize;
-		mtd->writesize = type->pagesize;
-		mtd->oobsize = mtd->writesize / 32;
-		busw = type->options & NAND_BUSWIDTH_16;
+		/* If we were executing a FLEX-based routine, wait for RBn and
+		 * read the status register. */
+		flex_wait_rbn(afm);
+		flex_cmd(afm, NAND_CMD_STATUS);
+		status = (int)(afm_readreg(NANDHAM_FLEX_DATA) & 0xff);
 	}
 
-	afm_generic_config(afm, chip->options & NAND_BUSWIDTH_16,
-			   mtd->writesize, chip->chipsize);
-
-	/* Try to identify manufacturer */
-	for (maf_idx = 0; nand_manuf_ids[maf_idx].id != 0x0; maf_idx++) {
-		if (nand_manuf_ids[maf_idx].id == *maf_id)
-			break;
+	return status;
+}
+
+static void flex_command(struct mtd_info *mtd, unsigned int command,
+			 int column, int page)
+{
+	struct nand_chip *chip = mtd->priv;
+	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
+
+	/* Enable FLEX Mode */
+	afm_writereg(CFG_ENABLE_FLEX, NANDHAM_FLEXMODE_CFG);
+
+	switch (command) {
+	case NAND_CMD_RESET:
+	case NAND_CMD_PARAM:
+		/* Prime RBn wait */
+		INIT_COMPLETION(afm->rbn_completed);
+		afm_enable_interrupts(afm, NAND_INT_RBN);
+		break;
+	case NAND_CMD_READID:
+	case NAND_CMD_STATUS:
+		break;
+	default:
+		/* Catch unexpected commands */
+		BUG();
 	}
 
 	/*
-	 * Check, if buswidth is correct. Hardware drivers should set
-	 * chip correct !
+	 * Command Cycle
 	 */
-	if (busw != (chip->options & NAND_BUSWIDTH_16)) {
-		dev_info(afm->dev, "NAND device: Manufacturer ID:"
-			 " 0x%02x, Chip ID: 0x%02x (%s %s)\n", *maf_id,
-			 dev_id, nand_manuf_ids[maf_idx].name, mtd->name);
-		dev_info(afm->dev, "NAND bus width %d instead %d bit\n",
-			 (chip->options & NAND_BUSWIDTH_16) ? 16 : 8,
-			 busw ? 16 : 8);
-		return ERR_PTR(-EINVAL);
-	}
-
-	/* Calculate the address shift from the page size */
-	chip->page_shift = ffs(mtd->writesize) - 1;
-
-	/* Convert chipsize to number of pages per chip -1. */
-	chip->pagemask = (chip->chipsize >> chip->page_shift) - 1;
-
-	chip->bbt_erase_shift = ffs(mtd->erasesize) - 1;
-	chip->phys_erase_shift = chip->bbt_erase_shift;
-
-	chip->chip_shift = ffs(chip->chipsize) - 1;
-
-	/* Set the bad block position [AAC: Now obsolete?] */
-	chip->badblockpos = mtd->writesize > 512 ?
-		NAND_LARGE_BADBLOCK_POS : NAND_SMALL_BADBLOCK_POS;
-
-	/* Get chip options, preserve non chip based options */
-	chip->options &= ~NAND_CHIPOPTIONS_MSK;
-	chip->options |= type->options & NAND_CHIPOPTIONS_MSK;
+	flex_cmd(afm, command);
 
 	/*
-	 * Set chip as a default. Board drivers can override it, if necessary
+	 * Address Cycles
 	 */
-	chip->options |= NAND_NO_AUTOINCR;
+	if (column != -1)
+		flex_addr(afm, column,
+			  (command == NAND_CMD_READID) ? 1 : 2);
+	if (page != -1)
+		flex_addr(afm, page, (chip->chipsize > (128 << 20)) ? 3 : 2);
 
-	/* Check if chip is a not a samsung device. Do not clear the
-	 * options for chips which are not having an extended id.
+	/*
+	 * Wait for RBn, if required.
 	 */
-	if (*maf_id != NAND_MFR_SAMSUNG && !type->pagesize)
-		chip->options &= ~NAND_SAMSUNG_LP_OPTIONS;
+	if (command == NAND_CMD_RESET ||
+	    command == NAND_CMD_PARAM) {
+		flex_wait_rbn(afm);
+		afm_disable_interrupts(afm, NAND_INT_RBN);
+	}
+}
 
+static int afm_verify_buf_BUG(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
+	BUG();
 
-	chip->erase_cmd = afm_erase_cmd;
+	return 0;
+}
 
-	dev_info(afm->dev, "NAND device: Manufacturer ID:"
-		 " 0x%02x, Chip ID: 0x%02x (%s %s)\n", *maf_id, dev_id,
-		 nand_manuf_ids[maf_idx].name, type->name);
+static u16 afm_read_word_BUG(struct mtd_info *mtd)
+{
+	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
+	BUG();
 
-	return type;
+	return 0xff;
 }
 
-
-/* Scan device, part 1 : Determine device paramters */
-int afm_scan_ident(struct mtd_info *mtd, int maxchips)
+static int afm_block_bad_BUG(struct mtd_info *mtd, loff_t ofs, int getchip)
 {
-	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
-	int busw, maf_id;
-	struct nand_chip *chip = mtd->priv;
-	struct nand_flash_dev *type = NULL;
+	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
+	BUG();
 
-	if (maxchips != 1) {
-		dev_err(afm->dev, "Only chip per MTD device allowed\n");
-		return 1;
-	}
+	return 1;
+}
 
-	busw = chip->options & NAND_BUSWIDTH_16;
-	afm_set_defaults(chip, busw);
+static int afm_default_block_markbad_BUG(struct mtd_info *mtd, loff_t ofs)
+{
+	printk(KERN_ERR NAME ": %s Unsupported callback", __func__);
+	BUG();
 
-	type = afm_get_flash_type(mtd, chip, busw, &maf_id);
+	return 1;
+}
 
-	if (IS_ERR(type)) {
-		dev_err(afm->dev, "No NAND device found\n");
-		chip->select_chip(mtd, -1);
-		return PTR_ERR(type);
-	}
+/*
+ * AFM scan/probe NAND routines
+ */
 
-	/* Not dealing with multichip support just yet! */
-	chip->numchips = 1;
-	mtd->size = chip->chipsize;
+/* Set AFM generic call-backs (not chip-specific) */
+static void afm_set_defaults(struct nand_chip *chip, int busw)
+{
+	chip->chip_delay = 0;
+	chip->cmdfunc = flex_command;
+	chip->waitfunc = afm_wait;
+	chip->select_chip = afm_select_chip;
+	chip->read_byte = flex_read_byte;
+	chip->write_buf = flex_write_buf;
+	chip->read_buf = flex_read_buf;
 
-	return 0;
+	/* Unsupported callbacks */
+	chip->read_word = afm_read_word_BUG;
+	chip->block_bad = afm_block_bad_BUG;
+	chip->block_markbad = afm_default_block_markbad_BUG;
+	chip->verify_buf = afm_verify_buf_BUG;
 
+	chip->scan_bbt = stmnand_scan_bbt;
 }
 
-/* Scan device, part 2: Configure AFM according to device paramters */
+/* Configure AFM according to device paramters */
 static int afm_scan_tail(struct mtd_info *mtd)
 {
 	struct stm_nand_afm_controller *afm = mtd_to_afm(mtd);
@@ -2743,10 +2618,8 @@
 
 	if (mtd->writesize == 512 && mtd->oobsize == 16) {
 		chip->ecc.layout = &afm_oob_16;
-		chip->badblock_pattern = &bbt_scan_sp;
 	} else if (mtd->writesize == 2048 && mtd->oobsize == 64) {
 		chip->ecc.layout = &afm_oob_64;
-		chip->badblock_pattern = &bbt_scan_lp;
 	} else {
 		dev_err(afm->dev, "Unsupported chip type "
 			"[pagesize = %d, oobsize = %d]\n",
@@ -2754,10 +2627,8 @@
 		return 1;
 	}
 
-#ifdef CONFIG_STM_NAND_AFM_BOOTMODESUPPORT
-	/* Handle boot-mode ECC when scanning for bad blocks */
-	chip->badblock_pattern->options |= NAND_BBT_SCANSTMBOOTECC;
-#endif
+	/* Use our own 'erase_cmd', not the one set in nand_get_flash_type() */
+	chip->erase_cmd = afm_erase_cmd;
 
 	/* Set ECC parameters and call-backs */
 	chip->ecc.mode = NAND_ECC_HW;
@@ -2800,24 +2671,27 @@
 	/* Initialize state */
 	chip->state = FL_READY;
 
+	/* De-select the device */
+	chip->select_chip(mtd, -1);
+
 	/* Invalidate the pagebuffer reference */
 	chip->pagebuf = -1;
 
 	/* Fill in remaining MTD driver data */
 	mtd->type = MTD_NANDFLASH;
 	mtd->flags = MTD_CAP_NANDFLASH;
-	mtd->erase = afm_erase;  /* uses chip->erase_cmd */
+	mtd->erase = afm_erase;
 	mtd->point = NULL;
 	mtd->unpoint = NULL;
 	mtd->read = afm_read;
 	mtd->write = afm_write;
 	mtd->read_oob = afm_read_oob;
 	mtd->write_oob = afm_write_oob;
-	mtd->sync = afm_sync;
+	mtd->sync = nand_sync;
 	mtd->lock = NULL;
 	mtd->unlock = NULL;
-	mtd->suspend = afm_suspend;
-	mtd->resume = afm_resume;
+	mtd->suspend = nand_suspend;
+	mtd->resume = nand_resume;
 	mtd->block_isbad = afm_block_isbad;
 	mtd->block_markbad = afm_block_markbad;
 
@@ -2839,19 +2713,6 @@
 	return ret;
 }
 
-/* Scan for the NAND device */
-int afm_scan(struct mtd_info *mtd, int maxchips)
-{
-	int ret;
-
-	ret = afm_scan_ident(mtd, maxchips);
-	if (!ret)
-		ret = afm_scan_tail(mtd);
-
-
-	return ret;
-}
-
 #ifdef CONFIG_STM_NAND_AFM_PBLBOOTBOUNDARY
 
 #define PBL_BOOT_BOUNDARY_POINTER	0x0034
@@ -2892,6 +2753,8 @@
 
 	block_end = min(512UL, (data->boot_end >> chip->phys_erase_shift));
 
+	chip->pagebuf = -1;
+
 	for (block = 0; block < block_end; block++) {
 		offs = block << chip->phys_erase_shift;
 
@@ -3032,17 +2895,17 @@
 #endif
 
 
-static struct stm_nand_afm_device * __init
+static struct stm_nand_afm_device * __devinit
 afm_init_bank(struct stm_nand_afm_controller *afm,
 	      struct stm_nand_bank_data *bank,
-	      const char *name)
+	      struct platform_device *pdev)
 {
 	struct stm_nand_afm_device *data;
 	int err;
 
 #ifdef CONFIG_STM_NAND_AFM_BOOTMODESUPPORT
 	struct mtd_info *slave;
-	struct mtd_part *part;
+	uint64_t slave_offset;
 	char *boot_part_name;
 #ifdef CONFIG_STM_NAND_AFM_PBLBOOTBOUNDARY
 	uint32_t boundary;
@@ -3060,6 +2923,7 @@
 	data->chip.priv = data;
 	data->mtd.priv = &data->chip;
 	data->mtd.owner = THIS_MODULE;
+	data->mtd.dev.parent = &pdev->dev;
 	data->dev = afm->dev;
 
 	/* Use hwcontrol structure to manage access to AFM Controller */
@@ -3067,21 +2931,84 @@
 	data->chip.state = FL_READY;
 
 	/* Assign more sensible name (default is string from nand_ids.c!) */
-	data->mtd.name = name;
+	data->mtd.name = dev_name(&pdev->dev);
 	data->csn = bank->csn;
 
-	data->timing_data = bank->timing_data;
-
 	data->chip.options = bank->options;
 	data->chip.options |= NAND_NO_AUTOINCR;
 
-	/* Scan to find existance of device */
-	if (afm_scan(&data->mtd, 1)) {
-		dev_err(afm->dev, "device scan failed\n");
+	afm_set_defaults(&data->chip, data->chip.options & NAND_BUSWIDTH_16);
+
+	/* Scan to find existence of device */
+	if (nand_scan_ident(&data->mtd, 1) != 0) {
+		err = -ENODEV;
+		goto err2;
+	}
+
+	/* Calculate AFM_GEN_CFG for device found */
+	data->afm_gen_cfg = afm_gen_config(afm,
+				data->chip.options & NAND_BUSWIDTH_16,
+				data->mtd.writesize,
+				data->chip.chipsize);
+
+	/*
+	 * Configure timing registers
+	 */
+	if (bank->timing_spec) {
+		dev_info(afm->dev, "Using platform timing data\n");
+		afm_calc_timing_registers(bank->timing_spec, bank->timing_relax,
+					  &data->ctl_timing,
+					  &data->wen_timing,
+					  &data->ren_timing);
+		data->chip.chip_delay = bank->timing_spec->tR;
+	} else if (bank->timing_data) {
+		dev_info(afm->dev, "Using legacy platform timing data\n");
+		afm_calc_timing_registers_legacy(bank->timing_data,
+						 &data->ctl_timing,
+						 &data->wen_timing,
+						 &data->ren_timing);
+		data->chip.chip_delay = bank->timing_data->chip_delay;
+	} else if (data->chip.onfi_version) {
+		struct nand_onfi_params *onfi = &data->chip.onfi_params;
+		int mode;
+
+		mode = fls(le16_to_cpu(onfi->async_timing_mode)) - 1;
+		/* Modes 4 and 5 (EDO) are not supported on our H/W */
+		if (mode > 3)
+			mode = 3;
+
+		dev_info(afm->dev, "Using ONFI Timing Mode %d\n", mode);
+		afm_calc_timing_registers(&nand_onfi_timing_specs[mode],
+					  bank->timing_relax,
+					  &data->ctl_timing,
+					  &data->wen_timing,
+					  &data->ren_timing);
+		data->chip.chip_delay = le16_to_cpu(data->chip.onfi_params.t_r);
+	} else {
+		dev_warn(afm->dev, "No timing data available\n");
+	}
+
+	/* Ensure 'complete' chip-specific configuration on next select_chip()
+	 * activation */
+	afm->current_csn = -1;
+
+	/* Complete the scan */
+	if (afm_scan_tail(&data->mtd) != 0) {
 		err = -ENXIO;
 		goto err2;
 	}
 
+	/* If all blocks are marked bad, mount as "recovery" partition */
+	if (stmnand_blocks_all_bad(&data->mtd)) {
+		dev_err(afm->dev, "initiating NAND Recovery Mode\n");
+		data->mtd.name = "NAND RECOVERY MODE";
+		err = add_mtd_device(&data->mtd);
+		if (err)
+			goto err2;
+
+		return data;
+	}
+
 #ifdef CONFIG_MTD_PARTITIONS
 	/* Try probing for MTD partitions */
 	data->nr_parts = parse_mtd_partitions(&data->mtd,
@@ -3107,11 +3034,11 @@
 			CONFIG_STM_NAND_AFM_BOOTPARTITION;
 
 		/* Update boot-mode slave partition */
-		slave = get_mtd_partition_slave(&data->mtd, boot_part_name);
+		slave = get_mtd_partition_slave(&data->mtd, boot_part_name,
+						&slave_offset);
 		if (slave) {
-			part = PART(slave);
-			data->boot_start = part->offset;
-			data->boot_end = part->offset + slave->size;
+			data->boot_start = slave_offset;
+			data->boot_end = slave_offset + slave->size;
 
 #ifdef CONFIG_STM_NAND_AFM_PBLBOOTBOUNDARY
 			/* Update 'boot_end' with value in PBL image */
@@ -3169,31 +3096,47 @@
 /*
  * stm-nand-afm device probe
  */
-static int __init stm_afm_probe(struct platform_device *pdev)
+static int __devinit stm_afm_probe(struct platform_device *pdev)
 {
 	struct stm_plat_nand_flex_data *pdata = pdev->dev.platform_data;
 	struct stm_nand_bank_data *bank;
 	struct stm_nand_afm_controller *afm;
+	struct stm_nand_afm_device *data;
 	int n;
-	int res;
+	int err = 0;
 
-	afm = afm_init_controller(pdev);
+	afm = afm_init_resources(pdev);
 	if (IS_ERR(afm)) {
 		dev_err(&pdev->dev, "failed to initialise NAND Controller.\n");
-		res = PTR_ERR(afm);
-		return res;
+		err = PTR_ERR(afm);
+		return err;
 	}
 
 	bank = pdata->banks;
 	for (n = 0; n < pdata->nr_banks; n++) {
-		afm->devices[n] = afm_init_bank(afm, bank,
-						dev_name(&pdev->dev));
+		data = afm_init_bank(afm, bank, pdev);
+
+		if (IS_ERR(data)) {
+			err = PTR_ERR(data);
+			goto err1;
+		}
+
+		afm->devices[n] = data;
 		bank++;
 	}
 
-	platform_set_drvdata(pdev, afm);
-
 	return 0;
+
+ err1:
+	while (--n > 0) {
+		data = afm->devices[n];
+		nand_release(&data->mtd);
+		kfree(data);
+	}
+
+	afm_exit_controller(pdev);
+
+	return err;
 }
 
 
@@ -3216,17 +3159,34 @@
 
 	afm_exit_controller(pdev);
 
-	platform_set_drvdata(pdev, NULL);
+	return 0;
+}
+
+#ifdef CONFIG_HIBERNATION
+static int stm_nand_afm_restore(struct device *dev)
+{
+	struct stm_nand_afm_controller *afm = dev_get_drvdata(dev);
+
+	afm->current_csn = -1;
+	afm_init_controller(afm);
 
 	return 0;
 }
 
+static struct dev_pm_ops stm_nand_afm_pm = {
+	.restore = stm_nand_afm_restore,
+};
+#else
+static struct dev_pm_ops stm_nand_afm_pm;
+#endif
+
 static struct platform_driver stm_afm_nand_driver = {
 	.probe		= stm_afm_probe,
 	.remove		= stm_afm_remove,
 	.driver		= {
 		.name	= NAME,
 		.owner	= THIS_MODULE,
+		.pm	= &stm_nand_afm_pm,
 	},
 };
 
diff -Naur a/drivers/mtd/nand/stm_nand_bbt.c b/drivers/mtd/nand/stm_nand_bbt.c
--- a/drivers/mtd/nand/stm_nand_bbt.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/mtd/nand/stm_nand_bbt.c	2013-11-01 18:44:50.961823910 +0200
@@ -0,0 +1,347 @@
+/*
+ *  stm_nand_bbt.c         STM NAND BBT Support
+ *
+ *  This file adds some extra functionality to the existing BBT support found
+ *  in nand_bbt.c:
+ *
+ *     - STM_NAND_SAFE_MOUNT: A configurable option to help prevent corruption
+ *	 that might otherwise result from the presence of 'alien' BBTs
+ *	 (i.e. BBTs written by a driver different to that currently employed).
+ *
+ *     - Enable detection of STM NAND ECC tags when scanning for
+ *       manufacturer-programmed bad block markers.
+ *
+ *  Copyright (c) 2012 STMicroelectronics Limited
+ *  Author: Angus Clark <Angus.Clark@st.com>
+ *
+ *  May be copied or modified under the terms of the GNU General Public
+ *  License Version 2.0 only.  See linux/COPYING for more information.
+ *
+ */
+
+#include "stm_nand_bbt.h"
+
+#ifndef CONFIG_STM_NAND_SAFE_MOUNT
+int stmnand_examine_bbts(struct mtd_info *mtd, int bch_remap)
+{
+	return 0;
+}
+EXPORT_SYMBOL(stmnand_examine_bbts);
+#else /* CONFIG_STM_NAND_SAFE_MOUNT */
+
+#define BCH_SECTOR_BYTES	1024
+#define BCH18_ECC_BYTES		32
+#define BCH30_ECC_BYTES		54
+
+/* Undo the Page-OOB mapping performed by the stm-nand-bch driver */
+static void __attribute__((unused)) stmnand_bch_unmap(uint8_t *page,
+				uint8_t *oob, int page_size, int oob_size,
+				int bch_remap)
+{
+	int n_sectors, s;
+	int ecc_bytes_per_sector;
+	int oob_bytes_remainder;
+	uint8_t *data;
+	uint8_t *dst_p, *dst_o, *src;
+
+	if (bch_remap == BCH_REMAP_NONE)
+		return;
+
+	n_sectors = page_size / BCH_SECTOR_BYTES;
+	if (!n_sectors)
+		return;
+
+	ecc_bytes_per_sector = (bch_remap == BCH_REMAP_18BIT) ?
+		BCH18_ECC_BYTES : BCH30_ECC_BYTES;
+	oob_bytes_remainder = oob_size - (n_sectors * ecc_bytes_per_sector);
+
+	data = kmalloc(page_size * oob_size, GFP_KERNEL);
+	memcpy(data, page, page_size);
+	memcpy(data + page_size, oob, oob_size);
+
+	memset(oob, 0xff, oob_size);
+	src = data;
+	dst_p = page;
+	dst_o = oob;
+
+	for (s = 0; s < n_sectors; s++) {
+		memcpy(dst_p, src, BCH_SECTOR_BYTES);
+		src += BCH_SECTOR_BYTES;
+		dst_p += BCH_SECTOR_BYTES;
+
+		memcpy(dst_o, src, ecc_bytes_per_sector);
+		src += ecc_bytes_per_sector;
+		dst_o += ecc_bytes_per_sector;
+	}
+
+	if (oob_bytes_remainder)
+		memcpy(dst_o, src, oob_bytes_remainder);
+
+	kfree(data);
+}
+
+/* Remap the Page-OOB data, as performed by the stm-nand-bch driver */
+void stmnand_bch_remap(uint8_t *page, uint8_t *oob,
+		       int page_size, int oob_size, int bch_remap)
+{
+	int n_sectors, s;
+	int ecc_bytes_per_sector;
+	int oob_bytes_remainder;
+	uint8_t *data;
+	uint8_t *dst, *src_p, *src_o;
+
+	if (bch_remap == BCH_REMAP_NONE)
+		return;
+
+	n_sectors = page_size / BCH_SECTOR_BYTES;
+	if (!n_sectors)
+		return;
+
+	ecc_bytes_per_sector =  (bch_remap == BCH_REMAP_18BIT) ?
+		BCH18_ECC_BYTES : BCH30_ECC_BYTES;
+	oob_bytes_remainder = oob_size - (n_sectors * ecc_bytes_per_sector);
+
+	data = kmalloc(page_size * oob_size, GFP_KERNEL);
+	memset(data, 0xff, page_size + oob_size);
+
+	src_p = page;
+	src_o = oob;
+	dst = data;
+
+	for (s = 0; s < n_sectors; s++) {
+		memcpy(dst, src_p, BCH_SECTOR_BYTES);
+		dst += BCH_SECTOR_BYTES;
+		src_p += BCH_SECTOR_BYTES;
+
+		memcpy(dst, src_o, ecc_bytes_per_sector);
+		dst += ecc_bytes_per_sector;
+		src_o += ecc_bytes_per_sector;
+	}
+
+	if (oob_bytes_remainder)
+		memcpy(dst, src_o, oob_bytes_remainder);
+
+	memcpy(page, data, page_size);
+	memcpy(oob, data + page_size, oob_size);
+
+	kfree(data);
+}
+
+static int stmnand_check_bbt_block(struct mtd_info *mtd, uint64_t offs,
+				   uint8_t *buf, int bch_remap)
+{
+	struct nand_bbt_descr *bbt_descrs[] = {
+		&bbt_main_descr,
+		&bbt_mirror_descr,
+		&bbt_main_descr_ode,
+		&bbt_mirror_descr_ode,
+	};
+
+	uint8_t *ibbt_pats[] = {
+		bbt_pattern,
+		mirror_pattern,
+	};
+
+	int ret, retlen;
+	int page_size = mtd->writesize;
+	int oob_size = mtd->oobsize;
+	uint8_t *oob = buf + mtd->writesize;
+	int i, j, e;
+	char *ecc_str;
+	uint64_t offs_bch_sig;
+
+	/* Try linux BBT signatures */
+	for (i = 0; i < ARRAY_SIZE(bbt_descrs); i++) {
+		ret = scan_read_raw(mtd, buf, offs, mtd->writesize);
+		if (ret < 0)
+			return ret;
+
+		/* Check for empty page */
+		e = 0;
+		for (j = 0; j < (page_size + oob_size) && e <= 1; j++)
+			e += hweight8(~buf[j]);
+		if (e <= 1)
+			return 0;
+
+		if (bch_remap)
+			stmnand_bch_remap(buf, oob, page_size, oob_size,
+					  bch_remap);
+
+		/* Check for BBT signature */
+		if (check_pattern(buf, page_size + oob_size, page_size,
+				  bbt_descrs[i]) == 0) {
+
+			/* Check ECC */
+			ret = mtd->read(mtd, offs, page_size, &retlen, buf);
+			if (ret == 0 || ret  == -EUCLEAN)
+				return 1;
+
+			if (retlen != page_size)
+				return ret;
+
+			/* Uncorrectable ECC error */
+			e = 0;
+			for (j = 0; j < oob_size; j += 16) {
+				e += hweight8(oob[j + 3] ^ 'A');
+				e += hweight8(oob[j + 4] ^ 'F');
+				e += hweight8(oob[j + 5] ^ 'M');
+			}
+			if (e <= 1)
+				ecc_str = "AFM";
+			else if (bbt_descrs[i] == &bbt_main_descr_ode ||
+				 bbt_descrs[i] == &bbt_mirror_descr_ode)
+				ecc_str = "Micron 'on-die'";
+			else
+				ecc_str = "FLEX/EMI";
+
+			printk(KERN_INFO "nand_bbt: 0x%012llx: found 'alien' "
+			       "BBT (%s?)\n", offs, ecc_str);
+			return -EBADMSG;
+		}
+	}
+
+	/* Try BCH inband signatures */
+	offs_bch_sig = offs + mtd->erasesize - mtd->writesize;
+	for (i = 0; i < ARRAY_SIZE(ibbt_pats); i++) {
+		ret = scan_read_raw(mtd, buf, offs_bch_sig, mtd->writesize);
+		if (ret < 0)
+			return ret;
+
+		e = 0;
+		/* Primary/Mirror Pattern */
+		for (j = 0; j < 4 && e <= 4; j++)
+			e += hweight8(buf[j] ^ ibbt_pats[i][j]);
+
+		/* Base Schema */
+		for (j = 0; j < 4 && e <= 4; j++)
+			e += hweight8(buf[8 + j] ^ 0x10);
+		/* IBBT BCH Schema */
+		for (j = 0; j < 4 && e <= 4; j++)
+			e += hweight8(buf[12 + j] ^ 0x10);
+
+		if (e <= 2) {
+			ret = mtd->read(mtd, offs_bch_sig, page_size, &retlen,
+					buf);
+			if (ret == 0 || ret  == -EUCLEAN)
+				return 1;
+
+			if (retlen != page_size)
+				return ret;
+
+			ecc_str = "";
+			if (buf[16] == BCH18_ECC_BYTES)
+				ecc_str = "18";
+			else if (buf[16] == BCH30_ECC_BYTES)
+				ecc_str = "30";
+
+			/* Uncorrectable ECC Error */
+			printk(KERN_INFO "nand_bbt: 0x%012llx: found 'alien' "
+			       "BBT (BCH%s %s)\n", offs, ecc_str, buf + 20);
+
+			return -EBADMSG;
+		}
+	}
+
+	return -EBADMSG;
+}
+
+/* Examine the BBT area */
+int stmnand_examine_bbts(struct mtd_info *mtd, int bch_remap)
+{
+	struct nand_chip *this = mtd->priv;
+
+	uint8_t *buf;
+	int valid = 0;
+	int alien = 0;
+	int i;
+	uint64_t offs;
+	int bbt_len;
+	int ret;
+
+	buf = kmalloc(mtd->writesize + mtd->oobsize, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	offs = mtd->size - mtd->erasesize;
+	for (i = 0; i < 4; i++) {
+		ret = stmnand_check_bbt_block(mtd, offs, buf, bch_remap);
+
+		if (ret == 1)
+			valid++;
+		else if (ret == -EBADMSG)
+			alien++;
+		else if (ret < 0)
+			return ret;
+
+		offs -= mtd->erasesize;
+	}
+	kfree(buf);
+
+	if (this->options & NAND_USE_FLASH_BBT) {
+		if (!valid && alien) {
+			printk(KERN_WARNING "nand_bbt: only found 'alien' BBT(s)\n");
+			goto recovery_mode;
+		}
+	} else {
+		if (valid) {
+			printk(KERN_WARNING "nand_bbt: found valid BBT but "
+			       "NAND_USE_FLASH_BBT not selected\n");
+			goto recovery_mode;
+		}
+		if (alien) {
+			printk(KERN_WARNING "nand_bbt: found 'alien' BBT(s)\n");
+			goto recovery_mode;
+		}
+	}
+
+	/* BBT status is consistent with current driver and configuration */
+	return 0;
+
+ recovery_mode:
+	bbt_len = mtd->size >> (this->bbt_erase_shift + 2);
+	this->bbt = kzalloc(bbt_len, GFP_KERNEL);
+	if (!this->bbt) {
+		printk(KERN_ERR "%s: Out of memory\n", __func__);
+		return -ENOMEM;
+	}
+	/* Mark all blocks as bad */
+	memset(this->bbt, 0xff, bbt_len);
+
+	return 1;
+}
+EXPORT_SYMBOL(stmnand_examine_bbts);
+#endif /* CONFIG_STM_NAND_SAFE_MOUNT */
+
+int stmnand_scan_bbt(struct mtd_info *mtd)
+{
+	struct nand_chip *this = mtd->priv;
+	int ret;
+
+	/* Check for 'alien' BBTs */
+	ret = stmnand_examine_bbts(mtd, BCH_REMAP_NONE);
+	if (ret != 0)
+		return ret < 0 ? ret : 0;
+
+	/* Enable detection of STM NAND ECC patterns */
+	if (!this->badblock_pattern)
+		this->badblock_pattern = (mtd->writesize > 512) ?
+			&largepage_memorybased : &smallpage_memorybased;
+
+	this->badblock_pattern->options |= (NAND_BBT_SCANSTMBOOTECC |
+					    NAND_BBT_SCANSTMAFMECC);
+
+	return nand_default_bbt(mtd);
+}
+EXPORT_SYMBOL(stmnand_scan_bbt);
+
+int stmnand_blocks_all_bad(struct mtd_info *mtd)
+{
+	uint64_t offs;
+
+	for (offs = 0; offs < mtd->size; offs += mtd->erasesize)
+		if (mtd->block_isbad(mtd, offs) == 0)
+			return 0;
+
+	return 1;
+}
+EXPORT_SYMBOL(stmnand_blocks_all_bad);
diff -Naur a/drivers/mtd/nand/stm_nand_bbt.h b/drivers/mtd/nand/stm_nand_bbt.h
--- a/drivers/mtd/nand/stm_nand_bbt.h	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/mtd/nand/stm_nand_bbt.h	2013-11-01 18:44:50.961823910 +0200
@@ -0,0 +1,15 @@
+#ifndef STM_NAND_BBT_H
+#define STM_NAND_BBT_H
+
+#define BCH_REMAP_NONE		0
+#define BCH_REMAP_18BIT		1
+#define BCH_REMAP_30BIT		2
+
+int stmnand_examine_bbts(struct mtd_info *mtd, int bch_remap);
+
+int stmnand_scan_bbt(struct mtd_info *mtd);
+
+int stmnand_blocks_all_bad(struct mtd_info *mtd);
+
+
+#endif /* STM_NAND_BBT_H */
diff -Naur a/drivers/mtd/nand/stm_nand_bch.c b/drivers/mtd/nand/stm_nand_bch.c
--- a/drivers/mtd/nand/stm_nand_bch.c	2013-11-01 20:19:18.769929055 +0200
+++ b/drivers/mtd/nand/stm_nand_bch.c	2013-11-01 18:44:50.965823938 +0200
@@ -20,6 +20,7 @@
 #include <linux/module.h>
 #include <linux/io.h>
 #include <linux/device.h>
+#include <linux/clk.h>
 #include <linux/platform_device.h>
 #include <linux/dma-mapping.h>
 #include <linux/mtd/mtd.h>
@@ -31,6 +32,7 @@
 #include <linux/utsrelease.h>
 
 #include "stm_nand_regs.h"
+#include "stm_nand_bbt.h"
 
 #define NAME	"stm-nand-bch"
 
@@ -47,6 +49,11 @@
 	[BCH_30BIT_ECC] = 54,
 	[BCH_NO_ECC] = 0,
 };
+static int bch_ecc_strength[] = {
+	[BCH_18BIT_ECC] = 18,
+	[BCH_30BIT_ECC] = 30,
+	[BCH_NO_ECC] = 0,
+};
 
 /*
  * Inband Bad Block Table (IBBT)
@@ -117,6 +124,13 @@
 	struct device		*dev;
 
 	int			bch_ecc_mode;	/* ECC mode */
+	int			extra_addr;	/* 'Extra' address cycle */
+
+	/* The threshold at which the number of corrected bit-flips per sector
+	 * is deemed to have reached an excessive level (triggers '-EUCLEAN'
+	 * return code).
+	 */
+	int			bitflip_threshold;
 
 	uint32_t		page_shift;	/* Some working variables */
 	uint32_t		block_shift;
@@ -229,6 +243,29 @@
 	bch_prog_read_page.gen_cfg |= gen_cfg_ecc;
 	bch_prog_write_page.gen_cfg |= gen_cfg_ecc;
 	bch_prog_erase_block.gen_cfg |= gen_cfg_ecc;
+
+	/* The template sequences above are defined for devices that require an
+	 * "extra" address cycle: that is, 5 address cycles for page Read/Write
+	 * operations, and 3 address cycles for Erase operations.  Here, we
+	 * update the sequences for devices that do not require an extra address
+	 * cycle.
+	 */
+	if (!nandi->extra_addr) {
+		/* Clear 'GEN_CFG_EXTRA_ADD_CYCLE' flag */
+		bch_prog_read_page.gen_cfg &= ~GEN_CFG_EXTRA_ADD_CYCLE;
+		bch_prog_write_page.gen_cfg &= ~GEN_CFG_EXTRA_ADD_CYCLE;
+		bch_prog_erase_block.gen_cfg &= ~GEN_CFG_EXTRA_ADD_CYCLE;
+
+		/* Configure Erase sequence for 2 address cycles (page
+		 * address) */
+		bch_prog_erase_block.seq[0] = BCH_CL_CMD_1;
+		bch_prog_erase_block.seq[1] = BCH_AL_EX_0;
+		bch_prog_erase_block.seq[2] = BCH_AL_EX_1;
+		bch_prog_erase_block.seq[3] = BCH_CL_CMD_2;
+		bch_prog_erase_block.seq[4] = BCH_CL_CMD_3;
+		bch_prog_erase_block.seq[5] = BCH_OP_ERR;
+		bch_prog_erase_block.seq[6] = BCH_STOP;
+	}
 }
 
 /*
@@ -321,20 +358,31 @@
 	return status;
 }
 
-/* Attempt to establish if a page is empty (likely to have been erased), while
- * tolerating a number of bits stuck at, or drifted to, 0.
+/*
+ * Detect an erased page, tolerating and correcting up to a specified number of
+ * bits at '0'.  (For many devices, it is now deemed within spec for an erased
+ * page to include a number of bits at '0', either as a result of read-disturb
+ * behaviour or 'stuck-at-zero' failures.)  Returns the number of corrected
+ * bits, or a '-1' if we have exceeded the maximum number of bits at '0' (likely
+ * to be a genuine uncorrectable ECC error).  In the latter case, the data must
+ * be returned unmodified, in accordance with the MTD API.
  */
-static int is_page_empty(uint8_t *data, uint32_t page_size, int max_bit_errors)
+static int check_erased_page(uint8_t *data, uint32_t page_size, int max_zeros)
 {
-	int e = 0;
+	uint8_t *b = data;
+	int i;
+	int zeros = 0;
 
-	while (page_size--) {
-		e += hweight8(~*data++);
-		if (e > max_bit_errors)
-			return 0;
+	for (i = 0; i < page_size; i++) {
+		zeros += hweight8(~*b++);
+		if (zeros > max_zeros)
+			return -1;
 	}
 
-	return 1;
+	if (zeros)
+		memset(data, 0xff, page_size);
+
+	return zeros;
 }
 
 /* Returns the number of ECC errors, or '-1' for uncorrectable error */
@@ -389,16 +437,15 @@
 	/* Use the maximum per-sector ECC count! */
 	ecc_err = readl(nandi->base + NANDBCH_ECC_SCORE_REG_A) & 0xff;
 	if (ecc_err == 0xff) {
-		/* Do we have a genuine uncorrectable ECC error, or is it just
-		 * an erased page?
+		/* Downgrade uncorrectable ECC error for an erased page,
+		 * tolerating 'sectors_per_page' bits at zero.
 		 */
-		if (is_page_empty(buf, page_size, nandi->sectors_per_page)) {
-			dev_dbg(nandi->dev, "%s: detected uncorrectable error, "
-				"but looks like an erased page\n", __func__);
-			ret = 0;
-		} else {
-			ret = -1;
-		}
+		ret = check_erased_page(buf, page_size,
+					nandi->sectors_per_page);
+		if (ret >= 0)
+			dev_dbg(nandi->dev, "%s: erased page detected: "
+				"downgrading uncorrectable ECC error.\n",
+				__func__);
 	} else {
 		ret = (int)ecc_err;
 	}
@@ -465,7 +512,7 @@
 	loff_t page_offs;
 	int page_num;
 	uint32_t col_offs;
-	int ecc_errs;
+	int ecc_errs, max_ecc_errs = 0;
 	size_t bytes;
 	uint8_t *p;
 
@@ -499,14 +546,17 @@
 			p = bounce ? nandi->page_buf : buf;
 
 			ecc_errs = bch_read_page(nandi, page_offs, p);
+			if (bounce)
+				memcpy(buf, p + col_offs, bytes);
+
 			if (ecc_errs < 0) {
-				/* Might be better to break/return here... but
-				 * we follow approach in
-				 * nand_base.c:do_nand_read_ops()
-				 */
 				dev_err(nandi->dev, "%s: uncorrectable error "
 					"at 0x%012llx\n", __func__, page_offs);
 				nandi->info.mtd.ecc_stats.failed++;
+
+				/* Do not cache uncorrectable pages */
+				if (bounce)
+					nandi->cached_page = -1;
 			} else {
 				if (ecc_errs) {
 					dev_info(nandi->dev, "%s: corrected %u "
@@ -514,12 +564,12 @@
 						 __func__, ecc_errs, page_offs);
 					nandi->info.mtd.ecc_stats.corrected +=
 						ecc_errs;
+					if (ecc_errs > max_ecc_errs)
+						max_ecc_errs = ecc_errs;
 				}
-			}
 
-			if (bounce) {
-				nandi->cached_page = page_num;
-				memcpy(buf, p + col_offs, bytes);
+				if (bounce)
+					nandi->cached_page = page_num;
 			}
 		}
 
@@ -535,10 +585,13 @@
 		col_offs = 0;
 	}
 
+	/* Return '-EBADMSG' if we have encountered an uncorrectable error. */
 	if (nandi->info.mtd.ecc_stats.failed - stats.failed)
 		return -EBADMSG;
 
-	if (nandi->info.mtd.ecc_stats.corrected - stats.corrected)
+	/* Return '-EUCLEAN' if we have reached bit-flips threshold. */
+	if ((nandi->bch_ecc_mode != BCH_NO_ECC) &&
+	    (max_ecc_errs >= nandi->bitflip_threshold))
 		return -EUCLEAN;
 
 	return 0;
@@ -551,6 +604,7 @@
 		     size_t *retlen, const uint8_t *buf)
 {
 	uint32_t page_size = nandi->info.mtd.writesize;
+	int page_num;
 	int bounce;
 	const uint8_t *p = NULL;
 
@@ -568,8 +622,10 @@
 	}
 
 	if (retlen)
-		*retlen = 0
-			;
+		*retlen = 0;
+
+	page_num = (int)(to >> nandi->page_shift);
+
 	while (len > 0) {
 
 		if (bounce) {
@@ -580,10 +636,14 @@
 			p = buf;
 		}
 
+		if (nandi->cached_page == page_num)
+			nandi->cached_page = -1;
+
 		if (bch_write_page(nandi, to, p) & NAND_STATUS_FAIL)
 			return -EIO;
 
 		to += page_size;
+		page_num++;
 		buf += page_size;
 		len -= page_size;
 
@@ -682,7 +742,7 @@
 		flex_addr(nandi, column,
 			  (command == NAND_CMD_READID) ? 1 : 2);
 	if (page != -1)
-		flex_addr(nandi, page, (chip->chipsize > (128 << 20)) ? 3 : 2);
+		flex_addr(nandi, page, nandi->extra_addr ? 3 : 2);
 
 	/* Complete 'READ0' command */
 	if (command == NAND_CMD_READ0)
@@ -872,7 +932,7 @@
 
 	flex_cmd(nandi, NAND_CMD_READ0);
 	flex_addr(nandi, col_addr, 2);
-	flex_addr(nandi, page_addr, 3);
+	flex_addr(nandi, page_addr, nandi->extra_addr ? 3 : 2);
 	flex_cmd(nandi, NAND_CMD_READSTART);
 
 	flex_wait_rbn(nandi);
@@ -909,7 +969,7 @@
 
 	flex_cmd(nandi, NAND_CMD_SEQIN);
 	flex_addr(nandi, col_addr, 2);
-	flex_addr(nandi, page_addr, 3);
+	flex_addr(nandi, page_addr, nandi->extra_addr ? 3 : 2);
 
 	writesl(nandi->base + NANDHAM_FLEX_DATA, buf, len/4);
 
@@ -965,6 +1025,7 @@
 	struct mtd_info *mtd = &nandi->info.mtd;
 	uint8_t *oob_buf = nandi->oob_buf;
 	int i;
+	int e;
 	int ret = 0;
 
 	/* Read the OOB area */
@@ -984,31 +1045,26 @@
 		ret = 1;
 	}
 
-#ifdef NANDI_BBM_TOLERATE_BCH_DATA
-	/* Check for valid BCH ECC data by performing a page read */
+	/* Tolerate 'alien' Hamming Boot Mode ECC */
 	if (ret == 1) {
-		loff_t offs = (loff_t)page << nandi->page_shift;
-		uint8_t *page_buf = nandi->page_buf;
-
-		nandi->cached_page = -1;
-		if (bch_read_page(nandi, offs, page_buf) >= 0) {
-			/* All 0x00s leads to valid BCH ECC, but likely to be
-			 * bad-block marker */
+		e = 0;
+		for (i = 0; i < mtd->oobsize; i += 16)
+			e += hweight8(oob_buf[i + 3] ^ 'B');
+		if (e <= 1)
 			ret = 0;
-			for (i = 0; i < mtd->writesize; i++) {
-				if (page_buf[i] != 0x00) {
-					ret = 1;
-					break;
-				}
-			}
+	}
 
-			/* No uncorrectable errors, assume valid BCH ECC data */
-			if (ret == 0)
-				dev_info(nandi->dev, "BBM @ 0x%012llx: valid "
-					 "BCH ECC data, treat as good\n", offs);
+	/* Tolerate 'alien' Hamming AFM ECC */
+	if (ret == 1) {
+		e = 0;
+		for (i = 0; i < mtd->oobsize; i += 16) {
+			e += hweight8(oob_buf[i + 3] ^ 'A');
+			e += hweight8(oob_buf[i + 4] ^ 'F');
+			e += hweight8(oob_buf[i + 5] ^ 'M');
 		}
+		if (e <= 1)
+			ret = 0;
 	}
-#endif
 
 	return ret;
 }
@@ -1466,12 +1522,12 @@
 	struct mtd_info *mtd = &nandi->info.mtd;
 	uint32_t page_addr = from >> nandi->page_shift;
 	int pages;
-	uint32_t oob_bytes_per_sector = mtd->oobsize / nandi->sectors_per_page;
-	uint32_t oob_pad_per_page = mtd->oobsize % nandi->sectors_per_page;
 	int ecc_size = bch_ecc_sizes[nandi->bch_ecc_mode];
+	uint32_t oob_remainder;
 	uint8_t *o = ops->oobbuf;
 	uint8_t *p = ops->datbuf;
 	uint8_t *t;
+	int unified_buf;
 	int s;
 
 	nandi->cached_page = -1;
@@ -1480,12 +1536,20 @@
 		(ops->len >> nandi->page_shift) :
 		(ops->ooblen / mtd->oobsize);
 
+	/* Allow page:oob:page:oob... convention */
+	unified_buf = (p == o) ? 1 : 0;
+
+	oob_remainder = mtd->oobsize - (nandi->sectors_per_page * ecc_size);
+
 	while (pages) {
 		t = nandi->page_buf;
 
 		flex_read_raw(nandi, page_addr, 0, t,
 			      mtd->writesize + mtd->oobsize);
 
+		if (unified_buf)
+			o = p + mtd->writesize;
+
 		for (s = 0; s < nandi->sectors_per_page; s++) {
 			if (p) {
 				memcpy(p, t, NANDI_BCH_SECTOR_SIZE);
@@ -1496,20 +1560,21 @@
 
 			if (o) {
 				memcpy(o, t, ecc_size);
-				memset(o + ecc_size, 0xff,
-				       oob_bytes_per_sector - ecc_size);
-
-				ops->oobretlen += oob_bytes_per_sector;
-				o += oob_bytes_per_sector;
+				ops->oobretlen += ecc_size;
+				o += ecc_size;
 			}
 			t += ecc_size;
 		}
 
-		if (oob_pad_per_page && o) {
-			memset(o, 0xff, oob_pad_per_page);
-			o += oob_pad_per_page;
+		if (oob_remainder && o) {
+			memcpy(o, t, oob_remainder);
+			o += oob_remainder;
+			ops->oobretlen += oob_remainder;
 		}
 
+		if (unified_buf)
+			p += mtd->oobsize;
+
 		page_addr++;
 		pages--;
 	}
@@ -1526,9 +1591,8 @@
 	struct mtd_info *mtd = &nandi->info.mtd;
 	uint32_t page_addr = to >> nandi->page_shift;
 	int pages;
-	uint32_t oob_bytes_per_sector = mtd->oobsize / nandi->sectors_per_page;
-	uint32_t oob_pad_per_page = mtd->oobsize % nandi->sectors_per_page;
 	int ecc_size = bch_ecc_sizes[nandi->bch_ecc_mode];
+	uint32_t oob_remainder;
 	uint8_t *o = ops->oobbuf;
 	uint8_t *p = ops->datbuf;
 	uint8_t *t;
@@ -1541,6 +1605,8 @@
 		(ops->len >> nandi->page_shift) :
 		(ops->ooblen / mtd->oobsize);
 
+	oob_remainder = mtd->oobsize - (nandi->sectors_per_page * ecc_size);
+
 	while (pages) {
 		t = nandi->page_buf;
 
@@ -1556,18 +1622,22 @@
 
 			if (o) {
 				memcpy(t, o, ecc_size);
-				ops->oobretlen += oob_bytes_per_sector;
-				o += oob_bytes_per_sector;
+				o += ecc_size;
+				ops->oobretlen += ecc_size;
 			} else {
 				memset(t, 0xff, ecc_size);
 			}
 			t += ecc_size;
 		}
 
-		if (oob_pad_per_page) {
-			memset(t, 0xff, oob_pad_per_page);
-			if (o)
-				o += oob_pad_per_page;
+		if (oob_remainder) {
+			if (o) {
+				memcpy(t, o, oob_remainder);
+				o += oob_remainder;
+				ops->oobretlen += oob_remainder;
+			} else {
+				memset(t, 0xff, oob_remainder);
+			}
 		}
 
 		status = flex_write_raw(nandi, page_addr, 0, nandi->page_buf,
@@ -1598,17 +1668,20 @@
 		(ops->oobbuf ? ops->ooblen : 0),
 		mtd_oob_mode_strs[ops->mode]);
 
+	if (!ops->oobbuf && ops->mode != MTD_OOB_RAW)
+		return mtd_read(mtd, from, ops->len, &ops->retlen, ops->datbuf);
+
 	ops->oobretlen = 0;
 	ops->retlen = 0;
 
 	/* We report OOB as unavailable (i.e. oobavail = 0), therefore nothing
 	 * should call this */
-	if (ops->mode == MTD_OOB_AUTO)
+	if (ops->oobbuf && ops->mode == MTD_OOB_AUTO)
 		return -ENOTSUPP;
 
 	/* Not currently supported by MTD.  Note, will have to fake support if
 	 * backporting 'in-band' nand_bbt.c... */
-	if (ops->datbuf && ops->mode == MTD_OOB_PLACE)
+	if (ops->datbuf && ops->oobbuf && ops->mode == MTD_OOB_PLACE)
 		return -ENOTSUPP;
 
 	/* Do not allow oob reads with ooboffs */
@@ -1668,17 +1741,20 @@
 		(ops->oobbuf ? ops->ooblen : 0),
 		mtd_oob_mode_strs[ops->mode]);
 
+	if (!ops->oobbuf && ops->mode != MTD_OOB_RAW)
+		return mtd_write(mtd, to, ops->len, &ops->retlen, ops->datbuf);
+
 	ops->oobretlen = 0;
 	ops->retlen = 0;
 
 	/* We report OOB as unavailable (i.e. oobavail = 0), therefore nothing
 	 * should call this */
-	if (ops->mode == MTD_OOB_AUTO)
+	if (ops->oobbuf && ops->mode == MTD_OOB_AUTO)
 		return -ENOTSUPP;
 
 	/* Not currently supported by MTD.  Note, will have to fake support if
 	 * backporting wavefront nand_bbt.c... */
-	if (ops->datbuf && ops->mode == MTD_OOB_PLACE)
+	if (ops->datbuf && ops->oobbuf && ops->mode == MTD_OOB_PLACE)
 		return -ENOTSUPP;
 
 	/* Do not allow oob writes with ooboffs */
@@ -1780,9 +1856,10 @@
 	struct nand_chip *chip = mtd->priv;
 	struct nandi_controller *nandi = chip->priv;
 
-	uint32_t block_mask = mtd->erasesize - 1;
+	uint64_t block_mask = mtd->erasesize - 1;
 	loff_t offs = instr->addr;
 	size_t len = instr->len;
+	uint64_t offs_cached;
 	uint8_t status;
 	int ret;
 
@@ -1815,6 +1892,10 @@
 		goto erase_exit;
 	}
 
+	/* Offset of block containing cached page */
+	offs_cached = ((uint64_t)nandi->cached_page << nandi->page_shift) &
+		~block_mask;
+
 	instr->state = MTD_ERASING;
 	while (len) {
 		if (!nand_erasebb && mtd_block_isbad(mtd, offs)) {
@@ -1825,6 +1906,9 @@
 			goto erase_exit;
 		}
 
+		if (offs == offs_cached)
+			nandi->cached_page = -1;
+
 		status = bch_erase_block(nandi, offs);
 
 		if (status & NAND_STATUS_FAIL) {
@@ -2091,6 +2175,8 @@
 		nandi->sectors_per_page);
 	pr_info("\t%-20s: %s\n", "BCH ECC mode",
 		bch_ecc_strs[nandi->bch_ecc_mode]);
+	pr_info("\t%-20s: %u\n", "Bit-flips threshold",
+		nandi->bitflip_threshold);
 	pr_info("\n");
 	nandi_dump_bch_progs(nandi);
 	pr_info("--------------------------------------------------"
@@ -2191,6 +2277,7 @@
 	chip->block_bad = flex_block_bad_BUG; /**/
 	chip->block_markbad = flex_block_markbad_BUG; /**/
 	chip->verify_buf = flex_verify_buf_BUG; /**/
+	chip->options |= NAND_USE_FLASH_BBT;
 	chip->scan_bbt = flex_scan_bbt_BUG; /**/
 
 	/* mtd_info */
@@ -2218,6 +2305,320 @@
 	mtd->resume = nand_resume;
 }
 
+static int nandi_examine_bbts(struct nandi_controller *nandi,
+			      struct mtd_info *mtd)
+{
+	int bch_remap;
+
+	switch (nandi->bch_ecc_mode) {
+	case BCH_18BIT_ECC:
+		bch_remap = BCH_REMAP_18BIT;
+		break;
+	case BCH_30BIT_ECC:
+		bch_remap = BCH_REMAP_30BIT;
+		break;
+	default:
+		bch_remap = BCH_REMAP_NONE;
+	}
+
+	return stmnand_examine_bbts(mtd, bch_remap);
+}
+
+/*
+ * Timing Configuration
+ */
+
+/* Derive Hamming-FLEX timing register values from 'nand_timing_spec' data */
+static void flex_calc_timing_registers(struct nand_timing_spec *spec,
+				       int tCLK, int relax,
+				       uint32_t *ctl_timing,
+				       uint32_t *wen_timing,
+				       uint32_t *ren_timing)
+{
+	int tMAX_HOLD;
+	int n_ctl_setup;
+	int n_ctl_hold;
+	int n_ctl_wb;
+
+	int tMAX_WEN_OFF;
+	int n_wen_on;
+	int n_wen_off;
+
+	int tMAX_REN_OFF;
+	int n_ren_on;
+	int n_ren_off;
+
+	/*
+	 * CTL_TIMING
+	 */
+
+	/*	- SETUP */
+	n_ctl_setup = (spec->tCLS - spec->tWP + tCLK - 1)/tCLK;
+	if (n_ctl_setup < 1)
+		n_ctl_setup = 1;
+	n_ctl_setup += relax;
+
+	/*	- HOLD */
+	tMAX_HOLD = spec->tCLH;
+	if (spec->tCH > tMAX_HOLD)
+		tMAX_HOLD = spec->tCH;
+	if (spec->tALH > tMAX_HOLD)
+		tMAX_HOLD = spec->tALH;
+	if (spec->tDH > tMAX_HOLD)
+		tMAX_HOLD = spec->tDH;
+	n_ctl_hold = (tMAX_HOLD + tCLK - 1)/tCLK + relax;
+
+	/*	- CE_deassert_hold = 0 */
+
+	/*	- WE_high_to_RBn_low */
+	n_ctl_wb = (spec->tWB + tCLK - 1)/tCLK;
+
+	*ctl_timing = ((n_ctl_setup & 0xff) |
+		       (n_ctl_hold & 0xff) << 8 |
+		       (n_ctl_wb & 0xff) << 24);
+
+	/*
+	 * WEN_TIMING
+	 */
+
+	/*	- ON */
+	n_wen_on = (spec->tWH + tCLK - 1)/tCLK + relax;
+
+	/*	- OFF */
+	tMAX_WEN_OFF = spec->tWC - spec->tWH;
+	if (spec->tWP > tMAX_WEN_OFF)
+		tMAX_WEN_OFF = spec->tWP;
+	n_wen_off = (tMAX_WEN_OFF + tCLK - 1)/tCLK + relax;
+
+	*wen_timing = ((n_wen_on & 0xff) |
+		       (n_wen_off & 0xff) << 8);
+
+	/*
+	 * REN_TIMING
+	 */
+
+	/*	- ON */
+	n_ren_on = (spec->tREH + tCLK - 1)/tCLK + relax;
+
+	/*	- OFF */
+	tMAX_REN_OFF = spec->tRC - spec->tREH;
+	if (spec->tRP > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tRP;
+	if (spec->tREA > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tREA;
+	n_ren_off = (tMAX_REN_OFF + tCLK - 1)/tCLK + 1 + relax;
+
+	*ren_timing = ((n_ren_on & 0xff) |
+		       (n_ren_off & 0xff) << 8);
+}
+
+/* Derive BCH timing register values from 'nand_timing_spec' data */
+static void bch_calc_timing_registers(struct nand_timing_spec *spec,
+				      int tCLK, int relax,
+				      uint32_t *ctl_timing,
+				      uint32_t *wen_timing,
+				      uint32_t *ren_timing)
+{
+	int tMAX_HOLD;
+	int n_ctl_setup;
+	int n_ctl_hold;
+	int n_ctl_wb;
+
+	int n_wen_on;
+	int n_wen_off;
+	int wen_half_on;
+	int wen_half_off;
+
+	int tMAX_REN_ON;
+	int tMAX_CS_DEASSERT;
+	int n_d_latch;
+	int n_telqv;
+	int n_ren_on;
+	int n_ren_off;
+	int ren_half_on;
+	int ren_half_off;
+
+	/*
+	 * CTL_TIMING
+	 */
+
+	/*	- SETUP */
+	if (spec->tCLS > spec->tWP)
+		n_ctl_setup = (spec->tCLS - spec->tWP + tCLK - 1)/tCLK;
+	else
+		n_ctl_setup = 0;
+	n_ctl_setup += relax;
+
+	/*	- HOLD */
+	tMAX_HOLD = spec->tCLH;
+	if (spec->tCH > tMAX_HOLD)
+		tMAX_HOLD = spec->tCH;
+	if (spec->tALH > tMAX_HOLD)
+		tMAX_HOLD = spec->tALH;
+	if (spec->tDH > tMAX_HOLD)
+		tMAX_HOLD = spec->tDH;
+	n_ctl_hold = (tMAX_HOLD + tCLK - 1)/tCLK + relax;
+	/*	- CE_deassert_hold = 0 */
+
+	/*	- WE_high_to_RBn_low */
+	n_ctl_wb = (spec->tWB + tCLK - 1)/tCLK;
+
+	*ctl_timing = ((n_ctl_setup & 0xff) |
+		       (n_ctl_hold & 0xff) << 8 |
+		       (n_ctl_wb & 0xff) << 24);
+
+	/*
+	 * WEN_TIMING
+	 */
+
+	/*	- ON */
+	n_wen_on = (2 * spec->tWH + tCLK - 1)/tCLK;
+	wen_half_on = n_wen_on % 2;
+	n_wen_on /= 2;
+	n_wen_on += relax;
+
+	/*	- OFF */
+	n_wen_off = (2 * spec->tWP + tCLK - 1)/tCLK;
+	wen_half_off = n_wen_off % 2;
+	n_wen_off /= 2;
+	n_wen_off += relax;
+
+	*wen_timing = ((n_wen_on & 0xff) |
+		       (n_wen_off & 0xff) << 8 |
+		       (wen_half_on << 16) |
+		       (wen_half_off << 17));
+
+	/*
+	 * REN_TIMING
+	 */
+
+	/*	- ON */
+	tMAX_REN_ON = spec->tRC - spec->tRP;
+	if (spec->tREH > tMAX_REN_ON)
+		tMAX_REN_ON = spec->tREH;
+
+	n_ren_on = (2 * tMAX_REN_ON + tCLK - 1)/tCLK;
+	ren_half_on = n_ren_on % 2;
+	n_ren_on /= 2;
+	n_ren_on += relax;
+
+	/*	- OFF */
+	n_ren_off = (2 * spec->tREA + tCLK - 1)/tCLK;
+	ren_half_off = n_ren_off % 2;
+	n_ren_off /= 2;
+	n_ren_off += relax;
+
+	/*	- DATA_LATCH */
+	if (spec->tREA <= (spec->tRP - (2 * tCLK)))
+		n_d_latch = 0;
+	else if (spec->tREA <= (spec->tRP - tCLK))
+		n_d_latch = 1;
+	else if ((spec->tREA <= spec->tRP) && (spec->tRHOH >= 2 * tCLK))
+		n_d_latch = 2;
+	else
+		n_d_latch = 3;
+
+	/*	- TELQV */
+	tMAX_CS_DEASSERT = spec->tCOH;
+	if (spec->tCHZ > tMAX_CS_DEASSERT)
+		tMAX_CS_DEASSERT = spec->tCHZ;
+	if (spec->tCSD > tMAX_CS_DEASSERT)
+		tMAX_CS_DEASSERT = spec->tCSD;
+
+	n_telqv = (tMAX_CS_DEASSERT + tCLK - 1)/tCLK;
+
+	*ren_timing = ((n_ren_on & 0xff) |
+		       (n_ren_off & 0xff) << 8 |
+		       (n_d_latch & 0x3) << 16 |
+		       (wen_half_on << 18) |
+		       (wen_half_off << 19) |
+		       (n_telqv & 0xff) << 24);
+}
+
+static void flex_configure_timing_registers(struct nandi_controller *nandi,
+					    struct nand_timing_spec *spec,
+					    int relax)
+{
+	struct clk *emi_clk;
+	int emi_t_ns;
+
+	uint32_t ctl_timing;
+	uint32_t wen_timing;
+	uint32_t ren_timing;
+
+	/* Select Hamming Controller */
+	emiss_nandi_select(STM_NANDI_HAMMING);
+
+	/* Get EMI clock (default 100MHz) */
+	emi_clk = clk_get(NULL, "emi_clk");
+	if (!emi_clk || IS_ERR(emi_clk)) {
+		dev_warn(nandi->dev, "Failed to get EMI clock, assuming "
+		"default 100MHz\n");
+		emi_t_ns = 10;
+	} else {
+		emi_t_ns = 1000000000 / clk_get_rate(emi_clk);
+	}
+
+	/* Derive timing register values from specification */
+	flex_calc_timing_registers(spec, emi_t_ns, relax,
+				   &ctl_timing, &wen_timing, &ren_timing);
+
+	dev_dbg(nandi->dev, "updating FLEX timing configuration "
+		"[0x%08x, 0x%08x, 0x%08x]\n",
+		ctl_timing, wen_timing, ren_timing);
+
+	/* Program timing registers */
+	writel(ctl_timing, nandi->base + NANDHAM_CTL_TIMING);
+	writel(wen_timing, nandi->base + NANDHAM_WEN_TIMING);
+	writel(ren_timing, nandi->base + NANDHAM_REN_TIMING);
+}
+
+static void bch_configure_timing_registers(struct nandi_controller *nandi,
+					   struct nand_timing_spec *spec,
+					   int relax)
+{
+	struct clk *bch_clk;
+	int bch_t_ns;
+
+	uint32_t ctl_timing;
+	uint32_t wen_timing;
+	uint32_t ren_timing;
+
+	/* Select BCH Controller */
+	emiss_nandi_select(STM_NANDI_BCH);
+
+	/* Get BCH clock (default 200MHz) */
+	bch_clk = clk_get(NULL, "bch_clk");
+	if (!bch_clk || IS_ERR(bch_clk)) {
+		dev_warn(nandi->dev, "Failed to get BCH clock, assuming "
+		"default 200MHz\n");
+		bch_t_ns = 5;
+	} else {
+		bch_t_ns = 1000000000 / clk_get_rate(bch_clk);
+	}
+
+	/* Derive timing register values from specification */
+	bch_calc_timing_registers(spec, bch_t_ns, relax,
+				  &ctl_timing, &wen_timing, &ren_timing);
+
+	dev_dbg(nandi->dev, "updating BCH timing configuration"
+		"[0x%08x, 0x%08x, 0x%08x]\n",
+		ctl_timing, wen_timing, ren_timing);
+
+	/* Program timing registers */
+	writel(ctl_timing, nandi->base + NANDBCH_CTL_TIMING);
+	writel(wen_timing, nandi->base + NANDBCH_WEN_TIMING);
+	writel(ren_timing, nandi->base + NANDBCH_REN_TIMING);
+}
+
+static void nandi_configure_timing_registers(struct nandi_controller *nandi,
+					     struct nand_timing_spec *spec,
+					     int relax)
+{
+	bch_configure_timing_registers(nandi, spec, relax);
+	flex_configure_timing_registers(nandi, spec, relax);
+}
+
 static void nandi_init_hamming(struct nandi_controller *nandi, int emi_bank)
 {
 	dev_dbg(nandi->dev, "%s\n", __func__);
@@ -2280,15 +2681,6 @@
 	/* Enable AFM */
 	writel(CFG_ENABLE_AFM, nandi->base + NANDBCH_CONTROLLER_CFG);
 
-	/* Timing parameters */
-	/* Values from validation found not to work on some parts.  Awaiting
-	 * clarification.  Use reset values for the time being.
-	 *
-	 * writel(0x14000205, nandi->base + NANDBCH_CTL_TIMING);
-	 * writel(0x00020304, nandi->base + NANDBCH_WEN_TIMING);
-	 * writel(0x060b0304, nandi->base + NANDBCH_REN_TIMING);
-	 */
-
 	/* Configure Read DMA Plugs (values supplied by Validation)*/
 	writel(0x00000005, nandi->dma + EMISS_NAND_RD_DMA_PAGE_SIZE);
 	writel(0x00000005, nandi->dma + EMISS_NAND_RD_DMA_MAX_OPCODE_SIZE);
@@ -2333,7 +2725,7 @@
 	return 0;
 }
 
-static struct nandi_controller * __init
+static struct nandi_controller * __devinit
 nandi_init_resources(struct platform_device *pdev)
 {
 	struct nandi_controller *nandi;
@@ -2377,13 +2769,13 @@
 	return nandi;
 }
 
-static void __devexit nandi_exit_controller(struct nandi_controller *nandi)
+static void nandi_exit_controller(struct nandi_controller *nandi)
 {
 
 }
 
-static void __devinit nandi_init_controller(struct nandi_controller *nandi,
-					    int emi_bank)
+static void nandi_init_controller(struct nandi_controller *nandi,
+				  int emi_bank)
 {
 	nandi_init_bch(nandi, emi_bank);
 	nandi_init_hamming(nandi, emi_bank);
@@ -2423,17 +2815,51 @@
 	mtd = &info->mtd;
 	mtd->priv = chip;
 	mtd->name = dev_name(&pdev->dev);
+	mtd->dev.parent = &pdev->dev;
 
 	nandi_set_mtd_defaults(nandi, mtd, chip);
 
 	if (nand_scan_ident(mtd, 1) != 0)
 		return -ENODEV;
 
+	/*
+	 * Configure timing registers
+	 */
+	if (bank->timing_spec) {
+		dev_info(&pdev->dev, "Using platform timing data\n");
+		nandi_configure_timing_registers(nandi, bank->timing_spec,
+						 bank->timing_relax);
+	} else if (chip->onfi_version) {
+		struct nand_onfi_params *onfi = &chip->onfi_params;
+		int mode;
+
+		mode = fls(le16_to_cpu(onfi->async_timing_mode)) - 1;
+
+		/* Modes 4 and 5 (EDO) are not supported on our H/W */
+		if (mode > 3)
+			mode = 3;
+
+		dev_info(&pdev->dev, "Using ONFI Timing Mode %d\n", mode);
+		nandi_configure_timing_registers(nandi,
+						 &nand_onfi_timing_specs[mode],
+						 bank->timing_relax);
+	} else {
+		dev_warn(&pdev->dev, "No timing data available\n");
+	}
+
+	if (mtd->writesize < NANDI_BCH_SECTOR_SIZE) {
+		dev_err(nandi->dev, "page size incompatible with BCH ECC "
+			"sector\n");
+		return -EINVAL;
+	}
+
 	/* Derive some working variables */
 	nandi->sectors_per_page = mtd->writesize / NANDI_BCH_SECTOR_SIZE;
 	nandi->blocks_per_device = mtd->size >> chip->phys_erase_shift;
 	nandi->page_shift = chip->page_shift;
 	nandi->block_shift = chip->phys_erase_shift;
+	nandi->extra_addr = ((chip->chipsize >> nandi->page_shift) >
+			     0x10000) ? 1 : 0;
 
 	/* Set ECC mode */
 	switch (pdata->bch_ecc_cfg) {
@@ -2454,6 +2880,22 @@
 		break;
 	}
 
+	/*
+	 * Get bit-flips threshold. A value of '0' is interpreted as
+	 * <ecc_strength>.
+	 */
+	if (pdata->bch_bitflip_threshold) {
+		nandi->bitflip_threshold = pdata->bch_bitflip_threshold;
+	} else {
+		dev_warn(nandi->dev, "WARNING: bit-flips threshold not specified.  Defaulting to ECC strength [%d]\n",
+			 bch_ecc_strength[nandi->bch_ecc_mode]);
+		nandi->bitflip_threshold =
+			bch_ecc_strength[nandi->bch_ecc_mode];
+	}
+
+	info->ecclayout.eccbytes = nandi->sectors_per_page *
+		bch_ecc_sizes[nandi->bch_ecc_mode];
+
 	/* Check compatibility */
 	if (bch_check_compatibility(nandi, mtd, chip) != 0) {
 		dev_err(nandi->dev, "NAND device incompatible with NANDi/BCH "
@@ -2494,6 +2936,12 @@
 	nandi->buf_list = (uint32_t *) PTR_ALIGN(bbt_info->bbt + bbt_buf_size,
 						 NANDI_BCH_DMA_ALIGNMENT);
 	nandi->cached_page = -1;
+	if (nandi_examine_bbts(nandi, mtd) != 0) {
+		dev_err(nandi->dev, "incompatible BBTs detected\n");
+		dev_err(nandi->dev, "initiating NAND Recovery Mode\n");
+		mtd->name = "NAND RECOVERY MODE";
+		return add_mtd_device(mtd);
+	}
 
 	/* Load Flash-resident BBT */
 	err = bch_load_bbt(nandi, bbt_info);
@@ -2576,12 +3024,32 @@
 	return 0;
 }
 
+#ifdef CONFIG_HIBERNATION
+static int stm_nand_bch_restore(struct device *dev)
+{
+	struct nandi_controller *nandi = dev_get_drvdata(dev);
+	struct stm_plat_nand_bch_data *pdata = dev->platform_data;
+	struct stm_nand_bank_data *bank = pdata->bank;;
+
+	nandi_init_controller(nandi, bank->csn);
+
+	return 0;
+}
+
+static struct dev_pm_ops stm_nand_bch_pm_ops = {
+	.restore = stm_nand_bch_restore,
+};
+#else
+static struct dev_pm_ops stm_nand_bch_pm_ops;
+#endif
+
 static struct platform_driver stm_nand_bch_driver = {
 	.probe		= stm_nand_bch_probe,
 	.remove		= stm_nand_bch_remove,
 	.driver		= {
 		.name	= NAME,
 		.owner	= THIS_MODULE,
+		.pm	= &stm_nand_bch_pm_ops,
 	},
 };
 
diff -Naur a/drivers/mtd/nand/stm_nand_ecc.c b/drivers/mtd/nand/stm_nand_ecc.c
--- a/drivers/mtd/nand/stm_nand_ecc.c	2013-11-01 20:19:18.773929081 +0200
+++ b/drivers/mtd/nand/stm_nand_ecc.c	2013-11-01 18:44:50.965823938 +0200
@@ -564,6 +564,46 @@
 }
 EXPORT_SYMBOL_GPL(stm_afm_lp1617);
 
+/* Test for empty/erased page (ST Hamming Controller ECC schemes) */
+int stmnand_test_empty_page(uint8_t *ecc_stored, uint8_t *ecc_calc,
+			    int eccsteps, int eccbytes,
+			    uint8_t *buf, uint8_t *oob,
+			    int pagesize, int oobsize, int max_bit_errors)
+{
+	int i, j;
+	int e = 0;
+	uint8_t *e1, *e2;
+
+	/* Is ECC data consistent with empty page */
+	e1 = ecc_stored;
+	e2 = ecc_calc;
+	for (i = 0; i < eccsteps; i++) {
+		for (j = 0; j < 3; j++)
+			if (e1[j] != 0xff || e2[j] != 0x00)
+				return 0;
+		e1 += eccbytes;
+		e2 += eccbytes;
+	}
+
+	/* Check page area is emtpy */
+	while (pagesize--) {
+		e += hweight8(~*buf++);
+		if (e > max_bit_errors)
+			return 0;
+	}
+
+	/* Check OOB area is emtpy */
+	while (oobsize--) {
+		e += hweight8(~*oob++);
+		if (e > max_bit_errors)
+			return 0;
+	}
+
+	return 1;
+}
+EXPORT_SYMBOL_GPL(stmnand_test_empty_page);
+
+
 /*****************************************************************************/
 
 
diff -Naur a/drivers/mtd/nand/stm_nand_ecc.h b/drivers/mtd/nand/stm_nand_ecc.h
--- a/drivers/mtd/nand/stm_nand_ecc.h	2013-11-01 20:19:18.773929081 +0200
+++ b/drivers/mtd/nand/stm_nand_ecc.h	2013-11-01 18:44:50.965823938 +0200
@@ -147,5 +147,10 @@
 
 unsigned char stm_afm_lp1617(const unsigned char *buf);
 
+int stmnand_test_empty_page(uint8_t *ecc_stored, uint8_t *ecc_calc,
+			    int eccsteps, int eccbytes,
+			    uint8_t *buf, uint8_t *oob,
+			    int pagesize, int oobsize, int max_bit_errors);
+
 #endif /* ifndef STM_NAND_ECC_H */
 
diff -Naur a/drivers/mtd/nand/stm_nand_emi.c b/drivers/mtd/nand/stm_nand_emi.c
--- a/drivers/mtd/nand/stm_nand_emi.c	2013-11-01 20:19:18.773929081 +0200
+++ b/drivers/mtd/nand/stm_nand_emi.c	2013-11-01 18:44:50.965823938 +0200
@@ -38,6 +38,8 @@
 #include <linux/stm/nand.h>
 #include <asm/dma.h>
 
+#include "stm_nand_bbt.h"
+
 #ifdef CONFIG_MTD_PARTITIONS
 #include <linux/mtd/partitions.h>
 #endif
@@ -483,12 +485,16 @@
 }
 
 #define GET_CLK_CYCLES(X, T)	(((X) + (T) - 1) / (T))
-/* Configure EMI Bank for NAND access */
-static int nand_config_emi(int bank, struct stm_nand_timing_data *td)
+
+/* Configure EMI Bank according to 'stm_nand_timing_data'
+ *
+ * [DEPRECATED in favour of nand_config_emi() based on 'struct nand_timing_spec'
+ * data.]
+ */
+static void nand_config_emi_legacy(int bank, struct stm_nand_timing_data *td)
 {
 	struct clk *emi_clk;
 	uint32_t emi_t_ns;
-	uint32_t emi_p_ns;
 
 	unsigned long config[4];
 
@@ -505,7 +511,7 @@
 	if (!td) {
 		printk(KERN_ERR NAME "No timing data specified in platform "
 		       "data\n");
-		return 1;
+		return;
 	}
 
 	/* Timings set in terms of EMI clock... */
@@ -518,7 +524,6 @@
 	} else {
 		emi_t_ns = 1000000000UL / clk_get_rate(emi_clk);
 	}
-	emi_p_ns = emi_t_ns / 2;
 
 	/* Convert nand timings to EMI compatible values */
 	rd_cycle = GET_CLK_CYCLES(td->rd_on + td->rd_off, emi_t_ns) + 3;
@@ -549,25 +554,124 @@
 
 	config[3] = 0x00;
 
+	pr_debug("EMI Configuration Data: {0x%08x, 0x%08x, 0x%08x, 0x%08x}\n",
+		 (unsigned int)config[0], (unsigned int)config[1],
+		 (unsigned int)config[2], (unsigned int)config[3]);
+
 	/* Configure Bank */
 	emi_bank_configure(bank, config);
 
 	/* Disable PC mode */
 	emi_config_pcmode(bank, 0);
+}
 
-	return 0;
+/* Configure EMI Bank according to 'nand_timing_spec' */
+static void nand_config_emi(int bank, struct nand_timing_spec *spec, int relax)
+{
+	struct clk *emi_clk;
+	int tCLK;
+
+	unsigned long config[4];
+
+	uint32_t rd_cycle, rd_oee1, rd_oee2, rd_latch;
+	uint32_t wr_cycle, wr_wee1, wr_wee2;
+	uint32_t bus_release;
+	uint32_t tMAX_SETUP, tMAX_HOLD;
+
+	printk(KERN_INFO NAME ": Configuring EMI Bank %d for NAND access\n",
+	       bank);
+
+	/* Get EMI clock (default 100MHz) */
+	emi_clk = clk_get(NULL, "emi_clk");
+	if (!emi_clk || IS_ERR(emi_clk)) {
+		printk(KERN_WARNING NAME
+		       ": Failed to get EMI clock, assuming default 100MHz\n");
+		tCLK = 10;
+	} else {
+		tCLK = 1000000000 / clk_get_rate(emi_clk);
+	}
+
+	rd_cycle = (spec->tRC + tCLK - 1)/tCLK + 1 + relax;
+	rd_oee1 = 0;
+	rd_oee2 = (spec->tREH + tCLK - 1)/tCLK + relax;
+	rd_latch = (spec->tREH + tCLK - 1)/tCLK + relax;
+
+	bus_release = (spec->tCHZ + tCLK - 1)/tCLK + relax;
+
+	tMAX_SETUP = spec->tCLS;
+	if (spec->tCS > tMAX_SETUP)
+		tMAX_SETUP = spec->tCS;
+	if (spec->tALS > tMAX_SETUP)
+		tMAX_SETUP = spec->tALS;
+	if (spec->tDS > tMAX_SETUP)
+		tMAX_SETUP = spec->tDS;
+	if (spec->tWP > tMAX_SETUP)
+		tMAX_SETUP = spec->tWP;
+
+	tMAX_HOLD = spec->tCLH;
+	if (spec->tCH > tMAX_HOLD)
+		tMAX_HOLD = spec->tCH;
+	if (spec->tALH > tMAX_HOLD)
+		tMAX_HOLD = spec->tALH;
+	if (spec->tDH > tMAX_HOLD)
+		tMAX_HOLD = spec->tDH;
+	if (spec->tWH > tMAX_HOLD)
+		tMAX_HOLD = spec->tWH;
+
+	if (spec->tWC > (tMAX_SETUP + tMAX_HOLD))
+		wr_cycle = (spec->tWC + tCLK - 1)/tCLK + 1 + relax;
+	else
+		wr_cycle = (tMAX_SETUP + tMAX_HOLD + tCLK - 1)/tCLK + 1 + relax;
+	wr_wee1 = 0;
+	wr_wee2 = (tMAX_HOLD + tCLK - 1)/tCLK + relax;
+
+	config[0] = (EMI_CFG0_WE_USE_OE_CFG |
+		     EMI_CFG0_LATCH_POINT(rd_latch) |
+		     EMI_CFG0_BUS_RELEASE(bus_release) |
+		     EMI_CFG0_CS_ACTIVE(ACTIVE_CODE_RDWR) |
+		     EMI_CFG0_OE_ACTIVE(ACTIVE_CODE_RD) |
+		     EMI_CFG0_BE_ACTIVE(ACTIVE_CODE_OFF) |
+		     EMI_CFG0_PORTSIZE_8BIT |
+		     EMI_CFG0_DEVICE_NORMAL);
+
+	config[1] = (EMI_CFG1_READ_CYCLESNOTPHASE |
+		     EMI_CFG1_READ_CYCLES(rd_cycle) |
+		     EMI_CFG1_READ_OEE1(rd_oee1) |
+		     EMI_CFG1_READ_OEE2(rd_oee2));
+
+	config[2] = (EMI_CFG2_WRITE_CYCLESNOTPHASE |
+		     EMI_CFG2_WRITE_CYCLES(wr_cycle) |
+		     EMI_CFG2_WRITE_OEE1(wr_wee1) |
+		     EMI_CFG2_WRITE_OEE2(wr_wee2));
+
+	config[3] = 0;
+
+	pr_debug("EMI Configuration Data: {0x%08x, 0x%08x, 0x%08x, 0x%08x}\n",
+		 (unsigned int)config[0], (unsigned int)config[1],
+		 (unsigned int)config[2], (unsigned int)config[3]);
+
+	/* Configure Bank */
+	emi_bank_configure(bank, config);
+
+	/* Disable PC mode */
+	emi_config_pcmode(bank, 0);
 }
 
 /*
  * Probe for the NAND device.
  */
-static struct stm_nand_emi * __init nand_probe_bank(
+static struct stm_nand_emi * __devinit nand_probe_bank(
 	struct stm_nand_bank_data *bank, int rbn_gpio,
-	const char* name)
+	struct platform_device *pdev)
 {
 	struct stm_nand_emi *data;
-	struct stm_nand_timing_data *tm;
 
+	/* Default EMI config data, for device probing */
+	unsigned long emi_cfg_probe[] = {
+		0x04402e99,
+		0x0a000400,
+		0x0a000400,
+		0x00000000};
 	int res = 0;
 
 	/* Allocate memory for the driver structure (and zero it) */
@@ -584,15 +688,12 @@
 		bank->emi_withinbankoffset;
 	data->emi_size = (1 << 18) + 1;
 
-	/* Configure EMI Bank */
-	if (nand_config_emi(data->emi_bank, bank->timing_data) != 0) {
-		printk(KERN_ERR NAME ": Failed to configure EMI bank "
-		       "for NAND device\n");
-		goto out1;
-	}
+	/* Configure EMI Bank for device probe */
+	emi_bank_configure(data->emi_bank, emi_cfg_probe);
+	emi_config_pcmode(data->emi_bank, 0);
 
 	/* Request IO Memory */
-	if (!request_mem_region(data->emi_base, data->emi_size, name)) {
+	if (!request_mem_region(data->emi_base, data->emi_size, NAME)) {
 		printk(KERN_ERR NAME ": Request mem 0x%x region failed\n",
 		       data->emi_base);
 		res = -ENODEV;
@@ -640,25 +741,21 @@
 	data->chip.priv = data;
 	data->mtd.priv = &data->chip;
 	data->mtd.owner = THIS_MODULE;
+	data->mtd.dev.parent = &pdev->dev;
 
 	/* Assign more sensible name (default is string from nand_ids.c!) */
-	data->mtd.name = name;
-
-	tm = bank->timing_data;
+	data->mtd.name = dev_name(&pdev->dev);
 
 	data->chip.IO_ADDR_R = data->io_base;
 	data->chip.IO_ADDR_W = data->io_base;
-	data->chip.chip_delay = tm->chip_delay;
+	data->rbn_gpio = -1;
+	data->chip.chip_delay = 50;
 	data->chip.cmd_ctrl = nand_cmd_ctrl_emi;
 
 	/* Do we have access to NAND_RBn? */
 	if (gpio_is_valid(rbn_gpio)) {
 		data->rbn_gpio = rbn_gpio;
 		data->chip.dev_ready = nand_device_ready;
-	} else {
-		data->rbn_gpio = -1;
-		if (data->chip.chip_delay == 0)
-			data->chip.chip_delay = 30;
 	}
 
 	/* Set IO routines for acessing NAND pages */
@@ -689,13 +786,61 @@
 	/* Copy chip options from platform data */
 	data->chip.options = bank->options;
 
-	/* Scan to find existance of the device */
-	if (nand_scan(&data->mtd, 1)) {
+	data->chip.scan_bbt = stmnand_scan_bbt;
+
+	/* Scan to find existence of device */
+	if (nand_scan_ident(&data->mtd, 1) != 0) {
 		printk(KERN_ERR NAME ": nand_scan failed\n");
+		res = -ENODEV;
+		goto out6;
+	}
+
+	/*
+	 * Configure timing registers
+	 */
+	if (bank->timing_spec) {
+		printk(KERN_INFO NAME ": Using platform timing data\n");
+		nand_config_emi(data->emi_bank, bank->timing_spec,
+				bank->timing_relax);
+		data->chip.chip_delay = bank->timing_spec->tR;
+	} else if (bank->timing_data) {
+		printk(KERN_INFO NAME ": Using legacy platform timing data\n");
+		nand_config_emi_legacy(data->emi_bank, bank->timing_data);
+		data->chip.chip_delay = bank->timing_data->chip_delay;
+	} else if (data->chip.onfi_version) {
+		struct nand_onfi_params *onfi = &data->chip.onfi_params;
+		int mode;
+
+		mode = fls(le16_to_cpu(onfi->async_timing_mode)) - 1;
+		/* Modes 4 and 5 (EDO) are not supported on our H/W */
+		if (mode > 3)
+			mode = 3;
+
+		printk(KERN_INFO NAME ": Using ONFI Timing Mode %d\n", mode);
+		nand_config_emi(data->emi_bank, &nand_onfi_timing_specs[mode],
+				bank->timing_relax);
+		data->chip.chip_delay = le16_to_cpu(data->chip.onfi_params.t_r);
+	} else {
+		printk(KERN_WARNING NAME ": No timing data available\n");
+	}
+
+	/* Complete scan */
+	if (nand_scan_tail(&data->mtd) != 0) {
 		res = -ENXIO;
 		goto out6;
 	}
 
+	/* If all blocks are marked bad, mount as "recovery" partition */
+	if (stmnand_blocks_all_bad(&data->mtd)) {
+		printk(KERN_ERR NAME ": initiating NAND Recovery Mode\n");
+		data->mtd.name = "NAND RECOVERY MODE";
+		res = add_mtd_device(&data->mtd);
+		if (res)
+			goto out6;
+
+		return data;
+	}
+
 #ifdef CONFIG_MTD_PARTITIONS
 	res = parse_mtd_partitions(&data->mtd, part_probes, &data->parts, 0);
 	if (res > 0) {
@@ -732,14 +877,36 @@
 	return ERR_PTR(res);
 }
 
-static int __init stm_nand_emi_probe(struct platform_device *pdev)
+static void nand_remove_bank(struct stm_nand_emi *emi,
+			     struct stm_nand_bank_data *data)
+{
+	nand_release(&emi->mtd);
+
+#ifdef CONFIG_MTD_PARTITIONS
+	if (emi->parts && emi->parts != data->partitions)
+		kfree(emi->parts);
+#endif
+	iounmap(emi->io_addr);
+	iounmap(emi->io_cmd);
+#ifdef CONFIG_STM_NAND_EMI_CACHED
+	iounmap(emi->io_data);
+#endif
+	iounmap(emi->io_base);
+	release_mem_region(emi->emi_base, emi->emi_size);
+#ifdef CONFIG_STM_NAND_EMI_FDMA
+	exit_fdma_nand(emi);
+#endif
+	kfree(emi);
+}
+
+static int __devinit stm_nand_emi_probe(struct platform_device *pdev)
 {
 	struct stm_plat_nand_emi_data *pdata = pdev->dev.platform_data;
-	int res;
+	struct stm_nand_emi_group *group;
+	struct stm_nand_emi *emi;
+	int err;
 	int n;
 	int rbn_gpio;
-	struct stm_nand_emi_group *group;
-	struct stm_nand_bank_data *bank;
 
 	group = kzalloc(sizeof(struct stm_nand_emi_group) +
 			(sizeof(struct stm_nand_emi *) * pdata->nr_banks),
@@ -749,8 +916,8 @@
 
 	rbn_gpio = pdata->emi_rbn_gpio;
 	if (gpio_is_valid(rbn_gpio)) {
-		res = gpio_request(rbn_gpio, "nand_RBn");
-		if (res == 0) {
+		err = gpio_request(rbn_gpio, "nand_RBn");
+		if (err == 0) {
 			gpio_direction_input(rbn_gpio);
 		} else {
 			dev_err(&pdev->dev, "nand_rbn unavailable. "
@@ -762,16 +929,32 @@
 	group->rbn_gpio = rbn_gpio;
 	group->nr_banks = pdata->nr_banks;
 
-	bank = pdata->banks;
-	for (n=0; n<pdata->nr_banks; n++) {
-		group->banks[n] = nand_probe_bank(bank, rbn_gpio,
-						  dev_name(&pdev->dev));
-		bank++;
+	for (n = 0; n < pdata->nr_banks; n++) {
+		emi = nand_probe_bank(&pdata->banks[n], rbn_gpio, pdev);
+
+		if (IS_ERR(emi)) {
+			err = PTR_ERR(emi);
+			goto err1;
+		}
+
+		group->banks[n] = emi;
 	}
 
 	platform_set_drvdata(pdev, group);
 
 	return 0;
+
+ err1:
+	while (--n > 0)
+		nand_remove_bank(group->banks[n], &pdata->banks[n]);
+
+	if (gpio_is_valid(group->rbn_gpio))
+		gpio_free(group->rbn_gpio);
+
+	platform_set_drvdata(pdev, NULL);
+	kfree(group);
+
+	return err;
 }
 
 /*
@@ -780,33 +963,11 @@
 static int __devexit stm_nand_emi_remove(struct platform_device *pdev)
 {
 	struct stm_nand_emi_group *group = platform_get_drvdata(pdev);
-#ifdef CONFIG_MTD_PARTITIONS
 	struct stm_plat_nand_emi_data *pdata = pdev->dev.platform_data;
-#endif
 	int n;
 
-	for (n=0; n<group->nr_banks; n++) {
-		struct stm_nand_emi *data = group->banks[n];
-
-		nand_release(&data->mtd);
-
-#ifdef CONFIG_MTD_PARTITIONS
-		if (data->parts && data->parts != pdata->banks[n].partitions)
-			kfree(data->parts);
-#endif
-
-		iounmap(data->io_addr);
-		iounmap(data->io_cmd);
-#ifdef CONFIG_STM_NAND_EMI_CACHED
-		iounmap(data->io_data);
-#endif
-		iounmap(data->io_base);
-		release_mem_region(data->emi_base, data->emi_size);
-#ifdef CONFIG_STM_NAND_EMI_FDMA
-		exit_fdma_nand(data);
-#endif
-		kfree(data);
-	}
+	for (n = 0; n < group->nr_banks; n++)
+		nand_remove_bank(group->banks[n], &pdata->banks[n]);
 
 	if (gpio_is_valid(group->rbn_gpio))
 		gpio_free(group->rbn_gpio);
diff -Naur a/drivers/mtd/nand/stm_nand_flex.c b/drivers/mtd/nand/stm_nand_flex.c
--- a/drivers/mtd/nand/stm_nand_flex.c	2013-11-01 20:19:18.777929094 +0200
+++ b/drivers/mtd/nand/stm_nand_flex.c	2013-11-01 18:44:50.965823938 +0200
@@ -62,6 +62,7 @@
 #include <linux/delay.h>
 
 #include "stm_nand_regs.h"
+#include "stm_nand_bbt.h"
 
 #ifdef CONFIG_MTD_PARTITIONS
 #include <linux/mtd/partitions.h>
@@ -84,6 +85,11 @@
 	/* mtd_info params */
 	u_int32_t		subpage_sft;
 };
+
+/* Module parameter for specifying name of boot partition */
+static char *nbootpart;
+module_param(nbootpart, charp, 0000);
+MODULE_PARM_DESC(nbootpart, "MTD name of NAND boot-mode ECC partition");
 #endif /* CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT */
 
 /* NAND device connected to STM NAND Controller operatring in FLEX mode.  (There
@@ -95,7 +101,9 @@
 	struct mtd_info		mtd;
 	int			csn;
 
-	struct stm_nand_timing_data *timing_data;
+	uint32_t		ctl_timing;
+	uint32_t		wen_timing;
+	uint32_t		ren_timing;
 
 #ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
 	unsigned long		boot_start;
@@ -135,10 +143,6 @@
 	struct stm_nand_flex_device *devices[0];
 };
 
-#ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
-/* The command line passed to nboot_setup() */
-__initdata static char *cmdline;
-#endif
 
 static struct stm_nand_flex_controller* mtd_to_flex(struct mtd_info *mtd)
 {
@@ -245,7 +249,7 @@
 	struct stm_nand_flex_controller *flex = mtd_to_flex(mtd);
 
 	/* Apply a small delay before sampling RBn signal */
-	ndelay(100);
+	ndelay(200);
 	return (flex_readreg(NANDHAM_RBN_STA) & (0x4)) ? 1 : 0;
 }
 
@@ -438,46 +442,6 @@
 	.oobfree = {{0, 0} },	/* No free OOB bytes */
 };
 
-static uint8_t scan_ff_pattern[] = { 0xff, 0xff };
-static struct nand_bbt_descr bbt_scan_sp = {
-	.options = NAND_BBT_SCAN2NDPAGE | NAND_BBT_SCANSTMBOOTECC,
-	.offs = 5,
-	.len = 1,
-	.pattern = scan_ff_pattern
-};
-
-static struct nand_bbt_descr bbt_scan_lp = {
-	.options = NAND_BBT_SCAN2NDPAGE | NAND_BBT_SCANSTMBOOTECC,
-	.offs = 0,
-	.len = 2,
-	.pattern = scan_ff_pattern
-};
-
-/* Update 'badblock_pattern' to handle STM boot-mode ECC prior to bad-block
- * scanning */
-static int scan_bbt_stmecc(struct mtd_info *mtd)
-{
-	struct nand_chip *chip = mtd->priv;
-
-	chip->badblock_pattern = (mtd->writesize > 512) ?
-		&bbt_scan_lp : &bbt_scan_sp;
-
-	return nand_default_bbt(mtd);
-}
-
-
-/* Replicated from ../mtdpart.c: required here to get slave MTD offsets and
- * determine which ECC mode to use.
- */
-struct mtd_part {
-	struct mtd_info mtd;
-	struct mtd_info *master;
-	u_int32_t offset;
-	struct list_head list;
-};
-
-#define PART(x)  ((struct mtd_part *)(x))
-
 /* Boot mode ECC calc/correct function */
 int boot_calc_ecc(struct mtd_info *mtd, const unsigned char *buf,
 		  unsigned char *ecc)
@@ -783,10 +747,15 @@
 
 #endif /* CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT */
 
-
-/* Configure NAND controller timing registers */
-static void flex_set_timings(struct stm_nand_flex_controller *flex,
-			     struct stm_nand_timing_data *tm)
+/* Derive timing register values from 'stm_nand_timing_data' data.
+ *
+ * [DEPRECATED in favour of flex_calc_timing_registers() based on 'struct
+ * nand_timing_spec' data.]
+ */
+static void flex_calc_timing_registers_legacy(struct stm_nand_timing_data *tm,
+					      uint32_t *ctl_timing,
+					      uint32_t *wen_timing,
+					      uint32_t *ren_timing)
 {
 	uint32_t n;
 	uint32_t reg;
@@ -818,8 +787,7 @@
 	n = (tm->WE_to_RBn + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 24;
 
-	DEBUG(MTD_DEBUG_LEVEL0, "%s: CTL_TIMING = 0x%08x\n", NAME, reg);
-	flex_writereg(reg, NANDHAM_CTL_TIMING);
+	*ctl_timing = reg;
 
 	/* WEN_TIMING */
 	n = (tm->wr_on + emi_t_ns - 1)/emi_t_ns;
@@ -828,8 +796,8 @@
 	n = (tm->wr_off + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 8;
 
-	DEBUG(MTD_DEBUG_LEVEL0, "%s: WEN_TIMING = 0x%08x\n", NAME, reg);
-	flex_writereg(reg, NANDHAM_WEN_TIMING);
+	*wen_timing = reg;
+
 
 	/* REN_TIMING */
 	n = (tm->rd_on + emi_t_ns - 1)/emi_t_ns;
@@ -838,8 +806,105 @@
 	n = (tm->rd_off + emi_t_ns - 1)/emi_t_ns;
 	reg |= (n & 0xff) << 8;
 
-	DEBUG(MTD_DEBUG_LEVEL0, "%s: REN_TIMING = 0x%08x\n", NAME, reg);
-	flex_writereg(reg, NANDHAM_REN_TIMING);
+	*ren_timing = reg;
+}
+
+/* Derive timing register values from 'nand_timing_spec' data */
+static void flex_calc_timing_registers(struct nand_timing_spec *spec,
+				       int relax,
+				       uint32_t *ctl_timing,
+				       uint32_t *wen_timing,
+				       uint32_t *ren_timing)
+{
+	struct clk *emi_clk;
+	int tCLK;
+
+	int tMAX_HOLD;
+	int n_ctl_setup;
+	int n_ctl_hold;
+	int n_ctl_wb;
+
+	int tMAX_WEN_OFF;
+	int n_wen_on;
+	int n_wen_off;
+
+	int tMAX_REN_OFF;
+	int n_ren_on;
+	int n_ren_off;
+
+	/* Get EMI clock (default 100MHz) */
+	emi_clk = clk_get(NULL, "emi_clk");
+	if (!emi_clk || IS_ERR(emi_clk)) {
+		printk(KERN_WARNING NAME
+		       ": Failed to get EMI clock, assuming default 100MHz\n");
+		tCLK = 10;
+	} else {
+		tCLK = 1000000000 / clk_get_rate(emi_clk);
+	}
+
+	/*
+	 * CTL_TIMING
+	 */
+
+	/*	- SETUP */
+	n_ctl_setup = (spec->tCLS - spec->tWP + tCLK - 1)/tCLK;
+	if (n_ctl_setup < 1)
+		n_ctl_setup = 1;
+	n_ctl_setup += relax;
+
+	/*	- HOLD */
+	tMAX_HOLD = spec->tCLH;
+	if (spec->tCH > tMAX_HOLD)
+		tMAX_HOLD = spec->tCH;
+	if (spec->tALH > tMAX_HOLD)
+		tMAX_HOLD = spec->tALH;
+	if (spec->tDH > tMAX_HOLD)
+		tMAX_HOLD = spec->tDH;
+	n_ctl_hold = (tMAX_HOLD + tCLK - 1)/tCLK + relax;
+
+	/*	- CE_deassert_hold = 0 */
+
+	/*	- WE_high_to_RBn_low */
+	n_ctl_wb = (spec->tWB + tCLK - 1)/tCLK;
+
+	*ctl_timing = ((n_ctl_setup & 0xff) |
+		       (n_ctl_hold & 0xff) << 8 |
+		       (n_ctl_wb & 0xff) << 24);
+
+	/*
+	 * WEN_TIMING
+	 */
+
+	/*	- ON */
+	n_wen_on = (spec->tWH + tCLK - 1)/tCLK + relax;
+
+	/*	- OFF */
+	tMAX_WEN_OFF = spec->tWC - spec->tWH;
+	if (spec->tWP > tMAX_WEN_OFF)
+		tMAX_WEN_OFF = spec->tWP;
+	n_wen_off = (tMAX_WEN_OFF + tCLK - 1)/tCLK + relax;
+
+	*wen_timing = ((n_wen_on & 0xff) |
+		       (n_wen_off & 0xff) << 8);
+
+	/*
+	 * REN_TIMING
+	 */
+
+	/*	- ON */
+	n_ren_on = (spec->tREH + tCLK - 1)/tCLK + relax;
+
+	/*	- OFF */
+	tMAX_REN_OFF = spec->tRC - spec->tREH;
+	if (spec->tRP > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tRP;
+	if (spec->tREA > tMAX_REN_OFF)
+		tMAX_REN_OFF = spec->tREA;
+	n_ren_off = (tMAX_REN_OFF + tCLK - 1)/tCLK + 1 + relax;
+
+	*ren_timing = ((n_ren_on & 0xff) |
+		       (n_ren_off & 0xff) << 8);
+
 }
 
 /* FLEX mode chip select: For now we only support 1 chip per
@@ -868,9 +933,17 @@
 		flex->current_csn = data->csn;
 		flex_writereg(0x1 << data->csn, NANDHAM_FLEX_MUXCTRL);
 
-		/* Set up timing parameters */
-		flex_set_timings(flex, data->timing_data);
-
+		/* Configure timing registers */
+		if (data->ctl_timing) {
+			pr_debug("Updating timing configuration "
+				 "[0x%08x, 0x%08x, 0x%08x]\n",
+				 data->ctl_timing,
+				 data->wen_timing,
+				 data->ren_timing);
+			flex_writereg(data->ctl_timing, NANDHAM_CTL_TIMING);
+			flex_writereg(data->wen_timing, NANDHAM_WEN_TIMING);
+			flex_writereg(data->ren_timing, NANDHAM_REN_TIMING);
+		}
 	} else {
 		printk(KERN_ERR NAME ": attempt to select chipnr = %d\n",
 		       chipnr);
@@ -912,8 +985,33 @@
 }
 #endif /* CONFIG_MTD_DEBUG */
 
-static struct stm_nand_flex_controller * __init
-flex_init_controller(struct platform_device *pdev)
+void flex_init_controller(struct stm_nand_flex_controller *flex)
+{
+	/* Disable boot_not_flex */
+	flex_writereg(0x00000000, NANDHAM_BOOTBANK_CFG);
+
+	/* Reset FLEX Controller */
+	flex_writereg((0x1 << 3), NANDHAM_FLEXMODE_CFG);
+	udelay(1);
+	flex_writereg(0x00, NANDHAM_FLEXMODE_CFG);
+
+	/* Set Controller to FLEX mode */
+	flex_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
+
+	/* Not using interrupts in FLEX mode */
+	flex_writereg(0x00, NANDHAM_INT_EN);
+
+	/* To fit with MTD framework, configure FLEX_DATA reg for 1-byte
+	 * read/writes, and deassert CSn
+	 */
+	flex_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		      NANDHAM_FLEX_DATAWRITE_CONFIG);
+	flex_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
+		      NANDHAM_FLEX_DATAREAD_CONFIG);
+}
+
+static struct stm_nand_flex_controller * __devinit
+flex_init_resources(struct platform_device *pdev)
 {
 	struct stm_plat_nand_flex_data *pdata = pdev->dev.platform_data;
 	struct resource *resource;
@@ -975,37 +1073,18 @@
 		goto out4;
 	}
 
-	flex->current_csn = -1;
-
 	/* Initialise 'controller' structure */
 	spin_lock_init(&flex->hwcontrol.lock);
 	init_waitqueue_head(&flex->hwcontrol.wq);
 
-	/* Disable boot_not_flex */
-	flex_writereg(0x00000000, NANDHAM_BOOTBANK_CFG);
-
-	/* Reset FLEX Controller */
-	flex_writereg((0x1 << 3), NANDHAM_FLEXMODE_CFG);
-	udelay(1);
-	flex_writereg(0x00, NANDHAM_FLEXMODE_CFG);
-
-	/* Set Controller to FLEX mode */
-	flex_writereg(0x00000001, NANDHAM_FLEXMODE_CFG);
-
-	/* Not using interrupts in FLEX mode */
-	flex_writereg(0x00, NANDHAM_INT_EN);
+	flex->current_csn = -1;
 
-	/* To fit with MTD framework, configure FLEX_DATA reg for 1-byte
-	 * read/writes, and deassert CSn
-	 */
-	flex_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
-		      NANDHAM_FLEX_DATAWRITE_CONFIG);
-	flex_writereg(FLEX_DATA_CFG_BEATS_1 | FLEX_DATA_CFG_CSN,
-		      NANDHAM_FLEX_DATAREAD_CONFIG);
+	flex_init_controller(flex);
 
 #ifdef CONFIG_MTD_DEBUG
 	flex_print_regs(flex);
 #endif
+	platform_set_drvdata(pdev, flex);
 
 	return flex;
  out4:
@@ -1017,32 +1096,38 @@
  out2:
 	release_resource(flex->mem_region);
  out1:
+	kfree(flex);
+
 	return ERR_PTR(res);
 }
 
-static void __devexit flex_exit_controller(struct platform_device *pdev)
+static void flex_exit_controller(struct platform_device *pdev)
 {
 	struct stm_nand_flex_controller *flex = platform_get_drvdata(pdev);
 
+	platform_set_drvdata(pdev, NULL);
+
 	kfree(flex->buf);
 	iounmap(flex->base_addr);
 #ifdef CONFIG_STM_NAND_FLEX_CACHED
 	iounmap(flex->data_cached);
 #endif
 	release_resource(flex->mem_region);
+
+	kfree(flex);
 }
 
-static struct stm_nand_flex_device * __init
+static struct stm_nand_flex_device * __devinit
 flex_init_bank(struct stm_nand_flex_controller *flex,
 	       struct stm_nand_bank_data *bank,
-	       int rbn_connected, const char *name)
+	       int rbn_connected, struct platform_device *pdev)
 {
 	struct stm_nand_flex_device *data;
 	int res;
 
 #ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
 	struct mtd_info *slave;
-	struct mtd_part *part;
+	uint64_t slave_offset;
 	char *boot_part_name;
 #endif
 
@@ -1059,28 +1144,22 @@
 	data->chip.priv = data;
 	data->mtd.priv = &data->chip;
 	data->mtd.owner = THIS_MODULE;
+	data->mtd.dev.parent = &pdev->dev;
 
 	/* Assign more sensible name (default is string from nand_ids.c!) */
-	data->mtd.name = name;
+	data->mtd.name = dev_name(&pdev->dev);
 	data->csn = bank->csn;
 
 	/* Use hwcontrol structure to manage access to FLEX Controller */
 	data->chip.controller = &flex->hwcontrol;
 	data->chip.state = FL_READY;
 
-	/* Get chip's timing data */
-	data->timing_data = bank->timing_data;
-
 	/* Copy over chip specific platform data */
-	data->chip.chip_delay = data->timing_data->chip_delay;
 	data->chip.options = bank->options;
 	data->chip.options |= NAND_NO_AUTOINCR;      /* Not tested, disable */
 
-#ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
-	/* Handle STM H/W ECC layouts when performing initial scan for
-	 * bad-blocks */
-	data->chip.scan_bbt = scan_bbt_stmecc;
-#endif
+	data->chip.scan_bbt = stmnand_scan_bbt;
+
 	/* Callbacks for FLEX mode operation */
 	data->chip.cmd_ctrl = flex_cmd_ctrl;
 	data->chip.select_chip = flex_select_chip;
@@ -1096,6 +1175,9 @@
 	if (rbn_connected)
 		data->chip.dev_ready = flex_rbn;
 
+	/* Safe default chip_delay */
+	data->chip.chip_delay = 50;
+
 	/* For now, use NAND_ECC_SOFT. Callbacks filled in during scan() */
 	data->chip.ecc.mode = NAND_ECC_SOFT;
 
@@ -1109,13 +1191,71 @@
 	memset(flex->base_addr + NANDHAM_AFM_SEQUENCE_REG_1, 0, 32);
 #endif
 
-	/* Scan to find existance of the device */
-	if (nand_scan(&data->mtd, 1)) {
-		printk(KERN_ERR NAME ":nand_scan failed\n");
+	/* Scan to find existence of device */
+	if (nand_scan_ident(&data->mtd, 1) != 0) {
+		res = -ENODEV;
+		goto out2;
+	}
+
+	/*
+	 * Configure timing registers
+	 */
+	if (bank->timing_spec) {
+		printk(KERN_INFO NAME ": Using platform timing data\n");
+		flex_calc_timing_registers(bank->timing_spec,
+					   bank->timing_relax,
+					   &data->ctl_timing,
+					   &data->wen_timing,
+					   &data->ren_timing);
+		data->chip.chip_delay = bank->timing_spec->tR;
+	} else if (bank->timing_data) {
+		printk(KERN_INFO NAME ": Using legacy platform timing data\n");
+		flex_calc_timing_registers_legacy(bank->timing_data,
+						  &data->ctl_timing,
+						  &data->wen_timing,
+						  &data->ren_timing);
+		data->chip.chip_delay = bank->timing_data->chip_delay;
+	} else if (data->chip.onfi_version) {
+		struct nand_onfi_params *onfi = &data->chip.onfi_params;
+		int mode;
+
+		mode = fls(le16_to_cpu(onfi->async_timing_mode)) - 1;
+		/* Modes 4 and 5 (EDO) are not supported on our H/W */
+		if (mode > 3)
+			mode = 3;
+
+		printk(KERN_INFO NAME ": Using ONFI Timing Mode %d\n", mode);
+		flex_calc_timing_registers(&nand_onfi_timing_specs[mode],
+					   bank->timing_relax,
+					   &data->ctl_timing,
+					   &data->wen_timing,
+					   &data->ren_timing);
+		data->chip.chip_delay = le16_to_cpu(data->chip.onfi_params.t_r);
+	} else {
+		printk(KERN_WARNING NAME ": No timing data available\n");
+	}
+
+	/* Ensure 'complete' chip-specific configuration on next select_chip()
+	 * activation */
+	flex->current_csn = -1;
+
+	/* Complete scan */
+	if (nand_scan_tail(&data->mtd) != 0) {
 		res = -ENXIO;
 		goto out2;
 	}
 
+	/* If all blocks are marked bad, mount as "recovery" partition */
+	if (stmnand_blocks_all_bad(&data->mtd)) {
+		printk(KERN_ERR NAME ": initiating NAND Recovery Mode\n");
+		data->mtd.name = "NAND RECOVERY MODE";
+		res = add_mtd_device(&data->mtd);
+		if (res)
+			goto out2;
+
+		return data;
+	}
+
 #ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
 	if (data->chip.ecc.mode == NAND_ECC_4BITONDIE) {
 		printk(KERN_ERR NAME ": boot-mode ECC not supported on "
@@ -1133,9 +1273,10 @@
 	data->mtd.write_oob = nand_write_oob;
 
 	/* Set name of boot partition */
-	boot_part_name = cmdline ? cmdline : CONFIG_STM_NAND_FLEX_BOOTPARTITION;
+	boot_part_name = nbootpart ? nbootpart :
+		CONFIG_STM_NAND_FLEX_BOOTPARTITION;
 	printk(KERN_INFO NAME ": Using boot partition name [%s] (from %s)\n",
-	       boot_part_name, cmdline ? "command line" : "kernel config");
+	       boot_part_name, nbootpart ? "command line" : "kernel config");
 
 #endif
 
@@ -1159,15 +1300,15 @@
 
 #ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
 		/* Update boot-mode slave partition */
-		slave = get_mtd_partition_slave(&data->mtd, boot_part_name);
+		slave = get_mtd_partition_slave(&data->mtd, boot_part_name,
+						&slave_offset);
 		if (slave) {
 			printk(KERN_INFO NAME ": Found BOOT parition"
 			       "[%s], updating ECC paramters\n",
 			       slave->name);
 
-			part = PART(slave);
-			data->boot_start = part->offset;
-			data->boot_end = part->offset + slave->size;
+			data->boot_start = slave_offset;
+			data->boot_end = slave_offset + slave->size;
 
 			slave->oobavail =
 				data->ecc_boot.ecc_ctrl.layout->oobavail;
@@ -1203,32 +1344,48 @@
 	return ERR_PTR(res);
 }
 
-static int __init stm_nand_flex_probe(struct platform_device *pdev)
+static int __devinit stm_nand_flex_probe(struct platform_device *pdev)
 {
 	struct stm_plat_nand_flex_data *pdata = pdev->dev.platform_data;
-	int res;
-	int n;
 	struct stm_nand_bank_data *bank;
 	struct stm_nand_flex_controller *flex;
+	struct stm_nand_flex_device *data;
+	int err;
+	int n;
 
-	flex = flex_init_controller(pdev);
+	flex = flex_init_resources(pdev);
 	if (IS_ERR(flex)) {
 		dev_err(&pdev->dev, "Failed to initialise NAND Controller.\n");
-		res = PTR_ERR(flex);
-		return res;
+		err = PTR_ERR(flex);
+		return err;
 	}
 
 	bank = pdata->banks;
 	for (n=0; n<pdata->nr_banks; n++) {
-		flex->devices[n] = flex_init_bank(flex, bank,
-						  pdata->flex_rbn_connected,
-						  dev_name(&pdev->dev));
+		data = flex_init_bank(flex, bank, pdata->flex_rbn_connected,
+				      pdev);
+
+		if (IS_ERR(data)) {
+			err = PTR_ERR(data);
+			goto err1;
+		}
+
+		flex->devices[n] = data;
 		bank++;
 	}
 
-	platform_set_drvdata(pdev, flex);
-
 	return 0;
+
+ err1:
+	while (--n > 0) {
+		data = flex->devices[n];
+		nand_release(&data->mtd);
+		kfree(data);
+	}
+
+	flex_exit_controller(pdev);
+
+	return err;
 }
 
 static int __devexit stm_nand_flex_remove(struct platform_device *pdev)
@@ -1237,7 +1394,7 @@
 	struct stm_nand_flex_controller *flex = platform_get_drvdata(pdev);
 	int n;
 
-	for (n=0; n<pdata->nr_banks; n++) {
+	for (n = 0; n < pdata->nr_banks; n++) {
 		struct stm_nand_flex_device *data = flex->devices[n];
 		nand_release(&data->mtd);
 
@@ -1251,30 +1408,37 @@
 
 	flex_exit_controller(pdev);
 
-	platform_set_drvdata(pdev, NULL);
+	return 0;
+}
+
+#ifdef CONFIG_HIBERNATION
+static int stm_nand_flex_restore(struct device *dev)
+{
+	struct stm_nand_flex_controller *flex = dev_get_drvdata(dev);
+
+	flex->current_csn = -1;
+	flex_init_controller(flex);
 
 	return 0;
 }
 
+static struct dev_pm_ops stm_nand_flex_pm = {
+	.restore = stm_nand_flex_restore,
+};
+#else
+static struct dev_pm_ops stm_nand_flex_pm;
+#endif
+
 static struct platform_driver stm_nand_flex_driver = {
 	.probe		= stm_nand_flex_probe,
 	.remove		= stm_nand_flex_remove,
 	.driver		= {
 		.name	= NAME,
 		.owner	= THIS_MODULE,
+		.pm	= &stm_nand_flex_pm,
 	},
 };
 
-#ifdef CONFIG_STM_NAND_FLEX_BOOTMODESUPPORT
-static int __init bootpart_setup(char *s)
-{
-	cmdline = s;
-	return 1;
-}
-
-__setup("nbootpart=", bootpart_setup);
-#endif
-
 static int __init stm_nand_flex_init(void)
 {
 	return platform_driver_register(&stm_nand_flex_driver);
diff -Naur a/drivers/mtd/tests/mtd_readtest.c b/drivers/mtd/tests/mtd_readtest.c
--- a/drivers/mtd/tests/mtd_readtest.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mtd/tests/mtd_readtest.c	2013-11-01 18:44:50.977823997 +0200
@@ -147,6 +147,10 @@
 	}
 	memset(bbt, 0 , ebcnt);
 
+	/* NOR flash does not implement block_isbad */
+	if (mtd->block_isbad == NULL)
+		return 0;
+
 	printk(PRINT_PREF "scanning for bad eraseblocks\n");
 	for (i = 0; i < ebcnt; ++i) {
 		bbt[i] = is_block_bad(i) ? 1 : 0;
@@ -184,7 +188,7 @@
 	tmp = mtd->size;
 	do_div(tmp, mtd->erasesize);
 	ebcnt = tmp;
-	pgcnt = mtd->erasesize / mtd->writesize;
+	pgcnt = mtd->erasesize / pgsize;
 
 	printk(PRINT_PREF "MTD device size %llu, eraseblock size %u, "
 	       "page size %u, count of eraseblocks %u, pages per "
diff -Naur a/drivers/mtd/tests/mtd_speedtest.c b/drivers/mtd/tests/mtd_speedtest.c
--- a/drivers/mtd/tests/mtd_speedtest.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mtd/tests/mtd_speedtest.c	2013-11-01 18:44:50.977823997 +0200
@@ -301,6 +301,10 @@
 	}
 	memset(bbt, 0 , ebcnt);
 
+	/* NOR flash does not implement block_isbad */
+	if (mtd->block_isbad == NULL)
+		goto out;
+
 	printk(PRINT_PREF "scanning for bad eraseblocks\n");
 	for (i = 0; i < ebcnt; ++i) {
 		bbt[i] = is_block_bad(i) ? 1 : 0;
@@ -309,6 +313,7 @@
 		cond_resched();
 	}
 	printk(PRINT_PREF "scanned %d eraseblocks, %d are bad\n", i, bad);
+out:
 	goodebcnt = ebcnt - bad;
 	return 0;
 }
@@ -340,7 +345,7 @@
 	tmp = mtd->size;
 	do_div(tmp, mtd->erasesize);
 	ebcnt = tmp;
-	pgcnt = mtd->erasesize / mtd->writesize;
+	pgcnt = mtd->erasesize / pgsize;
 
 	printk(PRINT_PREF "MTD device size %llu, eraseblock size %u, "
 	       "page size %u, count of eraseblocks %u, pages per "
diff -Naur a/drivers/mtd/tests/mtd_stresstest.c b/drivers/mtd/tests/mtd_stresstest.c
--- a/drivers/mtd/tests/mtd_stresstest.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/mtd/tests/mtd_stresstest.c	2013-11-01 18:44:50.977823997 +0200
@@ -227,6 +227,10 @@
 	}
 	memset(bbt, 0 , ebcnt);
 
+	/* NOR flash does not implement block_isbad */
+	if (mtd->block_isbad == NULL)
+		return 0;
+
 	printk(PRINT_PREF "scanning for bad eraseblocks\n");
 	for (i = 0; i < ebcnt; ++i) {
 		bbt[i] = is_block_bad(i) ? 1 : 0;
@@ -265,7 +269,7 @@
 	tmp = mtd->size;
 	do_div(tmp, mtd->erasesize);
 	ebcnt = tmp;
-	pgcnt = mtd->erasesize / mtd->writesize;
+	pgcnt = mtd->erasesize / pgsize;
 
 	printk(PRINT_PREF "MTD device size %llu, eraseblock size %u, "
 	       "page size %u, count of eraseblocks %u, pages per "
diff -Naur a/drivers/net/atlx/atl1.c b/drivers/net/atlx/atl1.c
--- a/drivers/net/atlx/atl1.c	2013-11-01 20:18:04.221559388 +0200
+++ b/drivers/net/atlx/atl1.c	2013-11-01 18:44:51.049824348 +0200
@@ -2478,7 +2478,7 @@
 					"pcie phy link down %x\n", status);
 			if (netif_running(adapter->netdev)) {	/* reset MAC */
 				iowrite32(0, adapter->hw.hw_addr + REG_IMR);
-				schedule_work(&adapter->pcie_dma_to_rst_task);
+				schedule_work(&adapter->reset_dev_task);
 				return IRQ_HANDLED;
 			}
 		}
@@ -2490,7 +2490,7 @@
 					"pcie DMA r/w error (status = 0x%x)\n",
 					status);
 			iowrite32(0, adapter->hw.hw_addr + REG_IMR);
-			schedule_work(&adapter->pcie_dma_to_rst_task);
+			schedule_work(&adapter->reset_dev_task);
 			return IRQ_HANDLED;
 		}
 
@@ -2635,10 +2635,10 @@
 	atl1_clean_rx_ring(adapter);
 }
 
-static void atl1_tx_timeout_task(struct work_struct *work)
+static void atl1_reset_dev_task(struct work_struct *work)
 {
 	struct atl1_adapter *adapter =
-		container_of(work, struct atl1_adapter, tx_timeout_task);
+		container_of(work, struct atl1_adapter, reset_dev_task);
 	struct net_device *netdev = adapter->netdev;
 
 	netif_device_detach(netdev);
@@ -3050,12 +3050,10 @@
 		    (unsigned long)adapter);
 	adapter->phy_timer_pending = false;
 
-	INIT_WORK(&adapter->tx_timeout_task, atl1_tx_timeout_task);
+	INIT_WORK(&adapter->reset_dev_task, atl1_reset_dev_task);
 
 	INIT_WORK(&adapter->link_chg_task, atlx_link_chg_task);
 
-	INIT_WORK(&adapter->pcie_dma_to_rst_task, atl1_tx_timeout_task);
-
 	err = register_netdev(netdev);
 	if (err)
 		goto err_common;
diff -Naur a/drivers/net/atlx/atl1.h b/drivers/net/atlx/atl1.h
--- a/drivers/net/atlx/atl1.h	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/atlx/atl1.h	2013-11-01 18:44:51.049824348 +0200
@@ -762,9 +762,8 @@
 	u16 link_speed;
 	u16 link_duplex;
 	spinlock_t lock;
-	struct work_struct tx_timeout_task;
+	struct work_struct reset_dev_task;
 	struct work_struct link_chg_task;
-	struct work_struct pcie_dma_to_rst_task;
 
 	struct timer_list phy_config_timer;
 	bool phy_timer_pending;
diff -Naur a/drivers/net/atlx/atlx.c b/drivers/net/atlx/atlx.c
--- a/drivers/net/atlx/atlx.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/atlx/atlx.c	2013-11-01 18:44:51.053824374 +0200
@@ -189,7 +189,7 @@
 {
 	struct atlx_adapter *adapter = netdev_priv(netdev);
 	/* Do the reset outside of interrupt context */
-	schedule_work(&adapter->tx_timeout_task);
+	schedule_work(&adapter->reset_dev_task);
 }
 
 /*
diff -Naur a/drivers/net/bonding/bond_3ad.c b/drivers/net/bonding/bond_3ad.c
--- a/drivers/net/bonding/bond_3ad.c	2013-11-01 20:18:04.253559551 +0200
+++ b/drivers/net/bonding/bond_3ad.c	2013-11-01 18:44:51.097824594 +0200
@@ -1471,8 +1471,11 @@
 
 static int agg_device_up(const struct aggregator *agg)
 {
-	return (netif_running(agg->slave->dev) &&
-		netif_carrier_ok(agg->slave->dev));
+	struct port *port = agg->lag_ports;
+	if (!port)
+		return 0;
+	return (netif_running(port->slave->dev) &&
+		netif_carrier_ok(port->slave->dev));
 }
 
 /**
diff -Naur a/drivers/net/bonding/bonding.h b/drivers/net/bonding/bonding.h
--- a/drivers/net/bonding/bonding.h	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/bonding/bonding.h	2013-11-01 18:44:51.105824624 +0200
@@ -236,11 +236,11 @@
 
 	bond_for_each_slave(bond, slave, i) {
 		if (slave->dev == slave_dev) {
-			break;
+			return slave;
 		}
 	}
 
-	return slave;
+	return 0;
 }
 
 static inline struct bonding *bond_get_bond_by_slave(struct slave *slave)
diff -Naur a/drivers/net/dl2k.c b/drivers/net/dl2k.c
--- a/drivers/net/dl2k.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/dl2k.c	2013-11-01 18:44:51.165824924 +0200
@@ -1279,55 +1279,21 @@
 {
 	int phy_addr;
 	struct netdev_private *np = netdev_priv(dev);
-	struct mii_data *miidata = (struct mii_data *) &rq->ifr_ifru;
-
-	struct netdev_desc *desc;
-	int i;
+	struct mii_ioctl_data *miidata = if_mii(rq);
 
 	phy_addr = np->phy_addr;
 	switch (cmd) {
-	case SIOCDEVPRIVATE:
-		break;
-
-	case SIOCDEVPRIVATE + 1:
-		miidata->out_value = mii_read (dev, phy_addr, miidata->reg_num);
-		break;
-	case SIOCDEVPRIVATE + 2:
-		mii_write (dev, phy_addr, miidata->reg_num, miidata->in_value);
-		break;
-	case SIOCDEVPRIVATE + 3:
+	case SIOCGMIIPHY:
+		miidata->phy_id = phy_addr;
 		break;
-	case SIOCDEVPRIVATE + 4:
+	case SIOCGMIIREG:
+		miidata->val_out = mii_read (dev, phy_addr, miidata->reg_num);
 		break;
-	case SIOCDEVPRIVATE + 5:
-		netif_stop_queue (dev);
+	case SIOCSMIIREG:
+		if (!capable(CAP_NET_ADMIN))
+			return -EPERM;
+		mii_write (dev, phy_addr, miidata->reg_num, miidata->val_in);
 		break;
-	case SIOCDEVPRIVATE + 6:
-		netif_wake_queue (dev);
-		break;
-	case SIOCDEVPRIVATE + 7:
-		printk
-		    ("tx_full=%x cur_tx=%lx old_tx=%lx cur_rx=%lx old_rx=%lx\n",
-		     netif_queue_stopped(dev), np->cur_tx, np->old_tx, np->cur_rx,
-		     np->old_rx);
-		break;
-	case SIOCDEVPRIVATE + 8:
-		printk("TX ring:\n");
-		for (i = 0; i < TX_RING_SIZE; i++) {
-			desc = &np->tx_ring[i];
-			printk
-			    ("%02x:cur:%08x next:%08x status:%08x frag1:%08x frag0:%08x",
-			     i,
-			     (u32) (np->tx_ring_dma + i * sizeof (*desc)),
-			     (u32)le64_to_cpu(desc->next_desc),
-			     (u32)le64_to_cpu(desc->status),
-			     (u32)(le64_to_cpu(desc->fraginfo) >> 32),
-			     (u32)le64_to_cpu(desc->fraginfo));
-			printk ("\n");
-		}
-		printk ("\n");
-		break;
-
 	default:
 		return -EOPNOTSUPP;
 	}
@@ -1448,7 +1414,7 @@
 
 	do {
 		bmsr = mii_read (dev, phy_addr, MII_BMSR);
-		if (bmsr & MII_BMSR_LINK_STATUS)
+		if (bmsr & BMSR_LSTATUS)
 			return 0;
 		mdelay (1);
 	} while (--wait > 0);
@@ -1469,60 +1435,60 @@
 
 	bmsr = mii_read (dev, phy_addr, MII_BMSR);
 	if (np->an_enable) {
-		if (!(bmsr & MII_BMSR_AN_COMPLETE)) {
+		if (!(bmsr & BMSR_ANEGCOMPLETE)) {
 			/* Auto-Negotiation not completed */
 			return -1;
 		}
-		negotiate = mii_read (dev, phy_addr, MII_ANAR) &
-			mii_read (dev, phy_addr, MII_ANLPAR);
-		mscr = mii_read (dev, phy_addr, MII_MSCR);
-		mssr = mii_read (dev, phy_addr, MII_MSSR);
-		if (mscr & MII_MSCR_1000BT_FD && mssr & MII_MSSR_LP_1000BT_FD) {
+		negotiate = mii_read (dev, phy_addr, MII_ADVERTISE) &
+			mii_read (dev, phy_addr, MII_LPA);
+		mscr = mii_read (dev, phy_addr, MII_CTRL1000);
+		mssr = mii_read (dev, phy_addr, MII_STAT1000);
+		if (mscr & ADVERTISE_1000FULL && mssr & LPA_1000FULL) {
 			np->speed = 1000;
 			np->full_duplex = 1;
 			printk (KERN_INFO "Auto 1000 Mbps, Full duplex\n");
-		} else if (mscr & MII_MSCR_1000BT_HD && mssr & MII_MSSR_LP_1000BT_HD) {
+		} else if (mscr & ADVERTISE_1000HALF && mssr & LPA_1000HALF) {
 			np->speed = 1000;
 			np->full_duplex = 0;
 			printk (KERN_INFO "Auto 1000 Mbps, Half duplex\n");
-		} else if (negotiate & MII_ANAR_100BX_FD) {
+		} else if (negotiate & ADVERTISE_100FULL) {
 			np->speed = 100;
 			np->full_duplex = 1;
 			printk (KERN_INFO "Auto 100 Mbps, Full duplex\n");
-		} else if (negotiate & MII_ANAR_100BX_HD) {
+		} else if (negotiate & ADVERTISE_100HALF) {
 			np->speed = 100;
 			np->full_duplex = 0;
 			printk (KERN_INFO "Auto 100 Mbps, Half duplex\n");
-		} else if (negotiate & MII_ANAR_10BT_FD) {
+		} else if (negotiate & ADVERTISE_10FULL) {
 			np->speed = 10;
 			np->full_duplex = 1;
 			printk (KERN_INFO "Auto 10 Mbps, Full duplex\n");
-		} else if (negotiate & MII_ANAR_10BT_HD) {
+		} else if (negotiate & ADVERTISE_10HALF) {
 			np->speed = 10;
 			np->full_duplex = 0;
 			printk (KERN_INFO "Auto 10 Mbps, Half duplex\n");
 		}
-		if (negotiate & MII_ANAR_PAUSE) {
+		if (negotiate & ADVERTISE_PAUSE_CAP) {
 			np->tx_flow &= 1;
 			np->rx_flow &= 1;
-		} else if (negotiate & MII_ANAR_ASYMMETRIC) {
+		} else if (negotiate & ADVERTISE_PAUSE_ASYM) {
 			np->tx_flow = 0;
 			np->rx_flow &= 1;
 		}
 		/* else tx_flow, rx_flow = user select  */
 	} else {
 		__u16 bmcr = mii_read (dev, phy_addr, MII_BMCR);
-		switch (bmcr & (MII_BMCR_SPEED_100 | MII_BMCR_SPEED_1000)) {
-		case MII_BMCR_SPEED_1000:
+		switch (bmcr & (BMCR_SPEED100 | BMCR_SPEED1000)) {
+		case BMCR_SPEED1000:
 			printk (KERN_INFO "Operating at 1000 Mbps, ");
 			break;
-		case MII_BMCR_SPEED_100:
+		case BMCR_SPEED100:
 			printk (KERN_INFO "Operating at 100 Mbps, ");
 			break;
 		case 0:
 			printk (KERN_INFO "Operating at 10 Mbps, ");
 		}
-		if (bmcr & MII_BMCR_DUPLEX_MODE) {
+		if (bmcr & BMCR_FULLDPLX) {
 			printk (KERN_CONT "Full duplex\n");
 		} else {
 			printk (KERN_CONT "Half duplex\n");
@@ -1556,24 +1522,22 @@
 	if (np->an_enable) {
 		/* Advertise capabilities */
 		bmsr = mii_read (dev, phy_addr, MII_BMSR);
-		anar = mii_read (dev, phy_addr, MII_ANAR) &
-			     ~MII_ANAR_100BX_FD &
-			     ~MII_ANAR_100BX_HD &
-			     ~MII_ANAR_100BT4 &
-			     ~MII_ANAR_10BT_FD &
-			     ~MII_ANAR_10BT_HD;
-		if (bmsr & MII_BMSR_100BX_FD)
-			anar |= MII_ANAR_100BX_FD;
-		if (bmsr & MII_BMSR_100BX_HD)
-			anar |= MII_ANAR_100BX_HD;
-		if (bmsr & MII_BMSR_100BT4)
-			anar |= MII_ANAR_100BT4;
-		if (bmsr & MII_BMSR_10BT_FD)
-			anar |= MII_ANAR_10BT_FD;
-		if (bmsr & MII_BMSR_10BT_HD)
-			anar |= MII_ANAR_10BT_HD;
-		anar |= MII_ANAR_PAUSE | MII_ANAR_ASYMMETRIC;
-		mii_write (dev, phy_addr, MII_ANAR, anar);
+		anar = mii_read (dev, phy_addr, MII_ADVERTISE) &
+			~(ADVERTISE_100FULL | ADVERTISE_10FULL |
+			  ADVERTISE_100HALF | ADVERTISE_10HALF |
+			  ADVERTISE_100BASE4);
+		if (bmsr & BMSR_100FULL)
+			anar |= ADVERTISE_100FULL;
+		if (bmsr & BMSR_100HALF)
+			anar |= ADVERTISE_100HALF;
+		if (bmsr & BMSR_100BASE4)
+			anar |= ADVERTISE_100BASE4;
+		if (bmsr & BMSR_10FULL)
+			anar |= ADVERTISE_10FULL;
+		if (bmsr & BMSR_10HALF)
+			anar |= ADVERTISE_10HALF;
+		anar |= ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM;
+		mii_write (dev, phy_addr, MII_ADVERTISE, anar);
 
 		/* Enable Auto crossover */
 		pscr = mii_read (dev, phy_addr, MII_PHY_SCR);
@@ -1581,8 +1545,8 @@
 		mii_write (dev, phy_addr, MII_PHY_SCR, pscr);
 
 		/* Soft reset PHY */
-		mii_write (dev, phy_addr, MII_BMCR, MII_BMCR_RESET);
-		bmcr = MII_BMCR_AN_ENABLE | MII_BMCR_RESTART_AN | MII_BMCR_RESET;
+		mii_write (dev, phy_addr, MII_BMCR, BMCR_RESET);
+		bmcr = BMCR_ANENABLE | BMCR_ANRESTART | BMCR_RESET;
 		mii_write (dev, phy_addr, MII_BMCR, bmcr);
 		mdelay(1);
 	} else {
@@ -1594,7 +1558,7 @@
 
 		/* 2) PHY Reset */
 		bmcr = mii_read (dev, phy_addr, MII_BMCR);
-		bmcr |= MII_BMCR_RESET;
+		bmcr |= BMCR_RESET;
 		mii_write (dev, phy_addr, MII_BMCR, bmcr);
 
 		/* 3) Power Down */
@@ -1603,25 +1567,25 @@
 		mdelay (100);	/* wait a certain time */
 
 		/* 4) Advertise nothing */
-		mii_write (dev, phy_addr, MII_ANAR, 0);
+		mii_write (dev, phy_addr, MII_ADVERTISE, 0);
 
 		/* 5) Set media and Power Up */
-		bmcr = MII_BMCR_POWER_DOWN;
+		bmcr = BMCR_PDOWN;
 		if (np->speed == 100) {
-			bmcr |= MII_BMCR_SPEED_100;
+			bmcr |= BMCR_SPEED100;
 			printk (KERN_INFO "Manual 100 Mbps, ");
 		} else if (np->speed == 10) {
 			printk (KERN_INFO "Manual 10 Mbps, ");
 		}
 		if (np->full_duplex) {
-			bmcr |= MII_BMCR_DUPLEX_MODE;
+			bmcr |= BMCR_FULLDPLX;
 			printk (KERN_CONT "Full duplex\n");
 		} else {
 			printk (KERN_CONT "Half duplex\n");
 		}
 #if 0
 		/* Set 1000BaseT Master/Slave setting */
-		mscr = mii_read (dev, phy_addr, MII_MSCR);
+		mscr = mii_read (dev, phy_addr, MII_CTRL1000);
 		mscr |= MII_MSCR_CFG_ENABLE;
 		mscr &= ~MII_MSCR_CFG_VALUE = 0;
 #endif
@@ -1644,7 +1608,7 @@
 
 	bmsr = mii_read (dev, phy_addr, PCS_BMSR);
 	if (np->an_enable) {
-		if (!(bmsr & MII_BMSR_AN_COMPLETE)) {
+		if (!(bmsr & BMSR_ANEGCOMPLETE)) {
 			/* Auto-Negotiation not completed */
 			return -1;
 		}
@@ -1669,7 +1633,7 @@
 	} else {
 		__u16 bmcr = mii_read (dev, phy_addr, PCS_BMCR);
 		printk (KERN_INFO "Operating at 1000 Mbps, ");
-		if (bmcr & MII_BMCR_DUPLEX_MODE) {
+		if (bmcr & BMCR_FULLDPLX) {
 			printk (KERN_CONT "Full duplex\n");
 		} else {
 			printk (KERN_CONT "Half duplex\n");
@@ -1702,7 +1666,7 @@
 	if (np->an_enable) {
 		/* Advertise capabilities */
 		esr = mii_read (dev, phy_addr, PCS_ESR);
-		anar = mii_read (dev, phy_addr, MII_ANAR) &
+		anar = mii_read (dev, phy_addr, MII_ADVERTISE) &
 			~PCS_ANAR_HALF_DUPLEX &
 			~PCS_ANAR_FULL_DUPLEX;
 		if (esr & (MII_ESR_1000BT_HD | MII_ESR_1000BX_HD))
@@ -1710,22 +1674,21 @@
 		if (esr & (MII_ESR_1000BT_FD | MII_ESR_1000BX_FD))
 			anar |= PCS_ANAR_FULL_DUPLEX;
 		anar |= PCS_ANAR_PAUSE | PCS_ANAR_ASYMMETRIC;
-		mii_write (dev, phy_addr, MII_ANAR, anar);
+		mii_write (dev, phy_addr, MII_ADVERTISE, anar);
 
 		/* Soft reset PHY */
-		mii_write (dev, phy_addr, MII_BMCR, MII_BMCR_RESET);
-		bmcr = MII_BMCR_AN_ENABLE | MII_BMCR_RESTART_AN |
-		       MII_BMCR_RESET;
+		mii_write (dev, phy_addr, MII_BMCR, BMCR_RESET);
+		bmcr = BMCR_ANENABLE | BMCR_ANRESTART | BMCR_RESET;
 		mii_write (dev, phy_addr, MII_BMCR, bmcr);
 		mdelay(1);
 	} else {
 		/* Force speed setting */
 		/* PHY Reset */
-		bmcr = MII_BMCR_RESET;
+		bmcr = BMCR_RESET;
 		mii_write (dev, phy_addr, MII_BMCR, bmcr);
 		mdelay(10);
 		if (np->full_duplex) {
-			bmcr = MII_BMCR_DUPLEX_MODE;
+			bmcr = BMCR_FULLDPLX;
 			printk (KERN_INFO "Manual full duplex\n");
 		} else {
 			bmcr = 0;
@@ -1735,7 +1698,7 @@
 		mdelay(10);
 
 		/*  Advertise nothing */
-		mii_write (dev, phy_addr, MII_ANAR, 0);
+		mii_write (dev, phy_addr, MII_ADVERTISE, 0);
 	}
 	return 0;
 }
diff -Naur a/drivers/net/dl2k.h b/drivers/net/dl2k.h
--- a/drivers/net/dl2k.h	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/dl2k.h	2013-11-01 18:44:51.165824924 +0200
@@ -28,6 +28,7 @@
 #include <linux/init.h>
 #include <linux/crc32.h>
 #include <linux/ethtool.h>
+#include <linux/mii.h>
 #include <linux/bitops.h>
 #include <asm/processor.h>	/* Processor type for cache alignment. */
 #include <asm/io.h>
@@ -271,20 +272,9 @@
 #define MII_RESET_TIME_OUT		10000
 /* MII register */
 enum _mii_reg {
-	MII_BMCR = 0,
-	MII_BMSR = 1,
-	MII_PHY_ID1 = 2,
-	MII_PHY_ID2 = 3,
-	MII_ANAR = 4,
-	MII_ANLPAR = 5,
-	MII_ANER = 6,
-	MII_ANNPT = 7,
-	MII_ANLPRNP = 8,
-	MII_MSCR = 9,
-	MII_MSSR = 10,
-	MII_ESR = 15,
 	MII_PHY_SCR = 16,
 };
+
 /* PCS register */
 enum _pcs_reg {
 	PCS_BMCR = 0,
@@ -297,102 +287,6 @@
 	PCS_ESR = 15,
 };
 
-/* Basic Mode Control Register */
-enum _mii_bmcr {
-	MII_BMCR_RESET = 0x8000,
-	MII_BMCR_LOOP_BACK = 0x4000,
-	MII_BMCR_SPEED_LSB = 0x2000,
-	MII_BMCR_AN_ENABLE = 0x1000,
-	MII_BMCR_POWER_DOWN = 0x0800,
-	MII_BMCR_ISOLATE = 0x0400,
-	MII_BMCR_RESTART_AN = 0x0200,
-	MII_BMCR_DUPLEX_MODE = 0x0100,
-	MII_BMCR_COL_TEST = 0x0080,
-	MII_BMCR_SPEED_MSB = 0x0040,
-	MII_BMCR_SPEED_RESERVED = 0x003f,
-	MII_BMCR_SPEED_10 = 0,
-	MII_BMCR_SPEED_100 = MII_BMCR_SPEED_LSB,
-	MII_BMCR_SPEED_1000 = MII_BMCR_SPEED_MSB,
-};
-
-/* Basic Mode Status Register */
-enum _mii_bmsr {
-	MII_BMSR_100BT4 = 0x8000,
-	MII_BMSR_100BX_FD = 0x4000,
-	MII_BMSR_100BX_HD = 0x2000,
-	MII_BMSR_10BT_FD = 0x1000,
-	MII_BMSR_10BT_HD = 0x0800,
-	MII_BMSR_100BT2_FD = 0x0400,
-	MII_BMSR_100BT2_HD = 0x0200,
-	MII_BMSR_EXT_STATUS = 0x0100,
-	MII_BMSR_PREAMBLE_SUPP = 0x0040,
-	MII_BMSR_AN_COMPLETE = 0x0020,
-	MII_BMSR_REMOTE_FAULT = 0x0010,
-	MII_BMSR_AN_ABILITY = 0x0008,
-	MII_BMSR_LINK_STATUS = 0x0004,
-	MII_BMSR_JABBER_DETECT = 0x0002,
-	MII_BMSR_EXT_CAP = 0x0001,
-};
-
-/* ANAR */
-enum _mii_anar {
-	MII_ANAR_NEXT_PAGE = 0x8000,
-	MII_ANAR_REMOTE_FAULT = 0x4000,
-	MII_ANAR_ASYMMETRIC = 0x0800,
-	MII_ANAR_PAUSE = 0x0400,
-	MII_ANAR_100BT4 = 0x0200,
-	MII_ANAR_100BX_FD = 0x0100,
-	MII_ANAR_100BX_HD = 0x0080,
-	MII_ANAR_10BT_FD = 0x0020,
-	MII_ANAR_10BT_HD = 0x0010,
-	MII_ANAR_SELECTOR = 0x001f,
-	MII_IEEE8023_CSMACD = 0x0001,
-};
-
-/* ANLPAR */
-enum _mii_anlpar {
-	MII_ANLPAR_NEXT_PAGE = MII_ANAR_NEXT_PAGE,
-	MII_ANLPAR_REMOTE_FAULT = MII_ANAR_REMOTE_FAULT,
-	MII_ANLPAR_ASYMMETRIC = MII_ANAR_ASYMMETRIC,
-	MII_ANLPAR_PAUSE = MII_ANAR_PAUSE,
-	MII_ANLPAR_100BT4 = MII_ANAR_100BT4,
-	MII_ANLPAR_100BX_FD = MII_ANAR_100BX_FD,
-	MII_ANLPAR_100BX_HD = MII_ANAR_100BX_HD,
-	MII_ANLPAR_10BT_FD = MII_ANAR_10BT_FD,
-	MII_ANLPAR_10BT_HD = MII_ANAR_10BT_HD,
-	MII_ANLPAR_SELECTOR = MII_ANAR_SELECTOR,
-};
-
-/* Auto-Negotiation Expansion Register */
-enum _mii_aner {
-	MII_ANER_PAR_DETECT_FAULT = 0x0010,
-	MII_ANER_LP_NEXTPAGABLE = 0x0008,
-	MII_ANER_NETXTPAGABLE = 0x0004,
-	MII_ANER_PAGE_RECEIVED = 0x0002,
-	MII_ANER_LP_NEGOTIABLE = 0x0001,
-};
-
-/* MASTER-SLAVE Control Register */
-enum _mii_mscr {
-	MII_MSCR_TEST_MODE = 0xe000,
-	MII_MSCR_CFG_ENABLE = 0x1000,
-	MII_MSCR_CFG_VALUE = 0x0800,
-	MII_MSCR_PORT_VALUE = 0x0400,
-	MII_MSCR_1000BT_FD = 0x0200,
-	MII_MSCR_1000BT_HD = 0X0100,
-};
-
-/* MASTER-SLAVE Status Register */
-enum _mii_mssr {
-	MII_MSSR_CFG_FAULT = 0x8000,
-	MII_MSSR_CFG_RES = 0x4000,
-	MII_MSSR_LOCAL_RCV_STATUS = 0x2000,
-	MII_MSSR_REMOTE_RCVR = 0x1000,
-	MII_MSSR_LP_1000BT_FD = 0x0800,
-	MII_MSSR_LP_1000BT_HD = 0x0400,
-	MII_MSSR_IDLE_ERR_COUNT = 0x00ff,
-};
-
 /* IEEE Extened Status Register */
 enum _mii_esr {
 	MII_ESR_1000BX_FD = 0x8000,
@@ -471,13 +365,6 @@
 	char *data;
 };
 
-struct mii_data {
-	__u16 reserved;
-	__u16 reg_num;
-	__u16 in_value;
-	__u16 out_value;
-};
-
 /* The Rx and Tx buffer descriptors. */
 struct netdev_desc {
 	__le64 next_desc;
diff -Naur a/drivers/net/ks8851_mll.c b/drivers/net/ks8851_mll.c
--- a/drivers/net/ks8851_mll.c	2013-11-01 20:18:04.357560070 +0200
+++ b/drivers/net/ks8851_mll.c	2013-11-01 18:44:51.353825863 +0200
@@ -35,7 +35,7 @@
 #define	DRV_NAME	"ks8851_mll"
 
 static u8 KS_DEFAULT_MAC_ADDRESS[] = { 0x00, 0x10, 0xA1, 0x86, 0x95, 0x11 };
-#define MAX_RECV_FRAMES			32
+#define MAX_RECV_FRAMES			255
 #define MAX_BUF_SIZE			2048
 #define TX_BUF_SIZE			2000
 #define RX_BUF_SIZE			2000
diff -Naur a/drivers/net/netxen/netxen_nic_ctx.c b/drivers/net/netxen/netxen_nic_ctx.c
--- a/drivers/net/netxen/netxen_nic_ctx.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/netxen/netxen_nic_ctx.c	2013-11-01 18:44:51.393826055 +0200
@@ -112,6 +112,21 @@
 	return 0;
 }
 
+int
+nx_fw_cmd_set_gbe_port(struct netxen_adapter *adapter,
+	u32 speed, u32 duplex, u32 autoneg)
+{
+
+	return netxen_issue_cmd(adapter,
+		adapter->ahw.pci_func,
+		NXHAL_VERSION,
+		speed,
+		duplex,
+		autoneg,
+		NX_CDRP_CMD_CONFIG_GBE_PORT);
+
+}
+
 static int
 nx_fw_cmd_create_rx_ctx(struct netxen_adapter *adapter)
 {
diff -Naur a/drivers/net/netxen/netxen_nic_ethtool.c b/drivers/net/netxen/netxen_nic_ethtool.c
--- a/drivers/net/netxen/netxen_nic_ethtool.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/netxen/netxen_nic_ethtool.c	2013-11-01 18:44:51.393826055 +0200
@@ -216,7 +216,6 @@
 			check_sfp_module = netif_running(dev) &&
 				adapter->has_link_events;
 		} else {
-			ecmd->autoneg = AUTONEG_ENABLE;
 			ecmd->supported |= (SUPPORTED_TP |SUPPORTED_Autoneg);
 			ecmd->advertising |=
 				(ADVERTISED_TP | ADVERTISED_Autoneg);
@@ -254,54 +253,25 @@
 netxen_nic_set_settings(struct net_device *dev, struct ethtool_cmd *ecmd)
 {
 	struct netxen_adapter *adapter = netdev_priv(dev);
-	__u32 status;
+	int ret;
 
-	/* read which mode */
-	if (adapter->ahw.port_type == NETXEN_NIC_GBE) {
-		/* autonegotiation */
-		if (adapter->phy_write
-		    && adapter->phy_write(adapter,
-					  NETXEN_NIU_GB_MII_MGMT_ADDR_AUTONEG,
-					  ecmd->autoneg) != 0)
-			return -EIO;
-		else
-			adapter->link_autoneg = ecmd->autoneg;
-
-		if (adapter->phy_read
-		    && adapter->phy_read(adapter,
-					 NETXEN_NIU_GB_MII_MGMT_ADDR_PHY_STATUS,
-					 &status) != 0)
-			return -EIO;
-
-		/* speed */
-		switch (ecmd->speed) {
-		case SPEED_10:
-			netxen_set_phy_speed(status, 0);
-			break;
-		case SPEED_100:
-			netxen_set_phy_speed(status, 1);
-			break;
-		case SPEED_1000:
-			netxen_set_phy_speed(status, 2);
-			break;
-		}
-		/* set duplex mode */
-		if (ecmd->duplex == DUPLEX_HALF)
-			netxen_clear_phy_duplex(status);
-		if (ecmd->duplex == DUPLEX_FULL)
-			netxen_set_phy_duplex(status);
-		if (adapter->phy_write
-		    && adapter->phy_write(adapter,
-					  NETXEN_NIU_GB_MII_MGMT_ADDR_PHY_STATUS,
-					  *((int *)&status)) != 0)
-			return -EIO;
-		else {
-			adapter->link_speed = ecmd->speed;
-			adapter->link_duplex = ecmd->duplex;
-		}
-	} else
+	if (adapter->ahw.port_type != NETXEN_NIC_GBE)
 		return -EOPNOTSUPP;
 
+	if (!(adapter->capabilities & NX_FW_CAPABILITY_GBE_LINK_CFG))
+		return -EOPNOTSUPP;
+
+	ret = nx_fw_cmd_set_gbe_port(adapter, ecmd->speed, ecmd->duplex,
+				     ecmd->autoneg);
+	if (ret == NX_RCODE_NOT_SUPPORTED)
+		return -EOPNOTSUPP;
+	else if (ret)
+		return -EIO;
+
+	adapter->link_speed = ecmd->speed;
+	adapter->link_duplex = ecmd->duplex;
+	adapter->link_autoneg = ecmd->autoneg;
+
 	if (!netif_running(dev))
 		return 0;
 
diff -Naur a/drivers/net/netxen/netxen_nic.h b/drivers/net/netxen/netxen_nic.h
--- a/drivers/net/netxen/netxen_nic.h	2013-11-01 20:18:04.365560103 +0200
+++ b/drivers/net/netxen/netxen_nic.h	2013-11-01 18:44:51.393826055 +0200
@@ -700,7 +700,8 @@
 #define NX_CDRP_CMD_READ_PEXQ_PARAMETERS	0x0000001c
 #define NX_CDRP_CMD_GET_LIC_CAPABILITIES	0x0000001d
 #define NX_CDRP_CMD_READ_MAX_LRO_PER_BOARD	0x0000001e
-#define NX_CDRP_CMD_MAX				0x0000001f
+#define NX_CDRP_CMD_CONFIG_GBE_PORT		0x0000001f
+#define NX_CDRP_CMD_MAX				0x00000020
 
 #define NX_RCODE_SUCCESS		0
 #define NX_RCODE_NO_HOST_MEM		1
@@ -1015,6 +1016,7 @@
 #define NX_FW_CAPABILITY_BDG			(1 << 8)
 #define NX_FW_CAPABILITY_FVLANTX		(1 << 9)
 #define NX_FW_CAPABILITY_HW_LRO			(1 << 10)
+#define NX_FW_CAPABILITY_GBE_LINK_CFG		(1 << 11)
 
 /* module types */
 #define LINKEVENT_MODULE_NOT_PRESENT			1
@@ -1323,6 +1325,9 @@
 int netxen_linkevent_request(struct netxen_adapter *adapter, int enable);
 void netxen_advert_link_change(struct netxen_adapter *adapter, int linkup);
 
+int nx_fw_cmd_set_gbe_port(struct netxen_adapter *adapter,
+		u32 speed, u32 duplex, u32 autoneg);
+
 int nx_fw_cmd_set_mtu(struct netxen_adapter *adapter, int mtu);
 int netxen_nic_change_mtu(struct net_device *netdev, int new_mtu);
 int netxen_config_hw_lro(struct netxen_adapter *adapter, int enable);
diff -Naur a/drivers/net/phy/icplus.c b/drivers/net/phy/icplus.c
--- a/drivers/net/phy/icplus.c	2013-11-01 20:19:18.793929174 +0200
+++ b/drivers/net/phy/icplus.c	2013-11-01 18:44:51.429826240 +0200
@@ -44,6 +44,44 @@
 #define IP101A_IRQ_CONF_STATUS		0x11	/* Conf Info IRQ & Status Reg */
 #define	IP101A_IRQ_PIN_USED		(1<<15)
 #define	IP101A_IRQ_DEFAULT		IP101A_IRQ_PIN_USED
+#define IP101A_G_WOL_CTRL		0x10	/* WoL+ Control Register */
+#define IP101A_G_WOL_MAC_ADDR		0x10	/* WoL+ MAC addr Register */
+#define IP101A_G_WOL_STATUS		0x11	/* WoL+ Status Register */
+
+/* WOL PLUS register definitions */
+#define IP101A_G_WOL_ENABLE		(1 << 15)
+#define IP101A_G_WOL_MASTER		(1 << 14)
+#define IP101A_G_WOL_INTH		(1 << 13)
+#define IP101A_G_WOL_MAGIC_PKT		(1 << 11)
+#define IP101A_G_WOL_ANY_PKT 		(1 << 10)
+#define IP101A_G_WOL_LINK_CHANGE	(1 << 9)
+#define IP101A_G_WOL_DOWN_SPEED		(1 << 8)
+#define IP101A_G_WOL_TIMER_SEL_30S	(0 << 6)
+#define IP101A_G_WOL_TIMER_SEL_3M	(1 << 6)
+#define IP101A_G_WOL_TIMER_SEL_5M	(2 << 6)
+#define IP101A_G_WOL_TIMER_SEL_10M	(3 << 6)
+#define IP101A_G_WOL_MANUAL_SET		(1 << 5)
+#define IP101A_G_WOL_TIMER_SEL_30SEC	0xff3f	/* 30 sec. */
+#define IP101A_G_WOL_TIMER_SEL_3MIN	0x0040	/* 3 min. */
+#define IP101A_G_WOL_TIMER_SEL_5MIN	0x0080	/* 5 min. */
+#define IP101A_G_WOL_TIMER_SEL_10MIN	0x00c0	/* 10 min. */
+
+/* After 3min the PHY can enter in WoL+ mode and the link is 10M
+ * it resumes by default as soon as the link change or there is
+ * traffic on the wire.
+ */
+#define	IP101A_G_DEFAULT_WOL	(IP101A_G_WOL_ENABLE | IP101A_G_WOL_MASTER | \
+				 IP101A_G_WOL_ANY_PKT	|	\
+				 IP101A_G_WOL_LINK_CHANGE |	\
+				 IP101A_G_WOL_DOWN_SPEED |	\
+				 IP101A_G_WOL_TIMER_SEL_3MIN)
+#undef ICPLUS_DEBUG
+/*#define ICPLUS_DEBUG*/
+#ifdef ICPLUS_DEBUG
+#define DBG(fmt, args...)  printk(fmt, ## args)
+#else
+#define DBG(fmt, args...)  do { } while (0)
+#endif
 
 static int ip175c_config_init(struct phy_device *phydev)
 {
@@ -142,6 +180,132 @@
 	return 0;
 }
 
+static int ip101a_g_down_speed(struct phy_device *phydev, int down_speed)
+{
+	int reg = phy_read_page(phydev, IP101A_G_WOL_CTRL, 4);
+	if (reg < 0)
+		return reg;
+
+	if (down_speed)
+		reg |= IP101A_G_WOL_DOWN_SPEED;
+	else
+		reg &= ~IP101A_G_WOL_DOWN_SPEED;
+
+	return phy_write_page(phydev, IP101A_G_WOL_CTRL, 4, reg);
+}
+
+static int ip101a_g_set_mode(struct phy_device *phydev, int mode)
+{
+	int reg = phy_read_page(phydev, IP101A_G_WOL_CTRL, 4);
+	if (reg < 0)
+		return reg;
+
+	DBG("IC+101A/G set %s mode timer\n", mode ? "master" : "slave");
+	if (mode)
+		reg |= IP101A_G_WOL_MASTER;
+	else
+		reg &= ~IP101A_G_WOL_MASTER;
+
+	reg &= IP101A_G_WOL_TIMER_SEL_30SEC;
+
+	return phy_write_page(phydev, IP101A_G_WOL_CTRL, 4, reg);
+}
+
+static int ip101a_g_set_macaddr(struct phy_device *phydev)
+{
+	struct net_device *netdev = phydev->attached_dev;
+	int old = phy_read(phydev, 20);
+
+	if (!netdev)
+		return -ENODEV;
+
+	/* Supposing at this stage the parent has a valid dev_addr;
+	 * so do not perform any extra check.
+	 */
+	if (!is_valid_ether_addr(netdev->dev_addr))
+		return -EINVAL;
+
+	phy_write(phydev, 20, 5);
+	phy_write(phydev, IP101A_G_WOL_MAC_ADDR,
+		  netdev->dev_addr[0] << 8 | netdev->dev_addr[1]);
+	phy_write(phydev, IP101A_G_WOL_MAC_ADDR,
+		  netdev->dev_addr[2] << 8 | netdev->dev_addr[3]);
+	phy_write(phydev, IP101A_G_WOL_MAC_ADDR,
+		  netdev->dev_addr[4] << 8 | netdev->dev_addr[5]);
+
+	phy_write(phydev, 20, old);
+	return 0;
+}
+
+static int ip101a_g_set_wol(struct phy_device *phydev)
+{
+	int wol_mode = phydev->wol;
+	int value;
+
+	value = phy_read_page(phydev, IP101A_G_WOL_CTRL, 4);
+	if (value < 0)
+		return value;
+
+	value &= ~(IP101A_G_WOL_MAGIC_PKT | IP101A_G_WOL_ANY_PKT |
+		 IP101A_G_WOL_LINK_CHANGE);
+
+	if (wol_mode & WAKE_MAGIC) {
+		int ret;
+
+		ret = ip101a_g_set_macaddr(phydev);
+		if (ret)
+			return ret;
+
+		value |= IP101A_G_WOL_MAGIC_PKT;
+	}
+
+	if (wol_mode & WAKE_UCAST)
+		value |= IP101A_G_WOL_ANY_PKT;
+
+	value |= IP101A_G_WOL_LINK_CHANGE | IP101A_G_WOL_ENABLE;
+
+	phy_write_page(phydev, IP101A_G_WOL_CTRL, 4, value);
+
+	DBG("IC+101A/G WoL+ crtl register 0x%x\n",
+	    phy_read_page(phydev, IP101A_G_WOL_CTRL, 4));
+
+	pr_info("IC+101a/g: wait for entering in WoL+ mode...\n");
+	mdelay(30000);
+
+	return 0;
+}
+
+int ip101a_g_suspend(struct phy_device *phydev)
+{
+	if (device_may_wakeup(&phydev->dev)) {
+		int ret;
+
+		/* Set Master mode and disable speed down feature (not usable
+		 * when suspend).
+		 */
+		ret = ip101a_g_down_speed(phydev, 1);
+		if (ret)
+			return ret;
+		ret = ip101a_g_set_mode(phydev, 1);
+		if (ret)
+			return ret;
+
+		return ip101a_g_set_wol(phydev);
+	} else
+		return genphy_suspend(phydev);
+}
+
+int ip101a_g_resume(struct phy_device *phydev)
+{
+	if (device_may_wakeup(&phydev->dev)) {
+		/* Restore the default WoL+ settings */
+		phy_write_page(phydev, IP101A_G_WOL_CTRL, 4,
+			       IP101A_G_DEFAULT_WOL);
+		return 0;
+	}
+	return genphy_resume(phydev);
+}
+
 static int ip101a_config_init(struct phy_device *phydev)
 {
 	int c;
@@ -154,10 +318,16 @@
 	if (c < 0)
 		return c;
 
-	/* Enable Auto Power Saving mode */
+	/* Set the WoL+ with the default configuration */
+	phy_write_page(phydev, IP101A_G_WOL_CTRL, 4, IP101A_G_DEFAULT_WOL);
+	DBG("IC+101A/G WoL+ crtl register 0x%x\n",
+	    phy_read_page(phydev, IP101A_G_WOL_CTRL, 4));
+
 	c = phy_read(phydev, IP10XX_SPEC_CTRL_STATUS);
 	if (c < 0)
 		return c;
+
+	/* Enable Auto Power Saving mode */
 	c |= IP101A_APS_ON;
 	c = phy_write(phydev, IP10XX_SPEC_CTRL_STATUS, c);
 	if (c < 0)
@@ -187,9 +357,16 @@
 
 static int ip101a_ack_interrupt(struct phy_device *phydev)
 {
-	int err = phy_read(phydev, IP101A_IRQ_CONF_STATUS);
-	if (err < 0)
-		return err;
+	int ret;
+
+	ret = phy_read(phydev, IP101A_IRQ_CONF_STATUS);
+	if (ret < 0)
+		return ret;
+
+	ret = phy_read_page(phydev, IP101A_G_WOL_STATUS, 17);
+	if (ret < 0)
+		return ret;
+	DBG("WOL status register 0x%x\n", ret);
 
 	return 0;
 }
@@ -231,9 +408,10 @@
 	.config_aneg	= &genphy_config_aneg,
 	.read_status	= &genphy_read_status,
 	.flags		= PHY_HAS_INTERRUPT,
+	.wol_supported	= WAKE_PHY | WAKE_UCAST | WAKE_MAGIC,
 	.ack_interrupt	= ip101a_ack_interrupt,
-	.suspend	= genphy_suspend,
-	.resume		= genphy_resume,
+	.suspend	= ip101a_g_suspend,
+	.resume		= ip101a_g_resume,
 	.driver		= { .owner = THIS_MODULE,},
 };
 
diff -Naur a/drivers/net/phy/Kconfig b/drivers/net/phy/Kconfig
--- a/drivers/net/phy/Kconfig	2013-11-01 20:19:18.789929160 +0200
+++ b/drivers/net/phy/Kconfig	2013-11-01 18:44:51.429826240 +0200
@@ -65,7 +65,7 @@
 config ICPLUS_PHY
 	tristate "Drivers for ICPlus PHYs"
 	---help---
-	  Currently supports the IP175C and IP1001 PHYs.
+	  Currently supports the IP175C, IP1001 and IP101 A/G PHYs.
 
 config REALTEK_PHY
 	tristate "Drivers for Realtek PHYs"
diff -Naur a/drivers/net/phy/mdio_bus.c b/drivers/net/phy/mdio_bus.c
--- a/drivers/net/phy/mdio_bus.c	2013-11-01 20:19:18.793929174 +0200
+++ b/drivers/net/phy/mdio_bus.c	2013-11-01 18:44:51.433826253 +0200
@@ -277,6 +277,13 @@
 	if (!netdev)
 		return true;
 
+	/* PHY supports WoL+ that has been enabled by ethtool.
+	 * So we can call the suspend function that is expected
+	 * able to program internal registers to wake-up the system.
+	 */
+	if (phydev->wol)
+		return true;
+
 	/*
 	 * Don't suspend PHY if the attched netdev parent may wakeup.
 	 * The parent may point to a PCI device, as in tg3 driver.
diff -Naur a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c
--- a/drivers/net/phy/phy.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/phy/phy.c	2013-11-01 18:44:51.433826253 +0200
@@ -299,6 +299,36 @@
 }
 EXPORT_SYMBOL(phy_ethtool_gset);
 
+int phy_ethtool_set_wol(struct phy_device *phydev, struct ethtool_wolinfo *wol)
+{
+	u32 support = phydev->drv->wol_supported;
+
+	if (wol->wolopts & ~support)
+		return -EINVAL;
+
+	phydev->wol = wol->wolopts;
+	if (wol->wolopts) {
+		device_set_wakeup_enable(&phydev->dev, 1);
+		enable_irq_wake(phydev->irq);
+	} else {
+		device_set_wakeup_enable(&phydev->dev, 0);
+		disable_irq_wake(phydev->irq);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(phy_ethtool_set_wol);
+
+int phy_ethtool_get_wol(struct phy_device *phydev, struct ethtool_wolinfo *wol)
+{
+	if (device_can_wakeup(&phydev->dev)) {
+		wol->supported = phydev->drv->wol_supported;
+		wol->wolopts = phydev->wol;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(phy_ethtool_get_wol);
+
 /**
  * phy_mii_ioctl - generic PHY MII ioctl interface
  * @phydev: the phy_device struct
@@ -510,7 +540,7 @@
 {
 	struct phy_device *phydev = phy_dat;
 
-	if (PHY_HALTED == phydev->state)
+	if ((PHY_HALTED == phydev->state) && (!device_may_wakeup(&phydev->dev)))
 		return IRQ_NONE;		/* It can't be ours.  */
 
 	/* The MDIO bus is not allowed to be written in interrupt
@@ -964,3 +994,35 @@
 
 	schedule_delayed_work(&phydev->state_queue, PHY_STATE_TIME * HZ);
 }
+
+int phy_read_page(struct phy_device *phydev, u16 regnum, int page)
+{
+	int ret, old;
+
+	old = phy_read(phydev, 20);
+
+	/* Write the page in 0.20 reg */
+	phy_write(phydev, 20, page);
+	/* Read data from user page for the regnum */
+	ret = phy_read(phydev, regnum);
+	/* Restore page0 */
+	phy_write(phydev, 20, old);
+
+	return ret;
+}
+EXPORT_SYMBOL(phy_read_page);
+
+int phy_write_page(struct phy_device *phydev, u16 regnum, int page, int data)
+{
+	int old = phy_read(phydev, 20);
+
+	/* Write the page in 0.20 reg */
+	phy_write(phydev, 20, page);
+	/* Write date to page for regnum */
+	phy_write(phydev, regnum, data);
+	/* Restore page0 */
+	phy_write(phydev, 20, old);
+
+	return 0;
+}
+EXPORT_SYMBOL(phy_write_page);
diff -Naur a/drivers/net/phy/phy_device.c b/drivers/net/phy/phy_device.c
--- a/drivers/net/phy/phy_device.c	2013-11-01 20:19:18.797929193 +0200
+++ b/drivers/net/phy/phy_device.c	2013-11-01 18:44:51.433826253 +0200
@@ -878,7 +878,6 @@
 static inline void mmd_phy_cl45(struct mii_bus *bus, int prtad, int devad,
 				int addr)
 {
-
 	/* Write the desired MMD Devad */
 	bus->write(bus, addr, MII_MMD_CRTL, devad);
 
@@ -891,7 +890,7 @@
 }
 
 /**
- * read_phy_mmd - reads data from the MMC register (clause 22 to access to
+ * read_phy_mmd - reads data from the MMD register (clause 22 to access to
  * 		  clause 45)
  * @bus: the target MII bus
  * @prtad: MMD Address
@@ -920,7 +919,7 @@
 }
 
 /**
- * write_phy_mmd - writes data to the MMC register (clause 22 to access to
+ * write_phy_mmd - writes data to the MMD register (clause 22 to access to
  * 		   clause 45)
  * @bus: the target MII bus
  * @prtad: MMD Address
@@ -928,7 +927,7 @@
  * @addr: PHY address on the MII bus
  * @data: data to write in the MMD register
  *
- * Description: Reads data from the MMD regisetrs of the
+ * Description: write data from the MMD regisetrs of the
  * phy addr. To read these register we have:
  * 1) Write reg 13 // DEVAD
  * 2) Write reg 14 // MMD Address
@@ -1036,6 +1035,13 @@
 	/* Disable the interrupt if the PHY doesn't support it */
 	if (!(phydrv->flags & PHY_HAS_INTERRUPT))
 		phydev->irq = PHY_POLL;
+	else {
+		/* Check if the PHY is WoL capable but driver cannot work
+		 * in polling mode.
+		 */
+		if (phydrv->wol_supported)
+			device_set_wakeup_capable(dev, 1);
+	}
 
 	mutex_lock(&phydev->lock);
 
diff -Naur a/drivers/net/r8169.c b/drivers/net/r8169.c
--- a/drivers/net/r8169.c	2013-11-01 20:18:04.397560261 +0200
+++ b/drivers/net/r8169.c	2013-11-01 18:44:51.461826397 +0200
@@ -176,6 +176,7 @@
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8168), 0, 0, RTL_CFG_1 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_REALTEK,	0x8169), 0, 0, RTL_CFG_0 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_DLINK,	0x4300), 0, 0, RTL_CFG_0 },
+	{ PCI_DEVICE(PCI_VENDOR_ID_DLINK,	0x4302), 0, 0, RTL_CFG_0 },
 	{ PCI_DEVICE(PCI_VENDOR_ID_AT,		0xc107), 0, 0, RTL_CFG_0 },
 	{ PCI_DEVICE(0x16ec,			0x0116), 0, 0, RTL_CFG_0 },
 	{ PCI_VENDOR_ID_LINKSYS,		0x1032,
@@ -1306,7 +1307,7 @@
 		{ 0x7c800000, 0x28000000,	RTL_GIGA_MAC_VER_26 },
 
 		/* 8168C family. */
-		{ 0x7cf00000, 0x3ca00000,	RTL_GIGA_MAC_VER_24 },
+		{ 0x7cf00000, 0x3cb00000,	RTL_GIGA_MAC_VER_24 },
 		{ 0x7cf00000, 0x3c900000,	RTL_GIGA_MAC_VER_23 },
 		{ 0x7cf00000, 0x3c800000,	RTL_GIGA_MAC_VER_18 },
 		{ 0x7c800000, 0x3c800000,	RTL_GIGA_MAC_VER_24 },
@@ -3076,7 +3077,7 @@
 		goto err_out_mwi_3;
 	}
 
-	tp->cp_cmd = PCIMulRW | RxChkSum;
+	tp->cp_cmd = RxChkSum;
 
 	if ((sizeof(dma_addr_t) > 4) &&
 	    !pci_set_dma_mask(pdev, DMA_BIT_MASK(64)) && use_dac) {
@@ -3824,8 +3825,7 @@
 	Cxpl_dbg_sel | \
 	ASF | \
 	PktCntrDisable | \
-	PCIDAC | \
-	PCIMulRW)
+	Mac_dbgo_sel)
 
 static void rtl_hw_start_8102e_1(void __iomem *ioaddr, struct pci_dev *pdev)
 {
@@ -3855,8 +3855,6 @@
 	if ((cfg1 & LEDS0) && (cfg1 & LEDS1))
 		RTL_W8(Config1, cfg1 & ~LEDS0);
 
-	RTL_W16(CPlusCmd, RTL_R16(CPlusCmd) & ~R810X_CPCMD_QUIRK_MASK);
-
 	rtl_ephy_init(ioaddr, e_info_8102e_1, ARRAY_SIZE(e_info_8102e_1));
 }
 
@@ -3868,8 +3866,6 @@
 
 	RTL_W8(Config1, MEMMAP | IOMAP | VPD | PMEnable);
 	RTL_W8(Config3, RTL_R8(Config3) & ~Beacon_en);
-
-	RTL_W16(CPlusCmd, RTL_R16(CPlusCmd) & ~R810X_CPCMD_QUIRK_MASK);
 }
 
 static void rtl_hw_start_8102e_3(void __iomem *ioaddr, struct pci_dev *pdev)
@@ -3895,6 +3891,8 @@
 		}
 	}
 
+	RTL_W8(Cfg9346, Cfg9346_Unlock);
+
 	switch (tp->mac_version) {
 	case RTL_GIGA_MAC_VER_07:
 		rtl_hw_start_8102e_1(ioaddr, pdev);
@@ -3909,14 +3907,13 @@
 		break;
 	}
 
-	RTL_W8(Cfg9346, Cfg9346_Unlock);
+	RTL_W8(Cfg9346, Cfg9346_Lock);
 
 	RTL_W8(EarlyTxThres, EarlyTxThld);
 
 	rtl_set_rx_max_size(ioaddr, tp->rx_buf_sz);
 
-	tp->cp_cmd |= rtl_rw_cpluscmd(ioaddr) | PCIMulRW;
-
+	tp->cp_cmd &= ~R810X_CPCMD_QUIRK_MASK;
 	RTL_W16(CPlusCmd, tp->cp_cmd);
 
 	RTL_W16(IntrMitigate, 0x0000);
@@ -3926,14 +3923,10 @@
 	RTL_W8(ChipCmd, CmdTxEnb | CmdRxEnb);
 	rtl_set_rx_tx_config_registers(tp);
 
-	RTL_W8(Cfg9346, Cfg9346_Lock);
-
 	RTL_R8(IntrMask);
 
 	rtl_set_rx_mode(dev);
 
-	RTL_W8(ChipCmd, CmdTxEnb | CmdRxEnb);
-
 	RTL_W16(MultiIntr, RTL_R16(MultiIntr) & 0xf000);
 
 	RTL_W16(IntrMask, tp->intr_event);
@@ -4579,13 +4572,6 @@
 			dev->stats.rx_bytes += pkt_size;
 			dev->stats.rx_packets++;
 		}
-
-		/* Work around for AMD plateform. */
-		if ((desc->opts2 & cpu_to_le32(0xfffe000)) &&
-		    (tp->mac_version == RTL_GIGA_MAC_VER_05)) {
-			desc->opts2 = 0;
-			cur_rx++;
-		}
 	}
 
 	count = cur_rx - tp->cur_rx;
diff -Naur a/drivers/net/stmmac/norm_desc.c b/drivers/net/stmmac/norm_desc.c
--- a/drivers/net/stmmac/norm_desc.c	2013-11-01 20:19:18.821929318 +0200
+++ b/drivers/net/stmmac/norm_desc.c	2013-11-01 18:44:52.053829323 +0200
@@ -115,10 +115,8 @@
 		ret = discard_frame;
 	}
 #ifdef STMMAC_VLAN_TAG_USED
-	if (p->des01.rx.vlan_tag) {
+	if (p->des01.rx.vlan_tag)
 		x->vlan_tag++;
-		stats->vlan_tag++;
-	}
 #endif
 	return ret;
 }
diff -Naur a/drivers/net/stmmac/stmmac_ethtool.c b/drivers/net/stmmac/stmmac_ethtool.c
--- a/drivers/net/stmmac/stmmac_ethtool.c	2013-11-01 20:19:18.825929333 +0200
+++ b/drivers/net/stmmac/stmmac_ethtool.c	2013-11-01 18:44:52.057829344 +0200
@@ -449,6 +449,7 @@
 		wol->supported = WAKE_MAGIC | WAKE_UCAST;
 		wol->wolopts = priv->wolopts;
 	}
+	/* FIXME: get WoL from PHY that supports Wol+ */
 	spin_unlock_irq(&priv->lock);
 }
 
@@ -457,6 +458,18 @@
 	struct stmmac_priv *priv = netdev_priv(dev);
 	u32 support = WAKE_MAGIC | WAKE_UCAST;
 
+	if (priv->phy_wol_plus & wol->wolopts) {
+		int ret;
+
+		pr_info("stmmac: use Phy WoL+\n");
+
+		spin_lock_irq(&priv->lock);
+		ret = phy_ethtool_set_wol(priv->phydev, wol);
+		spin_unlock_irq(&priv->lock);
+
+		return ret;
+	}
+
 	/* By default almost all GMAC devices support the WoL via
 	 * magic frame but we can disable it if the HW capability
 	 * register shows no support for pmt_magic_frame. */
diff -Naur a/drivers/net/stmmac/stmmac.h b/drivers/net/stmmac/stmmac.h
--- a/drivers/net/stmmac/stmmac.h	2013-11-01 20:19:18.825929333 +0200
+++ b/drivers/net/stmmac/stmmac.h	2013-11-01 18:44:52.053829323 +0200
@@ -88,6 +88,7 @@
 	bool tx_path_in_lpi_mode;
 	bool eee_enabled;
 	int lpi_irq;
+	int phy_wol_plus;
 };
 
 extern int phyaddr;
diff -Naur a/drivers/net/stmmac/stmmac_main.c b/drivers/net/stmmac/stmmac_main.c
--- a/drivers/net/stmmac/stmmac_main.c	2013-11-01 20:19:18.833929378 +0200
+++ b/drivers/net/stmmac/stmmac_main.c	2013-11-01 18:44:52.057829344 +0200
@@ -136,6 +136,13 @@
 MODULE_PARM_DESC(eee_timer, "LPI tx expiration time in msec");
 #define STMMAC_LPI_TIMER(x) (jiffies + msecs_to_jiffies(x))
 
+/* Enable this option the driver could use the WoL+ feature
+ * available in some new PHY drivers. This allows to completely power-off
+ * the mac when suspend and the WoL will be done by the PHY device directly. */
+static int wol_plus_en;
+module_param(wol_plus_en, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(wol_plus_en, "Driver can use the WoL+ feature");
+
 static irqreturn_t stmmac_interrupt(int irq, void *dev_id);
 static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev);
 #ifdef CONFIG_STMMAC_DEBUG_FS
@@ -424,6 +431,10 @@
 
 	priv->phydev = phydev;
 
+	if ((priv->phydev->drv->wol_supported) && (wol_plus_en)) {
+		pr_info("stmmac: attached PHY supports WoL Plus\n");
+		priv->phy_wol_plus = priv->phydev->drv->wol_supported;
+	}
 	return 0;
 }
 
@@ -767,14 +778,16 @@
 	unsigned int has_work = 0;
 	int rxret, tx_work = 0;
 
-	rxret = priv->hw->desc->get_rx_owner(priv->dma_rx +
-		(priv->cur_rx % priv->dma_rx_size));
+	if (likely(priv->dma_rx)) {
+		rxret = priv->hw->desc->get_rx_owner(priv->dma_rx +
+			(priv->cur_rx % priv->dma_rx_size));
 
-	if (priv->dirty_tx != priv->cur_tx)
-		tx_work = 1;
+		if (priv->dirty_tx != priv->cur_tx)
+			tx_work = 1;
 
-	if (likely(!rxret || tx_work))
-		has_work = 1;
+		if (likely(!rxret || tx_work))
+			has_work = 1;
+	}
 
 	return has_work;
 }
@@ -990,12 +1003,6 @@
 	stmmac_check_ether_addr(priv);
 
 	/* MDIO bus Registration */
-	ret = stmmac_mdio_register(dev);
-	if (ret < 0) {
-		pr_debug("%s: MDIO bus (id: %d) registration failed",
-			 __func__, priv->plat->bus_id);
-		return ret;
-	}
 
 #ifdef CONFIG_STMMAC_TIMER
 	priv->tm = kzalloc(sizeof(struct stmmac_timer *), GFP_KERNEL);
@@ -1191,8 +1198,6 @@
 #ifdef CONFIG_STMMAC_DEBUG_FS
 	stmmac_exit_fs();
 #endif
-	stmmac_mdio_unregister(dev);
-
 	return 0;
 }
 
@@ -2054,15 +2059,23 @@
 	ret = register_netdev(ndev);
 	if (ret) {
 		pr_err("%s: ERROR %i registering the device\n", __func__, ret);
-		goto error;
+		goto netdev_error;
+	}
+
+	ret = stmmac_mdio_register(ndev);
+	if (ret < 0) {
+		pr_err("%s: MDIO bus (id: %d) registration failed",
+			__func__, priv->plat->bus_id);
+		goto exit_error;
 	}
 
 	return priv;
 
-error:
+exit_error:
+	unregister_netdev(ndev);
+netdev_error:
 	netif_napi_del(&priv->napi);
 
-	unregister_netdev(ndev);
 	free_netdev(ndev);
 
 	return NULL;
@@ -2086,6 +2099,7 @@
 
 	stmmac_set_mac(priv->ioaddr, false);
 	netif_carrier_off(ndev);
+	stmmac_mdio_unregister(ndev);
 	unregister_netdev(ndev);
 	free_netdev(ndev);
 
@@ -2124,8 +2138,13 @@
 				     dis_ic);
 	priv->hw->desc->init_tx_desc(priv->dma_tx, priv->dma_tx_size);
 
-	/* Enable Power down mode by programming the PMT regs */
-	if (device_may_wakeup(priv->device))
+	/* If the wake-up On Lan can be done by the PHY device
+	 * (that supports WoL+) there is no reason to program the PMT
+	 * registers. This means that to enable Power down mode programming
+	 * the PMT regs either the phy doesn't support WoL+ or the PHY
+	 * supports that but not the WoL mode required by the user.
+	 */
+	if (device_may_wakeup(priv->device) && (!priv->phy_wol_plus))
 		priv->hw->mac->pmt(priv->ioaddr, priv->wolopts);
 	else
 		stmmac_set_mac(priv->ioaddr, false);
@@ -2143,12 +2162,12 @@
 
 	spin_lock(&priv->lock);
 
-	/* Power Down bit, into the PM register, is cleared
-	 * automatically as soon as a magic packet or a Wake-up frame
-	 * is received. Anyway, it's better to manually clear
-	 * this bit because it can generate problems while resuming
-	 * from another devices (e.g. serial console). */
-	if (device_may_wakeup(priv->device))
+	if (device_may_wakeup(priv->device) && (!priv->phy_wol_plus))
+		/* Power Down bit, into the PM register, is cleared
+		 * automatically as soon as a magic packet or a Wake-up frame
+		 * is received. Anyway, it's better to manually clear
+		 * this bit because it can generate problems while resuming
+		 * from another devices (e.g. serial console). */
 		priv->hw->mac->pmt(priv->ioaddr, 0);
 
 	netif_device_attach(ndev);
@@ -2232,6 +2251,10 @@
 		} else if (!strncmp(opt, "pause:", 6)) {
 			if (strict_strtoul(opt + 6, 0, (unsigned long *)&pause))
 				goto err;
+		} else if (!strncmp(opt, "wol_plus_en:", 12)) {
+			if (strict_strtoul(opt + 12, 0,
+					   (unsigned long *)&wol_plus_en))
+				goto err;
 #ifdef CONFIG_STMMAC_TIMER
 		} else if (!strncmp(opt, "tmrate:", 7)) {
 			if (strict_strtoul(opt + 7, 0,
diff -Naur a/drivers/net/tg3.c b/drivers/net/tg3.c
--- a/drivers/net/tg3.c	2013-11-01 20:18:04.437560460 +0200
+++ b/drivers/net/tg3.c	2013-11-01 18:44:52.093829524 +0200
@@ -4994,6 +4994,9 @@
 	int i;
 	struct tg3 *tp = netdev_priv(dev);
 
+	if (tg3_irq_sync(tp))
+		return;
+
 	for (i = 0; i < tp->irq_cnt; i++)
 		tg3_interrupt(tp->napi[i].irq_vec, &tp->napi[i]);
 }
@@ -13888,6 +13891,7 @@
 	tp->pm_cap = pm_cap;
 	tp->rx_mode = TG3_DEF_RX_MODE;
 	tp->tx_mode = TG3_DEF_TX_MODE;
+	tp->irq_sync = 1;
 
 	if (tg3_debug > 0)
 		tp->msg_enable = tg3_debug;
diff -Naur a/drivers/net/tun.c b/drivers/net/tun.c
--- a/drivers/net/tun.c	2013-11-01 20:18:04.449560513 +0200
+++ b/drivers/net/tun.c	2013-11-01 18:44:52.133829730 +0200
@@ -1121,10 +1121,12 @@
 	int sndbuf;
 	int ret;
 
-	if (cmd == TUNSETIFF || _IOC_TYPE(cmd) == 0x89)
+	if (cmd == TUNSETIFF || _IOC_TYPE(cmd) == 0x89) {
 		if (copy_from_user(&ifr, argp, sizeof ifr))
 			return -EFAULT;
-
+	} else {
+		memset(&ifr, 0, sizeof(ifr));
+	}
 	if (cmd == TUNGETFEATURES) {
 		/* Currently this just means: "what IFF flags are valid?".
 		 * This is needed because we never checked for invalid flags on
diff -Naur a/drivers/net/usb/kaweth.c b/drivers/net/usb/kaweth.c
--- a/drivers/net/usb/kaweth.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/net/usb/kaweth.c	2013-11-01 18:44:52.149829809 +0200
@@ -1325,7 +1325,7 @@
         int retv;
         int length = 0; /* shut up GCC */
 
-        urb = usb_alloc_urb(0, GFP_NOIO);
+	urb = usb_alloc_urb(0, GFP_ATOMIC);
         if (!urb)
                 return -ENOMEM;
 
diff -Naur a/drivers/net/usb/usbnet.c b/drivers/net/usb/usbnet.c
--- a/drivers/net/usb/usbnet.c	2013-11-01 20:18:04.461560579 +0200
+++ b/drivers/net/usb/usbnet.c	2013-11-01 18:44:52.161829862 +0200
@@ -584,6 +584,14 @@
 		entry = (struct skb_data *) skb->cb;
 		urb = entry->urb;
 
+		/*
+		 * Get reference count of the URB to avoid it to be
+		 * freed during usb_unlink_urb, which may trigger
+		 * use-after-free problem inside usb_unlink_urb since
+		 * usb_unlink_urb is always racing with .complete
+		 * handler(include defer_bh).
+		 */
+		usb_get_urb(urb);
 		spin_unlock_irqrestore(&q->lock, flags);
 		// during some PM-driven resume scenarios,
 		// these (async) unlinks complete immediately
@@ -592,6 +600,7 @@
 			devdbg (dev, "unlink urb err, %d", retval);
 		else
 			count++;
+		usb_put_urb(urb);
 		spin_lock_irqsave(&q->lock, flags);
 	}
 	spin_unlock_irqrestore (&q->lock, flags);
@@ -989,7 +998,6 @@
 		}
 	}
 
-	urb->dev = NULL;
 	entry->state = tx_done;
 	defer_bh(dev, skb, &dev->txq);
 }
diff -Naur a/drivers/net/wireless/b43legacy/main.c b/drivers/net/wireless/b43legacy/main.c
--- a/drivers/net/wireless/b43legacy/main.c	2013-11-01 20:18:04.537560963 +0200
+++ b/drivers/net/wireless/b43legacy/main.c	2013-11-01 18:44:52.325830681 +0200
@@ -3870,6 +3870,8 @@
 	cancel_work_sync(&wldev->restart_work);
 
 	B43legacy_WARN_ON(!wl);
+	if (!wldev->fw.ucode)
+		return;			/* NULL if fw never loaded */
 	if (wl->current_dev == wldev)
 		ieee80211_unregister_hw(wl->hw);
 
diff -Naur a/drivers/pci/quirks.c b/drivers/pci/quirks.c
--- a/drivers/pci/quirks.c	2013-11-01 20:18:04.673561631 +0200
+++ b/drivers/pci/quirks.c	2013-11-01 18:44:52.629832182 +0200
@@ -2550,6 +2550,40 @@
 }
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_TI, 0xb800, fixup_ti816x_class);
 
+/*
+ * Some BIOS implementations leave the Intel GPU interrupts enabled,
+ * even though no one is handling them (f.e. i915 driver is never loaded).
+ * Additionally the interrupt destination is not set up properly
+ * and the interrupt ends up -somewhere-.
+ *
+ * These spurious interrupts are "sticky" and the kernel disables
+ * the (shared) interrupt line after 100.000+ generated interrupts.
+ *
+ * Fix it by disabling the still enabled interrupts.
+ * This resolves crashes often seen on monitor unplug.
+ */
+#define I915_DEIER_REG 0x4400c
+static void __devinit disable_igfx_irq(struct pci_dev *dev)
+{
+	void __iomem *regs = pci_iomap(dev, 0, 0);
+	if (regs == NULL) {
+		dev_warn(&dev->dev, "igfx quirk: Can't iomap PCI device\n");
+		return;
+	}
+
+	/* Check if any interrupt line is still enabled */
+	if (readl(regs + I915_DEIER_REG) != 0) {
+		dev_warn(&dev->dev, "BIOS left Intel GPU interrupts enabled; "
+			"disabling\n");
+
+		writel(0, regs + I915_DEIER_REG);
+	}
+
+	pci_iounmap(dev, regs);
+}
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_INTEL, 0x0102, disable_igfx_irq);
+DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_INTEL, 0x010a, disable_igfx_irq);
+
 static void pci_do_fixups(struct pci_dev *dev, struct pci_fixup *f,
 			  struct pci_fixup *end)
 {
diff -Naur a/drivers/pnp/quirks.c b/drivers/pnp/quirks.c
--- a/drivers/pnp/quirks.c	2013-11-01 20:18:04.705561796 +0200
+++ b/drivers/pnp/quirks.c	2013-11-01 18:44:52.713832606 +0200
@@ -300,9 +300,9 @@
 	}
 }
 
-#ifdef CONFIG_AMD_NB
+#ifdef CONFIG_K8_NB
 
-#include <asm/amd_nb.h>
+#include <asm/k8.h>
 
 static void quirk_amd_mmconfig_area(struct pnp_dev *dev)
 {
@@ -366,7 +366,7 @@
 	/* PnP resources that might overlap PCI BARs */
 	{"PNP0c01", quirk_system_pci_resources},
 	{"PNP0c02", quirk_system_pci_resources},
-#ifdef CONFIG_AMD_NB
+#ifdef CONFIG_K8_NB
 	{"PNP0c01", quirk_amd_mmconfig_area},
 #endif
 	{""}
diff -Naur a/drivers/rtc/rtc-wm831x.c b/drivers/rtc/rtc-wm831x.c
--- a/drivers/rtc/rtc-wm831x.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/rtc/rtc-wm831x.c	2013-11-01 18:44:52.777832923 +0200
@@ -23,7 +23,7 @@
 #include <linux/mfd/wm831x/core.h>
 #include <linux/delay.h>
 #include <linux/platform_device.h>
-
+#include <linux/random.h>
 
 /*
  * R16416 (0x4020) - RTC Write Counter
@@ -95,6 +95,26 @@
 	unsigned int alarm_enabled:1;
 };
 
+static void wm831x_rtc_add_randomness(struct wm831x *wm831x)
+{
+	int ret;
+	u16 reg;
+
+	/*
+	 * The write counter contains a pseudo-random number which is
+	 * regenerated every time we set the RTC so it should be a
+	 * useful per-system source of entropy.
+	 */
+	ret = wm831x_reg_read(wm831x, WM831X_RTC_WRITE_COUNTER);
+	if (ret >= 0) {
+		reg = ret;
+		add_device_randomness(&reg, sizeof(reg));
+	} else {
+		dev_warn(wm831x->dev, "Failed to read RTC write counter: %d\n",
+			 ret);
+	}
+}
+
 /*
  * Read current time and date in RTC
  */
@@ -464,6 +484,8 @@
 			alm_irq, ret);
 	}
 
+	wm831x_rtc_add_randomness(wm831x);
+
 	return 0;
 
 err:
diff -Naur a/drivers/scsi/bnx2i/bnx2i_hwi.c b/drivers/scsi/bnx2i/bnx2i_hwi.c
--- a/drivers/scsi/bnx2i/bnx2i_hwi.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/scsi/bnx2i/bnx2i_hwi.c	2013-11-01 18:44:53.093834486 +0200
@@ -1156,6 +1156,9 @@
 	int rc = 0;
 	u64 mask64;
 
+	memset(&iscsi_init, 0x00, sizeof(struct iscsi_kwqe_init1));
+	memset(&iscsi_init2, 0x00, sizeof(struct iscsi_kwqe_init2));
+
 	bnx2i_adjust_qp_size(hba);
 
 	iscsi_init.flags =
diff -Naur a/drivers/scsi/libsas/sas_expander.c b/drivers/scsi/libsas/sas_expander.c
--- a/drivers/scsi/libsas/sas_expander.c	2013-11-01 20:18:04.813562328 +0200
+++ b/drivers/scsi/libsas/sas_expander.c	2013-11-01 18:44:53.201835016 +0200
@@ -754,7 +754,7 @@
 }
 
 /* See if this phy is part of a wide port */
-static int sas_ex_join_wide_port(struct domain_device *parent, int phy_id)
+static bool sas_ex_join_wide_port(struct domain_device *parent, int phy_id)
 {
 	struct ex_phy *phy = &parent->ex_dev.ex_phy[phy_id];
 	int i;
@@ -770,11 +770,11 @@
 			sas_port_add_phy(ephy->port, phy->phy);
 			phy->port = ephy->port;
 			phy->phy_state = PHY_DEVICE_DISCOVERED;
-			return 0;
+			return true;
 		}
 	}
 
-	return -ENODEV;
+	return false;
 }
 
 static struct domain_device *sas_ex_discover_expander(
@@ -912,8 +912,7 @@
 		return res;
 	}
 
-	res = sas_ex_join_wide_port(dev, phy_id);
-	if (!res) {
+	if (sas_ex_join_wide_port(dev, phy_id)) {
 		SAS_DPRINTK("Attaching ex phy%d to wide port %016llx\n",
 			    phy_id, SAS_ADDR(ex_phy->attached_sas_addr));
 		return res;
@@ -958,8 +957,7 @@
 			if (SAS_ADDR(ex->ex_phy[i].attached_sas_addr) ==
 			    SAS_ADDR(child->sas_addr)) {
 				ex->ex_phy[i].phy_state= PHY_DEVICE_DISCOVERED;
-				res = sas_ex_join_wide_port(dev, i);
-				if (!res)
+				if (sas_ex_join_wide_port(dev, i))
 					SAS_DPRINTK("Attaching ex phy%d to wide port %016llx\n",
 						    i, SAS_ADDR(ex->ex_phy[i].attached_sas_addr));
 
@@ -1812,32 +1810,20 @@
 {
 	struct ex_phy *ex_phy = &dev->ex_dev.ex_phy[phy_id];
 	struct domain_device *child;
-	bool found = false;
-	int res, i;
+	int res;
 
 	SAS_DPRINTK("ex %016llx phy%d new device attached\n",
 		    SAS_ADDR(dev->sas_addr), phy_id);
 	res = sas_ex_phy_discover(dev, phy_id);
 	if (res)
-		goto out;
-	/* to support the wide port inserted */
-	for (i = 0; i < dev->ex_dev.num_phys; i++) {
-		struct ex_phy *ex_phy_temp = &dev->ex_dev.ex_phy[i];
-		if (i == phy_id)
-			continue;
-		if (SAS_ADDR(ex_phy_temp->attached_sas_addr) ==
-		    SAS_ADDR(ex_phy->attached_sas_addr)) {
-			found = true;
-			break;
-		}
-	}
-	if (found) {
-		sas_ex_join_wide_port(dev, phy_id);
+		return res;
+
+	if (sas_ex_join_wide_port(dev, phy_id))
 		return 0;
-	}
+
 	res = sas_ex_discover_devices(dev, phy_id);
-	if (!res)
-		goto out;
+	if (res)
+		return res;
 	list_for_each_entry(child, &dev->ex_dev.children, siblings) {
 		if (SAS_ADDR(child->sas_addr) ==
 		    SAS_ADDR(ex_phy->attached_sas_addr)) {
@@ -1847,7 +1833,6 @@
 			break;
 		}
 	}
-out:
 	return res;
 }
 
@@ -1946,9 +1931,7 @@
 	struct domain_device *dev = NULL;
 
 	res = sas_find_bcast_dev(port_dev, &dev);
-	if (res)
-		goto out;
-	if (dev) {
+	while (res == 0 && dev) {
 		struct expander_device *ex = &dev->ex_dev;
 		int i = 0, phy_id;
 
@@ -1960,8 +1943,10 @@
 			res = sas_rediscover(dev, phy_id);
 			i = phy_id + 1;
 		} while (i < ex->num_phys);
+
+		dev = NULL;
+		res = sas_find_bcast_dev(port_dev, &dev);
 	}
-out:
 	return res;
 }
 
diff -Naur a/drivers/scsi/mpt2sas/mpt2sas_ctl.c b/drivers/scsi/mpt2sas/mpt2sas_ctl.c
--- a/drivers/scsi/mpt2sas/mpt2sas_ctl.c	2013-11-01 20:18:04.833562417 +0200
+++ b/drivers/scsi/mpt2sas/mpt2sas_ctl.c	2013-11-01 18:44:53.269835362 +0200
@@ -750,8 +750,11 @@
 		    (u32)mpt2sas_base_get_sense_buffer_dma(ioc, smid);
 		priv_sense = mpt2sas_base_get_sense_buffer(ioc, smid);
 		memset(priv_sense, 0, SCSI_SENSE_BUFFERSIZE);
-		mpt2sas_base_put_smid_scsi_io(ioc, smid,
-		    le16_to_cpu(mpi_request->FunctionDependent1));
+		if (mpi_request->Function == MPI2_FUNCTION_SCSI_IO_REQUEST)
+			mpt2sas_base_put_smid_scsi_io(ioc, smid,
+			    le16_to_cpu(mpi_request->FunctionDependent1));
+		else
+			mpt2sas_base_put_smid_default(ioc, smid);
 		break;
 	}
 	case MPI2_FUNCTION_SCSI_TASK_MGMT:
diff -Naur a/drivers/scsi/scsi_error.c b/drivers/scsi/scsi_error.c
--- a/drivers/scsi/scsi_error.c	2013-11-01 20:18:04.869562602 +0200
+++ b/drivers/scsi/scsi_error.c	2013-11-01 18:44:53.337835693 +0200
@@ -1550,6 +1550,20 @@
 	 * requests are started.
 	 */
 	scsi_run_host_queues(shost);
+
+	/*
+	 * if eh is active and host_eh_scheduled is pending we need to re-run
+	 * recovery.  we do this check after scsi_run_host_queues() to allow
+	 * everything pent up since the last eh run a chance to make forward
+	 * progress before we sync again.  Either we'll immediately re-run
+	 * recovery or scsi_device_unbusy() will wake us again when these
+	 * pending commands complete.
+	 */
+	spin_lock_irqsave(shost->host_lock, flags);
+	if (shost->host_eh_scheduled)
+		if (scsi_host_set_state(shost, SHOST_RECOVERY))
+			WARN_ON(scsi_host_set_state(shost, SHOST_CANCEL_RECOVERY));
+	spin_unlock_irqrestore(shost->host_lock, flags);
 }
 
 /**
diff -Naur a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
--- a/drivers/scsi/scsi_lib.c	2013-11-01 20:18:04.873562629 +0200
+++ b/drivers/scsi/scsi_lib.c	2013-11-01 18:44:53.341835719 +0200
@@ -215,6 +215,8 @@
 	int ret = DRIVER_ERROR << 24;
 
 	req = blk_get_request(sdev->request_queue, write, __GFP_WAIT);
+	if (!req)
+		return ret;
 
 	if (bufflen &&	blk_rq_map_kern(sdev->request_queue, req,
 					buffer, bufflen, __GFP_WAIT))
@@ -482,15 +484,26 @@
  */
 static void scsi_requeue_command(struct request_queue *q, struct scsi_cmnd *cmd)
 {
+	struct scsi_device *sdev = cmd->device;
 	struct request *req = cmd->request;
 	unsigned long flags;
 
+	/*
+	 * We need to hold a reference on the device to avoid the queue being
+	 * killed after the unlock and before scsi_run_queue is invoked which
+	 * may happen because scsi_unprep_request() puts the command which
+	 * releases its reference on the device.
+	 */
+	get_device(&sdev->sdev_gendev);
+
 	spin_lock_irqsave(q->queue_lock, flags);
 	scsi_unprep_request(req);
 	blk_requeue_request(q, req);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
 	scsi_run_queue(q);
+
+	put_device(&sdev->sdev_gendev);
 }
 
 void scsi_next_command(struct scsi_cmnd *cmd)
diff -Naur a/drivers/scsi/scsi_priv.h b/drivers/scsi/scsi_priv.h
--- a/drivers/scsi/scsi_priv.h	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/scsi/scsi_priv.h	2013-11-01 18:44:53.341835719 +0200
@@ -107,6 +107,7 @@
 #endif /* CONFIG_PROC_FS */
 
 /* scsi_scan.c */
+extern int scsi_complete_async_scans(void);
 extern int scsi_scan_host_selected(struct Scsi_Host *, unsigned int,
 				   unsigned int, unsigned int, int);
 extern void scsi_forget_host(struct Scsi_Host *);
diff -Naur a/drivers/scsi/scsi_wait_scan.c b/drivers/scsi/scsi_wait_scan.c
--- a/drivers/scsi/scsi_wait_scan.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/scsi/scsi_wait_scan.c	2013-11-01 18:44:53.349835751 +0200
@@ -13,6 +13,7 @@
 #include <linux/module.h>
 #include <linux/device.h>
 #include <scsi/scsi_scan.h>
+#include "scsi_priv.h"
 
 static int __init wait_scan_init(void)
 {
diff -Naur a/drivers/serial/8250.c b/drivers/serial/8250.c
--- a/drivers/serial/8250.c	2013-11-01 20:18:04.897562748 +0200
+++ b/drivers/serial/8250.c	2013-11-01 18:44:53.397835989 +0200
@@ -81,7 +81,7 @@
 #define DEBUG_INTR(fmt...)	do { } while (0)
 #endif
 
-#define PASS_LIMIT	256
+#define PASS_LIMIT	512
 
 #define BOTH_EMPTY 	(UART_LSR_TEMT | UART_LSR_THRE)
 
diff -Naur a/drivers/staging/comedi/comedi_fops.c b/drivers/staging/comedi/comedi_fops.c
--- a/drivers/staging/comedi/comedi_fops.c	2013-11-01 20:18:04.917562840 +0200
+++ b/drivers/staging/comedi/comedi_fops.c	2013-11-01 18:44:53.493836467 +0200
@@ -809,7 +809,7 @@
 				ret = -EAGAIN;
 				break;
 			}
-			ret = s->async->inttrig(dev, s, insn->data[0]);
+			ret = s->async->inttrig(dev, s, data[0]);
 			if (ret >= 0)
 				ret = 1;
 			break;
@@ -1035,7 +1035,6 @@
 		goto cleanup;
 	}
 
-	kfree(async->cmd.chanlist);
 	async->cmd = user_cmd;
 	async->cmd.data = NULL;
 	/* load channel/gain list */
@@ -1499,7 +1498,7 @@
 
 	mask = 0;
 	read_subdev = comedi_get_read_subdevice(dev_file_info);
-	if (read_subdev) {
+	if (read_subdev && read_subdev->async) {
 		poll_wait(file, &read_subdev->async->wait_head, wait);
 		if (!read_subdev->busy
 		    || comedi_buf_read_n_available(read_subdev->async) > 0
@@ -1509,7 +1508,7 @@
 		}
 	}
 	write_subdev = comedi_get_write_subdevice(dev_file_info);
-	if (write_subdev) {
+	if (write_subdev && write_subdev->async) {
 		poll_wait(file, &write_subdev->async->wait_head, wait);
 		comedi_buf_write_alloc(write_subdev->async,
 				       write_subdev->async->prealloc_bufsz);
@@ -1551,7 +1550,7 @@
 	}
 
 	s = comedi_get_write_subdevice(dev_file_info);
-	if (s == NULL) {
+	if (s == NULL || s->async == NULL) {
 		retval = -EIO;
 		goto done;
 	}
@@ -1659,7 +1658,7 @@
 	}
 
 	s = comedi_get_read_subdevice(dev_file_info);
-	if (s == NULL) {
+	if (s == NULL || s->async == NULL) {
 		retval = -EIO;
 		goto done;
 	}
@@ -1759,6 +1758,8 @@
 	if (async) {
 		comedi_reset_async_buf(async);
 		async->inttrig = NULL;
+		kfree(async->cmd.chanlist);
+		async->cmd.chanlist = NULL;
 	} else {
 		printk(KERN_ERR
 		       "BUG: (?) do_become_nonbusy called with async=0\n");
diff -Naur a/drivers/staging/comedi/drivers/comedi_test.c b/drivers/staging/comedi/drivers/comedi_test.c
--- a/drivers/staging/comedi/drivers/comedi_test.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/staging/comedi/drivers/comedi_test.c	2013-11-01 18:44:53.549836743 +0200
@@ -450,7 +450,7 @@
 			      struct comedi_subdevice *s)
 {
 	devpriv->timer_running = 0;
-	del_timer(&devpriv->timer);
+	del_timer_sync(&devpriv->timer);
 	return 0;
 }
 
diff -Naur a/drivers/staging/comedi/drivers/das08.c b/drivers/staging/comedi/drivers/das08.c
--- a/drivers/staging/comedi/drivers/das08.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/staging/comedi/drivers/das08.c	2013-11-01 18:44:53.553836771 +0200
@@ -652,7 +652,7 @@
 	int chan;
 
 	lsb = data[0] & 0xff;
-	msb = (data[0] >> 8) & 0xf;
+	msb = (data[0] >> 8) & 0xff;
 
 	chan = CR_CHAN(insn->chanspec);
 
diff -Naur a/drivers/staging/comedi/drivers/jr3_pci.c b/drivers/staging/comedi/drivers/jr3_pci.c
--- a/drivers/staging/comedi/drivers/jr3_pci.c	2013-11-01 20:18:04.921562867 +0200
+++ b/drivers/staging/comedi/drivers/jr3_pci.c	2013-11-01 18:44:53.569836841 +0200
@@ -917,7 +917,7 @@
 	}
 
 	/*  Reset DSP card */
-	devpriv->iobase->channel[0].reset = 0;
+	writel(0, &devpriv->iobase->channel[0].reset);
 
 	result = comedi_load_firmware(dev, "jr3pci.idm", jr3_download_firmware);
 	printk("Firmare load %d\n", result);
diff -Naur a/drivers/staging/comedi/drivers/ni_labpc.c b/drivers/staging/comedi/drivers/ni_labpc.c
--- a/drivers/staging/comedi/drivers/ni_labpc.c	2013-11-01 20:18:04.921562867 +0200
+++ b/drivers/staging/comedi/drivers/ni_labpc.c	2013-11-01 18:44:53.585836923 +0200
@@ -1178,7 +1178,9 @@
 	else
 		channel = CR_CHAN(cmd->chanlist[0]);
 	/*  munge channel bits for differential / scan disabled mode */
-	if (labpc_ai_scan_mode(cmd) != MODE_SINGLE_CHAN && aref == AREF_DIFF)
+	if ((labpc_ai_scan_mode(cmd) == MODE_SINGLE_CHAN ||
+	     labpc_ai_scan_mode(cmd) == MODE_SINGLE_CHAN_INTERVAL) &&
+	    aref == AREF_DIFF)
 		channel *= 2;
 	devpriv->command1_bits |= ADC_CHAN_BITS(channel);
 	devpriv->command1_bits |= thisboard->ai_range_code[range];
@@ -1193,21 +1195,6 @@
 		devpriv->write_byte(devpriv->command1_bits,
 				    dev->iobase + COMMAND1_REG);
 	}
-	/*  setup any external triggering/pacing (command4 register) */
-	devpriv->command4_bits = 0;
-	if (cmd->convert_src != TRIG_EXT)
-		devpriv->command4_bits |= EXT_CONVERT_DISABLE_BIT;
-	/* XXX should discard first scan when using interval scanning
-	 * since manual says it is not synced with scan clock */
-	if (labpc_use_continuous_mode(cmd) == 0) {
-		devpriv->command4_bits |= INTERVAL_SCAN_EN_BIT;
-		if (cmd->scan_begin_src == TRIG_EXT)
-			devpriv->command4_bits |= EXT_SCAN_EN_BIT;
-	}
-	/*  single-ended/differential */
-	if (aref == AREF_DIFF)
-		devpriv->command4_bits |= ADC_DIFF_BIT;
-	devpriv->write_byte(devpriv->command4_bits, dev->iobase + COMMAND4_REG);
 
 	devpriv->write_byte(cmd->chanlist_len,
 			    dev->iobase + INTERVAL_COUNT_REG);
@@ -1285,6 +1272,22 @@
 		devpriv->command3_bits &= ~ADC_FNE_INTR_EN_BIT;
 	devpriv->write_byte(devpriv->command3_bits, dev->iobase + COMMAND3_REG);
 
+	/*  setup any external triggering/pacing (command4 register) */
+	devpriv->command4_bits = 0;
+	if (cmd->convert_src != TRIG_EXT)
+		devpriv->command4_bits |= EXT_CONVERT_DISABLE_BIT;
+	/* XXX should discard first scan when using interval scanning
+	 * since manual says it is not synced with scan clock */
+	if (labpc_use_continuous_mode(cmd) == 0) {
+		devpriv->command4_bits |= INTERVAL_SCAN_EN_BIT;
+		if (cmd->scan_begin_src == TRIG_EXT)
+			devpriv->command4_bits |= EXT_SCAN_EN_BIT;
+	}
+	/*  single-ended/differential */
+	if (aref == AREF_DIFF)
+		devpriv->command4_bits |= ADC_DIFF_BIT;
+	devpriv->write_byte(devpriv->command4_bits, dev->iobase + COMMAND4_REG);
+
 	/*  startup aquisition */
 
 	/*  command2 reg */
diff -Naur a/drivers/staging/comedi/drivers/s626.c b/drivers/staging/comedi/drivers/s626.c
--- a/drivers/staging/comedi/drivers/s626.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/staging/comedi/drivers/s626.c	2013-11-01 18:44:53.609837042 +0200
@@ -2330,7 +2330,7 @@
 	/*   (data==NULL) ? (Preloadvalue=0) : (Preloadvalue=data[0]); */
 
 	k->SetMode(dev, k, Setup, TRUE);
-	Preload(dev, k, *(insn->data));
+	Preload(dev, k, data[0]);
 	k->PulseIndex(dev, k);
 	SetLatchSource(dev, k, valueSrclatch);
 	k->SetEnable(dev, k, (uint16_t) (enab != 0));
diff -Naur a/drivers/staging/vt6656/rf.c b/drivers/staging/vt6656/rf.c
--- a/drivers/staging/vt6656/rf.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/staging/vt6656/rf.c	2013-11-01 18:44:54.197839955 +0200
@@ -769,6 +769,9 @@
         return TRUE;
     }
 
+	if (uCH == 0)
+		return -EINVAL;
+
     switch (uRATE) {
     case RATE_1M:
     case RATE_2M:
diff -Naur a/drivers/stm/clk.c b/drivers/stm/clk.c
--- a/drivers/stm/clk.c	2013-11-01 20:19:18.869929548 +0200
+++ b/drivers/stm/clk.c	2013-11-01 18:44:54.253840242 +0200
@@ -334,7 +334,7 @@
 	}
 	if (clk->usage_counter)
 		/* disable the right parent if required */
-		clk_disable(ret ? parent : old_parent);
+		_clk_disable(ret ? parent : old_parent);
 
 	spin_unlock_irqrestore(&clock_lock, flags);
 
@@ -406,14 +406,10 @@
 	unsigned long rate = clk_get_rate(clk);
 	struct clk *child_clk;
 
-	seq_printf(s, "%*s%-*s: %4ld.%02ldMHz",
+	seq_printf(s, "%*s%-*s: %4ld.%02ldMHz users=%ld\n",
 		depth*2, "", 30-(depth*2), clk->name,
-		rate / 1000000, (rate % 1000000) / 10000);
-	if (clk_is_always_enabled(clk))
-		seq_printf(s, " always enabled");
-	else
-		seq_printf(s, " users=%ld", clk->usage_counter);
-	seq_printf(s, "\n");
+		rate / 1000000, (rate % 1000000) / 10000,
+		clk->usage_counter);
 
 	list_for_each_entry(child_clk, &clk->children, children_node)
 		clk_seq_show_clk(s, child_clk, depth+1);
diff -Naur a/drivers/stm/clocks/clock-stx5197.c b/drivers/stm/clocks/clock-stx5197.c
--- a/drivers/stm/clocks/clock-stx5197.c	2013-11-01 20:19:18.885929629 +0200
+++ b/drivers/stm/clocks/clock-stx5197.c	2013-11-01 18:44:54.257840258 +0200
@@ -535,7 +535,6 @@
 	CLK_WRITE(SYS_SERVICE_ADDR + setup0 + 4, pe);
 	CLK_WRITE(SYS_SERVICE_ADDR + setup0, val);
 	CLK_WRITE(SYS_SERVICE_ADDR + setup0, val | FS_PROG_EN);
-	mdelay(10);
 
 	if (used_dco) {
 		CLK_WRITE(SYS_SERVICE_ADDR + DCO_MODE_CFG, 1 | FS_PROG_EN);
diff -Naur a/drivers/stm/clocks/clock-stx5206.c b/drivers/stm/clocks/clock-stx5206.c
--- a/drivers/stm/clocks/clock-stx5206.c	2013-11-01 20:19:18.889929650 +0200
+++ b/drivers/stm/clocks/clock-stx5206.c	2013-11-01 18:44:54.257840258 +0200
@@ -523,7 +523,9 @@
 	if (!clk_p->parent)
 		/* Unsupported. Init must be called first. */
 		return CLK_ERR_BAD_PARAMETER;
-
+	if (clk_p->id == CLKA_REF)
+		/* Can't enable REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
 	/* PLL power up */
 	if (clk_p->id >= CLKA_PLL0HS && clk_p->id <= CLKA_PLL1)
 		return clkgena_xable_pll(clk_p, 1);
@@ -551,6 +553,10 @@
 	if (clk_p->id < CLKA_PLL0HS || clk_p->id > CLKA_IC_IF_200)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKA_REF)
+		/* Can't disable REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	/* Can this clock be disabled ? */
 	if (clk_p->flags & CLK_ALWAYS_ENABLED)
 		return 0;
@@ -940,6 +946,10 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		/* Can't enable REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 1);
 	else
@@ -961,6 +971,10 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		/* Can't disable REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 0);
 	else
@@ -1113,7 +1127,7 @@
 {
 	unsigned long set = 0;	/* Each bit set to 1 will be SETTED */
 	unsigned long reset = 0;	/* Each bit set to 1 will be RESETTED */
-	unsigned long reg;
+	unsigned long reg = 0;
 	unsigned long val;
 	static const char shift_table[] = {0, 2, 4, 6, 8, 10, 12};
 	/* *div_p = 0, 1, 2, 3, 4, 5, 6, 7, 8 */
@@ -1695,6 +1709,11 @@
 
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
+
+	if (clk_p->id == CLKC_REF)
+		/* Can't enable/disable REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id < CLKC_FS0_CH1 || clk_p->id > CLKC_FS0_CH4)
 		return CLK_ERR_BAD_PARAMETER;
 
diff -Naur a/drivers/stm/clocks/clock-stx7105.c b/drivers/stm/clocks/clock-stx7105.c
--- a/drivers/stm/clocks/clock-stx7105.c	2013-11-01 20:19:18.897929689 +0200
+++ b/drivers/stm/clocks/clock-stx7105.c	2013-11-01 18:44:54.257840258 +0200
@@ -522,10 +522,14 @@
 
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
+
 	if (!clk_p->parent)
 		/* Unsupported. Init must be called first. */
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKA_REF)
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	/* PLL power up */
 	if (clk_p->id >= CLKA_PLL0HS && clk_p->id <= CLKA_PLL1)
 		return clkgena_xable_pll(clk_p, 1);
@@ -552,6 +556,9 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKA_REF)
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	/* Can this clock be disabled ? */
 	if (clk_p->flags & CLK_ALWAYS_ENABLED)
 		return 0;
@@ -942,6 +949,9 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 1);
 	else
@@ -963,6 +973,9 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 0);
 	else
diff -Naur a/drivers/stm/clocks/clock-stx7108.c b/drivers/stm/clocks/clock-stx7108.c
--- a/drivers/stm/clocks/clock-stx7108.c	2013-11-01 20:19:18.901929706 +0200
+++ b/drivers/stm/clocks/clock-stx7108.c	2013-11-01 18:44:54.261840275 +0200
@@ -606,14 +606,17 @@
 		/* Unsupported. Init must be called first. */
 		return CLK_ERR_BAD_PARAMETER;
 
-	/* PLL power up */
-	if ((clk_p->id >= CLKA0_PLL0HS && clk_p->id <= CLKA0_PLL1) ||
-	    (clk_p->id >= CLKA1_PLL0HS && clk_p->id <= CLKA1_PLL1))
+	switch (clk_p->id) {
+	case CLKA1_REF:
+	case CLKA0_REF:
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	case CLKA0_PLL0HS ... CLKA0_PLL1:
+	case CLKA1_PLL0HS ... CLKA1_PLL1:
 		return clkgenax_xable_pll(clk_p, 1);
-
-	err = clkgenax_set_parent(clk_p, clk_p->parent);
-	/* clkgenax_set_parent() is performing also a recalc() */
-
+	default:
+		err = clkgenax_set_parent(clk_p, clk_p->parent);
+		/* clkgenax_set_parent() is performing also a recalc() */
+	}
 	return err;
 }
 
@@ -633,14 +636,16 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
-	/* Can this clock be disabled ? */
-	if (clk_p->flags & CLK_ALWAYS_ENABLED)
-		return 0;
-
-	/* PLL power down */
-	if ((clk_p->id >= CLKA0_PLL0HS && clk_p->id <= CLKA0_PLL1) ||
-	    (clk_p->id >= CLKA1_PLL0HS && clk_p->id <= CLKA1_PLL1))
+	switch (clk_p->id) {
+	case CLKA1_REF:
+	case CLKA0_REF:
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	case CLKA0_PLL0HS ... CLKA0_PLL1:
+	case CLKA1_PLL0HS ... CLKA1_PLL1:
 		return clkgenax_xable_pll(clk_p, 0);
+	default:
+		break;
+	}
 
 	idx = clkgenax_get_index(clk_p->id, &srcreg, &shift);
 	if (idx == -1)
@@ -1252,6 +1257,9 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 1);
 	else
diff -Naur a/drivers/stm/clocks/clock-stx7111.c b/drivers/stm/clocks/clock-stx7111.c
--- a/drivers/stm/clocks/clock-stx7111.c	2013-11-01 20:19:18.909929755 +0200
+++ b/drivers/stm/clocks/clock-stx7111.c	2013-11-01 18:44:54.261840275 +0200
@@ -492,6 +492,10 @@
 		/* Unsupported. Init must be called first. */
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKA_REF)
+		/* Can't enable the REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	/* PLL power up */
 	if (clk_p->id >= CLKA_PLL0HS && clk_p->id <= CLKA_PLL1)
 		return clkgena_xable_pll(clk_p, 1);
@@ -519,6 +523,10 @@
 	if (clk_p->id < CLKA_PLL0HS || clk_p->id > CLKA_IC_IF_200)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKA_REF)
+		/* Can't disable the REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	/* Can this clock be disabled ? */
 	if (clk_p->flags & CLK_ALWAYS_ENABLED)
 		return 0;
@@ -911,6 +919,10 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		/* Can't enable the REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 1);
 	else
@@ -932,6 +944,10 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
+	if (clk_p->id == CLKB_REF)
+		/* Can't disable the REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id >= CLKB_FS0_CH1 && clk_p->id <= CLKB_FS1_CH4)
 		err = clkgenb_xable_fsyn(clk_p, 0);
 	else
@@ -1606,6 +1622,11 @@
 
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
+
+	if (clk_p->id == CLKC_REF)
+		/* Can't enable/disable the REF clock */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+
 	if (clk_p->id < CLKC_FS0_CH1 || clk_p->id > CLKC_FS0_CH4)
 		return CLK_ERR_BAD_PARAMETER;
 
diff -Naur a/drivers/stm/clocks/clock-stx7141.c b/drivers/stm/clocks/clock-stx7141.c
--- a/drivers/stm/clocks/clock-stx7141.c	2013-11-01 20:19:18.917929788 +0200
+++ b/drivers/stm/clocks/clock-stx7141.c	2013-11-01 18:44:54.261840275 +0200
@@ -10,6 +10,9 @@
  *****************************************************************************/
 
 /* ----- Modification history (most recent first)----
+08/aug/12 carmelo.amoroso@st.com
+	  clkgenf_enable/disable, do not consider an error enabling/disabling
+	  the CLKF_REF clock, as it is always enabled.
 19/may/10 francesco.virlinzi@st.com/fabrice.charpentier@st.com
 	  Added several divisor factor on 656_1, DISP_HD. PIX_SD, etc
 11/mar/10 fabrice.charpentier@st.com
@@ -2214,7 +2217,13 @@
 
 static int clkgenf_enable(clk_t *clk_p)
 {
-	if (!clk_p || clk_p->id != CLKF_USB48)
+	if (!clk_p)
+		return CLK_ERR_BAD_PARAMETER;
+
+	if (clk_p->id == CLKF_REF)
+		/* CLKF_REF is always enabled */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	else if (clk_p->id != CLKF_USB48)
 		return CLK_ERR_BAD_PARAMETER;
 
 	if (chip_major_version() < 2)
@@ -2236,7 +2245,13 @@
 
 static int clkgenf_disable(clk_t *clk_p)
 {
-	if (!clk_p || clk_p->id != CLKF_USB48)
+	if (!clk_p)
+		return CLK_ERR_BAD_PARAMETER;
+
+	if (clk_p->id == CLKF_REF)
+		/* CLKF_REF is always enabled */
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	else if (clk_p->id != CLKF_USB48)
 		return CLK_ERR_BAD_PARAMETER;
 
 	if (chip_major_version() < 2)
diff -Naur a/drivers/stm/clocks/clock-stxh205.c b/drivers/stm/clocks/clock-stxh205.c
--- a/drivers/stm/clocks/clock-stxh205.c	2013-11-01 20:19:18.929929846 +0200
+++ b/drivers/stm/clocks/clock-stxh205.c	2013-11-01 18:44:54.265840301 +0200
@@ -847,6 +847,9 @@
 	unsigned long div, idf, ndiv, cp;
 	int err = 0;
 	long deviation, new_deviation;
+#if !defined(CLKLLA_NO_PLL)
+		unsigned long data;
+#endif
 
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
@@ -864,7 +867,6 @@
 		if (err != 0)
 			break;
 #if !defined(CLKLLA_NO_PLL)
-		unsigned long data;
 		data = CLK_READ(CKGA0_BASE_ADDRESS + CKGA_PLL0_REG0_CFG)
 				& 0xffffff00;
 		data |= ndiv;
@@ -1513,9 +1515,14 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
-	if (clk_p->id == CLK_B_REF)
+	switch (clk_p->id) {
+	case CLK_B_REF:
+	case CLK_B_FS0_VCO:
+	case CLK_B_FS1_VCO:
 		return CLK_ERR_FEATURE_NOT_SUPPORTED;
-
+	default:
+		break;
+	}
 	if (clk_p->id >= CLK_B_VID_HD_LOCAL && clk_p->id <= CLK_B_CLK_27_1)
 		err = clkgenb_xable_fsyn(clk_p, 1);
 	else
@@ -1537,8 +1544,14 @@
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
 
-	if (clk_p->id == CLK_B_REF)
+	switch (clk_p->id) {
+	case CLK_B_REF:
+	case CLK_B_FS0_VCO:
+	case CLK_B_FS1_VCO:
 		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	default:
+		break;
+	}
 
 	if (clk_p->id >= CLK_B_VID_HD_LOCAL && clk_p->id <= CLK_B_CLK_27_1)
 		err = clkgenb_xable_fsyn(clk_p, 0);
@@ -1763,6 +1776,15 @@
 
 	if (!clk_p)
 		return CLK_ERR_BAD_PARAMETER;
+
+	switch (clk_p->id) {
+	case CLK_C_REF:
+	case CLK_C_FS_VCO:
+		return CLK_ERR_FEATURE_NOT_SUPPORTED;
+	default:
+		break;
+	}
+
 	if (clk_p->id < CLK_C_SPDIF || clk_p->id > CLK_C_PCM1)
 		return CLK_ERR_BAD_PARAMETER;
 
diff -Naur a/drivers/stm/fli75xx.c b/drivers/stm/fli75xx.c
--- a/drivers/stm/fli75xx.c	2013-11-01 20:19:18.945929933 +0200
+++ b/drivers/stm/fli75xx.c	2013-11-01 18:44:54.373840840 +0200
@@ -122,6 +122,8 @@
 		emiss_nandi_select(STM_NANDI_BCH);
 		fli75xx_nand_bch_data.bank = config->banks;
 		fli75xx_nand_bch_data.bch_ecc_cfg = config->bch_ecc_cfg;
+		fli75xx_nand_bch_data.bch_bitflip_threshold =
+			config->bch_bitflip_threshold;
 		fli75xx_nandi_device.dev.platform_data =
 			&fli75xx_nand_bch_data;
 		fli75xx_nandi_device.name = "stm-nand-bch";
diff -Naur a/drivers/stm/Kconfig b/drivers/stm/Kconfig
--- a/drivers/stm/Kconfig	2013-11-01 20:19:18.869929548 +0200
+++ b/drivers/stm/Kconfig	2013-11-01 18:44:54.253840242 +0200
@@ -238,4 +238,47 @@
 	help
 	  Enable this option to print out information about the PMS
 
+config STM_LPM
+	bool "STM Low Power Monitor"
+	depends on CPU_SUBTYPE_STXH205 || CPU_SUBTYPE_STX7108
+	select LIBELF_64
+	default n
+	help
+	 Enable this option for Standby Controller support.
+
+config STM_LPM_I2C
+	bool "External SBC"
+	depends on STM_LPM &&  CPU_SUBTYPE_STX7108
+	default n
+	help
+	 Enable this option for Standby controller which is connected to SOC
+	 with i2c interface.
+
+config STM_LPM_MB
+	bool "Internal SBC"
+	depends on STM_LPM &&  CPU_SUBTYPE_STXH205
+	default n
+	help
+	 Enable this option for Standby controller which are internal to SOC.
+
+config STM_LPM_RD_MONITOR
+	bool "STLPM Monitoring power key press on GPIO"
+	depends on STM_LPM && CPU_SUBTYPE_STX7108
+	default n
+	help
+	 This enable intercept GPIO (7108_RD signal on HDK7108 board) activity.
+	 This GPIO is connected to HDK7108 board's front panel and controlled
+	 by external SBC.
+	 When user presses standby button on FP, SBC drive this PIO to low.
+	 STLPM driver intercept this GPIO interrupt and export to user land.
+	 Application can track powerkey in sysfs to check if power key on front panel
+	 is pressed or not.
+
+config STM_LPM_DEBUG
+	bool "STM Low Power Monitor debug"
+	depends on STM_LPM
+	default n
+	help
+	 Enable this option to print debug information.
+
 endmenu
diff -Naur a/drivers/stm/lpm_com.c b/drivers/stm/lpm_com.c
--- a/drivers/stm/lpm_com.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/lpm_com.c	2013-11-01 18:44:54.381840861 +0200
@@ -0,0 +1,423 @@
+/*
+ * <root>/drivers/stm/lpm_com.c
+ *
+ * This driver implements communication with Standby Controller
+ * in some STMicroelectronics devices
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+
+#include <linux/stm/lpm.h>
+#include <asm/unaligned.h>
+#include "lpm_def.h"
+
+/**
+ * stm_lpm_get_version() - To get version of driver and firmware
+ * @driver_version:	driver version
+ * @fw_version:	firmware version
+ *
+ * This function will return firmware and driver version in parameters.
+ *
+ * Return - 0 on success
+ * Return -  negative error code on failure.
+ */
+
+int stm_lpm_get_version(struct stm_lpm_version *driver_version,
+	struct stm_lpm_version *fw_version)
+{
+	int err = 0;
+	struct lpm_message response = {0};
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_VER,
+		.msg_size = 0
+	};
+	/* Check parameters */
+	if (unlikely((driver_version == NULL) || (fw_version == NULL)))
+		return -EINVAL;
+
+	/* Send message to SBC and get response */
+	err = lpm_exchange_msg(&send_msg, &response);
+	if (likely(err == 0)) {
+		/* Copy the firmware version in paramater */
+		fw_version->major_comm_protocol = response.msg_data[0] >> 4;
+		fw_version->minor_comm_protocol = response.msg_data[0] & 0x0F;
+		fw_version->major_soft = response.msg_data[1] >> 4;
+		fw_version->minor_soft = response.msg_data[1] & 0x0F;
+		fw_version->patch_soft = response.msg_data[2] >> 4;
+		fw_version->month = response.msg_data[2] & 0x0F;
+		memcpy(&fw_version->day, &response.msg_data[3], 2);
+
+		driver_version->major_comm_protocol = LPM_MAJOR_PROTO_VER;
+		driver_version->minor_comm_protocol = LPM_MINOR_PROTO_VER;
+		driver_version->major_soft = LPM_MAJOR_SOFT_VER;
+		driver_version->minor_soft = LPM_MINOR_SOFT_VER;
+		driver_version->patch_soft = LPM_PATCH_SOFT_VER;
+		driver_version->month = LPM_BUILD_MONTH;
+		driver_version->day = LPM_BUILD_DAY;
+		driver_version->year = LPM_BUILD_YEAR;
+	}
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_get_version);
+
+/**
+ * stm_lpm_configure_wdt - Set watchdog timeout for Standby Controller
+ * @time_in_ms:	timeout in milli second
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_configure_wdt(u16 time_in_ms)
+{
+	char msg[2];
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_WDT,
+		.msg = msg,
+		.msg_size = 2
+	};
+	struct lpm_message response;
+	if (!time_in_ms)
+		return -EINVAL;
+	put_unaligned_le16(time_in_ms, msg);
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_configure_wdt);
+
+/**
+ * stm_lpm_get_fw_state - Get the SBC firmware status
+ * @fw_state:	enum for firmware status
+ *
+ * Firmware status will be returned in passed parameter.
+ *
+ * Return - 0 on success
+ * Return - negative  error code on failure.
+ */
+
+int stm_lpm_get_fw_state(enum stm_lpm_sbc_state *fw_state)
+{
+	int err = 0;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_GET_STATUS,
+		.msg_size = 0
+	};
+	struct lpm_message reply_msg = {0};
+	if (fw_state == NULL)
+		return -EINVAL;
+	err = lpm_exchange_msg(&send_msg, &reply_msg);
+	if (likely(err == 0))
+		*fw_state = reply_msg.msg_data[0];
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_get_fw_state);
+
+/**
+ * stm_lpm_set_wakeup_device - To set wakeup devices
+ * @devices:	All enabled wakeup devices
+ *
+ * In older protocol version wakeup devices were limited to 8,
+ * whereas new protocol version supports upto 10 wakeup devices.
+ * Therefore two different message were used to set wakeup devices,
+ * driver checks firmware version and send wakeup device accordingly.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_set_wakeup_device(u16 devices)
+{
+	if (lpm_fw_proto_version() >= 1) {
+		struct stm_lpm_adv_feature feature;
+		feature.feature_name = STM_LPM_WU_TRIGGERS;
+		put_unaligned_le16(devices, feature.params.set_params);
+		return stm_lpm_set_adv_feature(1, &feature);
+	} else {
+		char msg = devices & 0xFF;
+		struct lpm_message response;
+		struct lpm_internal_send_msg send_msg = {
+			.command_id = LPM_MSG_SET_WUD,
+			.msg = &msg,
+			.msg_size = 1
+		};
+		/* In old protocol version max wakeup devices can be eight */
+		return lpm_exchange_msg(&send_msg, &response);
+	}
+}
+EXPORT_SYMBOL(stm_lpm_set_wakeup_device);
+
+/**
+ * stm_lpm_set_wakeup_time - To set wakeup time
+ * @timeout:	Timeout in seconds after which wakeup is required
+ *
+ * Wakeup will be done after current time + timeout
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_set_wakeup_time(u32 timeout)
+{
+	char msg[4];
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_TIMER,
+		.msg = msg,
+		.msg_size = 4
+	};
+	timeout = cpu_to_le32(timeout);
+	/* Copy timeout into message */
+	memcpy(msg, &timeout, 4);
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_set_wakeup_time);
+
+/**
+ * stm_lpm_set_rtc - To set rtc time for standby controller
+ * @new_rtc:	rtc value
+ *
+ * SBC can display RTC clock when in standby mode using this RTC value,
+ * This RTC will act as base for RTC hardware of SBC.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_set_rtc(struct rtc_time *new_rtc)
+{
+	char msg[3];
+	struct lpm_message response = {0};
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_RTC,
+		.msg = msg,
+		.msg_size = 3
+	};
+	/* Copy received values of rtc into message */
+	msg[2] = new_rtc->tm_sec;
+	msg[1] = new_rtc->tm_min;
+	msg[0] = new_rtc->tm_hour;
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_set_rtc);
+
+/**
+ * stm_lpm_get_wakeup_device - To get wake devices
+ * @wakeup_device:	wakeup device
+ *
+ * This function will return wakeup device because of which SBC has
+ * woken up the SOC.
+ * In older protocol version wakeup devices were limited to 8,
+ * whereas new Protocol version supports upto 10 wakeup devices.
+ * Therefore two different message were used to get wakeup device.
+ * Driver checks firmware version and send wakeup device accordingly.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_get_wakeup_device(enum stm_lpm_wakeup_devices *wakeup_device)
+{
+	int err = 0;
+	struct lpm_message response = {0};
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_GET_WUD,
+		.msg_size = 0
+	};
+	if (unlikely(wakeup_device == NULL))
+		return -EINVAL;
+	if (lpm_fw_proto_version() >= 1) {
+		struct stm_lpm_adv_feature  feature = {0};
+		err = stm_lpm_get_adv_feature(0, &feature);
+		if (likely(err == 0)) {
+			*wakeup_device = feature.params.get_params[5] << 8;
+			*wakeup_device |= feature.params.get_params[4];
+		}
+	} else {
+		err = lpm_exchange_msg(&send_msg, &response);
+		if (likely(err == 0))
+			*wakeup_device = response.msg_data[0];
+	}
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_get_wakeup_device);
+
+/**
+ * stm_lpm_setup_fp - To set front panel information for SBC
+ * @fp_setting:	Front panel setting
+ *
+ * This function will set front panel setting.
+ * By default host CPU is assumed to control the front panel.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_setup_fp(struct stm_lpm_fp_setting *fp_setting)
+{
+	char msg;
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_FP,
+		.msg = &msg,
+		.msg_size = 1
+	};
+	if (unlikely(fp_setting == NULL))
+		return -EINVAL;
+
+	msg = fp_setting->owner & OWNER_MASK;
+	msg |= (fp_setting->am_pm & 1) << 2;
+	msg |= (fp_setting->brightness & NIBBLE_MASK) << 4;
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_setup_fp);
+
+/**
+ * stm_lpm_setup_pio - To inform SBC about PIO Use
+ * @pio_setting:	pio_setting
+ *
+ * This function will inform SBC about PIO use,
+ * driver running on Host must configure the PIO.
+ * SBC will not do any configuration for PIO.
+ * GPIO can be used as power control for board,
+ * gpio interrupt, external interrupt, Phy WOL wakeup.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_setup_pio(struct stm_lpm_pio_setting *pio_setting)
+{
+	char msg[3];
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_PIO,
+		.msg = msg,
+		.msg_size = 3
+	};
+	if (unlikely(pio_setting == NULL || (pio_setting->pio_direction
+		 && pio_setting->interrupt_enabled)))
+		return -EINVAL;
+
+	msg[0] = pio_setting->pio_bank;
+	if (pio_setting->pio_use == STM_LPM_PIO_EXT_IT)
+		msg[0] = 0xFF;
+
+	pio_setting->pio_pin &= NIBBLE_MASK;
+	msg[1] = pio_setting->pio_level << PIO_LEVEL_SHIFT |
+	pio_setting->interrupt_enabled <<  PIO_IT_SHIFT |
+	pio_setting->pio_direction << PIO_DIRECTION_SHIFT |
+	pio_setting->pio_pin ;
+
+	msg[2] = pio_setting->pio_use;
+
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_setup_pio);
+
+/**
+ * stm_lpm_setup_keyscan - To inform SBC about wakeup key of Keyscan
+ * @key_data:	Keyscan Key info
+ *
+ * This function will inform SBC about keyscan key
+ * on which SBC will wakeup.
+ * Driver running on Host must configure the Keyscan IP.
+ * SBC will not do any configuration.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_setup_keyscan(u16 key_data)
+{
+	char msg[2];
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_KEY_SCAN,
+		.msg = msg,
+		.msg_size = 2
+	};
+	memcpy(msg, &key_data, 2);
+	return  lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_setup_keyscan);
+
+/**
+ * stm_lpm_set_adv_feature - Set advance feature of SBC
+ * @enabled:	If feature needs to enabled
+ * 		pass 1 for enabling, 0 disabling
+ * @feature:	Feature type and its parameters.
+ * 		Features can be :
+ * 		SBC VCORE External without parameter.
+ * 		SBC Low voltage detect with value of voltage.
+ * 		SBC clock selection(external, AGC or 32K).
+ * 		SBC RTC source 32K_TCXO or 32K_OSC
+ * 		SBC Wakeup triggers.
+ *
+ * This function will enable/disable selected feature on SBC
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_set_adv_feature(u8 enabled, struct stm_lpm_adv_feature *feature)
+{
+	char msg[4];
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_SET_ADV_FEA,
+		.msg = msg,
+		.msg_size = 4
+	};
+	if (unlikely(feature == NULL))
+		return -EINVAL;
+	memcpy((msg+2), feature->params.set_params, 2);
+	msg[0] = feature->feature_name;
+	msg[1] = enabled;
+	return lpm_exchange_msg(&send_msg, &response);
+}
+EXPORT_SYMBOL(stm_lpm_set_adv_feature);
+
+/**
+ * stm_lpm_get_adv_feature - To get current/supported features of SBC
+ * @all_features:	If required to get all features.
+ * 			pass 1 to get all supported features by SBC.
+ * 			pass 0 to get all current enabled feature of SBC.
+ * @features:		structure to get features of SBC
+ *
+ * Supported or currently  enabled features will be returned in get_params
+ * field of features argument.
+ * get_params[0-3] are bit map for each feature. Bit map 0-3 is reserved
+ * get_params[4-5] are bit map for wakeup triggers.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+int stm_lpm_get_adv_feature(unsigned char all_features,
+			struct stm_lpm_adv_feature *features)
+{
+	char msg = 0;
+	int err = 0;
+	struct lpm_message response;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_GET_ADV_FEA,
+		.msg = &msg,
+		.msg_size = 1
+	};
+	if (unlikely(features == NULL))
+		return -EINVAL;
+	if (all_features == 1)
+		msg = 1;
+	err = lpm_exchange_msg(&send_msg, &response);
+	if (likely(err == 0))
+		memcpy(features->params.get_params, response.msg_data, 6);
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_get_adv_feature);
diff -Naur a/drivers/stm/lpm_def.h b/drivers/stm/lpm_def.h
--- a/drivers/stm/lpm_def.h	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/lpm_def.h	2013-11-01 18:44:54.381840861 +0200
@@ -0,0 +1,326 @@
+/*
+ * <root>/drivers/stm/lpm_def.h
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+#ifndef __LPM_DEF_H_
+#define __LPM_DEF_H_
+#include <linux/i2c.h>
+/*
+ * LPM protocol has following architecture
+ * |	byte0	|	byte1	|	byte2	|	byte3	|
+ * |	cmd id	|	transid	|	msgdata	|	msgdata	|
+ *
+ * cmd id is command id
+ * transid is Transaction ID
+ * msgdata is data part of message
+ * msg data size can vary depending upon command
+ *
+ * In case of internal SBC, communication will be done using mailbox.
+ * mailbox has depth of 16 bytes.
+ * When message is greater than 16 bytes, such messages are treated as big
+ * messages and will be send by directly writing into DMEM of SBC.
+ *
+ * In case of external SBC (7108), which is connected with SOC via i2c
+ * communication will be done using i2c bus.
+ *
+ * Internal and external standby controllers expect message in
+ * little endian mode
+ */
+
+/* Message command ids */
+
+/* No operation */
+#define LPM_MSG_NOP		0x0
+
+/* Command id to retrieve version number */
+#define LPM_MSG_VER		0x1
+
+/* Command id to read current RTC value */
+#define LPM_MSG_READ_RTC	0x3
+
+/* Command id to trim RTC */
+#define LPM_MSG_SET_TRIM	0x4
+
+/* Command id to enter in passive standby mode */
+#define LPM_MSG_ENTER_PASSIVE	0x5
+
+/* Command id  to set watch dog timeout of SBC */
+#define LPM_MSG_SET_WDT		0x6
+
+/* Command id  to set new RTC value for SBC */
+#define LPM_MSG_SET_RTC		0x7
+
+/* Command id  to configure frontpanel display */
+#define LPM_MSG_SET_FP		0x8
+
+/* Command id to set wakeup time */
+#define LPM_MSG_SET_TIMER	0x9
+
+/* Command id to get status of SBC CPU */
+#define LPM_MSG_GET_STATUS	0xA
+
+/* Command id to generate reset */
+#define LPM_MSG_GEN_RESET	0xB
+
+/* Command id to set wakeup device */
+#define LPM_MSG_SET_WUD		0xC
+
+/* Command id to get wakeup device */
+#define LPM_MSG_GET_WUD		0xD
+
+/* Command id to offset in SBC memory */
+#define LPM_MSG_LGWR_OFFSET	0x10
+
+/* Command id to inform PIO setting */
+#define LPM_MSG_SET_PIO		0x11
+
+/* Command id to get advance features */
+#define LPM_MSG_GET_ADV_FEA	0x12
+
+/* Command id to set advance features */
+#define LPM_MSG_SET_ADV_FEA	0x13
+
+/* Command id to set key scan data */
+#define LPM_MSG_SET_KEY_SCAN	0x14
+
+/*
+ * Command id to set IR information on SBC CPU,
+ * these are IR keys on which SBC will do wakeup.
+ */
+#define LPM_MSG_SET_IR		0x41
+
+/* Command id to get data associated with some wakeup device */
+#define LPM_MSG_GET_IRQ		0x42
+
+/*
+ * Command id to inform trace data of SBC,
+ * SBC can send trace data to host using this command
+ */
+#define LPM_MSG_TRACE_DATA	0x43
+
+/* Command id to read message from SBC memory */
+#define LPM_MSG_BKBD_READ	0x44
+
+/* Command id inform SBC that write to SBC memory is done */
+#define LPM_MSG_BKBD_WRITE	0x45
+
+/* Bit-7 of command id used to mark reply from other CPU */
+#define LPM_MSG_REPLY		0x80
+
+/* Command for error */
+#define LPM_MSG_ERR		0x82
+
+/*
+ * Version number of driver , this has following fields
+ * protocol major and minor number
+ * software major, minor and patch number
+ * software release build, month, day and year
+ */
+#define LPM_MAJOR_PROTO_VER	1
+#define LPM_MINOR_PROTO_VER	0
+#define LPM_MAJOR_SOFT_VER	1
+#define LPM_MINOR_SOFT_VER	3
+#define LPM_PATCH_SOFT_VER	0
+#define LPM_BUILD_MONTH		9
+#define LPM_BUILD_DAY		7
+#define LPM_BUILD_YEAR		12
+
+/*
+ * Maximum size of message data that can be send over mailbox,
+ * mailbox is 16 byte deep, and 2 bytes are reserved for command
+ * and transaction id.
+ */
+#define LPM_MAX_MSG_DATA	14
+
+/*
+ * Address of external standby controller which is connected with i2c bus.
+ * This address is kept fixed in external standby controller's firmware.
+ */
+#define ADDRESS_OF_EXT_MC	0x94
+
+/*
+ * For internal standby controller
+ * Various offset of LPM IP, These offsets are w.r.t LPM memory resources.
+ * There are three LPM memory resources used
+ * first is for SBC DMEM and IMEM,
+ * second is for SBC mailbox,
+ * third is for SBC configuration registers.
+ */
+
+/* SBC data memory offset as seen by Host w.r.t mem resource 1 */
+#define DATA_OFFSET		0x010000
+
+/* SBC program memory as offset seen by Host w.r.t mem resource 1 */
+#define SBC_PRG_MEMORY_OFFSET	0x018000
+
+/* Marker in elf file to indicate writing to program area */
+#define SBC_PRG_MEMORY_ELF_MARKER	0x00400000
+
+/* SBC mailbox offset as seen by Host w.r.t mem source 2 */
+#define SBC_MBX_OFFSET		0
+
+/* SBC configuration register offset as seen on Host w.r.t mem source 3 */
+#define SBC_CONFIG_OFFSET	0
+
+/*
+ * Mailbox registers to be written by host,
+ * SBC firmware will read below registers to get host message.
+ * There are four such registers in mailbox each of 4 bytes.
+ */
+
+#define MBX_WRITE_STATUS1	(SBC_MBX_OFFSET + 0x004)
+#define MBX_WRITE_STATUS2	(SBC_MBX_OFFSET + 0x008)
+#define MBX_WRITE_STATUS3	(SBC_MBX_OFFSET + 0x00C)
+#define MBX_WRITE_STATUS4	(SBC_MBX_OFFSET + 0x010)
+
+/*
+ * Mailbox registers to be read by host,
+ * SBC firmware will write below registers to send message.
+ * There are four such registers in mailbox each of 4 bytes.
+ */
+
+#define MBX_READ_STATUS1	(SBC_MBX_OFFSET + 0x104)
+#define MBX_READ_STATUS2	(SBC_MBX_OFFSET + 0x108)
+#define MBX_READ_STATUS3	(SBC_MBX_OFFSET + 0x10C)
+#define MBX_READ_STATUS4	(SBC_MBX_OFFSET + 0x110)
+
+/* To clear mailbox interrupt status */
+#define MBX_READ_CLR_STATUS1	(SBC_MBX_OFFSET + 0x144)
+
+/* To enable/disable mailbox interrupt on Host :RW */
+#define MBX_INT_ENABLE		(SBC_MBX_OFFSET + 0x164)
+
+/* To enable mailbox interrupt on Host : WO only set allowed */
+#define MBX_INT_SET_ENABLE	(SBC_MBX_OFFSET + 0x184)
+
+/* To disable mailbox interrupt on Host : WO only clear allowed */
+#define MBX_INT_CLR_ENABLE	(SBC_MBX_OFFSET + 0x1A4)
+
+/*
+ * From host there are three type of message can be send to SBC
+ * No reply expected from SBC i.e. reset SBC, Passive standby
+ * Reply is expected from SBC i.e. get version etc.
+ * Reply is expected but interrupts are disabled
+ */
+#define SBC_REPLY_NO		0
+#define SBC_REPLY_YES		0x1
+#define SBC_REPLY_NO_IRQ	0x2
+
+/* Used to mask a byte */
+#define BYTE_MASK		0xFF
+
+/* For FP setting, mask to get owner's 2 bits */
+#define OWNER_MASK		0x3
+
+/* For FP setting, mask to brightness of LED 's 4 bits */
+#define NIBBLE_MASK		0xF
+
+/* Mask to get MSB of a half word */
+#define M_BIT_MASK		0x7FFFF
+
+/**
+ * Mask for PIO level, interrupt and  direction
+ * Bit 7 is used for level
+ * bit 6 is used for interrupt and
+ * bit 5 is used for direction of PIO
+ */
+#define PIO_LEVEL_SHIFT 	7
+#define PIO_IT_SHIFT 		6
+#define PIO_DIRECTION_SHIFT 	5
+
+/* Mask to get MSB of a half word */
+#define MASK_BIT_MASK		0x8000
+
+/* Message send to SBC does not have msg data */
+#define MSG_ZERO_SIZE		0
+
+/* Transaction id will be generated by lpm itself */
+#define MSG_ID_AUTO		0
+
+/* To write 8 bit data into LPM */
+#define lpm_write8(drv, offset, value)     iowrite8(value,	\
+				(drv)->lpm_mem_base[0] + offset)
+
+/* To read 8 bit data into LPM */
+#define lpm_read8(drv, offset) ioread8((drv)->lpm_mem_base[0] + \
+					offset)
+
+/* To write 32 bit data into LPM */
+#define lpm_write32(drv, index, offset, value)    iowrite32(value, \
+			(drv)->lpm_mem_base[index] + offset)
+
+/* To read 32 bit data into LPM */
+#define lpm_read32(drv, idx, offset)	ioread32( \
+			(drv)->lpm_mem_base[idx] + offset)
+
+/**
+ * lpm_message - LPM message for cross CPU communication
+ * @command_id:	Command ID
+ * @transaction_id: 	Transaction id
+ * @msg_data:	Message data associated with this command
+ *
+ * Normally each message is less than 16 bytes
+ * Any message more than 16 bytes considered as big message
+ *
+ * Internal and external SBC treats big message in different way
+ *
+ * In case of internal SBC, where size of mailbox is 16 byte
+ * If message is large then 16 bytes then direct write to SBC memory is done
+ *
+ * In case of external SBC,
+ * No special treatment for big messages, such messages are sent over
+ * serial i2c bus
+ */
+
+struct lpm_message {
+	unsigned char command_id;
+	unsigned char transaction_id;
+	unsigned char msg_data[LPM_MAX_MSG_DATA];
+} __attribute__((packed));
+
+/**
+ * lpm_internal_send_msg - Internal struct of driver
+ * @command_id:	command id
+ * @msg :	message part of command
+ * @msg_size:	size of message
+ * @trans_id :	Transaction id
+ * @reply_type :	reply type
+ */
+struct lpm_internal_send_msg {
+	unsigned char command_id;
+	unsigned char *msg;
+	unsigned char msg_size;
+	unsigned char trans_id;
+};
+
+
+/**
+ * lpm_exchange_msg - Internal function to exchange message with SBC
+ * @send_msg :	Message sent to SBC
+ * @response :	Response of SBC
+ */
+int lpm_exchange_msg(struct lpm_internal_send_msg *send_msg,
+		struct lpm_message *response);
+
+/**
+ * lpm_fw_proto_version - Internal function to get major firmware version
+ */
+char lpm_fw_proto_version(void);
+
+#ifdef CONFIG_STM_LPM_RD_MONITOR
+/* To monitor power pin on 7108*/
+void lpm_stop_power_monitor(struct i2c_client *client);
+int  lpm_start_power_monitor(struct i2c_client *client);
+#endif
+
+
+#endif /*__LPM_DEF_H*/
diff -Naur a/drivers/stm/lpm_gpio_monitor.c b/drivers/stm/lpm_gpio_monitor.c
--- a/drivers/stm/lpm_gpio_monitor.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/lpm_gpio_monitor.c	2013-11-01 18:44:54.381840861 +0200
@@ -0,0 +1,123 @@
+/*
+ * <root>/drivers/stm/lpm_gpio_monitor.c
+ *
+ * This will intercept GPIO connected with external SBC
+ * and export this GPIO activity into user space
+ *
+ * Use case: On user press of powerkey, box should go in standby,
+ * on subsequent standby key press, box should be become active.
+ *
+ * External SBC will drive this PIO,
+ * When user presses standby key on front panel then SBC will drive it to low,
+ * on getting low on this gpio, an interrupt will be received on host for gpio.
+ * Host will export this as powerkey press for user in sys-fs interface.
+ * On seeing power key press, user must initiate movement into HoM mode.
+ * On exiting HoM mode, SBC will drive it to high.
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+#include <linux/interrupt.h>
+#include <linux/i2c.h>
+#include <linux/stm/gpio.h>
+#include <linux/stm/lpm.h>
+#include <linux/stm/platform.h>
+
+/**
+ * monitor_gpio_handler - ISR for GPIO
+ * @irq:	irq
+ * @ptr:	data
+ */
+
+static irqreturn_t monitor_gpio_handler(int irq, void *ptr)
+{
+	struct stm_lpm_i2c_data *i2c_data;
+	struct i2c_client *client_data = ptr;
+	i2c_data = i2c_get_clientdata(client_data);
+	i2c_data->status_gpio = 0;
+	return IRQ_HANDLED;
+}
+
+/**
+ * stm_lpm_show_powerkey - to show power key in user space
+ * @dev:	device pointer
+ * @attr:	attribute pointer
+ * @buf :	buffer pointer
+ */
+
+static ssize_t stm_lpm_show_powerkey(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	int ret = 0;
+	struct stm_lpm_i2c_data  *i2c_data = dev->platform_data;
+	pr_debug("\n power key pressed %s\n",
+	i2c_data->status_gpio == 0 ? "Yes" : "No");
+	ret = sprintf(buf, "%d \n", i2c_data->status_gpio);
+	return ret;
+}
+
+static DEVICE_ATTR(powerkey, S_IRUGO, stm_lpm_show_powerkey, NULL);
+
+/**
+ * lpm_start_power_monitor - gpio monitor init function
+ * @client_data:	i2c client info
+ *
+ * This function register ISR with GPIO which is controlled by SBC
+ * and exports this GPIO into user land.
+ *
+ * Return - 0 on success
+ * Return - negative error on failure.
+ */
+
+int __init lpm_start_power_monitor(struct i2c_client *client_data)
+{
+	int ret = 0;
+	struct stm_lpm_i2c_data *i2c_data;
+	i2c_data = i2c_get_clientdata(client_data);
+	pr_debug("Platform data gpio no %d", i2c_data->number_gpio);
+	/* Request gpio */
+	ret = gpio_request(i2c_data->number_gpio, "monitor_gpio");
+
+	if (ret < 0) {
+		pr_err("stm_lpm : ERROR %d gpio pin request failed\n", ret);
+		return ret;
+	}
+	/* Configure gpio for power key press */
+	gpio_direction_input(i2c_data->number_gpio);
+	set_irq_type(gpio_to_irq(i2c_data->number_gpio), IRQF_TRIGGER_FALLING);
+
+	ret = request_irq(gpio_to_irq(i2c_data->number_gpio),
+				monitor_gpio_handler, IRQF_DISABLED,
+				"monitor_irq", client_data);
+	if (ret < 0) {
+		gpio_free(i2c_data->number_gpio);
+		pr_err("stm_lpm : ERROR %d irq request failed\n", ret);
+		return ret;
+	}
+	/* At init mark power key is not pressed */
+	i2c_data->status_gpio = 1;
+	ret = device_create_file(&(client_data->dev), &dev_attr_powerkey);
+	if (ret < 0) {
+		pr_err("stm_lpm : ERROR %d dev file creation failed\n", ret);
+		gpio_free(i2c_data->number_gpio);
+	}
+	return ret;
+}
+/**
+ * lpm_stop_power_monitor - free resources used for gpio monitor
+ * @client_data:	i2c client info
+ */
+
+void lpm_stop_power_monitor(struct i2c_client *client_data)
+{
+	struct stm_lpm_i2c_data *i2c_data = i2c_get_clientdata(client_data);
+	device_remove_file(&(client_data->dev), &dev_attr_powerkey);
+	gpio_free(i2c_data->number_gpio);
+}
diff -Naur a/drivers/stm/lpm_i2c.c b/drivers/stm/lpm_i2c.c
--- a/drivers/stm/lpm_i2c.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/lpm_i2c.c	2013-11-01 18:44:54.381840861 +0200
@@ -0,0 +1,413 @@
+/*
+ * <root>/drivers/stm/lpm_i2c.c
+ *
+ * This driver implements communication with external SBC
+ * over i2c bus in some STMicroelectronics devices.
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited.
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+#include <linux/stm/lpm.h>
+#include <linux/module.h>
+#include <linux/stm/platform.h>
+#include "lpm_def.h"
+
+#ifdef CONFIG_STM_LPM_DEBUG
+#define lpm_debug(fmt, ...) pr_debug(fmt, ##__VA_ARGS__)
+#else
+#define lpm_debug(fmt, ...)
+#endif
+
+/**
+ * struct stm_lpm_driver_data - Driver data for i2c based lpm driver
+ * @i2c_sbc_adapter:	I2C adapter used for communication with SBC
+ * @gbltrans_id: 	transaction id
+ * @fw_major_ver: 	major firmware version of Standby Controller
+ * @msg_protection_mutex:	protection mutex for i2c bus access
+ */
+
+struct stm_lpm_driver_data{
+	struct i2c_adapter *i2c_sbc_adapter;
+	u8 gbltrans_id;
+	char fw_major_ver;
+	struct mutex msg_protection_mutex;
+};
+
+static struct stm_lpm_driver_data *lpm_drv;
+
+static const struct i2c_device_id lpm_ids[] = {
+	{ "stm-lpm", 0 },
+	{ /* END OF LIST */ }
+};
+MODULE_DEVICE_TABLE(i2c, lpm_ids);
+
+/**
+ * stm_lpm_setup_ir() - To set ir key setup
+ * @num_keys:	number of IR keys
+ * @ir_key_info:	information of IR keys
+ *
+ * External SBC firmware does not support this.
+ */
+
+int stm_lpm_setup_ir(u8 num_keys, struct stm_lpm_ir_keyinfo *ir_key_info)
+{
+	return -ENOSYS;
+}
+EXPORT_SYMBOL(stm_lpm_setup_ir);
+
+/**
+ * stm_lpm_get_wakeup_info() - To get additional data from wakeup device
+ * @wakeupdevice:	device ID
+ * @validsize:	read valid size will be returned
+ * @datasize: 	data size to read
+ * @data: 	data pointer
+ *
+ * External SBC firmware does not support this.
+ */
+
+int stm_lpm_get_wakeup_info(enum stm_lpm_wakeup_devices *wakeupdevice,
+	u16 *validsize, u16 datasize, char *data)
+{
+	return -ENOSYS;
+}
+EXPORT_SYMBOL(stm_lpm_get_wakeup_info);
+
+/**
+ * stm_lpm_reset() - To reset part of full SOC
+ * @reset_type:	type of reset
+ *
+ * External SBC firmware does not support this.
+ */
+
+int stm_lpm_reset(enum stm_lpm_reset_type reset_type)
+{
+	return -ENOSYS;
+}
+EXPORT_SYMBOL(stm_lpm_reset);
+
+/**
+ * lpm_recv_response_i2c() - To get response from SBC
+ * @command_id:	command id of message
+ * @msg:	message pointer
+ *
+ * Return - Code returned from i2c_transfer
+ */
+
+static int lpm_recv_response_i2c(char command_id, struct lpm_message *msg)
+{
+	struct i2c_msg i2c_message = {
+		.addr = ADDRESS_OF_EXT_MC,
+		.flags = I2C_M_RD,
+		.buf = (char *)msg,
+		.len = 2
+	};
+	int err;
+
+	/* Fill message expected length */
+	switch (command_id) {
+	default:
+		break;
+
+	case LPM_MSG_VER:
+		i2c_message.len = 7;
+		break;
+	case LPM_MSG_READ_RTC:
+		i2c_message.len = 8;
+		break;
+	case LPM_MSG_GET_STATUS:
+	case LPM_MSG_GET_WUD:
+		i2c_message.len = 4;
+		break;
+	case LPM_MSG_GET_ADV_FEA:
+		i2c_message.len = 8;
+	}
+	/* Transact with SBC */
+	err = i2c_transfer(lpm_drv->i2c_sbc_adapter, &i2c_message, 1);
+	lpm_debug("i2c_transfer response  is %d \n", err);
+	return err;
+}
+
+/**
+ * lpm_send_msg() - Send message to SBC
+ * @msg:	message pointer
+ * @msg_size: 	message size
+ *
+ * Return - Code returned from i2c_transfer
+ */
+
+static int lpm_send_msg(char *msg, unsigned char msg_size)
+{
+	int err;
+	struct i2c_msg i2c_message = {
+		.addr = ADDRESS_OF_EXT_MC,
+		.flags = 0,
+		.buf = (char *) msg,
+		.len = msg_size+2
+	};
+	lpm_debug("lpm_send_msg, size of msg %d \n", msg_size + 2);
+	err = i2c_transfer(lpm_drv->i2c_sbc_adapter, &i2c_message, 1);
+	lpm_debug("i2c_transfer send  is %d \n", err);
+	return err;
+}
+
+/**
+ * lpm_exchange_msg() - Internal function  used for message exchange with SBC
+ * @send_msg:	message to send
+ * @response:	response from SBC firmware
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure
+ */
+
+int lpm_exchange_msg(struct lpm_internal_send_msg *send_msg,
+		struct lpm_message *response)
+{
+	char  *lpm_msg = NULL;
+	struct lpm_message msg = {0};
+	int err = 0;
+	int response_needed = 1;
+
+	lpm_debug("lpm_exchange_msg \n");
+	if (unlikely(send_msg->msg_size > LPM_MAX_MSG_DATA)) {
+		/* We would enter into this condition very rarely */
+		lpm_msg = kmalloc(send_msg->msg_size + 2, GFP_KERNEL);
+		if (unlikely(!lpm_msg))
+			return -ENOMEM;
+	} else {
+		lpm_msg = (char *)&msg;
+	}
+
+	if (response == NULL)
+		response_needed = 0;
+
+	mutex_lock(&lpm_drv->msg_protection_mutex);
+	lpm_msg[0] = send_msg->command_id;
+	lpm_msg[1] = lpm_drv->gbltrans_id++;
+	if (send_msg->msg_size)
+		memcpy(&lpm_msg[2], send_msg->msg, send_msg->msg_size);
+
+	lpm_debug("Send msg {%x, %x } \n", lpm_msg[0], lpm_msg[1]);
+
+	err = lpm_send_msg(lpm_msg, send_msg->msg_size);
+	if (unlikely(err <= 0)) {
+		pr_err("f/w is not responding \n");
+		err = -EAGAIN;
+		goto exit;
+	}
+	if (response_needed == 0)
+		goto exit;
+
+	err = lpm_recv_response_i2c(send_msg->command_id, response);
+	if (unlikely(err <= 0)) {
+		pr_err("f/w reply not received \n");
+		err = -EAGAIN;
+		goto exit;
+	}
+	lpm_debug("recd reply  %d {%x, %x } \n", err, response->command_id,
+		response->transaction_id);
+
+	BUG_ON(!(response->command_id & LPM_MSG_REPLY));
+	if (lpm_msg[1] == response->transaction_id) {
+		if (response->command_id == LPM_MSG_ERR) {
+			pr_err("f/w error code %d \n", response->msg_data[1]);
+			/*
+			 * Firmware does not support this command
+			 * therefore firmware gave error.
+			 * In such cases, return EREMOTEIO as firmware error
+			 * code is not yet decided.
+			 * To Do
+			 * conversion of firmware error into Linux world
+			 */
+			err = -EREMOTEIO;
+		}
+	} else {
+		/* In case of i2c, same tran id is expected as of command */
+		pr_err("Received  ID %d expected %d", response->transaction_id,
+				lpm_msg[1]);
+		err = -EREMOTEIO;
+	}
+
+exit:
+	mutex_unlock(&lpm_drv->msg_protection_mutex);
+
+	/* If we have allocated lpm_msg then free this message */
+	if (send_msg->msg_size > LPM_MSG_REPLY)
+		kfree(lpm_msg);
+	if (err > 0)
+		err = 0;
+	return err;
+}
+
+/**
+ * lpm_enter_passive_standby() - To inform SBC to get ready for standby
+ *
+ * This will inform SBC to get ready for standby
+ * Actual power off command to SBC will be send by kernel itself
+ * by generating i2c violation.
+ *
+ * Return code 0 on success
+ * Return code  negative error code on failure.
+ */
+
+static int lpm_enter_passive_standby(void)
+{
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_ENTER_PASSIVE,
+		.msg_size = 0
+	};
+	return lpm_exchange_msg(&send_msg, NULL);
+}
+
+/**
+ * lpm_fw_proto_version() - To get firmware major protocol version
+ *
+ * return major protocol version of firmware
+ */
+
+char lpm_fw_proto_version(void)
+{
+	return lpm_drv->fw_major_ver;
+}
+
+/**
+ * stm_lpm_probe() - Probe function of driver
+ * @client_data:	i2c client data
+ * @id:	2c device id
+ *
+ * Return - 0 on success
+ * Return - negative error  on failure
+ */
+
+static int __init stm_lpm_probe(struct i2c_client *client_data,
+				const struct i2c_device_id *id)
+{
+	struct stm_lpm_i2c_data *i2c_data;
+	int err = 0;
+	struct stm_lpm_version driver_ver, fw_ver;
+	lpm_debug("stm lpm probe \n");
+	/* Allocate data structure */
+	lpm_drv = kzalloc(sizeof(struct stm_lpm_driver_data), GFP_KERNEL);
+	if (unlikely(lpm_drv == NULL)) {
+		pr_err("%s: Request memory not done\n", __func__);
+		return -ENOMEM;
+	}
+	i2c_data = i2c_get_clientdata(client_data);
+	if (unlikely(i2c_data == NULL)) {
+		pr_err("No i2c_bus data\n");
+		err = -ENOENT;
+		goto exit;
+	}
+
+	lpm_drv->i2c_sbc_adapter = i2c_data->i2c_adap;
+	if (lpm_drv->i2c_sbc_adapter == NULL) {
+		pr_err("i2c adapter not found \n");
+		err = -ENODEV;
+		goto exit;
+	}
+	lpm_debug("stm lpm i2c adapter found at %d i2c is %x \n",
+	i2c_data->number_i2c, (unsigned int)lpm_drv->i2c_sbc_adapter);
+
+	/* Mark parent */
+	client_data->dev.parent = &lpm_drv->i2c_sbc_adapter->dev;
+	/* Mutex initialization */
+	mutex_init(&lpm_drv->msg_protection_mutex);
+	err = stm_lpm_get_version(&driver_ver, &fw_ver);
+	if (unlikely(err < 0)) {
+		pr_err("No SBC firmware available \n");
+		goto exit;
+	}
+	lpm_drv->fw_major_ver = fw_ver.major_comm_protocol;
+#ifdef CONFIG_STM_LPM_RD_MONITOR
+	/* Start monitor front panel power key */
+	err = lpm_start_power_monitor(client_data);
+#endif
+	return err;
+exit:
+	kfree(lpm_drv);
+	return err;
+}
+
+/**
+ * stm_lpm_remove() - To free used resources
+ * @client:	i2c client data
+ * Return code  0
+ */
+
+static int stm_lpm_remove(struct i2c_client *client)
+{
+	lpm_debug("stm_lpm_remove \n");
+#ifdef CONFIG_STM_LPM_RD_MONITOR
+	lpm_stop_power_monitor(client);
+#endif
+	kfree(lpm_drv);
+	return 0;
+}
+
+/**
+ * stm_lpm_freeze() - Freeze callback
+ * @i2c_data:	i2c client data
+ *
+ * Return - 0 on sucess
+ * Return - negative error on failure
+ */
+
+static int stm_lpm_freeze(struct i2c_client *i2c_data)
+{
+	lpm_debug("stm_lpm_freeze state \n");
+	return lpm_enter_passive_standby();
+}
+
+/**
+ * stm_lpm_restore() - Restore callback
+ * @i2c_data:	i2c client data
+ *
+ * Return - 0 on success
+ */
+
+static int stm_lpm_restore(struct i2c_client *i2c_data)
+{
+	struct stm_lpm_i2c_data *i2c_device_data;
+	lpm_debug("stm_lpm_restore \n");
+	i2c_device_data = i2c_get_clientdata(i2c_data);
+	/* We return from CPS, mark power key as not pressed */
+	i2c_device_data->status_gpio = 1;
+	return 0;
+}
+
+static struct i2c_driver stm_lpm_driver = {
+	.driver.name = "stm-lpm",
+	.driver.owner = THIS_MODULE,
+	.probe = stm_lpm_probe,
+	.remove = stm_lpm_remove,
+	.freeze = stm_lpm_freeze,
+	.restore = stm_lpm_restore,
+	.id_table = lpm_ids,
+};
+
+static int __init stm_lpm_init(void)
+{
+	int err = -ENXIO;
+	err = i2c_add_driver(&stm_lpm_driver);
+	lpm_debug("stm lpm init err %d \n", err);
+	return err;
+}
+
+void __exit stm_lpm_exit(void)
+{
+	i2c_del_driver(&stm_lpm_driver);
+	lpm_debug("stm lpm driver removed \n");
+}
+
+module_init(stm_lpm_init);
+module_exit(stm_lpm_exit);
+
+MODULE_AUTHOR("STMicroelectronics  <www.st.com>");
+MODULE_DESCRIPTION("lpm device driver for STMicroelectronics devices");
+MODULE_LICENSE("GPL");
diff -Naur a/drivers/stm/lpm_mb.c b/drivers/stm/lpm_mb.c
--- a/drivers/stm/lpm_mb.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/lpm_mb.c	2013-11-01 18:44:54.381840861 +0200
@@ -0,0 +1,898 @@
+/*
+ * <root>/drivers/stm/lpm_mb.c
+ *
+ * This driver implements communication with internal Standby Controller
+ * over mailbox interface in some STMicroelectronics devices.
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited.
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+#include <linux/stm/lpm.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/stm/platform.h>
+#include <linux/firmware.h>
+#include "lpm_def.h"
+#include <linux/libelf.h>
+#include <asm/unaligned.h>
+
+
+#ifdef CONFIG_STM_LPM_DEBUG
+#define lpm_debug(fmt, ...) pr_debug(fmt, ##__VA_ARGS__)
+#else
+#define lpm_debug(fmt, ...)
+#endif
+
+/**
+ * stm_lpm_driver_data - Local struct of driver
+ * @lpm_mem_base[3]:	memory region mapped by driver
+ * 		lpm_mem_base[0] is SBC program and data base address
+ * 		size of lpm_mem_base[0] is 0xA0000
+ *		lpm_mem_base[1] is SBC mailbox address
+ *		size of lpm_mem_base[1] is 0x400
+ * 		lpm_mem_base[2] is SBC configuration  address
+ * 		size of lpm_mem_base[1] is 0x200
+ * @fw_reply_msg:	reply message from firmware
+ * @fw_request_msg:	firmware request message
+ * @fw_name:	Name of firmware
+ * @reply_from_sbc:	reply from SBC, true in case reply received
+ * @fw_major_ver:	SBC's firmware Protocol major version number
+ * @stm_lpm_wait_queue:	work queue
+ * @msg_protection_mutex:	message protection mutex
+ * @glbtrans_id:	global transaction id used in communication
+ * @lpm_sbc_reply_work:	work struct
+ * @sbc_state:	State of SBC firmware
+ *
+ * We need to keep three addresses because in memory map of SBC,
+ * keyscan and HDMI lies in between above address range and there are
+ * other driver which map HDMI and keyscan memory.
+ */
+
+struct stm_lpm_driver_data {
+	void * __iomem lpm_mem_base[3];
+	struct lpm_message fw_reply_msg;
+	struct lpm_message fw_request_msg;
+	char fw_name[20];
+	int reply_from_sbc;
+	char fw_major_ver;
+	wait_queue_head_t stm_lpm_wait_queue;
+	struct mutex msg_protection_mutex;
+	unsigned char glbtrans_id;
+	struct work_struct lpm_sbc_reply_work;
+	enum stm_lpm_sbc_state sbc_state;
+};
+
+static struct stm_lpm_driver_data *lpm_drv;
+
+/* Work queue to process SBC firmware request */
+static void lpm_sbc_reply_worker(struct work_struct *work);
+
+/**
+ * lpm_send_big_message() - To send big message over SBC DMEM
+ * @size:	size of message
+ * @sbc_msg:	buffer pointer
+ *
+ * This function is used to send large messages(>LPM_MAX_MSG_DATA)
+ * using SBC DMEM.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+ */
+
+static int lpm_send_big_message(u16 size, const char *sbc_msg)
+{
+	int err = 0;
+	unsigned int offset;
+	char msg[6];
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_LGWR_OFFSET,
+		.msg = msg,
+		.msg_size = 2
+	};
+	struct lpm_message response = {0};
+	put_unaligned_le16(size, msg);
+	err = lpm_exchange_msg(&send_msg, &response);
+	if (likely(err == 0)) {
+		/* Get the offset in SBC memory */
+		offset = get_unaligned_le32(&response.msg_data[2]);
+		/* Copy message in SBC memory */
+		memcpy_toio(lpm_drv->lpm_mem_base[0] + DATA_OFFSET + offset ,
+		sbc_msg, size);
+		/* Send this big message */
+		put_unaligned_le16(size, msg);
+		put_unaligned_le32(offset, &msg[2]);
+		send_msg.command_id = LPM_MSG_BKBD_WRITE;
+		send_msg.msg_size = 6;
+		err = lpm_exchange_msg(&send_msg, &response);
+	}
+	return err;
+}
+
+/**
+ * stm_lpm_setup_ir() - To set ir key setup
+ * @num_keys:   Number of IR keys
+ * @ir_key_info:        Information of IR keys
+ *
+ * This function will configure IR information on SBC firmware.
+ * User needs to pass on which IR keys wakeup is required and
+ * the expected pattern for those keys.
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+*/
+
+int stm_lpm_setup_ir(u8 num_keys, struct stm_lpm_ir_keyinfo *ir_key_info)
+{
+	struct stm_lpm_ir_keyinfo *this_key;
+	u16 ir_size;
+	char *buf, *org_buf;
+	int count, i, err = 0;
+
+	for (count = 0; count < num_keys; count++) {
+		struct stm_lpm_ir_key *key_info;
+		this_key = ir_key_info;
+
+		ir_key_info++;
+		key_info = &this_key->ir_key;
+		/* Check key crediantials */
+		if (unlikely(this_key->time_period == 0 ||
+				key_info->num_patterns >= 64))
+			return -EINVAL;
+
+		ir_size = key_info->num_patterns*2 + 12;
+		buf = kmalloc(ir_size, GFP_KERNEL);
+		org_buf = buf;
+
+		/* Fill buffer */
+		*buf++ = LPM_MSG_SET_IR;
+		*buf++ = 0;
+		*buf++ = this_key->ir_id & 0xF;
+		*buf++ = ir_size;
+		*buf++ = this_key->time_period & 0xFF;
+		*buf++ = (this_key->time_period >> 8) & 0xFF;
+		*buf++ = this_key->time_out & 0xFF;
+		*buf++ = (this_key->time_out >> 8) & 0xFF;
+
+		if (!this_key->tolerance)
+			this_key->tolerance = 10;
+		*buf++ = this_key->tolerance;
+		*buf++ = key_info->key_index & 0xF;
+		*buf++ = key_info->num_patterns;
+		/* Now compress the actual data and copy */
+		buf = org_buf + 12;
+		for (i = 0; i < key_info->num_patterns ; i++) {
+			key_info->fifo[i].mark /= this_key->time_period;
+			*buf++ = key_info->fifo[i].mark;
+			key_info->fifo[i].symbol /=  this_key->time_period;
+			*buf++ = key_info->fifo[i].symbol;
+		}
+		err = lpm_send_big_message(ir_size, org_buf);
+		kfree(org_buf);
+		if (err < 0)
+			break;
+	}
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_setup_ir);
+
+/**
+ * stm_lpm_get_wakeup_info() - To get additional info about wakeup device
+ * @wakeupdevice:	wakeup device id
+ * @validsize:	read valid size will be returned
+ * @datasize:	data size to read
+ * @data:	data pointer
+ *
+ * This API will return additional data for wakeup device if required.
+ *
+ * Return - 0 on success if data read from SBC is <= datasize
+ * Return - 1 if data available with SBC is > datasize
+ * Return - negative error on failure
+*/
+
+int stm_lpm_get_wakeup_info(enum stm_lpm_wakeup_devices *wakeupdevice,
+			u16 *validsize, u16 datasize, char *data)
+{
+	int err = 0;
+	unsigned int offset;
+	char msg[3];
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_GET_IRQ,
+		.msg = msg,
+		.msg_size = 3
+	};
+	struct lpm_message response = {0};
+	msg[0] = *wakeupdevice;
+
+	/* Copy size requested */
+	put_unaligned_le16(datasize, &msg[1]);
+	err = lpm_exchange_msg(&send_msg, &response);
+	if (unlikely(err < 0))
+		goto exit;
+
+	/* Two response are possible*/
+	if (response.command_id == LPM_MSG_BKBD_READ) {
+		/*
+		 * If SBC replied to read response from its DMEM then
+		 * get the offset to read from SBC memory.
+		 */
+		offset = get_unaligned_le32(&response.msg_data[2]);
+		/* Get valid size from SBC */
+		*validsize = lpm_read8(lpm_drv, DATA_OFFSET + offset + 2);
+		*validsize |= lpm_read8(lpm_drv, DATA_OFFSET + offset + 3) << 8;
+		/* Check if bit#15 is set */
+		if (*validsize & MASK_BIT_MASK)
+			err = 1;
+		*validsize &= M_BIT_MASK;
+		/*
+		 * Below condition is not possible
+		 * SBC have to provide data less than or equal to datasize
+		 * Added below check, if some bug pops up in firmware
+		 */
+		if (unlikely(*validsize > datasize))
+			*validsize = datasize;
+
+		memcpy_fromio(data, lpm_drv->lpm_mem_base[0] + DATA_OFFSET +
+					offset + 4, *validsize);
+	} else {
+		*validsize = get_unaligned_le16(response.msg_data);
+		/* Check if bit#15 is set in mailbox */
+		if (*validsize & MASK_BIT_MASK)
+			err = 1;
+		*validsize &= M_BIT_MASK;
+		/*
+		 * Below condition is not possible
+		 * SBC have to provide data less than or equal to datasize
+		 * Added below check, if some bug pops up in firmware
+		 */
+		if (unlikely(*validsize > datasize))
+			*validsize = datasize;
+		/* Copy data to user */
+		memcpy(data, &response.msg_data[2], *validsize);
+
+	}
+exit:
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_get_wakeup_info);
+
+/**
+ * stm_lpm_reset() - To reset part of full SOC
+ * @reset_type:	type of reset
+ *
+ * Return - 0 on success
+ * Return - negative error on failure
+*/
+
+int stm_lpm_reset(enum stm_lpm_reset_type reset_type)
+{
+	int err = 0;
+	char msg = reset_type;
+	struct lpm_internal_send_msg send_msg = {
+		.command_id = LPM_MSG_GEN_RESET,
+		.msg = &msg,
+		.msg_size = 1
+	};
+	err = lpm_exchange_msg(&send_msg, NULL);
+	if (err == 0 && reset_type == STM_LPM_SBC_RESET) {
+		/* Set the firmware as booting */
+		int i = 0;
+		mutex_lock(&lpm_drv->msg_protection_mutex);
+		lpm_drv->sbc_state = STM_LPM_SBC_BOOT;
+		mutex_unlock(&lpm_drv->msg_protection_mutex);
+		/* Wait till 1 second to get response from firmware */
+		do {
+			mdelay(100);
+			err = stm_lpm_get_fw_state(&lpm_drv->sbc_state);
+			if (err < 0 ||
+				lpm_drv->sbc_state == STM_LPM_SBC_RUNNING)
+				break;
+			i++;
+		} while (i != 10);
+	}
+	return err;
+}
+EXPORT_SYMBOL(stm_lpm_reset);
+
+/**
+ * lpm_fw_proto_version() - To get firmware major protocol version
+ *
+ * return major protocol version of firmware
+*/
+
+char lpm_fw_proto_version(void)
+{
+	return lpm_drv->fw_major_ver;
+}
+
+/**
+ * lpm_isr() - Mailbox ISR
+ * @this_irq:	irq
+ * @params:	Parameters
+ *
+ * This ISR is invoked when there is some message from SBC.
+ * Message could be reply or some request.
+ * If this a request then such message will be posted to a work queue.
+ *
+ */
+
+static irqreturn_t lpm_isr(int this_irq, void *params)
+{
+	struct stm_lpm_driver_data *lpm_drv_p;
+	u32 msg_read[4], i;
+	struct lpm_message *msg;
+	char *msg_p;
+	lpm_drv_p = (struct stm_lpm_driver_data *)params;
+
+	/*
+	 * Read the data from mailbox
+	 * SBC will always be in little endian mode
+	 * if host is in big endian then reverse int
+	 */
+	for (i = 0; i < 4; i++) {
+		msg_read[i] = lpm_read32(lpm_drv_p, 1, MBX_READ_STATUS1 + i*4);
+		msg_read[i] = cpu_to_le32(msg_read[i]);
+		}
+	/* Copy first message to check if it's reply from SBC or request */
+	msg_p = (char *) &msg_read[0];
+	/* Check if reply from SBC or request from SBC */
+	if ((*msg_p & LPM_MSG_REPLY) ||
+	   ((*msg_p && LPM_MSG_BKBD_READ))) {
+		msg = &lpm_drv_p->fw_reply_msg;
+		lpm_drv_p->reply_from_sbc = 1;
+	} else {
+		msg = &lpm_drv_p->fw_request_msg;
+	}
+	/* Copy mailbox data into local structure */
+	memcpy(msg, &msg_read, 16);
+
+	/* Signal work queue or API caller depending upon message from SBC */
+	if (lpm_drv_p->reply_from_sbc == 1)
+		wake_up_interruptible(&lpm_drv_p->stm_lpm_wait_queue);
+	else
+		schedule_work(&lpm_drv_p->lpm_sbc_reply_work);
+
+	 /* Clear mail box */
+	lpm_write32(lpm_drv_p, 1, MBX_READ_CLR_STATUS1, 0xFFFFFFFF);
+	return IRQ_HANDLED;
+}
+
+/**
+ * lpm_sbc_reply_worker() - When SBC wants some data from Host
+ * @work:	work
+ *
+ * This work queue will be signaled when SBC needs some information from Host.
+ * Reply to firmware will be sent over mailbox.
+ */
+
+static void lpm_sbc_reply_worker(struct work_struct *work)
+{
+	unsigned char msg[5];
+	struct lpm_internal_send_msg send_msg = {
+		.msg = msg
+	};
+	struct lpm_message *msg_p;
+	char msg_size, msg_id;
+	msg_p = &lpm_drv->fw_request_msg;
+	lpm_debug("Send reply to firmware \n");
+	lpm_debug("recd command id %x \n", msg_p->command_id);
+	if (msg_p->command_id == LPM_MSG_VER) {
+		/* In case firmware requested driver version*/
+		msg[0] = LPM_MAJOR_PROTO_VER << 4;
+		msg[0] |= LPM_MINOR_PROTO_VER;
+		msg[1] = LPM_MAJOR_SOFT_VER << 4;
+		msg[1] |= LPM_MINOR_SOFT_VER;
+		msg[2] = LPM_PATCH_SOFT_VER << 4;
+		msg[2] |= LPM_BUILD_MONTH;
+		msg[3] = LPM_BUILD_DAY;
+		msg[4] = LPM_BUILD_YEAR;
+		msg_size = 5;
+		msg_id = LPM_MSG_VER | LPM_MSG_REPLY;
+	} else {
+		/* Send reply to SBC as error*/
+		msg[0] = msg_p->command_id;
+		msg[1] = -EINVAL;
+		msg_size = 2;
+		msg_id = LPM_MSG_ERR;
+	}
+	send_msg.command_id = msg_id;
+	send_msg.msg_size = msg_size;
+	send_msg.trans_id = msg_p->transaction_id;
+	lpm_exchange_msg(&send_msg, NULL);
+	msg_p->command_id = 0;
+}
+
+/**
+ * lpm_send_msg() - Send mailbox message
+ * @msg:	message pointer
+ * @msg_size:	message size
+ *
+ * Return - 0 if firmware is running
+ * Return - -EREMOTEIO either firmware is not loaded or not running
+ */
+
+static int lpm_send_msg(struct lpm_message *msg,
+				unsigned char msg_size)
+{
+	int err = 0, count;
+	u32 *tmp_i = (u32 *)msg;
+	/* Check if firmware is loaded or not */
+	if (!(lpm_drv->sbc_state == STM_LPM_SBC_RUNNING ||
+		lpm_drv->sbc_state == STM_LPM_SBC_BOOT))
+		return -EREMOTEIO;
+
+	/*
+	 * Write data to mailbox, covert data into LE format.
+	 * also mailbox is 4 byte deep, we need to write 4 byte always
+	 *
+	 * First byte of message is used to generate interrupt as well as
+	 * serve as command id.
+	 * Therefore first four byte of message part are written at last.
+	 */
+	for (count = (msg_size+1)/4; count >= 0; count--) {
+			*(tmp_i+count) = cpu_to_le32(*(tmp_i+count));
+			lpm_write32(lpm_drv, 1, (MBX_WRITE_STATUS1 + (count*4)),
+			*(tmp_i+count));
+	}
+	return err;
+}
+
+/**
+ * lpm_get_response() - To get SBC response
+ * @response:	response of SBC
+ *
+ * This function is to get SBC response in polling mode
+ * This will be called when interrupts are disabled and we
+ * still need to get response from SBC.
+ *
+ * Return - 1 on success
+ * Return - 0 when SBC firmware is not responding
+ */
+
+static int lpm_get_response(struct lpm_message *response)
+{
+	int count, i;
+	u32 msg_read1[4];
+	/* Poll time of 1 Second is good enough to see SBC reply */
+	for (count = 0; count < 100; count++) {
+		msg_read1[0] = lpm_read32(lpm_drv, 1, MBX_READ_STATUS1);
+		msg_read1[0] = cpu_to_le32(msg_read1[0]);
+		/* If we received a reply then break the loop */
+		if (msg_read1[0] & 0xFF)
+			break;
+		mdelay(10);
+	}
+
+	/* If no reply within 1 second then firmware is not responding */
+	if (count == 100) {
+		pr_err("count %d value %x \n", count, msg_read1[0]);
+		return 0;
+	}
+	/* Get other data from mailbox */
+	for (i = 1; i < 4; i++) {
+		msg_read1[i] = lpm_read32(lpm_drv, 1, MBX_READ_STATUS1 + i*4);
+		msg_read1[i] = cpu_to_le32(msg_read1[i]);
+	}
+	/* Copy data received from mailbox*/
+	memcpy(&lpm_drv->fw_reply_msg, (void *)msg_read1, 16);
+	lpm_write32(lpm_drv, 1, MBX_READ_CLR_STATUS1, 0xFFFFFFFF);
+	return 1;
+}
+
+/**
+ * lpm_exchange_msg() - Internal function  used for message exchange with SBC
+ * @send_msg:	message to send
+ * @response:	response from SBC firmware
+ *
+ * This function can be called in three contexts
+ * One when reply from SBC is expected for this command
+ * Second when reply from SBC is not expected
+ * Third when called from interrupt disabled but reply is expected
+ *
+ * Return - 0 on success
+ * Return - negative error code on failure.
+*/
+
+int lpm_exchange_msg(struct lpm_internal_send_msg *send_msg,
+		struct lpm_message *response)
+{
+	struct lpm_message lpm_msg = {0};
+	int err = 0;
+	int reply_type =  SBC_REPLY_YES;
+	lpm_debug("lpm_exchange_msg \n");
+
+	/*
+	 * Lock the mailbox, prevent other caller to access MB write
+	 * In case API is called with interrupt disabled from Linux PM
+	 * try to lock mutex.
+	 */
+	if (in_atomic() || irqs_disabled()) {
+		err = mutex_trylock(&lpm_drv->msg_protection_mutex);
+		reply_type = SBC_REPLY_NO_IRQ;
+		if (!err)
+			return -EAGAIN;
+	} else {
+		mutex_lock(&lpm_drv->msg_protection_mutex);
+		if (response == NULL)
+			reply_type = SBC_REPLY_NO;
+	}
+
+	lpm_msg.command_id = send_msg->command_id;
+
+	if (lpm_msg.command_id & LPM_MSG_REPLY)
+		lpm_msg.transaction_id = send_msg->trans_id;
+	else
+		lpm_msg.transaction_id = lpm_drv->glbtrans_id++;
+
+	/* Copy data into mailbox message */
+	if (send_msg->msg_size)
+		memcpy(&lpm_msg.msg_data, send_msg->msg, send_msg->msg_size);
+
+	/* Print message information for debug purpose */
+	lpm_debug("Sending msg {%x, %x} \n", lpm_msg.command_id,
+				lpm_msg.transaction_id);
+
+	lpm_drv->reply_from_sbc = 0;
+
+	/* Send message to mailbox write */
+	err = lpm_send_msg(&lpm_msg, send_msg->msg_size);
+	if (unlikely(err < 0)) {
+		pr_err("firmware not loaded \n");
+		goto exit_fun;
+	}
+
+	switch (reply_type) {
+	case SBC_REPLY_NO_IRQ:
+		err = lpm_get_response(response);
+		break;
+	case  SBC_REPLY_YES:
+		/*
+		 * wait for response here
+		 * In case of signal, we can get negative value
+		 * In such case wait till timeout or response from SBC
+		 */
+		do {
+			err = wait_event_interruptible_timeout(
+				lpm_drv->stm_lpm_wait_queue,
+				lpm_drv->reply_from_sbc == 1,
+				msecs_to_jiffies(100));
+		} while (err < 0);
+		break;
+	case SBC_REPLY_NO:
+		goto exit_fun;
+		break;
+	}
+	lpm_debug("recd reply  %x {%x, %x } \n", err,
+		lpm_drv->fw_reply_msg.command_id,
+	lpm_drv->fw_reply_msg.transaction_id);
+
+	if (unlikely(err == 0)) {
+		pr_err("f/w is not responding \n");
+		err = -EAGAIN;
+		goto exit_fun;
+	}
+
+	BUG_ON(!(lpm_drv->fw_reply_msg.command_id & LPM_MSG_REPLY));
+
+	memcpy(response, &lpm_drv->fw_reply_msg,
+		sizeof(struct lpm_message));
+	if (lpm_msg.transaction_id == lpm_drv->fw_reply_msg.transaction_id) {
+		if (response->command_id == LPM_MSG_ERR) {
+			pr_err("Firmware error code %d \n",
+						response->msg_data[1]);
+			/*
+			 * Firmware does not support this command
+			 * therefore firmware gave error.
+			 * In such cases, return EREMOTEIO as firmware error
+			 * code is not yet decided.
+			 * To Do
+			 * conversion of firmware error code into Linux world
+			 */
+			err = -EREMOTEIO;
+		}
+		/* There is possibility we might get response for large msg. */
+		if (response->command_id == LPM_MSG_BKBD_READ)
+			lpm_debug("Got in reply a big message \n");
+	} else {
+		/*
+		 * Different trans id is expected from SBC as big messages are
+		 * encapsulated into LPM_MSG_BKBD_WRIRE message.
+		 */
+		lpm_debug("Received ID %x \n", response->transaction_id);
+	}
+
+exit_fun:
+	mutex_unlock(&lpm_drv->msg_protection_mutex);
+	/* Convert success error code into 0*/
+	if (err > 0)
+		err = 0;
+	return err;
+}
+
+/**
+ * lpm_load_segment() - To load SBC firmware
+ * @lpm_drv_p:	driver data
+ * @elfinfo:	firmware elf information
+ * @i:	Index of elf information
+ *
+ * Return - 0 on success
+*/
+
+static int lpm_load_segment(struct stm_lpm_driver_data *lpm_drv_p,
+				struct ELF64_info *elfinfo, int i)
+{
+
+	Elf64_Phdr *phdr = &elfinfo->progbase[i];
+	void *data = elfinfo->base;
+	signed long offset = DATA_OFFSET + phdr->p_paddr;
+	unsigned long size = phdr->p_memsz;
+	/*
+	 * Check if we need to write onto program area or data area.
+	 * SBC_PRG_MEMORY_ELF_MARKER marker in elf indicate writing to
+	 * program area
+	 */
+	if (phdr->p_paddr == SBC_PRG_MEMORY_ELF_MARKER)
+		offset = SBC_PRG_MEMORY_OFFSET;
+
+	memcpy_toio(lpm_drv_p->lpm_mem_base[0] + offset,
+		data + phdr->p_offset, size);
+	return 0;
+}
+
+/**
+ * lpm_load_fw() - Load sbc firmware
+ * @fw:	pointer to firmware
+ * @lpm_drv_p:	driver date
+ *
+ * Return - 0 on success
+ * Return - negative error on failure
+*/
+
+static int lpm_load_fw(const struct firmware *fw,
+		struct stm_lpm_driver_data *lpm_drv_p)
+{
+	struct ELF64_info *elfinfo = NULL;
+	struct stm_lpm_version driver_ver, fw_ver;
+	int i;
+	int err = 0;
+	if (unlikely(!fw)) {
+		pr_err("LPM: Unable to load LPM firmware: not present?\n");
+		return -EINVAL;
+	}
+
+	pr_info("LPM: Found sbc f/w \n");
+	elfinfo = (struct ELF64_info *)ELF64_initFromMem((uint8_t *)fw->data,
+						fw->size, 0);
+	if (unlikely(elfinfo == NULL))
+			return -ENOMEM;
+
+	for (i = 0; i < elfinfo->header->e_phnum; i++)
+		if (elfinfo->progbase[i].p_type == PT_LOAD)
+			lpm_load_segment(lpm_drv_p, elfinfo, i);
+
+	/* Initialize sbc lpm */
+	i = readl((u32)lpm_drv_p->lpm_mem_base[2] + SBC_CONFIG_OFFSET);
+	i |= 0x1;
+	writel(i, (u32)lpm_drv_p->lpm_mem_base[2] + SBC_CONFIG_OFFSET);
+	kfree((void *)elfinfo);
+
+	/* Wait till 1 second to get response from firmware */
+	i = 0;
+	do {
+		mdelay(100);
+		err = stm_lpm_get_fw_state(&lpm_drv_p->sbc_state);
+		if (err < 0 || lpm_drv_p->sbc_state == STM_LPM_SBC_RUNNING)
+			break;
+		i++;
+	} while (i != 10);
+	if (err == 0) {
+		err = stm_lpm_get_version(&driver_ver, &fw_ver);
+		if (likely(err == 0))
+			lpm_drv_p->fw_major_ver = fw_ver.major_comm_protocol;
+	}
+	/* We do not return error if caused by SBC communication */
+	return 1;
+}
+
+/**
+ * lpm_load_firmware() - Request firmware to load
+ * @pdev:	pointer to platform device
+ *
+ * Return - 0 on success
+ * Return - negative error on failure
+*/
+
+static int lpm_load_firmware(struct platform_device *pdev)
+{
+	int err;
+	int result;
+	struct stm_lpm_driver_data *lpm_drv_p;
+	lpm_drv_p = platform_get_drvdata(pdev);
+	result = snprintf(lpm_drv_p->fw_name, sizeof(lpm_drv_p->fw_name),
+			"lpm_fw%s.elf", get_cpu_subtype(&current_cpu_data));
+
+	/* was the string truncated? */
+	BUG_ON(result >= sizeof(lpm_drv_p->fw_name));
+
+	lpm_debug("LPM: Requesting Firmware (%s)...\n",
+		lpm_drv_p->fw_name);
+
+	err = request_firmware_nowait(THIS_MODULE, 1, lpm_drv_p->fw_name,
+			&pdev->dev, (struct stm_lpm_driver_data *)lpm_drv_p,
+			(void *)lpm_load_fw);
+
+	return err;
+}
+
+/**
+ * stm_lpm_probe() - Probe function of driver
+ * @pdev:	platform device pointer
+ *
+ * Return - 0 on success
+ * Return - negative error on failure
+*/
+
+static int __init stm_lpm_probe(struct platform_device *pdev)
+{
+	struct resource *res;
+	int err = 0;
+	int count = 0;
+	lpm_debug("stm lpm probe \n");
+
+	lpm_drv = devm_kzalloc(&pdev->dev, sizeof(struct stm_lpm_driver_data),
+				GFP_KERNEL);
+	if (unlikely(lpm_drv == NULL)) {
+		pr_err("%s: Request memory failed \n", __func__);
+		return -ENOMEM;
+	}
+
+	for (count = 0; count < 3; count++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, count);
+		if (!res) {
+			err = -ENODEV;
+			goto free_and_exit;
+		}
+		lpm_debug("mem:SBC res->start %x %x\n", res->start, res->end);
+		if (!devm_request_mem_region(&pdev->dev, res->start,
+			resource_size(res), "stm-lpm")) {
+			pr_err("%s: Request mem 0x%x region failed \n",
+				__func__, res->start);
+			err = -ENOMEM;
+			goto free_and_exit;
+		}
+		lpm_drv->lpm_mem_base[count] = devm_ioremap_nocache(&pdev->dev,
+							res->start,
+							resource_size(res));
+		if (!lpm_drv->lpm_mem_base[count]) {
+			pr_err("%s: Request iomem 0x%x region failed \n",
+				__func__, (unsigned int)res->start);
+			err = -ENOMEM;
+			goto free_and_exit;
+		}
+		lpm_debug("lpm_add %x \n", (u32)lpm_drv->lpm_mem_base[count]);
+	}
+
+	/* Irq request */
+	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+	if (!res) {
+		pr_err("%s Request irq %x not done\n", __func__, res->start);
+		err = -ENODEV;
+		goto free_and_exit;
+	}
+	if (devm_request_irq(&pdev->dev, res->start, lpm_isr,
+			IRQF_DISABLED, "stlmp", (void *)lpm_drv) < 0) {
+		pr_err("%s: Request stm lpm irq not done\n", __func__);
+		err = -ENODEV;
+		goto free_and_exit;
+	}
+
+	init_waitqueue_head(&lpm_drv->stm_lpm_wait_queue);
+
+	mutex_init(&lpm_drv->msg_protection_mutex);
+
+	/* stm lpm does not need dedicate work queue so use default queue */
+	INIT_WORK(&lpm_drv->lpm_sbc_reply_work, lpm_sbc_reply_worker);
+
+	platform_set_drvdata(pdev , lpm_drv);
+
+	/*
+	 * Program Mailbox for interrupt enable
+	 */
+	lpm_write32(lpm_drv, 1, MBX_INT_SET_ENABLE, 0xFF);
+	lpm_drv->sbc_state = STM_LPM_SBC_BOOT;
+	lpm_load_firmware(pdev);
+	return err;
+
+free_and_exit:
+	kfree(lpm_drv);
+	return err;
+}
+
+/**
+ * stm_lpm_remove() - To free used resources
+ * @pdev:	device pointer
+ * Return code 0
+ */
+
+static int stm_lpm_remove(struct platform_device *pdev)
+{
+	struct stm_lpm_driver_data *lpm_drv_p;
+	lpm_debug("stm_lpm_remove \n");
+	lpm_drv_p = platform_get_drvdata(pdev);
+	kfree(lpm_drv_p);
+	return 0;
+}
+
+/**
+ * stm_lpm_freeze() - Freeze callback
+ * @dev:	device pointer
+ *
+ * This is not really required but keeping this
+ * in case needed for future
+ * Return - 0 for success
+ */
+
+static int stm_lpm_freeze(struct device *dev)
+{
+	lpm_debug("stm_lpm_freeze \n");
+	return 0;
+}
+
+/**
+ * stm_lpm_restore() - Restore callback
+ * @dev:	device pointer
+ *
+ * This is not really required but keeping this
+ * in case needed for future
+ * Return - 0 for success
+ */
+
+static int stm_lpm_restore(struct device *dev)
+{
+	lpm_debug("stm_lpm_restore \n");
+	return 0;
+}
+
+static struct dev_pm_ops stm_lpm_pm_ops = {
+		.freeze = stm_lpm_freeze,
+		.restore = stm_lpm_restore,
+};
+
+static struct platform_driver stm_lpm_driver = {
+	.driver.name = "stm-lpm",
+	.driver.owner = THIS_MODULE,
+	.driver.pm  = &stm_lpm_pm_ops,
+	.probe = stm_lpm_probe,
+	.remove = stm_lpm_remove,
+};
+
+static int __init stm_lpm_init(void)
+{
+	int err = 0;
+	err = platform_driver_register(&stm_lpm_driver);
+	if (err)
+		pr_err("STM_LPM driver fails on registrating (%x)\n" , err);
+	else
+		pr_info("STM_LPM driver registered\n");
+	return err;
+}
+
+void __exit stm_lpm_exit(void)
+{
+	pr_info("STM_LPM driver removed \n");
+	platform_driver_unregister(&stm_lpm_driver);
+}
+
+module_init(stm_lpm_init);
+module_exit(stm_lpm_exit);
+
+MODULE_AUTHOR("STMicroelectronics  <www.st.com>");
+MODULE_DESCRIPTION("lpm device driver for STMicroelectronics devices");
+MODULE_LICENSE("GPL");
diff -Naur a/drivers/stm/Makefile b/drivers/stm/Makefile
--- a/drivers/stm/Makefile	2013-11-01 20:19:18.869929548 +0200
+++ b/drivers/stm/Makefile	2013-11-01 18:44:54.253840242 +0200
@@ -32,6 +32,13 @@
 obj-$(CONFIG_STM_PCI_EMISS)		+= pci-emiss.o
 obj-$(CONFIG_STM_PCIE)			+= pcie.o
 
+obj-$(CONFIG_CPU_SUBTYPE_STXH205)	+= stxh205_lpm.o
+obj-$(CONFIG_CPU_SUBTYPE_STX7108)	+= stx7108_lpm.o
+obj-$(CONFIG_STM_LPM)			+= lpm_com.o
+obj-$(CONFIG_STM_LPM_MB)		+= lpm_mb.o
+obj-$(CONFIG_STM_LPM_I2C)		+= lpm_i2c.o
+obj-$(CONFIG_STM_LPM_RD_MONITOR)	+= lpm_gpio_monitor.o
+
 obj-$(CONFIG_CPU_SUBTYPE_FLI75XX)	+= fli75xx.o fli75xx_clock.o fli75xx_audio.o fli75xx_comms.o fli75xx_hispeed.o fli75xx_pci.o
 obj-$(CONFIG_CPU_SUBTYPE_STXH205)	+= stxh205.o stxh205_clock.o stxh205_comms.o stxh205_hispeed.o stxh205_pci.o pio-control.o
 obj-$(CONFIG_CPU_SUBTYPE_STX5197)	+= stx5197.o stx5197_clock.o
diff -Naur a/drivers/stm/stx5206.c b/drivers/stm/stx5206.c
--- a/drivers/stm/stx5206.c	2013-11-01 20:19:19.117930777 +0200
+++ b/drivers/stm/stx5206.c	2013-11-01 18:44:54.425841086 +0200
@@ -304,6 +304,7 @@
 	.name			= "stm-temp",
 	.id			= -1,
 	.dev.platform_data	= &(struct plat_stm_temp_data) {
+		.correction_factor = 20,
 		.dcorrect = { SYS_CFG, 41, 5, 9 },
 		.overflow = { SYS_STA, 12, 8, 8 },
 		.data = { SYS_STA, 12, 10, 16 },
diff -Naur a/drivers/stm/stx7105.c b/drivers/stm/stx7105.c
--- a/drivers/stm/stx7105.c	2013-11-01 20:19:19.129930842 +0200
+++ b/drivers/stm/stx7105.c	2013-11-01 18:44:54.429841105 +0200
@@ -343,6 +343,7 @@
 	.name			= "stm-temp",
 	.id			= -1,
 	.dev.platform_data	= &(struct plat_stm_temp_data) {
+		.correction_factor = 20,
 		.dcorrect = { SYS_CFG, 41, 5, 9 },
 		.overflow = { SYS_STA, 12, 8, 8 },
 		.data = { SYS_STA, 12, 10, 16 },
diff -Naur a/drivers/stm/stx7108.c b/drivers/stm/stx7108.c
--- a/drivers/stm/stx7108.c	2013-11-01 20:19:19.141930896 +0200
+++ b/drivers/stm/stx7108.c	2013-11-01 18:44:54.433841134 +0200
@@ -254,6 +254,8 @@
 		emiss_nandi_select(STM_NANDI_BCH);
 		stx7108_nand_bch_data.bank = config->banks;
 		stx7108_nand_bch_data.bch_ecc_cfg = config->bch_ecc_cfg;
+		stx7108_nand_bch_data.bch_bitflip_threshold =
+			config->bch_bitflip_threshold;
 		stx7108_nandi_device.dev.platform_data =
 			&stx7108_nand_bch_data;
 		stx7108_nandi_device.name = "stm-nand-bch";
@@ -920,7 +922,7 @@
 
 static struct platform_device stx7108_sysconf_devices[] = {
 	{
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 0,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -941,7 +943,7 @@
 			},
 		}
 	}, {
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 1,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -962,7 +964,7 @@
 			},
 		}
 	}, {
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 2,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -983,7 +985,7 @@
 			},
 		}
 	}, {
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 3,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -1004,7 +1006,7 @@
 			},
 		}
 	}, {
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 4,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -1090,6 +1092,7 @@
 	.name		   = "stm-temp",
 	.id		     = -1,
 	.dev.platform_data      = &(struct plat_stm_temp_data) {
+		.correction_factor = 20,
 		.dcorrect = { SYS_CFG_BANK1, 8, 4, 8 },
 		.overflow = { SYS_STA_BANK1, 7, 8, 8 },
 		.data = { SYS_STA_BANK1, 7, 10, 16 },
diff -Naur a/drivers/stm/stx7108_lpm.c b/drivers/stm/stx7108_lpm.c
--- a/drivers/stm/stx7108_lpm.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/stx7108_lpm.c	2013-11-01 18:44:54.433841134 +0200
@@ -0,0 +1,57 @@
+/*
+ * <root>/drivers/stm/stx7108_lpm.c
+ *
+ * This define resources for external SBC
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+*/
+
+#include <linux/i2c.h>
+#include <linux/stm/platform.h>
+#include "linux/stm/stx7108.h"
+
+
+static struct i2c_board_info board_info = {
+		I2C_BOARD_INFO("stm-lpm", 0),
+		.platform_data = &(struct stm_lpm_i2c_data){
+			.number_i2c = 0,
+			.number_gpio = 0,
+		},
+};
+
+void stx7108_configure_lpm_i2c_interface(struct stx7108_lpm_i2c_config  *config)
+{
+	struct stm_lpm_i2c_data *i2c_data = board_info.platform_data;
+	i2c_data->number_i2c = config->number_i2c;
+	i2c_data->number_gpio = config->number_gpio;
+}
+
+static int __init stx7108_lpm_init(void)
+{
+	int err = 0;
+	struct stm_lpm_i2c_data *i2c_data;
+	struct i2c_client *client;
+	/* get 7108 specific i2c data */
+	struct i2c_board_info *info = &board_info;
+	i2c_data = info->platform_data;
+	/* get adapter on which i2c stm8 is connected */
+	i2c_data->i2c_adap = i2c_get_adapter(i2c_data->number_i2c);
+	if (i2c_data->i2c_adap == NULL)
+		return err;
+	/* add new device with above adapter */
+	client = i2c_new_device(i2c_data->i2c_adap, &board_info);
+	if (client == NULL)
+		return err;
+	/* set i2c_data as client i2c data */
+	i2c_set_clientdata(client , i2c_data);
+	return err;
+}
+
+module_init(stx7108_lpm_init);
diff -Naur a/drivers/stm/stx7111.c b/drivers/stm/stx7111.c
--- a/drivers/stm/stx7111.c	2013-11-01 20:19:19.157930978 +0200
+++ b/drivers/stm/stx7111.c	2013-11-01 18:44:54.433841134 +0200
@@ -229,6 +229,7 @@
 	.name			= "stm-temp",
 	.id			= -1,
 	.dev.platform_data	= &(struct plat_stm_temp_data) {
+		.correction_factor = 20,
 		.dcorrect = { SYS_CFG, 41, 5, 9 },
 		.overflow = { SYS_STA, 12, 8, 8 },
 		.data = { SYS_STA, 12, 10, 16 },
diff -Naur a/drivers/stm/stx7141.c b/drivers/stm/stx7141.c
--- a/drivers/stm/stx7141.c	2013-11-01 20:19:19.165931015 +0200
+++ b/drivers/stm/stx7141.c	2013-11-01 18:44:54.437841150 +0200
@@ -326,6 +326,7 @@
 		.name			= "stm-temp",
 		.id			= 0,
 		.dev.platform_data	= &(struct plat_stm_temp_data) {
+			.correction_factor = 20,
 			.dcorrect = { SYS_CFG, 41, 5, 9 },
 			.overflow = { SYS_STA, 12, 8, 8 },
 			.data = { SYS_STA, 12, 10, 16 },
@@ -342,6 +343,7 @@
 		.name			= "stm-temp",
 		.id			= 1,
 		.dev.platform_data	= &(struct plat_stm_temp_data) {
+			.correction_factor = 20,
 			.dcorrect = { SYS_CFG, 41, 15, 19 },
 			.overflow = { SYS_STA, 12, 26, 26 },
 			.custom_get_data = stx7141_temp1_get_data,
@@ -358,6 +360,7 @@
 		.name			= "stm-temp",
 		.id			= 2,
 		.dev.platform_data	= &(struct plat_stm_temp_data) {
+			.correction_factor = 20,
 			.dcorrect = { SYS_CFG, 41, 25, 29 },
 			.overflow = { SYS_STA, 13, 12, 12 },
 			.data = { SYS_STA, 13, 14, 20 },
@@ -766,7 +769,7 @@
 	sysconf_early_init(&stx7141_sysconf_device, 1);
 	stm_gpio_early_init(stx7141_pio_devices,
 			ARRAY_SIZE(stx7141_pio_devices),
-			ILC_FIRST_IRQ + ILC_NR_IRQS);
+			COMMS_ILC_FIRST_IRQ + COMMS_ILC_NR_IRQS);
 	stm_pad_init(ARRAY_SIZE(stx7141_pio_devices) * STM_GPIO_PINS_PER_PORT,
 		     -1, 0, stx7141_pio_config);
 
diff -Naur a/drivers/stm/stxh205.c b/drivers/stm/stxh205.c
--- a/drivers/stm/stxh205.c	2013-11-01 20:19:19.185931123 +0200
+++ b/drivers/stm/stxh205.c	2013-11-01 18:44:54.441841168 +0200
@@ -177,7 +177,7 @@
 	{
 		/* SBC system configuration bank 0 registers */
 		/* SYSCFG_BANK0 (aka SYSCFG_SBC, Sapphire): 0-42 */
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 0,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -196,7 +196,7 @@
 		}
 	}, {
 		/* SYSCFG_BANK1 (aka Coral): 100-176 */
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 1,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -215,7 +215,7 @@
 		}
 	}, {
 		/* SYSCFG_BANK2 (aka Perl): 200-243 */
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 2,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -234,7 +234,7 @@
 		}
 	}, {
 		/* SYSCFG_BANK3 (aka Opal): 400-510 */
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 3,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -253,7 +253,7 @@
 		}
 	}, {
 		/* LPM Configuration registers */
-		.name		= "sysconf",
+		.name		= "stm-sysconf",
 		.id		= 4,
 		.num_resources	= 1,
 		.resource	= (struct resource[]) {
@@ -332,7 +332,7 @@
 	.num_resources = 3,
 	.resource = (struct resource[]) {
 		STM_PLAT_RESOURCE_MEM_NAMED("emi memory", 0, 256 * 1024 * 1024),
-		STM_PLAT_RESOURCE_MEM_NAMED("emi4 config", 0xfe90000, 0x874),
+		STM_PLAT_RESOURCE_MEM_NAMED("emi4 config", 0xfe900000, 0x874),
 		STM_PLAT_RESOURCE_MEM_NAMED("emiss config", 0xfdaa9000 , 0x80),
 	},
 	.dev.platform_data = &(struct stm_device_config){
@@ -348,6 +348,27 @@
 /*
  * Temperature sensor
  */
+static int stxh205_temp_init(struct stm_device_state *device_state)
+{
+	struct clk *clk = clk_get(NULL, "CLK_A0_THNS");
+	struct clk *osc;
+
+	if (!IS_ERR(clk))
+		return -ENODEV;
+
+	osc = clk_get(NULL, "CLK_A0_REF");
+	if (!IS_ERR(osc)) {
+		clk_put(clk);
+		return -ENODEV;
+	}
+
+	clk_enable(clk);
+	clk_set_parent(clk, osc);
+	clk_set_rate(clk, clk_get_rate(osc) / 30);
+
+	return 0;
+}
+
 static void stxh205_temp_power(struct stm_device_state *device_state,
 		enum stm_device_power_state power)
 {
@@ -360,11 +381,13 @@
 	.name	= "stm-temp",
 	.id	= 0,
 	.dev.platform_data = &(struct plat_stm_temp_data) {
+		.correction_factor = -103,
 		.dcorrect = { SYSCONF(140), 4, 8 },
 		.overflow = { SYSCONF(148), 9, 9 },
 		.data = { SYSCONF(148), 11, 18 },
 		.device_config = &(struct stm_device_config) {
 			.sysconfs_num = 1,
+			.init = stxh205_temp_init,
 			.power = stxh205_temp_power,
 			.sysconfs = (struct stm_device_sysconf []){
 				STM_DEVICE_SYSCONF(SYSCONF(140),
@@ -549,9 +572,9 @@
 	/* SoC/IP Capabilities */
 	data->capabilities.no_read_repeat = 1;
 	data->capabilities.no_write_repeat = 1;
-	data->capabilities.no_sw_reset = 1;
+	data->capabilities.no_sw_reset = 0;
 	data->capabilities.read_status_bug = spifsm_read_status_clkdiv4;
-	data->capabilities.no_poll_mode_change = 1;
+	data->capabilities.no_poll_mode_change = 0;
 	data->capabilities.boot_from_spi = (sysconf_read(sc) == 0x1a) ? 1 : 0;
 
 	sysconf_release(sc);
@@ -598,6 +621,8 @@
 		emiss_nandi_select(STM_NANDI_BCH);
 		stxh205_nand_bch_data.bank = config->banks;
 		stxh205_nand_bch_data.bch_ecc_cfg = config->bch_ecc_cfg;
+		stxh205_nand_bch_data.bch_bitflip_threshold =
+			config->bch_bitflip_threshold;
 		stxh205_nandi_device.dev.platform_data =
 			&stxh205_nand_bch_data;
 		stxh205_nandi_device.name = "stm-nand-bch";
diff -Naur a/drivers/stm/stxh205_comms.c b/drivers/stm/stxh205_comms.c
--- a/drivers/stm/stxh205_comms.c	2013-11-01 20:19:19.189931134 +0200
+++ b/drivers/stm/stxh205_comms.c	2013-11-01 18:44:54.441841168 +0200
@@ -475,6 +475,8 @@
 			(char*[]) {"SCL", "SDA"});
 	} else {
 		pad_config = &stxh205_ssc_i2c_pad_configs[ssc];
+		clk_add_alias_platform_device(NULL, &stxh205_ssc_devices[ssc],
+					"sbc_comms_clk", NULL);
 	}
 
 	plat_data->pad_config = pad_config;
@@ -519,6 +521,8 @@
 			(char*[]) { "SDA", "MTSR", "MRST"});
 	} else {
 		pad_config = &stxh205_ssc_spi_pad_configs[ssc];
+		clk_add_alias_platform_device(NULL, &stxh205_ssc_devices[ssc],
+					"sbc_comms_clk", NULL);
 	}
 
 	plat_data->spi_chipselect = config->spi_chipselect;
diff -Naur a/drivers/stm/stxh205_hispeed.c b/drivers/stm/stxh205_hispeed.c
--- a/drivers/stm/stxh205_hispeed.c	2013-11-01 20:19:19.193931155 +0200
+++ b/drivers/stm/stxh205_hispeed.c	2013-11-01 18:44:54.441841168 +0200
@@ -41,6 +41,21 @@
 		}, \
 	}
 
+#define DATA_IN_PU(_port, _pin, _func, _retiming) \
+	{ \
+		.gpio = stm_gpio(_port, _pin), \
+		.direction = stm_pad_gpio_direction_custom, \
+		.function = _func, \
+		.priv = &(struct stxh205_pio_config) { \
+			.retime = _retiming, \
+			.mode = &(struct stm_pio_control_mode_config) { \
+				.oe = 0, \
+				.pu = 1, \
+				.od = 0, \
+		}, \
+	}, \
+	}
+
 #define DATA_OUT(_port, _pin, _func, _retiming) \
 	{ \
 		.gpio = stm_gpio(_port, _pin), \
@@ -128,7 +143,7 @@
 		DATA_OUT_PU(1, 0, 1, RET_BYPASS(0)),/* MDIO*/
 		CLOCK_OUT(1, 1, 1, RET_NICLK(0)),/* MDC */
 		DATA_IN(1, 2, 1, RET_BYPASS(0)),/* CRS */
-		DATA_IN(1, 3, 1, RET_BYPASS(0)),/* MDINT */
+		DATA_IN_PU(1, 3, 1, RET_BYPASS(0)),/* MDINT */
 		DATA_IN(1, 4, 1, RET_BYPASS(0)),/* RXD[0] */
 		DATA_IN(1, 5, 1, RET_BYPASS(0)),/* RXD[1] */
 		DATA_IN(1, 6, 1, RET_BYPASS(0)),/* RXD[2] */
@@ -165,7 +180,7 @@
 		DATA_OUT(0, 5, 1, RET_BYPASS(0)),/* TXEN */
 		DATA_OUT_PU(1, 0, 1, RET_BYPASS(0)),/* MDIO */
 		CLOCK_OUT(1, 1, 1, RET_NICLK(0)),/* MDC */
-		DATA_IN(1, 3, 1, RET_BYPASS(0)),/* MDINT */
+		DATA_IN_PU(1, 3, 1, RET_BYPASS(0)),/* MDINT */
 		DATA_IN(1, 4, 1, RET_BYPASS(0)),/* RXD.0 */
 		DATA_IN(1, 5, 1, RET_BYPASS(0)),/* RXD.1 */
 		DATA_IN(2, 0, 1, RET_BYPASS(0)),/* RXDV */
@@ -639,8 +654,10 @@
 	writel(0x80000000, mmio + SATA_OOBR);
 	writel(0x8204080C, mmio + SATA_OOBR);
 	writel(0x0204080C, mmio + SATA_OOBR);
-
-	stm_miphy_claim(0, SATA_MODE, dev);
+	if (!stm_miphy_claim(0, SATA_MODE, dev)) {
+		dev_err(dev, "Cannot claim MiPHY 0!\n");
+		return -ENODEV;
+	}
 	return 0;
 }
 
diff -Naur a/drivers/stm/stxh205_lpm.c b/drivers/stm/stxh205_lpm.c
--- a/drivers/stm/stxh205_lpm.c	1970-01-01 03:00:00.000000000 +0300
+++ b/drivers/stm/stxh205_lpm.c	2013-11-01 18:44:54.441841168 +0200
@@ -0,0 +1,52 @@
+/*
+ * <root>/drivers/stm/stxh205_lpm.c
+ *
+ * This define resources for internal SBC
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+#include <linux/platform_device.h>
+#include <linux/stm/platform.h>
+#include <asm/irq-ilc.h>
+
+/* SBC DMEM and IMEM area */
+#define SBC_ADDRESS	0xFE400000
+#define SBC_SIZE	0xA0000
+
+
+/* mail box address */
+#define SBC_MB_ADDRESS	0xFE4B4000
+#define SBC_MB_SIZE	0x400
+
+/* configuration register address */
+#define SBC_CF_ADDRESS	0xFE4B5100
+#define SBC_CF_SIZE	0x200
+
+
+static struct platform_device stm_lpm_device = {
+	.name = "stm-lpm",
+	.id = 0,
+	.num_resources = 4,
+	.resource = (struct resource[]) {
+		STM_PLAT_RESOURCE_MEM(SBC_ADDRESS, SBC_SIZE),
+		STM_PLAT_RESOURCE_MEM(SBC_MB_ADDRESS, SBC_MB_SIZE),
+		STM_PLAT_RESOURCE_MEM(SBC_CF_ADDRESS, SBC_CF_SIZE),
+		STM_PLAT_RESOURCE_IRQ(ILC_IRQ(64), -1),
+	}
+};
+
+
+static int __init stxh205_lpm_init(void)
+{
+	return platform_device_register(&stm_lpm_device);
+}
+
+module_init(stxh205_lpm_init);
diff -Naur a/drivers/stm/wakeup_devices.c b/drivers/stm/wakeup_devices.c
--- a/drivers/stm/wakeup_devices.c	2013-11-01 20:19:19.201931199 +0200
+++ b/drivers/stm/wakeup_devices.c	2013-11-01 18:44:54.441841168 +0200
@@ -9,6 +9,7 @@
 #include <linux/stm/wakeup_devices.h>
 #include <linux/device.h>
 #include <linux/platform_device.h>
+#include <linux/phy.h>
 
 static int wokenup_by;
 
@@ -38,11 +39,11 @@
 		else if (!strcmp(dev_name(dev), "hdmi"))
 			wkd->hdmi_can_wakeup = 1;
 		else if (!strcmp(dev_name(dev), "stmmaceth"))
-			wkd->eth_phy_can_wakeup = 1;
+			wkd->stm_mac0_can_wakeup = 1;
 		else if (!strcmp(dev_name(dev), "stmmaceth.0"))
-			wkd->eth_phy_can_wakeup = 1;
+			wkd->stm_mac0_can_wakeup = 1;
 		else if (!strcmp(dev_name(dev), "stmmaceth.1"))
-			wkd->eth1_phy_can_wakeup = 1;
+			wkd->stm_mac1_can_wakeup = 1;
 		else if (!strcmp(dev_name(dev), "stm-hdmi-cec"))
 			wkd->hdmi_cec = 1;
 		else if (!strcmp(dev_name(dev), "stm-hdmi-hot"))
@@ -55,17 +56,34 @@
 			wkd->asc = 1;
 		else if (!strncmp(dev_name(dev), "stm-asc.", 8))
 			wkd->asc = 1;
+	}
+	return 0;
+}
 
+#ifdef CONFIG_PHYLIB
+static int __check_mdio_wakeup_device(struct device *dev, void *data)
+{
+	struct stm_wakeup_devices *wkd = (struct stm_wakeup_devices *)data;
+
+	if (device_may_wakeup(dev)) {
+		if (!strncmp(dev_name(dev), "0:", 2))
+			wkd->stm_phy_can_wakeup = 1;
+		else if (!strncmp(dev_name(dev), "1:", 2))
+			wkd->stm_phy_can_wakeup = 1;
 	}
+
 	return 0;
 }
+#endif
 
 int stm_check_wakeup_devices(struct stm_wakeup_devices *wkd)
 {
 	stm_wake_init(wkd);
 	bus_for_each_dev(&platform_bus_type, NULL, wkd, __check_wakeup_device);
+#ifdef CONFIG_PHYLIB
+	bus_for_each_dev(&mdio_bus_type, NULL, wkd, __check_mdio_wakeup_device);
+#endif
 	return 0;
 }
 
 EXPORT_SYMBOL(stm_check_wakeup_devices);
-
diff -Naur a/drivers/telephony/ixj.c b/drivers/telephony/ixj.c
--- a/drivers/telephony/ixj.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/telephony/ixj.c	2013-11-01 18:44:54.449841215 +0200
@@ -3190,12 +3190,12 @@
 
 	ixj_fsk_alloc(j);
 
-	strcpy(sdmf1, j->cid_send.month);
-	strcat(sdmf1, j->cid_send.day);
-	strcat(sdmf1, j->cid_send.hour);
-	strcat(sdmf1, j->cid_send.min);
-	strcpy(sdmf2, j->cid_send.number);
-	strcpy(sdmf3, j->cid_send.name);
+	strlcpy(sdmf1, j->cid_send.month, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.day, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.hour, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.min, sizeof(sdmf1));
+	strlcpy(sdmf2, j->cid_send.number, sizeof(sdmf2));
+	strlcpy(sdmf3, j->cid_send.name, sizeof(sdmf3));
 
 	len1 = strlen(sdmf1);
 	len2 = strlen(sdmf2);
@@ -3340,12 +3340,12 @@
 		ixj_pre_cid(j);
 	}
 	j->flags.cidcw_ack = 0;
-	strcpy(sdmf1, j->cid_send.month);
-	strcat(sdmf1, j->cid_send.day);
-	strcat(sdmf1, j->cid_send.hour);
-	strcat(sdmf1, j->cid_send.min);
-	strcpy(sdmf2, j->cid_send.number);
-	strcpy(sdmf3, j->cid_send.name);
+	strlcpy(sdmf1, j->cid_send.month, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.day, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.hour, sizeof(sdmf1));
+	strlcat(sdmf1, j->cid_send.min, sizeof(sdmf1));
+	strlcpy(sdmf2, j->cid_send.number, sizeof(sdmf2));
+	strlcpy(sdmf3, j->cid_send.name, sizeof(sdmf3));
 
 	len1 = strlen(sdmf1);
 	len2 = strlen(sdmf2);
diff -Naur a/drivers/usb/class/cdc-acm.c b/drivers/usb/class/cdc-acm.c
--- a/drivers/usb/class/cdc-acm.c	2013-11-01 20:18:05.021563355 +0200
+++ b/drivers/usb/class/cdc-acm.c	2013-11-01 18:44:54.461841273 +0200
@@ -1120,7 +1120,8 @@
 	}
 
 
-	if (data_interface->cur_altsetting->desc.bNumEndpoints < 2)
+	if (data_interface->cur_altsetting->desc.bNumEndpoints < 2 ||
+	    control_interface->cur_altsetting->desc.bNumEndpoints == 0)
 		return -EINVAL;
 
 	epctrl = &control_interface->cur_altsetting->endpoint[0].desc;
diff -Naur a/drivers/usb/class/cdc-wdm.c b/drivers/usb/class/cdc-wdm.c
--- a/drivers/usb/class/cdc-wdm.c	2013-11-01 20:18:05.025563369 +0200
+++ b/drivers/usb/class/cdc-wdm.c	2013-11-01 18:44:54.465841286 +0200
@@ -52,6 +52,7 @@
 #define WDM_READ		4
 #define WDM_INT_STALL		5
 #define WDM_POLL_RUNNING	6
+#define WDM_OVERFLOW		10
 
 
 #define WDM_MAX			16
@@ -115,6 +116,7 @@
 {
 	struct wdm_device *desc = urb->context;
 	int status = urb->status;
+	int length = urb->actual_length;
 
 	spin_lock(&desc->iuspin);
 
@@ -144,9 +146,17 @@
 	}
 
 	desc->rerr = status;
-	desc->reslength = urb->actual_length;
-	memmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);
-	desc->length += desc->reslength;
+	if (length + desc->length > desc->wMaxCommand) {
+		/* The buffer would overflow */
+		set_bit(WDM_OVERFLOW, &desc->flags);
+	} else {
+		/* we may already be in overflow */
+		if (!test_bit(WDM_OVERFLOW, &desc->flags)) {
+			memmove(desc->ubuf + desc->length, desc->inbuf, length);
+			desc->length += length;
+			desc->reslength = length;
+		}
+	}
 	wake_up(&desc->wait);
 
 	set_bit(WDM_READ, &desc->flags);
@@ -398,6 +408,11 @@
 			rv = -ENODEV;
 			goto err;
 		}
+		if (test_bit(WDM_OVERFLOW, &desc->flags)) {
+			clear_bit(WDM_OVERFLOW, &desc->flags);
+			rv = -ENOBUFS;
+			goto err;
+		}
 		i++;
 		if (file->f_flags & O_NONBLOCK) {
 			if (!test_bit(WDM_READ, &desc->flags)) {
@@ -440,7 +455,10 @@
 			spin_unlock_irq(&desc->iuspin);
 			goto retry;
 		}
+
 		if (!desc->reslength) { /* zero length read */
+			dev_dbg(&desc->intf->dev, "%s: zero length - clearing WDM_READ\n", __func__);
+			clear_bit(WDM_READ, &desc->flags);
 			spin_unlock_irq(&desc->iuspin);
 			goto retry;
 		}
@@ -842,6 +860,7 @@
 	struct wdm_device *desc = usb_get_intfdata(intf);
 	int rv;
 
+	clear_bit(WDM_OVERFLOW, &desc->flags);
 	rv = recover_from_urb_loss(desc);
 	mutex_unlock(&desc->plock);
 	return 0;
diff -Naur a/drivers/usb/core/devio.c b/drivers/usb/core/devio.c
--- a/drivers/usb/core/devio.c	2013-11-01 20:18:05.029563399 +0200
+++ b/drivers/usb/core/devio.c	2013-11-01 18:44:54.469841303 +0200
@@ -1454,10 +1454,14 @@
 	void __user *addr = as->userurb;
 	unsigned int i;
 
-	if (as->userbuffer && urb->actual_length)
-		if (copy_to_user(as->userbuffer, urb->transfer_buffer,
-				 urb->actual_length))
+	if (as->userbuffer && urb->actual_length) {
+		if (urb->number_of_packets > 0)		/* Isochronous */
+			i = urb->transfer_buffer_length;
+		else					/* Non-Isoc */
+			i = urb->actual_length;
+		if (copy_to_user(as->userbuffer, urb->transfer_buffer, i))
 			return -EFAULT;
+	}
 	if (put_user(as->status, &userurb->status))
 		return -EFAULT;
 	if (put_user(urb->actual_length, &userurb->actual_length))
diff -Naur a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
--- a/drivers/usb/core/hub.c	2013-11-01 20:18:05.041563462 +0200
+++ b/drivers/usb/core/hub.c	2013-11-01 18:44:54.473841325 +0200
@@ -23,6 +23,7 @@
 #include <linux/mutex.h>
 #include <linux/freezer.h>
 #include <linux/usb/quirks.h>
+#include <linux/random.h>
 
 #include <asm/uaccess.h>
 #include <asm/byteorder.h>
@@ -458,10 +459,8 @@
  * talking to TTs must queue control transfers (not just bulk and iso), so
  * both can talk to the same hub concurrently.
  */
-static void hub_tt_work(struct work_struct *work)
+void _hub_tt_work(struct usb_hub *hub)
 {
-	struct usb_hub		*hub =
-		container_of(work, struct usb_hub, tt.clear_work);
 	unsigned long		flags;
 	int			limit = 100;
 
@@ -496,6 +495,14 @@
 	spin_unlock_irqrestore (&hub->tt.lock, flags);
 }
 
+void hub_tt_work(struct work_struct *work)
+{
+	struct usb_hub		*hub =
+		container_of(work, struct usb_hub, tt.clear_work);
+
+	_hub_tt_work(hub);
+}
+
 /**
  * usb_hub_clear_tt_buffer - clear control/bulk TT state in high speed hub
  * @urb: an URB associated with the failed or incomplete split transaction
@@ -543,7 +550,20 @@
 	/* tell keventd to clear state for this TT */
 	spin_lock_irqsave (&tt->lock, flags);
 	list_add_tail (&clear->clear_list, &tt->clear_list);
-	schedule_work(&tt->clear_work);
+	/* don't schedule on kevent if we're running on keventd (e.g.,
+	 * in hid_reset we can get here on kevent) unless on >=2.6.36
+	 */
+	if (!current_is_keventd())
+		/* put it on keventd */
+		schedule_work(&tt->clear_work);
+	else {
+		/* let khubd do it */
+		struct usb_hub		*hub =
+			container_of(&tt->clear_work, struct usb_hub,
+					tt.clear_work);
+		kick_khubd(hub);
+	}
+
 	spin_unlock_irqrestore (&tt->lock, flags);
 	return 0;
 }
@@ -1812,6 +1832,14 @@
 	/* Tell the world! */
 	announce_device(udev);
 
+	if (udev->serial)
+		add_device_randomness(udev->serial, strlen(udev->serial));
+	if (udev->product)
+		add_device_randomness(udev->product, strlen(udev->product));
+	if (udev->manufacturer)
+		add_device_randomness(udev->manufacturer,
+				      strlen(udev->manufacturer));
+
 	/* Register the device.  The device driver is responsible
 	 * for configuring the device and invoking the add-device
 	 * notifier chain (used by usbfs and possibly others).
@@ -3274,6 +3302,10 @@
 		if (hub->quiescing)
 			goto loop_autopm;
 
+		/* _hub_tt_work usually run on keventd */
+		if (!list_empty(&hub->tt.clear_list))
+			_hub_tt_work(hub);
+
 		if (hub->error) {
 			dev_dbg (hub_dev, "resetting for error %d\n",
 				hub->error);
diff -Naur a/drivers/usb/early/ehci-dbgp.c b/drivers/usb/early/ehci-dbgp.c
--- a/drivers/usb/early/ehci-dbgp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/usb/early/ehci-dbgp.c	2013-11-01 18:44:54.481841371 +0200
@@ -449,7 +449,7 @@
 	writel(FLAG_CF, &ehci_regs->configured_flag);
 
 	/* Wait until the controller is no longer halted */
-	loop = 10;
+	loop = 1000;
 	do {
 		status = readl(&ehci_regs->status);
 		if (!(status & STS_HALT))
diff -Naur a/drivers/usb/host/ehci.h b/drivers/usb/host/ehci.h
--- a/drivers/usb/host/ehci.h	2013-11-01 20:19:19.213931253 +0200
+++ b/drivers/usb/host/ehci.h	2013-11-01 18:44:54.553841731 +0200
@@ -74,6 +74,7 @@
 	/* async schedule support */
 	struct ehci_qh		*async;
 	struct ehci_qh		*reclaim;
+	struct ehci_qh		*qh_scan_next;
 	unsigned		scanning : 1;
 
 	/* periodic schedule support */
@@ -116,7 +117,6 @@
 	struct timer_list	iaa_watchdog;
 	struct timer_list	watchdog;
 	unsigned long		actions;
-	unsigned		stamp;
 	unsigned		random_frame;
 	unsigned long		next_statechange;
 	ktime_t			last_periodic_enable;
@@ -336,6 +336,7 @@
 	struct ehci_qh		*reclaim;	/* next to reclaim */
 
 	struct ehci_hcd		*ehci;
+	unsigned long		unlink_time;
 
 	/*
 	 * Do NOT use atomic operations for QH refcounting. On some CPUs
diff -Naur a/drivers/usb/host/ehci-hcd.c b/drivers/usb/host/ehci-hcd.c
--- a/drivers/usb/host/ehci-hcd.c	2013-11-01 20:19:19.209931242 +0200
+++ b/drivers/usb/host/ehci-hcd.c	2013-11-01 18:44:54.537841651 +0200
@@ -84,7 +84,8 @@
 #define EHCI_IAA_MSECS		10		/* arbitrary */
 #define EHCI_IO_JIFFIES		(HZ/10)		/* io watchdog > irq_thresh */
 #define EHCI_ASYNC_JIFFIES	(HZ/20)		/* async idle timeout */
-#define EHCI_SHRINK_FRAMES	5		/* async qh unlink delay */
+#define EHCI_SHRINK_JIFFIES	(DIV_ROUND_UP(HZ, 200) + 1)
+						/* 200-ms async qh unlink delay */
 
 /* Initial IRQ latency:  faster than hw default */
 static int log2_irq_thresh = 0;		// 0 to 6
@@ -139,10 +140,7 @@
 			break;
 		/* case TIMER_ASYNC_SHRINK: */
 		default:
-			/* add a jiffie since we synch against the
-			 * 8 KHz uframe counter.
-			 */
-			t = DIV_ROUND_UP(EHCI_SHRINK_FRAMES * HZ, 1000) + 1;
+			t = EHCI_SHRINK_JIFFIES;
 			break;
 		}
 		mod_timer(&ehci->watchdog, t + jiffies);
diff -Naur a/drivers/usb/host/ehci-q.c b/drivers/usb/host/ehci-q.c
--- a/drivers/usb/host/ehci-q.c	2013-11-01 20:19:19.213931253 +0200
+++ b/drivers/usb/host/ehci-q.c	2013-11-01 18:44:54.549841705 +0200
@@ -1217,6 +1217,8 @@
 
 	prev->hw->hw_next = qh->hw->hw_next;
 	prev->qh_next = qh->qh_next;
+	if (ehci->qh_scan_next == qh)
+		ehci->qh_scan_next = qh->qh_next.qh;
 	wmb ();
 
 	/* If the controller isn't running, we don't have to wait for it */
@@ -1242,53 +1244,49 @@
 	struct ehci_qh		*qh;
 	enum ehci_timer_action	action = TIMER_IO_WATCHDOG;
 
-	ehci->stamp = ehci_readl(ehci, &ehci->regs->frame_index);
 	timer_action_done (ehci, TIMER_ASYNC_SHRINK);
-rescan:
 	stopped = !HC_IS_RUNNING(ehci_to_hcd(ehci)->state);
-	qh = ehci->async->qh_next.qh;
-	if (likely (qh != NULL)) {
-		do {
-			/* clean any finished work for this qh */
-			if (!list_empty(&qh->qtd_list) && (stopped ||
-					qh->stamp != ehci->stamp)) {
-				int temp;
-
-				/* unlinks could happen here; completion
-				 * reporting drops the lock.  rescan using
-				 * the latest schedule, but don't rescan
-				 * qhs we already finished (no looping)
-				 * unless the controller is stopped.
-				 */
-				qh = qh_get (qh);
-				qh->stamp = ehci->stamp;
-				temp = qh_completions (ehci, qh);
-				if (qh->needs_rescan)
-					unlink_async(ehci, qh);
-				qh_put (qh);
-				if (temp != 0) {
-					goto rescan;
-				}
-			}
-
-			/* unlink idle entries, reducing DMA usage as well
-			 * as HCD schedule-scanning costs.  delay for any qh
-			 * we just scanned, there's a not-unusual case that it
-			 * doesn't stay idle for long.
-			 * (plus, avoids some kind of re-activation race.)
-			 */
-			if (list_empty(&qh->qtd_list)
-					&& qh->qh_state == QH_STATE_LINKED) {
-				if (!ehci->reclaim && (stopped ||
-					((ehci->stamp - qh->stamp) & 0x1fff)
-						>= EHCI_SHRINK_FRAMES * 8))
-					start_unlink_async(ehci, qh);
-				else
-					action = TIMER_ASYNC_SHRINK;
-			}
 
-			qh = qh->qh_next.qh;
-		} while (qh);
+	ehci->qh_scan_next = ehci->async->qh_next.qh;
+	while (ehci->qh_scan_next) {
+		qh = ehci->qh_scan_next;
+		ehci->qh_scan_next = qh->qh_next.qh;
+ rescan:
+		/* clean any finished work for this qh */
+		if (!list_empty(&qh->qtd_list)) {
+			int temp;
+
+			/*
+			 * Unlinks could happen here; completion reporting
+			 * drops the lock.  That's why ehci->qh_scan_next
+			 * always holds the next qh to scan; if the next qh
+			 * gets unlinked then ehci->qh_scan_next is adjusted
+			 * in start_unlink_async().
+			 */
+			qh = qh_get(qh);
+			temp = qh_completions(ehci, qh);
+			if (qh->needs_rescan)
+				unlink_async(ehci, qh);
+			qh->unlink_time = jiffies + EHCI_SHRINK_JIFFIES;
+			qh_put(qh);
+			if (temp != 0)
+				goto rescan;
+		}
+
+		/* unlink idle entries, reducing DMA usage as well
+		 * as HCD schedule-scanning costs.  delay for any qh
+		 * we just scanned, there's a not-unusual case that it
+		 * doesn't stay idle for long.
+		 * (plus, avoids some kind of re-activation race.)
+		 */
+		if (list_empty(&qh->qtd_list)
+				&& qh->qh_state == QH_STATE_LINKED) {
+			if (!ehci->reclaim && (stopped ||
+					time_after_eq(jiffies, qh->unlink_time)))
+				start_unlink_async(ehci, qh);
+			else
+				action = TIMER_ASYNC_SHRINK;
+		}
 	}
 	if (action == TIMER_ASYNC_SHRINK)
 		timer_action (ehci, TIMER_ASYNC_SHRINK);
diff -Naur a/drivers/usb/host/pci-quirks.c b/drivers/usb/host/pci-quirks.c
--- a/drivers/usb/host/pci-quirks.c	2013-11-01 20:18:05.081563654 +0200
+++ b/drivers/usb/host/pci-quirks.c	2013-11-01 18:44:54.585841890 +0200
@@ -418,12 +418,12 @@
 	void __iomem *op_reg_base;
 	u32 val;
 	int timeout;
+	int len = pci_resource_len(pdev, 0);
 
 	if (!mmio_resource_enabled(pdev, 0))
 		return;
 
-	base = ioremap_nocache(pci_resource_start(pdev, 0),
-				pci_resource_len(pdev, 0));
+	base = ioremap_nocache(pci_resource_start(pdev, 0), len);
 	if (base == NULL)
 		return;
 
@@ -433,9 +433,17 @@
 	 */
 	ext_cap_offset = xhci_find_next_cap_offset(base, XHCI_HCC_PARAMS_OFFSET);
 	do {
+		if ((ext_cap_offset + sizeof(val)) > len) {
+			/* We're reading garbage from the controller */
+			dev_warn(&pdev->dev,
+				 "xHCI controller failing to respond");
+			return;
+		}
+
 		if (!ext_cap_offset)
 			/* We've reached the end of the extended capabilities */
 			goto hc_init;
+
 		val = readl(base + ext_cap_offset);
 		if (XHCI_EXT_CAPS_ID(val) == XHCI_EXT_CAPS_LEGACY)
 			break;
@@ -458,9 +466,13 @@
 		}
 	}
 
-	/* Disable any BIOS SMIs */
-	writel(XHCI_LEGACY_DISABLE_SMI,
-			base + ext_cap_offset + XHCI_LEGACY_CONTROL_OFFSET);
+	val = readl(base + ext_cap_offset + XHCI_LEGACY_CONTROL_OFFSET);
+	/* Mask off (turn off) any enabled SMIs */
+	val &= XHCI_LEGACY_DISABLE_SMI;
+	/* Mask all SMI events bits, RW1C */
+	val |= XHCI_LEGACY_SMI_EVENTS;
+	/* Disable any BIOS SMIs and clear all SMI events*/
+	writel(val, base + ext_cap_offset + XHCI_LEGACY_CONTROL_OFFSET);
 
 hc_init:
 	op_reg_base = base + XHCI_HC_LENGTH(readl(base));
diff -Naur a/drivers/usb/host/xhci-ext-caps.h b/drivers/usb/host/xhci-ext-caps.h
--- a/drivers/usb/host/xhci-ext-caps.h	2013-11-01 20:18:05.089563700 +0200
+++ b/drivers/usb/host/xhci-ext-caps.h	2013-11-01 18:44:54.601841968 +0200
@@ -62,8 +62,9 @@
 /* USB Legacy Support Control and Status Register  - section 7.1.2 */
 /* Add this offset, plus the value of xECP in HCCPARAMS to the base address */
 #define XHCI_LEGACY_CONTROL_OFFSET	(0x04)
-/* bits 1:2, 5:12, and 17:19 need to be preserved; bits 21:28 should be zero */
-#define	XHCI_LEGACY_DISABLE_SMI		((0x3 << 1) + (0xff << 5) + (0x7 << 17))
+/* bits 1:3, 5:12, and 17:19 need to be preserved; bits 21:28 should be zero */
+#define	XHCI_LEGACY_DISABLE_SMI		((0x7 << 1) + (0xff << 5) + (0x7 << 17))
+#define XHCI_LEGACY_SMI_EVENTS		(0x7 << 29)
 
 /* command register values to disable interrupts and halt the HC */
 /* start/stop HC execution - do not write unless HC is halted*/
diff -Naur a/drivers/usb/host/xhci-hcd.c b/drivers/usb/host/xhci-hcd.c
--- a/drivers/usb/host/xhci-hcd.c	2013-11-01 20:18:05.089563700 +0200
+++ b/drivers/usb/host/xhci-hcd.c	2013-11-01 18:44:54.601841968 +0200
@@ -150,7 +150,7 @@
 	xhci_to_hcd(xhci)->state = HC_STATE_HALT;
 
 	ret = handshake(xhci, &xhci->op_regs->command,
-			CMD_RESET, 0, 250 * 1000);
+			CMD_RESET, 0, 10 * 1000 * 1000);
 	if (ret)
 		return ret;
 
diff -Naur a/drivers/usb/host/xhci-mem.c b/drivers/usb/host/xhci-mem.c
--- a/drivers/usb/host/xhci-mem.c	2013-11-01 20:18:05.093563712 +0200
+++ b/drivers/usb/host/xhci-mem.c	2013-11-01 18:44:54.601841968 +0200
@@ -934,11 +934,6 @@
 	int i;
 
 	/* Free the Event Ring Segment Table and the actual Event Ring */
-	if (xhci->ir_set) {
-		xhci_writel(xhci, 0, &xhci->ir_set->erst_size);
-		xhci_write_64(xhci, 0, &xhci->ir_set->erst_base);
-		xhci_write_64(xhci, 0, &xhci->ir_set->erst_dequeue);
-	}
 	size = sizeof(struct xhci_erst_entry)*(xhci->erst.num_entries);
 	if (xhci->erst.entries)
 		pci_free_consistent(pdev, size,
@@ -950,7 +945,7 @@
 	xhci->event_ring = NULL;
 	xhci_dbg(xhci, "Freed event ring\n");
 
-	xhci_write_64(xhci, 0, &xhci->op_regs->cmd_ring);
+	xhci->cmd_ring_reserved_trbs = 0;
 	if (xhci->cmd_ring)
 		xhci_ring_free(xhci, xhci->cmd_ring);
 	xhci->cmd_ring = NULL;
@@ -969,7 +964,6 @@
 	xhci->device_pool = NULL;
 	xhci_dbg(xhci, "Freed device context pool\n");
 
-	xhci_write_64(xhci, 0, &xhci->op_regs->dcbaa_ptr);
 	if (xhci->dcbaa)
 		pci_free_consistent(pdev, sizeof(*xhci->dcbaa),
 				xhci->dcbaa, xhci->dcbaa->dma);
@@ -1146,6 +1140,8 @@
 
 fail:
 	xhci_warn(xhci, "Couldn't initialize memory\n");
+	xhci_halt(xhci);
+	xhci_reset(xhci);
 	xhci_mem_cleanup(xhci);
 	return -ENOMEM;
 }
diff -Naur a/drivers/usb/serial/ftdi_sio.c b/drivers/usb/serial/ftdi_sio.c
--- a/drivers/usb/serial/ftdi_sio.c	2013-11-01 20:18:05.125563875 +0200
+++ b/drivers/usb/serial/ftdi_sio.c	2013-11-01 18:44:54.653842221 +0200
@@ -1784,7 +1784,8 @@
 
 	dbg("%s", __func__);
 
-	if (strcmp(udev->manufacturer, "CALAO Systems") == 0)
+	if ((udev->manufacturer) &&
+	    (strcmp(udev->manufacturer, "CALAO Systems") == 0))
 		return ftdi_jtag_probe(serial);
 
 	return 0;
@@ -2363,6 +2364,9 @@
 
 	cflag = termios->c_cflag;
 
+	if (!old_termios)
+		goto no_skip;
+
 	if (old_termios->c_cflag == termios->c_cflag
 	    && old_termios->c_ispeed == termios->c_ispeed
 	    && old_termios->c_ospeed == termios->c_ospeed)
@@ -2376,6 +2380,7 @@
 	    (termios->c_cflag & (CSIZE|PARODD|PARENB|CMSPAR|CSTOPB)))
 		goto no_data_parity_stop_changes;
 
+no_skip:
 	/* Set number of data bits, parity, stop bits */
 
 	termios->c_cflag &= ~CMSPAR;
diff -Naur a/drivers/usb/serial/garmin_gps.c b/drivers/usb/serial/garmin_gps.c
--- a/drivers/usb/serial/garmin_gps.c	2013-11-01 20:18:05.137563933 +0200
+++ b/drivers/usb/serial/garmin_gps.c	2013-11-01 18:44:54.657842239 +0200
@@ -974,10 +974,7 @@
 	if (!serial)
 		return;
 
-	mutex_lock(&port->serial->disc_mutex);
-
-	if (!port->serial->disconnected)
-		garmin_clear(garmin_data_p);
+	garmin_clear(garmin_data_p);
 
 	/* shutdown our urbs */
 	usb_kill_urb(port->read_urb);
@@ -986,8 +983,6 @@
 	/* keep reset state so we know that we must start a new session */
 	if (garmin_data_p->state != STATE_RESET)
 		garmin_data_p->state = STATE_DISCONNECTED;
-
-	mutex_unlock(&port->serial->disc_mutex);
 }
 
 
diff -Naur a/drivers/usb/serial/io_ti.c b/drivers/usb/serial/io_ti.c
--- a/drivers/usb/serial/io_ti.c	2013-11-01 20:18:05.149563988 +0200
+++ b/drivers/usb/serial/io_ti.c	2013-11-01 18:44:54.665842285 +0200
@@ -574,6 +574,9 @@
 	wait_queue_t wait;
 	unsigned long flags;
 
+	if (!tty)
+		return;
+
 	if (!timeout)
 		timeout = (HZ * EDGE_CLOSING_WAIT)/100;
 
diff -Naur a/drivers/usb/serial/mos7840.c b/drivers/usb/serial/mos7840.c
--- a/drivers/usb/serial/mos7840.c	2013-11-01 20:18:05.161564051 +0200
+++ b/drivers/usb/serial/mos7840.c	2013-11-01 18:44:54.681842359 +0200
@@ -1181,9 +1181,12 @@
 	}
 
 	spin_lock_irqsave(&mos7840_port->pool_lock, flags);
-	for (i = 0; i < NUM_URBS; ++i)
-		if (mos7840_port->busy[i])
-			chars += URB_TRANSFER_BUFFER_SIZE;
+	for (i = 0; i < NUM_URBS; ++i) {
+		if (mos7840_port->busy[i]) {
+			struct urb *urb = mos7840_port->write_urb_pool[i];
+			chars += urb->transfer_buffer_length;
+		}
+	}
 	spin_unlock_irqrestore(&mos7840_port->pool_lock, flags);
 	dbg("%s - returns %d", __func__, chars);
 	return chars;
@@ -2566,7 +2569,6 @@
 		kfree(mos7840_port->ctrl_buf);
 		usb_free_urb(mos7840_port->control_urb);
 		kfree(mos7840_port);
-		serial->port[i] = NULL;
 	}
 	return status;
 }
@@ -2633,6 +2635,7 @@
 		mos7840_port = mos7840_get_port_private(serial->port[i]);
 		dbg("mos7840_port %d = %p", i, mos7840_port);
 		if (mos7840_port) {
+			usb_free_urb(mos7840_port->control_urb);
 			kfree(mos7840_port->ctrl_buf);
 			kfree(mos7840_port->dr);
 			kfree(mos7840_port);
diff -Naur a/drivers/usb/serial/sierra.c b/drivers/usb/serial/sierra.c
--- a/drivers/usb/serial/sierra.c	2013-11-01 20:18:05.177564123 +0200
+++ b/drivers/usb/serial/sierra.c	2013-11-01 18:44:54.689842404 +0200
@@ -925,6 +925,7 @@
 			continue;
 		kfree(portdata);
 	}
+	kfree(serial->private);
 }
 
 #ifdef CONFIG_PM
diff -Naur a/drivers/usb/serial/usb-serial.c b/drivers/usb/serial/usb-serial.c
--- a/drivers/usb/serial/usb-serial.c	2013-11-01 20:18:05.181564153 +0200
+++ b/drivers/usb/serial/usb-serial.c	2013-11-01 18:44:54.693842415 +0200
@@ -1083,6 +1083,12 @@
 		serial->attached = 1;
 	}
 
+	/* Avoid race with tty_open and serial_install by setting the
+	 * disconnected flag and not clearing it until all ports have been
+	 * registered.
+	 */
+	serial->disconnected = 1;
+
 	if (get_free_serial(serial, num_ports, &minor) == NULL) {
 		dev_err(&interface->dev, "No more free serial devices\n");
 		goto probe_error;
@@ -1105,6 +1111,8 @@
 		}
 	}
 
+	serial->disconnected = 0;
+
 	usb_serial_console_init(debug, minor);
 
 exit:
diff -Naur a/drivers/usb/serial/whiteheat.c b/drivers/usb/serial/whiteheat.c
--- a/drivers/usb/serial/whiteheat.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/usb/serial/whiteheat.c	2013-11-01 18:44:54.697842436 +0200
@@ -576,6 +576,7 @@
 		"%s: please contact support@connecttech.com\n",
 		serial->type->description);
 	kfree(result);
+	kfree(command);
 	return -ENODEV;
 
 no_command_private:
diff -Naur a/drivers/video/uvesafb.c b/drivers/video/uvesafb.c
--- a/drivers/video/uvesafb.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/video/uvesafb.c	2013-11-01 18:44:55.233845102 +0200
@@ -814,8 +814,15 @@
 	par->pmi_setpal = pmi_setpal;
 	par->ypan = ypan;
 
-	if (par->pmi_setpal || par->ypan)
-		uvesafb_vbe_getpmi(task, par);
+	if (par->pmi_setpal || par->ypan) {
+		if (__supported_pte_mask & _PAGE_NX) {
+			par->pmi_setpal = par->ypan = 0;
+			printk(KERN_WARNING "uvesafb: NX protection is actively."
+				"We have better not to use the PMI.\n");
+		} else {
+			uvesafb_vbe_getpmi(task, par);
+		}
+	}
 #else
 	/* The protected mode interface is not available on non-x86. */
 	par->pmi_setpal = par->ypan = 0;
diff -Naur a/drivers/w1/w1.c b/drivers/w1/w1.c
--- a/drivers/w1/w1.c	2009-12-03 05:51:21.000000000 +0200
+++ b/drivers/w1/w1.c	2013-11-01 18:44:55.261845235 +0200
@@ -918,7 +918,8 @@
 			tmp64 = (triplet_ret >> 2);
 			rn |= (tmp64 << i);
 
-			if (kthread_should_stop()) {
+			/* ensure we're called from kthread and not by netlink callback */
+			if (!dev->priv && kthread_should_stop()) {
 				dev_dbg(&dev->dev, "Abort w1_search\n");
 				return;
 			}
diff -Naur a/fs/binfmt_elf.c b/fs/binfmt_elf.c
--- a/fs/binfmt_elf.c	2013-11-01 20:18:05.237564427 +0200
+++ b/fs/binfmt_elf.c	2013-11-01 18:44:55.585846838 +0200
@@ -1699,30 +1699,19 @@
 		return 0;
 	info->psinfo = kmalloc(sizeof(*info->psinfo), GFP_KERNEL);
 	if (!info->psinfo)
-		goto notes_free;
+		return 0;
 	info->prstatus = kmalloc(sizeof(*info->prstatus), GFP_KERNEL);
 	if (!info->prstatus)
-		goto psinfo_free;
+		return 0;
 	info->fpu = kmalloc(sizeof(*info->fpu), GFP_KERNEL);
 	if (!info->fpu)
-		goto prstatus_free;
+		return 0;
 #ifdef ELF_CORE_COPY_XFPREGS
 	info->xfpu = kmalloc(sizeof(*info->xfpu), GFP_KERNEL);
 	if (!info->xfpu)
-		goto fpu_free;
+		return 0;
 #endif
 	return 1;
-#ifdef ELF_CORE_COPY_XFPREGS
- fpu_free:
-	kfree(info->fpu);
-#endif
- prstatus_free:
-	kfree(info->prstatus);
- psinfo_free:
-	kfree(info->psinfo);
- notes_free:
-	kfree(info->notes);
-	return 0;
 }
 
 static int fill_note_info(struct elfhdr *elf, int phdrs,
diff -Naur a/fs/binfmt_em86.c b/fs/binfmt_em86.c
--- a/fs/binfmt_em86.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/binfmt_em86.c	2013-11-01 18:44:55.585846838 +0200
@@ -43,7 +43,6 @@
 			return -ENOEXEC;
 	}
 
-	bprm->recursion_depth++; /* Well, the bang-shell is implicit... */
 	allow_write_access(bprm->file);
 	fput(bprm->file);
 	bprm->file = NULL;
diff -Naur a/fs/binfmt_misc.c b/fs/binfmt_misc.c
--- a/fs/binfmt_misc.c	2013-11-01 20:18:05.241564454 +0200
+++ b/fs/binfmt_misc.c	2013-11-01 18:44:55.589846860 +0200
@@ -116,10 +116,6 @@
 	if (!enabled)
 		goto _ret;
 
-	retval = -ENOEXEC;
-	if (bprm->recursion_depth > BINPRM_MAX_RECURSION)
-		goto _ret;
-
 	/* to keep locking time low, we copy the interpreter string */
 	read_lock(&entries_lock);
 	fmt = check_file(bprm);
@@ -176,7 +172,10 @@
 		goto _error;
 	bprm->argc ++;
 
-	bprm->interp = iname;	/* for binfmt_script */
+	/* Update interp in case binfmt_script needs it. */
+	retval = bprm_change_interp(iname, bprm);
+	if (retval < 0)
+		goto _error;
 
 	interp_file = open_exec (iname);
 	retval = PTR_ERR (interp_file);
@@ -197,8 +196,6 @@
 	if (retval < 0)
 		goto _error;
 
-	bprm->recursion_depth++;
-
 	retval = search_binary_handler (bprm, regs);
 	if (retval < 0)
 		goto _error;
diff -Naur a/fs/binfmt_script.c b/fs/binfmt_script.c
--- a/fs/binfmt_script.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/binfmt_script.c	2013-11-01 18:44:55.589846860 +0200
@@ -22,15 +22,13 @@
 	char interp[BINPRM_BUF_SIZE];
 	int retval;
 
-	if ((bprm->buf[0] != '#') || (bprm->buf[1] != '!') ||
-	    (bprm->recursion_depth > BINPRM_MAX_RECURSION))
+	if ((bprm->buf[0] != '#') || (bprm->buf[1] != '!'))
 		return -ENOEXEC;
 	/*
 	 * This section does the #! interpretation.
 	 * Sorta complicated, but hopefully it will work.  -TYT
 	 */
 
-	bprm->recursion_depth++;
 	allow_write_access(bprm->file);
 	fput(bprm->file);
 	bprm->file = NULL;
@@ -82,7 +80,9 @@
 	retval = copy_strings_kernel(1, &i_name, bprm);
 	if (retval) return retval; 
 	bprm->argc++;
-	bprm->interp = interp;
+	retval = bprm_change_interp(interp, bprm);
+	if (retval < 0)
+		return retval;
 
 	/*
 	 * OK, now restart the process with the interpreter's dentry.
diff -Naur a/fs/btrfs/async-thread.c b/fs/btrfs/async-thread.c
--- a/fs/btrfs/async-thread.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/btrfs/async-thread.c	2013-11-01 18:44:55.593846887 +0200
@@ -211,10 +211,17 @@
 
 		work->ordered_func(work);
 
-		/* now take the lock again and call the freeing code */
+		/* now take the lock again and drop our item from the list */
 		spin_lock(&workers->order_lock);
 		list_del(&work->order_list);
+		spin_unlock(&workers->order_lock);
+
+		/*
+		 * we don't want to call the ordered free functions
+		 * with the lock held though
+		 */
 		work->ordered_free(work);
+		spin_lock(&workers->order_lock);
 	}
 
 	spin_unlock(&workers->order_lock);
diff -Naur a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c
--- a/fs/btrfs/volumes.c	2013-11-01 20:18:05.305564765 +0200
+++ b/fs/btrfs/volumes.c	2013-11-01 18:44:55.629847059 +0200
@@ -557,6 +557,12 @@
 		__btrfs_close_devices(fs_devices);
 		free_fs_devices(fs_devices);
 	}
+	/*
+	 * Wait for rcu kworkers under __btrfs_close_devices
+	 * to finish all blkdev_puts so device is really
+	 * free when umount is done.
+	 */
+	rcu_barrier();
 	return ret;
 }
 
diff -Naur a/fs/cifs/cifs_dfs_ref.c b/fs/cifs/cifs_dfs_ref.c
--- a/fs/cifs/cifs_dfs_ref.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/cifs/cifs_dfs_ref.c	2013-11-01 18:44:55.641847127 +0200
@@ -226,6 +226,8 @@
 compose_mount_options_err:
 	kfree(mountdata);
 	mountdata = ERR_PTR(rc);
+	kfree(*devname);
+	*devname = NULL;
 	goto compose_mount_options_out;
 }
 
diff -Naur a/fs/compat.c b/fs/compat.c
--- a/fs/compat.c	2013-11-01 20:18:05.337564930 +0200
+++ b/fs/compat.c	2013-11-01 18:44:55.677847298 +0200
@@ -1208,11 +1208,14 @@
 	struct file *file;
 	int fput_needed;
 	ssize_t ret;
+	loff_t pos;
 
 	file = fget_light(fd, &fput_needed);
 	if (!file)
 		return -EBADF;
-	ret = compat_readv(file, vec, vlen, &file->f_pos);
+	pos = file->f_pos;
+	ret = compat_readv(file, vec, vlen, &pos);
+	file->f_pos = pos;
 	fput_light(file, fput_needed);
 	return ret;
 }
@@ -1265,11 +1268,14 @@
 	struct file *file;
 	int fput_needed;
 	ssize_t ret;
+	loff_t pos;
 
 	file = fget_light(fd, &fput_needed);
 	if (!file)
 		return -EBADF;
-	ret = compat_writev(file, vec, vlen, &file->f_pos);
+	pos = file->f_pos;
+	ret = compat_writev(file, vec, vlen, &pos);
+	file->f_pos = pos;
 	fput_light(file, fput_needed);
 	return ret;
 }
diff -Naur a/fs/compat_ioctl.c b/fs/compat_ioctl.c
--- a/fs/compat_ioctl.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/compat_ioctl.c	2013-11-01 18:44:55.677847298 +0200
@@ -234,6 +234,8 @@
 	up = (struct compat_video_spu_palette __user *) arg;
 	err  = get_user(palp, &up->palette);
 	err |= get_user(length, &up->length);
+	if (err)
+		return -EFAULT;
 
 	up_native = compat_alloc_user_space(sizeof(struct video_spu_palette));
 	err  = put_user(compat_ptr(palp), &up_native->palette);
@@ -350,6 +352,7 @@
 	if (copy_from_user(&ifc32, compat_ptr(arg), sizeof(struct ifconf32)))
 		return -EFAULT;
 
+	memset(&ifc, 0, sizeof(ifc));
 	if (ifc32.ifcbuf == 0) {
 		ifc32.ifc_len = 0;
 		ifc.ifc_len = 0;
diff -Naur a/fs/ecryptfs/inode.c b/fs/ecryptfs/inode.c
--- a/fs/ecryptfs/inode.c	2013-11-01 20:18:05.369565075 +0200
+++ b/fs/ecryptfs/inode.c	2013-11-01 18:44:55.717847493 +0200
@@ -777,6 +777,9 @@
 		goto out;
 	}
 	crypt_stat = &ecryptfs_inode_to_private(dentry->d_inode)->crypt_stat;
+	if (crypt_stat->flags & ECRYPTFS_NEW_FILE)
+		crypt_stat->flags &= ~(ECRYPTFS_NEW_FILE);
+
 	/* Set up a fake ecryptfs file, this is used to interface with
 	 * the file in the underlying filesystem so that the
 	 * truncation has an effect there as well. */
@@ -1035,6 +1038,8 @@
 	rc = lower_dentry->d_inode->i_op->setxattr(lower_dentry, name, value,
 						   size, flags);
 	mutex_unlock(&lower_dentry->d_inode->i_mutex);
+	if (!rc)
+		fsstack_copy_attr_all(dentry->d_inode, lower_dentry->d_inode, NULL);
 out:
 	return rc;
 }
diff -Naur a/fs/ecryptfs/kthread.c b/fs/ecryptfs/kthread.c
--- a/fs/ecryptfs/kthread.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/ecryptfs/kthread.c	2013-11-01 18:44:55.717847493 +0200
@@ -148,7 +148,7 @@
 	(*lower_file) = dentry_open(lower_dentry, lower_mnt, flags, cred);
 	if (!IS_ERR(*lower_file))
 		goto out;
-	if (flags & O_RDONLY) {
+	if ((flags & O_ACCMODE) == O_RDONLY) {
 		rc = PTR_ERR((*lower_file));
 		goto out;
 	}
diff -Naur a/fs/eventpoll.c b/fs/eventpoll.c
--- a/fs/eventpoll.c	2013-11-01 20:18:05.381565141 +0200
+++ b/fs/eventpoll.c	2013-11-01 18:44:55.725847536 +0200
@@ -200,6 +200,12 @@
 
 	/* The user that created the eventpoll descriptor */
 	struct user_struct *user;
+
+	struct file *file;
+
+	/* used to optimize loop detection check */
+	int visited;
+	struct list_head visited_list_link;
 };
 
 /* Wait structure used by the poll hooks */
@@ -258,6 +264,15 @@
 /* Slab cache used to allocate "struct eppoll_entry" */
 static struct kmem_cache *pwq_cache __read_mostly;
 
+/* Visited nodes during ep_loop_check(), so we can unset them when we finish */
+static LIST_HEAD(visited_list);
+
+/*
+ * List of files with newly added links, where we may need to limit the number
+ * of emanating paths. Protected by the epmutex.
+ */
+static LIST_HEAD(tfile_check_list);
+
 #ifdef CONFIG_SYSCTL
 
 #include <linux/sysctl.h>
@@ -277,6 +292,12 @@
 };
 #endif /* CONFIG_SYSCTL */
 
+static const struct file_operations eventpoll_fops;
+
+static inline int is_file_epoll(struct file *f)
+{
+	return f->f_op == &eventpoll_fops;
+}
 
 /* Setup the structure that is used as key for the RB tree */
 static inline void ep_set_ffd(struct epoll_filefd *ffd,
@@ -300,6 +321,11 @@
 	return !list_empty(p);
 }
 
+static inline struct eppoll_entry *ep_pwq_from_wait(wait_queue_t *p)
+{
+	return container_of(p, struct eppoll_entry, wait);
+}
+
 /* Get the "struct epitem" from a wait queue pointer */
 static inline struct epitem *ep_item_from_wait(wait_queue_t *p)
 {
@@ -434,6 +460,18 @@
 	put_cpu();
 }
 
+static void ep_remove_wait_queue(struct eppoll_entry *pwq)
+{
+	wait_queue_head_t *whead;
+
+	rcu_read_lock();
+	/* If it is cleared by POLLFREE, it should be rcu-safe */
+	whead = rcu_dereference(pwq->whead);
+	if (whead)
+		remove_wait_queue(whead, &pwq->wait);
+	rcu_read_unlock();
+}
+
 /*
  * This function unregisters poll callbacks from the associated file
  * descriptor.  Must be called with "mtx" held (or "epmutex" if called from
@@ -448,7 +486,7 @@
 		pwq = list_first_entry(lsthead, struct eppoll_entry, llink);
 
 		list_del(&pwq->llink);
-		remove_wait_queue(pwq->whead, &pwq->wait);
+		ep_remove_wait_queue(pwq);
 		kmem_cache_free(pwq_cache, pwq);
 	}
 }
@@ -698,12 +736,6 @@
 	.poll		= ep_eventpoll_poll
 };
 
-/* Fast test to see if the file is an evenpoll file */
-static inline int is_file_epoll(struct file *f)
-{
-	return f->f_op == &eventpoll_fops;
-}
-
 /*
  * This is called from eventpoll_release() to unlink files from the eventpoll
  * interface. We need to have this facility to cleanup correctly files that are
@@ -814,6 +846,17 @@
 	struct epitem *epi = ep_item_from_wait(wait);
 	struct eventpoll *ep = epi->ep;
 
+	if ((unsigned long)key & POLLFREE) {
+		ep_pwq_from_wait(wait)->whead = NULL;
+		/*
+		 * whead = NULL above can race with ep_remove_wait_queue()
+		 * which can do another remove_wait_queue() after us, so we
+		 * can't use __remove_wait_queue(). whead->lock is held by
+		 * the caller.
+		 */
+		list_del_init(&wait->task_list);
+	}
+
 	spin_lock_irqsave(&ep->lock, flags);
 
 	/*
@@ -913,6 +956,103 @@
 	rb_insert_color(&epi->rbn, &ep->rbr);
 }
 
+
+
+#define PATH_ARR_SIZE 5
+/*
+ * These are the number paths of length 1 to 5, that we are allowing to emanate
+ * from a single file of interest. For example, we allow 1000 paths of length
+ * 1, to emanate from each file of interest. This essentially represents the
+ * potential wakeup paths, which need to be limited in order to avoid massive
+ * uncontrolled wakeup storms. The common use case should be a single ep which
+ * is connected to n file sources. In this case each file source has 1 path
+ * of length 1. Thus, the numbers below should be more than sufficient. These
+ * path limits are enforced during an EPOLL_CTL_ADD operation, since a modify
+ * and delete can't add additional paths. Protected by the epmutex.
+ */
+static const int path_limits[PATH_ARR_SIZE] = { 1000, 500, 100, 50, 10 };
+static int path_count[PATH_ARR_SIZE];
+
+static int path_count_inc(int nests)
+{
+	/* Allow an arbitrary number of depth 1 paths */
+	if (nests == 0)
+		return 0;
+
+	if (++path_count[nests] > path_limits[nests])
+		return -1;
+	return 0;
+}
+
+static void path_count_init(void)
+{
+	int i;
+
+	for (i = 0; i < PATH_ARR_SIZE; i++)
+		path_count[i] = 0;
+}
+
+static int reverse_path_check_proc(void *priv, void *cookie, int call_nests)
+{
+	int error = 0;
+	struct file *file = priv;
+	struct file *child_file;
+	struct epitem *epi;
+
+	list_for_each_entry(epi, &file->f_ep_links, fllink) {
+		child_file = epi->ep->file;
+		if (is_file_epoll(child_file)) {
+			if (list_empty(&child_file->f_ep_links)) {
+				if (path_count_inc(call_nests)) {
+					error = -1;
+					break;
+				}
+			} else {
+				error = ep_call_nested(&poll_loop_ncalls,
+							EP_MAX_NESTS,
+							reverse_path_check_proc,
+							child_file, child_file,
+							current);
+			}
+			if (error != 0)
+				break;
+		} else {
+			printk(KERN_ERR "reverse_path_check_proc: "
+				"file is not an ep!\n");
+		}
+	}
+	return error;
+}
+
+/**
+ * reverse_path_check - The tfile_check_list is list of file *, which have
+ *                      links that are proposed to be newly added. We need to
+ *                      make sure that those added links don't add too many
+ *                      paths such that we will spend all our time waking up
+ *                      eventpoll objects.
+ *
+ * Returns: Returns zero if the proposed links don't create too many paths,
+ *	    -1 otherwise.
+ */
+static int reverse_path_check(void)
+{
+	int length = 0;
+	int error = 0;
+	struct file *current_file;
+
+	/* let's call this for all tfiles */
+	list_for_each_entry(current_file, &tfile_check_list, f_tfile_llink) {
+		length++;
+		path_count_init();
+		error = ep_call_nested(&poll_loop_ncalls, EP_MAX_NESTS,
+					reverse_path_check_proc, current_file,
+					current_file, current);
+		if (error)
+			break;
+	}
+	return error;
+}
+
 /*
  * Must be called with "mtx" held.
  */
@@ -973,6 +1113,11 @@
 	 */
 	ep_rbtree_insert(ep, epi);
 
+	/* now check if we've created too many backpaths */
+	error = -EINVAL;
+	if (reverse_path_check())
+		goto error_remove_epi;
+
 	/* We have to drop the new item inside our item list to keep track of it */
 	spin_lock_irqsave(&ep->lock, flags);
 
@@ -997,6 +1142,14 @@
 
 	return 0;
 
+error_remove_epi:
+	spin_lock(&tfile->f_lock);
+	if (ep_is_linked(&epi->fllink))
+		list_del_init(&epi->fllink);
+	spin_unlock(&tfile->f_lock);
+
+	rb_erase(&epi->rbn, &ep->rbr);
+
 error_unregister:
 	ep_unregister_pollwait(ep, epi);
 
@@ -1030,10 +1183,30 @@
 	 * otherwise we might miss an event that happens between the
 	 * f_op->poll() call and the new event set registering.
 	 */
-	epi->event.events = event->events;
+	epi->event.events = event->events; /* need barrier below */
 	epi->event.data = event->data; /* protected by mtx */
 
 	/*
+	 * The following barrier has two effects:
+	 *
+	 * 1) Flush epi changes above to other CPUs.  This ensures
+	 *    we do not miss events from ep_poll_callback if an
+	 *    event occurs immediately after we call f_op->poll().
+	 *    We need this because we did not take ep->lock while
+	 *    changing epi above (but ep_poll_callback does take
+	 *    ep->lock).
+	 *
+	 * 2) We also need to ensure we do not miss _past_ events
+	 *    when calling f_op->poll().  This barrier also
+	 *    pairs with the barrier in wq_has_sleeper (see
+	 *    comments for wq_has_sleeper).
+	 *
+	 * This barrier will now guarantee ep_poll_callback or f_op->poll
+	 * (or both) will notice the readiness of an item.
+	 */
+	smp_mb();
+
+	/*
 	 * Get current event bits. We can safely use the file* here because
 	 * its usage count has been increased by the caller of this function.
 	 */
@@ -1223,18 +1396,36 @@
 	int error = 0;
 	struct file *file = priv;
 	struct eventpoll *ep = file->private_data;
+	struct eventpoll *ep_tovisit;
 	struct rb_node *rbp;
 	struct epitem *epi;
 
 	mutex_lock_nested(&ep->mtx, call_nests + 1);
+	ep->visited = 1;
+	list_add(&ep->visited_list_link, &visited_list);
 	for (rbp = rb_first(&ep->rbr); rbp; rbp = rb_next(rbp)) {
 		epi = rb_entry(rbp, struct epitem, rbn);
 		if (unlikely(is_file_epoll(epi->ffd.file))) {
+			ep_tovisit = epi->ffd.file->private_data;
+			if (ep_tovisit->visited)
+				continue;
 			error = ep_call_nested(&poll_loop_ncalls, EP_MAX_NESTS,
-					       ep_loop_check_proc, epi->ffd.file,
-					       epi->ffd.file->private_data, current);
+					ep_loop_check_proc, epi->ffd.file,
+					ep_tovisit, current);
 			if (error != 0)
 				break;
+		} else {
+			/*
+			 * If we've reached a file that is not associated with
+			 * an ep, then we need to check if the newly added
+			 * links are going to add too many wakeup paths. We do
+			 * this by adding it to the tfile_check_list, if it's
+			 * not already there, and calling reverse_path_check()
+			 * during ep_insert().
+			 */
+			if (list_empty(&epi->ffd.file->f_tfile_llink))
+				list_add(&epi->ffd.file->f_tfile_llink,
+					 &tfile_check_list);
 		}
 	}
 	mutex_unlock(&ep->mtx);
@@ -1255,8 +1446,31 @@
  */
 static int ep_loop_check(struct eventpoll *ep, struct file *file)
 {
-	return ep_call_nested(&poll_loop_ncalls, EP_MAX_NESTS,
+	int ret;
+	struct eventpoll *ep_cur, *ep_next;
+
+	ret = ep_call_nested(&poll_loop_ncalls, EP_MAX_NESTS,
 			      ep_loop_check_proc, file, ep, current);
+	/* clear visited list */
+	list_for_each_entry_safe(ep_cur, ep_next, &visited_list,
+							visited_list_link) {
+		ep_cur->visited = 0;
+		list_del(&ep_cur->visited_list_link);
+	}
+	return ret;
+}
+
+static void clear_tfile_check_list(void)
+{
+	struct file *file;
+
+	/* first clear the tfile_check_list */
+	while (!list_empty(&tfile_check_list)) {
+		file = list_first_entry(&tfile_check_list, struct file,
+					f_tfile_llink);
+		list_del_init(&file->f_tfile_llink);
+	}
+	INIT_LIST_HEAD(&tfile_check_list);
 }
 
 /*
@@ -1264,8 +1478,9 @@
  */
 SYSCALL_DEFINE1(epoll_create1, int, flags)
 {
-	int error;
+	int error, fd;
 	struct eventpoll *ep = NULL;
+	struct file *file;
 
 	/* Check the EPOLL_* constant for consistency.  */
 	BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC);
@@ -1282,11 +1497,25 @@
 	 * Creates all the items needed to setup an eventpoll file. That is,
 	 * a file structure and a free file descriptor.
 	 */
-	error = anon_inode_getfd("[eventpoll]", &eventpoll_fops, ep,
-				 flags & O_CLOEXEC);
-	if (error < 0)
-		ep_free(ep);
-
+	fd = get_unused_fd_flags(O_RDWR | (flags & O_CLOEXEC));
+	if (fd < 0) {
+		error = fd;
+		goto out_free_ep;
+	}
+	file = anon_inode_getfile("[eventpoll]", &eventpoll_fops, ep,
+				 O_RDWR | (flags & O_CLOEXEC));
+	if (IS_ERR(file)) {
+		error = PTR_ERR(file);
+		goto out_free_fd;
+	}
+	fd_install(fd, file);
+	ep->file = file;
+	return fd;
+
+out_free_fd:
+	put_unused_fd(fd);
+out_free_ep:
+	ep_free(ep);
 	return error;
 }
 
@@ -1352,21 +1581,29 @@
 	/*
 	 * When we insert an epoll file descriptor, inside another epoll file
 	 * descriptor, there is the change of creating closed loops, which are
-	 * better be handled here, than in more critical paths.
+	 * better be handled here, than in more critical paths. While we are
+	 * checking for loops we also determine the list of files reachable
+	 * and hang them on the tfile_check_list, so we can check that we
+	 * haven't created too many possible wakeup paths.
 	 *
-	 * We hold epmutex across the loop check and the insert in this case, in
-	 * order to prevent two separate inserts from racing and each doing the
-	 * insert "at the same time" such that ep_loop_check passes on both
-	 * before either one does the insert, thereby creating a cycle.
+	 * We need to hold the epmutex across both ep_insert and ep_remove
+	 * b/c we want to make sure we are looking at a coherent view of
+	 * epoll network.
 	 */
-	if (unlikely(is_file_epoll(tfile) && op == EPOLL_CTL_ADD)) {
+	if (op == EPOLL_CTL_ADD || op == EPOLL_CTL_DEL) {
 		mutex_lock(&epmutex);
 		did_lock_epmutex = 1;
-		error = -ELOOP;
-		if (ep_loop_check(ep, tfile) != 0)
-			goto error_tgt_fput;
 	}
-
+	if (op == EPOLL_CTL_ADD) {
+		if (is_file_epoll(tfile)) {
+			error = -ELOOP;
+			if (ep_loop_check(ep, tfile) != 0) {
+				clear_tfile_check_list();
+				goto error_tgt_fput;
+			}
+		} else
+			list_add(&tfile->f_tfile_llink, &tfile_check_list);
+	}
 
 	mutex_lock_nested(&ep->mtx, 0);
 
@@ -1385,6 +1622,7 @@
 			error = ep_insert(ep, &epds, tfile, fd);
 		} else
 			error = -EEXIST;
+		clear_tfile_check_list();
 		break;
 	case EPOLL_CTL_DEL:
 		if (epi)
@@ -1403,7 +1641,7 @@
 	mutex_unlock(&ep->mtx);
 
 error_tgt_fput:
-	if (unlikely(did_lock_epmutex))
+	if (did_lock_epmutex)
 		mutex_unlock(&epmutex);
 
 	fput(tfile);
diff -Naur a/fs/exec.c b/fs/exec.c
--- a/fs/exec.c	2013-11-01 20:18:05.381565141 +0200
+++ b/fs/exec.c	2013-11-01 18:44:55.725847536 +0200
@@ -1108,9 +1108,24 @@
 		mutex_unlock(&current->cred_guard_mutex);
 		abort_creds(bprm->cred);
 	}
+	/* If a binfmt changed the interp, free it. */
+	if (bprm->interp != bprm->filename)
+		kfree(bprm->interp);
 	kfree(bprm);
 }
 
+int bprm_change_interp(char *interp, struct linux_binprm *bprm)
+{
+	/* If a binfmt changed the interp, free it first. */
+	if (bprm->interp != bprm->filename)
+		kfree(bprm->interp);
+	bprm->interp = kstrdup(interp, GFP_KERNEL);
+	if (!bprm->interp)
+		return -ENOMEM;
+	return 0;
+}
+EXPORT_SYMBOL(bprm_change_interp);
+
 /*
  * install the new credentials for this executable
  */
@@ -1270,6 +1285,10 @@
 	int try,retval;
 	struct linux_binfmt *fmt;
 
+	/* This allows 4 levels of binfmt rewrites before failing hard. */
+	if (depth > 5)
+		return -ELOOP;
+
 	retval = security_bprm_check(bprm);
 	if (retval)
 		return retval;
@@ -1291,12 +1310,8 @@
 			if (!try_module_get(fmt->module))
 				continue;
 			read_unlock(&binfmt_lock);
+			bprm->recursion_depth = depth + 1;
 			retval = fn(bprm, regs);
-			/*
-			 * Restore the depth counter to its starting value
-			 * in this call, so we don't have to rely on every
-			 * load_binary function to restore it on return.
-			 */
 			bprm->recursion_depth = depth;
 			if (retval >= 0) {
 				if (depth == 0)
diff -Naur a/fs/ext3/ialloc.c b/fs/ext3/ialloc.c
--- a/fs/ext3/ialloc.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/ext3/ialloc.c	2013-11-01 18:44:55.753847673 +0200
@@ -575,8 +575,12 @@
 	if (IS_DIRSYNC(inode))
 		handle->h_sync = 1;
 	if (insert_inode_locked(inode) < 0) {
-		err = -EINVAL;
-		goto fail_drop;
+		/*
+		 * Likely a bitmap corruption causing inode to be allocated
+		 * twice.
+		 */
+		err = -EIO;
+		goto fail;
 	}
 	spin_lock(&sbi->s_next_gen_lock);
 	inode->i_generation = sbi->s_next_generation++;
diff -Naur a/fs/ext3/inode.c b/fs/ext3/inode.c
--- a/fs/ext3/inode.c	2013-11-01 20:18:05.389565180 +0200
+++ b/fs/ext3/inode.c	2013-11-01 18:44:55.753847673 +0200
@@ -2948,6 +2948,8 @@
 	struct ext3_inode_info *ei = EXT3_I(inode);
 	struct buffer_head *bh = iloc->bh;
 	int err = 0, rc, block;
+	int need_datasync = 0;
+	__le32 disksize;
 
 again:
 	/* we can't allow multiple procs in here at once, its a bit racey */
@@ -2985,7 +2987,11 @@
 		raw_inode->i_gid_high = 0;
 	}
 	raw_inode->i_links_count = cpu_to_le16(inode->i_nlink);
-	raw_inode->i_size = cpu_to_le32(ei->i_disksize);
+	disksize = cpu_to_le32(ei->i_disksize);
+	if (disksize != raw_inode->i_size) {
+		need_datasync = 1;
+		raw_inode->i_size = disksize;
+	}
 	raw_inode->i_atime = cpu_to_le32(inode->i_atime.tv_sec);
 	raw_inode->i_ctime = cpu_to_le32(inode->i_ctime.tv_sec);
 	raw_inode->i_mtime = cpu_to_le32(inode->i_mtime.tv_sec);
@@ -3001,8 +3007,11 @@
 	if (!S_ISREG(inode->i_mode)) {
 		raw_inode->i_dir_acl = cpu_to_le32(ei->i_dir_acl);
 	} else {
-		raw_inode->i_size_high =
-			cpu_to_le32(ei->i_disksize >> 32);
+		disksize = cpu_to_le32(ei->i_disksize >> 32);
+		if (disksize != raw_inode->i_size_high) {
+			raw_inode->i_size_high = disksize;
+			need_datasync = 1;
+		}
 		if (ei->i_disksize > 0x7fffffffULL) {
 			struct super_block *sb = inode->i_sb;
 			if (!EXT3_HAS_RO_COMPAT_FEATURE(sb,
@@ -3055,6 +3064,8 @@
 	ei->i_state &= ~EXT3_STATE_NEW;
 
 	atomic_set(&ei->i_sync_tid, handle->h_transaction->t_tid);
+	if (need_datasync)
+		atomic_set(&ei->i_datasync_tid, handle->h_transaction->t_tid);
 out_brelse:
 	brelse (bh);
 	ext3_std_error(inode->i_sb, err);
diff -Naur a/fs/ext4/acl.c b/fs/ext4/acl.c
--- a/fs/ext4/acl.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/ext4/acl.c	2013-11-01 18:44:55.761847722 +0200
@@ -454,8 +454,10 @@
 
 retry:
 	handle = ext4_journal_start(inode, EXT4_DATA_TRANS_BLOCKS(inode->i_sb));
-	if (IS_ERR(handle))
-		return PTR_ERR(handle);
+	if (IS_ERR(handle)) {
+		error = PTR_ERR(handle);
+		goto release_and_out;
+	}
 	error = ext4_set_acl(handle, inode, type, acl);
 	ext4_journal_stop(handle);
 	if (error == -ENOSPC && ext4_should_retry_alloc(inode->i_sb, &retries))
diff -Naur a/fs/ext4/ext4_extents.h b/fs/ext4/ext4_extents.h
--- a/fs/ext4/ext4_extents.h	2013-11-01 20:18:05.405565260 +0200
+++ b/fs/ext4/ext4_extents.h	2013-11-01 18:44:55.765847735 +0200
@@ -137,8 +137,11 @@
 #define EXT_BREAK      1
 #define EXT_REPEAT     2
 
-/* Maximum logical block in a file; ext4_extent's ee_block is __le32 */
-#define EXT_MAX_BLOCK	0xffffffff
+/*
+ * Maximum number of logical blocks in a file; ext4_extent's ee_block is
+ * __le32.
+ */
+#define EXT_MAX_BLOCKS	0xffffffff
 
 /*
  * EXT_INIT_MAX_LEN is the maximum number of blocks we can have in an
diff -Naur a/fs/ext4/extents.c b/fs/ext4/extents.c
--- a/fs/ext4/extents.c	2013-11-01 20:18:05.409565287 +0200
+++ b/fs/ext4/extents.c	2013-11-01 18:44:55.769847752 +0200
@@ -62,6 +62,7 @@
  * idx_pblock:
  * combine low and high parts of a leaf physical block number into ext4_fsblk_t
  */
+#define EXT4_EXT_DATA_VALID	0x8  /* extent contains valid data */
 ext4_fsblk_t idx_pblock(struct ext4_extent_idx *ix)
 {
 	ext4_fsblk_t block;
@@ -358,6 +359,8 @@
 	ext4_fsblk_t block = ext_pblock(ext);
 	int len = ext4_ext_get_actual_len(ext);
 
+	if (len == 0)
+		return 0;
 	return ext4_data_block_valid(EXT4_SB(inode->i_sb), block, len);
 }
 
@@ -1329,7 +1332,7 @@
 
 /*
  * ext4_ext_next_allocated_block:
- * returns allocated block in subsequent extent or EXT_MAX_BLOCK.
+ * returns allocated block in subsequent extent or EXT_MAX_BLOCKS.
  * NOTE: it considers block number from index entry as
  * allocated block. Thus, index entries have to be consistent
  * with leaves.
@@ -1343,7 +1346,7 @@
 	depth = path->p_depth;
 
 	if (depth == 0 && path->p_ext == NULL)
-		return EXT_MAX_BLOCK;
+		return EXT_MAX_BLOCKS;
 
 	while (depth >= 0) {
 		if (depth == path->p_depth) {
@@ -1360,12 +1363,12 @@
 		depth--;
 	}
 
-	return EXT_MAX_BLOCK;
+	return EXT_MAX_BLOCKS;
 }
 
 /*
  * ext4_ext_next_leaf_block:
- * returns first allocated block from next leaf or EXT_MAX_BLOCK
+ * returns first allocated block from next leaf or EXT_MAX_BLOCKS
  */
 static ext4_lblk_t ext4_ext_next_leaf_block(struct inode *inode,
 					struct ext4_ext_path *path)
@@ -1377,7 +1380,7 @@
 
 	/* zero-tree has no leaf blocks at all */
 	if (depth == 0)
-		return EXT_MAX_BLOCK;
+		return EXT_MAX_BLOCKS;
 
 	/* go to index block */
 	depth--;
@@ -1390,7 +1393,7 @@
 		depth--;
 	}
 
-	return EXT_MAX_BLOCK;
+	return EXT_MAX_BLOCKS;
 }
 
 /*
@@ -1570,13 +1573,13 @@
 	 */
 	if (b2 < b1) {
 		b2 = ext4_ext_next_allocated_block(path);
-		if (b2 == EXT_MAX_BLOCK)
+		if (b2 == EXT_MAX_BLOCKS)
 			goto out;
 	}
 
 	/* check for wrap through zero on extent logical start block*/
 	if (b1 + len1 < b1) {
-		len1 = EXT_MAX_BLOCK - b1;
+		len1 = EXT_MAX_BLOCKS - b1;
 		newext->ee_len = cpu_to_le16(len1);
 		ret = 1;
 	}
@@ -1652,7 +1655,7 @@
 	fex = EXT_LAST_EXTENT(eh);
 	next = ext4_ext_next_leaf_block(inode, path);
 	if (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)
-	    && next != EXT_MAX_BLOCK) {
+	    && next != EXT_MAX_BLOCKS) {
 		ext_debug("next leaf block - %d\n", next);
 		BUG_ON(npath != NULL);
 		npath = ext4_ext_find_extent(inode, next, NULL);
@@ -1770,7 +1773,7 @@
 	BUG_ON(func == NULL);
 	BUG_ON(inode == NULL);
 
-	while (block < last && block != EXT_MAX_BLOCK) {
+	while (block < last && block != EXT_MAX_BLOCKS) {
 		num = last - block;
 		/* find extent for this block */
 		down_read(&EXT4_I(inode)->i_data_sem);
@@ -1898,7 +1901,7 @@
 	if (ex == NULL) {
 		/* there is no extent yet, so gap is [0;-] */
 		lblock = 0;
-		len = EXT_MAX_BLOCK;
+		len = EXT_MAX_BLOCKS;
 		ext_debug("cache gap(whole file):");
 	} else if (block < le32_to_cpu(ex->ee_block)) {
 		lblock = block;
@@ -2143,8 +2146,8 @@
 		path[depth].p_ext = ex;
 
 		a = ex_ee_block > start ? ex_ee_block : start;
-		b = ex_ee_block + ex_ee_len - 1 < EXT_MAX_BLOCK ?
-			ex_ee_block + ex_ee_len - 1 : EXT_MAX_BLOCK;
+		b = ex_ee_block + ex_ee_len - 1 < EXT_MAX_BLOCKS ?
+			ex_ee_block + ex_ee_len - 1 : EXT_MAX_BLOCKS;
 
 		ext_debug("  border %u:%u\n", a, b);
 
@@ -2931,6 +2934,30 @@
 		ext4_ext_mark_uninitialized(ex3);
 		err = ext4_ext_insert_extent(handle, inode, path, ex3, flags);
 		if (err == -ENOSPC && may_zeroout) {
+			/*
+			 * This is different from the upstream, because we
+			 * need only a flag to say that the extent contains
+			 * the actual data.
+			 *
+			 * If the extent contains valid data, which can only
+			 * happen if AIO races with fallocate, then we got
+			 * here from ext4_convert_unwritten_extents_dio().
+			 * So we have to be careful not to zeroout valid data
+			 * in the extent.
+			 *
+			 * To avoid it, we only zeroout the ex3 and extend the
+			 * extent which is going to become initialized to cover
+			 * ex3 as well. and continue as we would if only
+			 * split in two was required.
+			 */
+			if (flags & EXT4_EXT_DATA_VALID) {
+				err =  ext4_ext_zeroout(inode, ex3);
+				if (err)
+					goto fix_extent_len;
+				max_blocks = allocated;
+				ex2->ee_len = cpu_to_le16(max_blocks);
+				goto skip;
+			}
 			err =  ext4_ext_zeroout(inode, &orig_ex);
 			if (err)
 				goto fix_extent_len;
@@ -2976,6 +3003,7 @@
 
 		allocated = max_blocks;
 	}
+skip:
 	/*
 	 * If there was a change of depth as part of the
 	 * insertion of ex3 above, we need to update the length
@@ -3028,11 +3056,16 @@
 	ext4_ext_dirty(handle, inode, path + depth);
 	return err;
 }
+
 static int ext4_convert_unwritten_extents_dio(handle_t *handle,
 					      struct inode *inode,
+					      ext4_lblk_t iblock,
+					      unsigned int max_blocks,
 					      struct ext4_ext_path *path)
 {
 	struct ext4_extent *ex;
+	ext4_lblk_t ee_block;
+	unsigned int ee_len;
 	struct ext4_extent_header *eh;
 	int depth;
 	int err = 0;
@@ -3041,6 +3074,30 @@
 	depth = ext_depth(inode);
 	eh = path[depth].p_hdr;
 	ex = path[depth].p_ext;
+	ee_block = le32_to_cpu(ex->ee_block);
+	ee_len = ext4_ext_get_actual_len(ex);
+
+	ext_debug("ext4_convert_unwritten_extents_endio: inode %lu, logical"
+		  "block %llu, max_blocks %u\n", inode->i_ino,
+		  (unsigned long long)ee_block, ee_len);
+
+	/* If extent is larger than requested then split is required */
+
+	if (ee_block != iblock || ee_len > max_blocks) {
+		err = ext4_split_unwritten_extents(handle, inode, path,
+					iblock, max_blocks,
+					EXT4_EXT_DATA_VALID);
+		if (err < 0)
+			goto out;
+		ext4_ext_drop_refs(path);
+		path = ext4_ext_find_extent(inode, iblock, path);
+		if (IS_ERR(path)) {
+			err = PTR_ERR(path);
+			goto out;
+		}
+		depth = ext_depth(inode);
+		ex = path[depth].p_ext;
+	}
 
 	err = ext4_ext_get_access(handle, inode, path + depth);
 	if (err)
@@ -3127,7 +3184,8 @@
 	/* async DIO end_io complete, convert the filled extent to written */
 	if (flags == EXT4_GET_BLOCKS_DIO_CONVERT_EXT) {
 		ret = ext4_convert_unwritten_extents_dio(handle, inode,
-							path);
+							 iblock, max_blocks,
+							 path);
 		if (ret >= 0)
 			ext4_update_inode_fsync_trans(handle, inode, 1);
 		goto out2;
@@ -3496,6 +3554,12 @@
 	int err = 0;
 
 	/*
+	 * finish any pending end_io work so we won't run the risk of
+	 * converting any truncated blocks to initialized later
+	 */
+	flush_aio_dio_completed_IO(inode);
+
+	/*
 	 * probably first extent we're gonna free will be last in block
 	 */
 	err = ext4_writepage_trans_blocks(inode);
@@ -3628,6 +3692,9 @@
 		mutex_unlock(&inode->i_mutex);
 		return ret;
 	}
+
+	/* Prevent race condition between unwritten */
+	flush_aio_dio_completed_IO(inode);
 retry:
 	while (ret >= 0 && ret < max_blocks) {
 		block = block + ret;
@@ -3781,15 +3848,14 @@
 		flags |= FIEMAP_EXTENT_UNWRITTEN;
 
 	/*
-	 * If this extent reaches EXT_MAX_BLOCK, it must be last.
+	 * If this extent reaches EXT_MAX_BLOCKS, it must be last.
 	 *
-	 * Or if ext4_ext_next_allocated_block is EXT_MAX_BLOCK,
+	 * Or if ext4_ext_next_allocated_block is EXT_MAX_BLOCKS,
 	 * this also indicates no more allocated blocks.
 	 *
-	 * XXX this might miss a single-block extent at EXT_MAX_BLOCK
 	 */
-	if (ext4_ext_next_allocated_block(path) == EXT_MAX_BLOCK ||
-	    newex->ec_block + newex->ec_len - 1 == EXT_MAX_BLOCK) {
+	if (ext4_ext_next_allocated_block(path) == EXT_MAX_BLOCKS ||
+	    newex->ec_block + newex->ec_len == EXT_MAX_BLOCKS) {
 		loff_t size = i_size_read(inode);
 		loff_t bs = EXT4_BLOCK_SIZE(inode->i_sb);
 
@@ -3869,8 +3935,8 @@
 
 		start_blk = start >> inode->i_sb->s_blocksize_bits;
 		last_blk = (start + len - 1) >> inode->i_sb->s_blocksize_bits;
-		if (last_blk >= EXT_MAX_BLOCK)
-			last_blk = EXT_MAX_BLOCK-1;
+		if (last_blk >= EXT_MAX_BLOCKS)
+			last_blk = EXT_MAX_BLOCKS-1;
 		len_blks = ((ext4_lblk_t) last_blk) - start_blk + 1;
 
 		/*
diff -Naur a/fs/ext4/ialloc.c b/fs/ext4/ialloc.c
--- a/fs/ext4/ialloc.c	2013-11-01 20:18:05.413565299 +0200
+++ b/fs/ext4/ialloc.c	2013-11-01 18:44:55.769847752 +0200
@@ -1015,8 +1015,12 @@
 	if (IS_DIRSYNC(inode))
 		ext4_handle_sync(handle);
 	if (insert_inode_locked(inode) < 0) {
-		err = -EINVAL;
-		goto fail_drop;
+		/*
+		 * Likely a bitmap corruption causing inode to be allocated
+		 * twice.
+		 */
+		err = -EIO;
+		goto fail;
 	}
 	spin_lock(&sbi->s_next_gen_lock);
 	inode->i_generation = sbi->s_next_generation++;
diff -Naur a/fs/ext4/inode.c b/fs/ext4/inode.c
--- a/fs/ext4/inode.c	2013-11-01 20:18:05.425565360 +0200
+++ b/fs/ext4/inode.c	2013-11-01 18:44:55.769847752 +0200
@@ -1112,6 +1112,15 @@
 		used = ei->i_reserved_data_blocks;
 	}
 
+	if (unlikely(ei->i_allocated_meta_blocks > ei->i_reserved_meta_blocks)) {
+		ext4_msg(inode->i_sb, KERN_NOTICE, "%s: ino %lu, allocated %d "
+			 "with only %d reserved metadata blocks\n", __func__,
+			 inode->i_ino, ei->i_allocated_meta_blocks,
+			 ei->i_reserved_meta_blocks);
+		WARN_ON(1);
+		ei->i_allocated_meta_blocks = ei->i_reserved_meta_blocks;
+	}
+
 	/* Update per-inode reservations */
 	ei->i_reserved_data_blocks -= used;
 	used += ei->i_allocated_meta_blocks;
@@ -5112,6 +5121,7 @@
 	struct ext4_inode_info *ei = EXT4_I(inode);
 	struct buffer_head *bh = iloc->bh;
 	int err = 0, rc, block;
+	int need_datasync = 0;
 
 	/* For fields not not tracking in the in-memory inode,
 	 * initialise them to zero for new inodes. */
@@ -5160,7 +5170,10 @@
 		raw_inode->i_file_acl_high =
 			cpu_to_le16(ei->i_file_acl >> 32);
 	raw_inode->i_file_acl_lo = cpu_to_le32(ei->i_file_acl);
-	ext4_isize_set(raw_inode, ei->i_disksize);
+	if (ei->i_disksize != ext4_isize(raw_inode)) {
+		ext4_isize_set(raw_inode, ei->i_disksize);
+		need_datasync = 1;
+	}
 	if (ei->i_disksize > 0x7fffffffULL) {
 		struct super_block *sb = inode->i_sb;
 		if (!EXT4_HAS_RO_COMPAT_FEATURE(sb,
@@ -5213,7 +5226,7 @@
 		err = rc;
 	ext4_clear_inode_state(inode, EXT4_STATE_NEW);
 
-	ext4_update_inode_fsync_trans(handle, inode, 0);
+	ext4_update_inode_fsync_trans(handle, inode, need_datasync);
 out_brelse:
 	brelse(bh);
 	ext4_std_error(inode->i_sb, err);
diff -Naur a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
--- a/fs/ext4/mballoc.c	2013-11-01 20:18:05.429565379 +0200
+++ b/fs/ext4/mballoc.c	2013-11-01 18:44:55.773847774 +0200
@@ -2070,7 +2070,11 @@
 		group = ac->ac_g_ex.fe_group;
 
 		for (i = 0; i < ngroups; group++, i++) {
-			if (group == ngroups)
+			/*
+			 * Artificially restricted ngroups for non-extent
+			 * files makes group > ngroups possible on first loop.
+			 */
+			if (group >= ngroups)
 				group = 0;
 
 			/* This now checks without needing the buddy page */
@@ -4163,7 +4167,7 @@
 		/* The max size of hash table is PREALLOC_TB_SIZE */
 		order = PREALLOC_TB_SIZE - 1;
 	/* Add the prealloc space to lg */
-	rcu_read_lock();
+	spin_lock(&lg->lg_prealloc_lock);
 	list_for_each_entry_rcu(tmp_pa, &lg->lg_prealloc_list[order],
 						pa_inode_list) {
 		spin_lock(&tmp_pa->pa_lock);
@@ -4187,12 +4191,12 @@
 	if (!added)
 		list_add_tail_rcu(&pa->pa_inode_list,
 					&lg->lg_prealloc_list[order]);
-	rcu_read_unlock();
+	spin_unlock(&lg->lg_prealloc_lock);
 
 	/* Now trim the list to be not more than 8 elements */
 	if (lg_prealloc_count > 8) {
 		ext4_mb_discard_lg_preallocations(sb, lg,
-						order, lg_prealloc_count);
+						  order, lg_prealloc_count);
 		return;
 	}
 	return ;
diff -Naur a/fs/ext4/move_extent.c b/fs/ext4/move_extent.c
--- a/fs/ext4/move_extent.c	2013-11-01 20:18:05.433565406 +0200
+++ b/fs/ext4/move_extent.c	2013-11-01 18:44:55.773847774 +0200
@@ -1001,12 +1001,12 @@
 		return -EINVAL;
 	}
 
-	if ((orig_start > EXT_MAX_BLOCK) ||
-	    (donor_start > EXT_MAX_BLOCK) ||
-	    (*len > EXT_MAX_BLOCK) ||
-	    (orig_start + *len > EXT_MAX_BLOCK))  {
+	if ((orig_start >= EXT_MAX_BLOCKS) ||
+	    (donor_start >= EXT_MAX_BLOCKS) ||
+	    (*len > EXT_MAX_BLOCKS) ||
+	    (orig_start + *len >= EXT_MAX_BLOCKS))  {
 		ext4_debug("ext4 move extent: Can't handle over [%u] blocks "
-			"[ino:orig %lu, donor %lu]\n", EXT_MAX_BLOCK,
+			"[ino:orig %lu, donor %lu]\n", EXT_MAX_BLOCKS,
 			orig_inode->i_ino, donor_inode->i_ino);
 		return -EINVAL;
 	}
@@ -1208,7 +1208,12 @@
 			orig_inode->i_ino, donor_inode->i_ino);
 		return -EINVAL;
 	}
-
+	/* TODO: This is non obvious task to swap blocks for inodes with full
+	   jornaling enabled */
+	if (ext4_should_journal_data(orig_inode) ||
+	    ext4_should_journal_data(donor_inode)) {
+		return -EINVAL;
+	}
 	/* Protect orig and donor inodes against a truncate */
 	ret1 = mext_inode_double_lock(orig_inode, donor_inode);
 	if (ret1 < 0)
diff -Naur a/fs/ext4/namei.c b/fs/ext4/namei.c
--- a/fs/ext4/namei.c	2013-11-01 20:18:05.437565418 +0200
+++ b/fs/ext4/namei.c	2013-11-01 18:44:55.773847774 +0200
@@ -1457,10 +1457,22 @@
 	frame->at = entries;
 	frame->bh = bh;
 	bh = bh2;
+
+	ext4_handle_dirty_metadata(handle, dir, frame->bh);
+	ext4_handle_dirty_metadata(handle, dir, bh);
+
 	de = do_split(handle,dir, &bh, frame, &hinfo, &retval);
-	dx_release (frames);
-	if (!(de))
+	if (!de) {
+		/*
+		 * Even if the block split failed, we have to properly write
+		 * out all the changes we did so far. Otherwise we can end up
+		 * with corrupted filesystem.
+		 */
+		ext4_mark_inode_dirty(handle, dir);
+		dx_release(frames);
 		return retval;
+	}
+	dx_release(frames);
 
 	retval = add_dirent_to_buf(handle, dentry, inode, de, bh);
 	brelse(bh);
@@ -1816,9 +1828,7 @@
 	err = PTR_ERR(inode);
 	if (!IS_ERR(inode)) {
 		init_special_inode(inode, inode->i_mode, rdev);
-#ifdef CONFIG_EXT4_FS_XATTR
 		inode->i_op = &ext4_special_inode_operations;
-#endif
 		err = ext4_add_nondir(handle, dentry, inode);
 	}
 	ext4_journal_stop(handle);
@@ -1991,7 +2001,7 @@
 	struct ext4_iloc iloc;
 	int err = 0, rc;
 
-	if (!ext4_handle_valid(handle))
+	if (!EXT4_SB(sb)->s_journal)
 		return 0;
 
 	mutex_lock(&EXT4_SB(sb)->s_orphan_lock);
@@ -2072,8 +2082,8 @@
 	struct ext4_iloc iloc;
 	int err = 0;
 
-	/* ext4_handle_valid() assumes a valid handle_t pointer */
-	if (handle && !ext4_handle_valid(handle))
+	if ((!EXT4_SB(inode->i_sb)->s_journal) &&
+	    !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS))
 		return 0;
 
 	mutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);
@@ -2092,7 +2102,7 @@
 	 * transaction handle with which to update the orphan list on
 	 * disk, but we still need to remove the inode from the linked
 	 * list in memory. */
-	if (sbi->s_journal && !handle)
+	if (!handle)
 		goto out;
 
 	err = ext4_reserve_inode_write(handle, inode, &iloc);
diff -Naur a/fs/ext4/super.c b/fs/ext4/super.c
--- a/fs/ext4/super.c	2013-11-01 20:18:05.441565432 +0200
+++ b/fs/ext4/super.c	2013-11-01 18:44:55.777847801 +0200
@@ -1937,7 +1937,9 @@
 				__func__, inode->i_ino, inode->i_size);
 			jbd_debug(2, "truncating inode %lu to %lld bytes\n",
 				  inode->i_ino, inode->i_size);
+			mutex_lock(&inode->i_mutex);
 			ext4_truncate(inode);
+			mutex_unlock(&inode->i_mutex);
 			nr_truncates++;
 		} else {
 			ext4_msg(sb, KERN_DEBUG,
@@ -1975,6 +1977,12 @@
  * in the vfs.  ext4 inode has 48 bits of i_block in fsblock units,
  * so that won't be a limiting factor.
  *
+ * However there is other limiting factor. We do store extents in the form
+ * of starting block and length, hence the resulting length of the extent
+ * covering maximum file size must fit into on-disk format containers as
+ * well. Given that length is always by 1 unit bigger than max unit (because
+ * we count 0 as well) we have to lower the s_maxbytes by one fs block.
+ *
  * Note, this does *not* consider any metadata overhead for vfs i_blocks.
  */
 static loff_t ext4_max_size(int blkbits, int has_huge_files)
@@ -1996,10 +2004,13 @@
 		upper_limit <<= blkbits;
 	}
 
-	/* 32-bit extent-start container, ee_block */
-	res = 1LL << 32;
+	/*
+	 * 32-bit extent-start container, ee_block. We lower the maxbytes
+	 * by one fs block, so ee_len can cover the extent of maximum file
+	 * size
+	 */
+	res = (1LL << 32) - 1;
 	res <<= blkbits;
-	res -= 1;
 
 	/* Sanity check against vm- & vfs- imposed limits */
 	if (res > upper_limit)
diff -Naur a/fs/fat/inode.c b/fs/fat/inode.c
--- a/fs/fat/inode.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/fat/inode.c	2013-11-01 18:44:55.781847814 +0200
@@ -558,7 +558,7 @@
 	buf->f_bavail = sbi->free_clusters;
 	buf->f_fsid.val[0] = (u32)id;
 	buf->f_fsid.val[1] = (u32)(id >> 32);
-	buf->f_namelen = sbi->options.isvfat ? 260 : 12;
+	buf->f_namelen = sbi->options.isvfat ? FAT_LFN_LEN : 12;
 
 	return 0;
 }
diff -Naur a/fs/fat/namei_vfat.c b/fs/fat/namei_vfat.c
--- a/fs/fat/namei_vfat.c	2013-11-01 20:19:19.265931512 +0200
+++ b/fs/fat/namei_vfat.c	2013-11-01 18:44:55.785847831 +0200
@@ -509,17 +509,18 @@
 	int charlen;
 
 	if (utf8) {
-		*outlen = utf8s_to_utf16s(name, len, (wchar_t *)outname);
+		*outlen = utf8s_to_utf16s(name, len, UTF16_HOST_ENDIAN,
+				(wchar_t *) outname, FAT_LFN_LEN + 2);
 		if (*outlen < 0)
 			return *outlen;
-		else if (*outlen > 255)
+		else if (*outlen > FAT_LFN_LEN)
 			return -ENAMETOOLONG;
 
 		op = &outname[*outlen * sizeof(wchar_t)];
 	} else {
 		if (nls) {
 			for (i = 0, ip = name, op = outname, *outlen = 0;
-			     i < len && *outlen <= 255;
+			     i < len && *outlen <= FAT_LFN_LEN;
 			     *outlen += 1)
 			{
 				if (escape && (*ip == ':')) {
@@ -559,7 +560,7 @@
 				return -ENAMETOOLONG;
 		} else {
 			for (i = 0, ip = name, op = outname, *outlen = 0;
-			     i < len && *outlen <= 255;
+			     i < len && *outlen <= FAT_LFN_LEN;
 			     i++, *outlen += 1)
 			{
 				*op++ = *ip++;
diff -Naur a/fs/fscache/stats.c b/fs/fscache/stats.c
--- a/fs/fscache/stats.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/fscache/stats.c	2013-11-01 18:44:55.797847893 +0200
@@ -276,5 +276,5 @@
 	.open		= fscache_stats_open,
 	.read		= seq_read,
 	.llseek		= seq_lseek,
-	.release	= seq_release,
+	.release        = single_release,
 };
diff -Naur a/fs/fuse/dir.c b/fs/fuse/dir.c
--- a/fs/fuse/dir.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/fuse/dir.c	2013-11-01 18:44:55.797847893 +0200
@@ -855,6 +855,7 @@
 		if (stat) {
 			generic_fillattr(inode, stat);
 			stat->mode = fi->orig_i_mode;
+			stat->ino = fi->orig_ino;
 		}
 	}
 
diff -Naur a/fs/fuse/file.c b/fs/fuse/file.c
--- a/fs/fuse/file.c	2013-11-01 20:18:05.457565525 +0200
+++ b/fs/fuse/file.c	2013-11-01 18:44:55.801847910 +0200
@@ -1664,7 +1664,7 @@
 	size_t n;
 	u32 max = FUSE_MAX_PAGES_PER_REQ << PAGE_SHIFT;
 
-	for (n = 0; n < count; n++) {
+	for (n = 0; n < count; n++, iov++) {
 		if (iov->iov_len > (size_t) max)
 			return -ENOMEM;
 		max -= iov->iov_len;
diff -Naur a/fs/fuse/fuse_i.h b/fs/fuse/fuse_i.h
--- a/fs/fuse/fuse_i.h	2013-11-01 20:18:05.457565525 +0200
+++ b/fs/fuse/fuse_i.h	2013-11-01 18:44:55.801847910 +0200
@@ -76,6 +76,9 @@
 	    preserve the original mode */
 	mode_t orig_i_mode;
 
+	/** 64 bit inode number */
+	u64 orig_ino;
+
 	/** Version of last attribute change */
 	u64 attr_version;
 
diff -Naur a/fs/fuse/inode.c b/fs/fuse/inode.c
--- a/fs/fuse/inode.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/fuse/inode.c	2013-11-01 18:44:55.801847910 +0200
@@ -86,6 +86,7 @@
 	fi->nlookup = 0;
 	fi->attr_version = 0;
 	fi->writectr = 0;
+	fi->orig_ino = 0;
 	INIT_LIST_HEAD(&fi->write_files);
 	INIT_LIST_HEAD(&fi->queued_writes);
 	INIT_LIST_HEAD(&fi->writepages);
@@ -140,6 +141,18 @@
 	return 0;
 }
 
+/*
+ * ino_t is 32-bits on 32-bit arch. We have to squash the 64-bit value down
+ * so that it will fit.
+ */
+static ino_t fuse_squash_ino(u64 ino64)
+{
+	ino_t ino = (ino_t) ino64;
+	if (sizeof(ino_t) < sizeof(u64))
+		ino ^= ino64 >> (sizeof(u64) - sizeof(ino_t)) * 8;
+	return ino;
+}
+
 void fuse_change_attributes_common(struct inode *inode, struct fuse_attr *attr,
 				   u64 attr_valid)
 {
@@ -149,7 +162,7 @@
 	fi->attr_version = ++fc->attr_version;
 	fi->i_time = attr_valid;
 
-	inode->i_ino     = attr->ino;
+	inode->i_ino     = fuse_squash_ino(attr->ino);
 	inode->i_mode    = (inode->i_mode & S_IFMT) | (attr->mode & 07777);
 	inode->i_nlink   = attr->nlink;
 	inode->i_uid     = attr->uid;
@@ -175,6 +188,8 @@
 	fi->orig_i_mode = inode->i_mode;
 	if (!(fc->flags & FUSE_DEFAULT_PERMISSIONS))
 		inode->i_mode &= ~S_ISVTX;
+
+	fi->orig_ino = attr->ino;
 }
 
 void fuse_change_attributes(struct inode *inode, struct fuse_attr *attr,
diff -Naur a/fs/hfsplus/catalog.c b/fs/hfsplus/catalog.c
--- a/fs/hfsplus/catalog.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/hfsplus/catalog.c	2013-11-01 18:44:55.825848039 +0200
@@ -329,6 +329,10 @@
 	err = hfs_brec_find(&src_fd);
 	if (err)
 		goto out;
+	if (src_fd.entrylength > sizeof(entry) || src_fd.entrylength < 0) {
+		err = -EIO;
+		goto out;
+	}
 
 	hfs_bnode_read(src_fd.bnode, &entry, src_fd.entryoffset,
 				src_fd.entrylength);
diff -Naur a/fs/hfsplus/dir.c b/fs/hfsplus/dir.c
--- a/fs/hfsplus/dir.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/hfsplus/dir.c	2013-11-01 18:44:55.829848051 +0200
@@ -138,6 +138,11 @@
 		filp->f_pos++;
 		/* fall through */
 	case 1:
+		if (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {
+			err = -EIO;
+			goto out;
+		}
+
 		hfs_bnode_read(fd.bnode, &entry, fd.entryoffset, fd.entrylength);
 		if (be16_to_cpu(entry.type) != HFSPLUS_FOLDER_THREAD) {
 			printk(KERN_ERR "hfs: bad catalog folder thread\n");
@@ -168,6 +173,12 @@
 			err = -EIO;
 			goto out;
 		}
+
+		if (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {
+			err = -EIO;
+			goto out;
+		}
+
 		hfs_bnode_read(fd.bnode, &entry, fd.entryoffset, fd.entrylength);
 		type = be16_to_cpu(entry.type);
 		len = HFSPLUS_MAX_STRLEN;
diff -Naur a/fs/hfsplus/extents.c b/fs/hfsplus/extents.c
--- a/fs/hfsplus/extents.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/hfsplus/extents.c	2013-11-01 18:44:55.829848051 +0200
@@ -447,7 +447,7 @@
 		struct address_space *mapping = inode->i_mapping;
 		struct page *page;
 		void *fsdata;
-		u32 size = inode->i_size;
+		loff_t size = inode->i_size;
 		int res;
 
 		res = pagecache_write_begin(NULL, mapping, size, 0,
diff -Naur a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c
--- a/fs/hugetlbfs/inode.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/hugetlbfs/inode.c	2013-11-01 18:44:55.841848110 +0200
@@ -601,9 +601,15 @@
 		spin_lock(&sbinfo->stat_lock);
 		/* If no limits set, just report 0 for max/free/used
 		 * blocks, like simple_statfs() */
-		if (sbinfo->max_blocks >= 0) {
-			buf->f_blocks = sbinfo->max_blocks;
-			buf->f_bavail = buf->f_bfree = sbinfo->free_blocks;
+		if (sbinfo->spool) {
+			long free_pages;
+
+			spin_lock(&sbinfo->spool->lock);
+			buf->f_blocks = sbinfo->spool->max_hpages;
+			free_pages = sbinfo->spool->max_hpages
+				- sbinfo->spool->used_hpages;
+			buf->f_bavail = buf->f_bfree = free_pages;
+			spin_unlock(&sbinfo->spool->lock);
 			buf->f_files = sbinfo->max_inodes;
 			buf->f_ffree = sbinfo->free_inodes;
 		}
@@ -619,6 +625,10 @@
 
 	if (sbi) {
 		sb->s_fs_info = NULL;
+
+		if (sbi->spool)
+			hugepage_put_subpool(sbi->spool);
+
 		kfree(sbi);
 	}
 }
@@ -842,10 +852,14 @@
 	sb->s_fs_info = sbinfo;
 	sbinfo->hstate = config.hstate;
 	spin_lock_init(&sbinfo->stat_lock);
-	sbinfo->max_blocks = config.nr_blocks;
-	sbinfo->free_blocks = config.nr_blocks;
 	sbinfo->max_inodes = config.nr_inodes;
 	sbinfo->free_inodes = config.nr_inodes;
+	sbinfo->spool = NULL;
+	if (config.nr_blocks != -1) {
+		sbinfo->spool = hugepage_new_subpool(config.nr_blocks);
+		if (!sbinfo->spool)
+			goto out_free;
+	}
 	sb->s_maxbytes = MAX_LFS_FILESIZE;
 	sb->s_blocksize = huge_page_size(config.hstate);
 	sb->s_blocksize_bits = huge_page_shift(config.hstate);
@@ -865,38 +879,12 @@
 	sb->s_root = root;
 	return 0;
 out_free:
+	if (sbinfo->spool)
+		kfree(sbinfo->spool);
 	kfree(sbinfo);
 	return -ENOMEM;
 }
 
-int hugetlb_get_quota(struct address_space *mapping, long delta)
-{
-	int ret = 0;
-	struct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(mapping->host->i_sb);
-
-	if (sbinfo->free_blocks > -1) {
-		spin_lock(&sbinfo->stat_lock);
-		if (sbinfo->free_blocks - delta >= 0)
-			sbinfo->free_blocks -= delta;
-		else
-			ret = -ENOMEM;
-		spin_unlock(&sbinfo->stat_lock);
-	}
-
-	return ret;
-}
-
-void hugetlb_put_quota(struct address_space *mapping, long delta)
-{
-	struct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(mapping->host->i_sb);
-
-	if (sbinfo->free_blocks > -1) {
-		spin_lock(&sbinfo->stat_lock);
-		sbinfo->free_blocks += delta;
-		spin_unlock(&sbinfo->stat_lock);
-	}
-}
-
 static int hugetlbfs_get_sb(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data, struct vfsmount *mnt)
 {
diff -Naur a/fs/isofs/export.c b/fs/isofs/export.c
--- a/fs/isofs/export.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/isofs/export.c	2013-11-01 18:44:55.845848131 +0200
@@ -131,6 +131,7 @@
 	len = 3;
 	fh32[0] = ei->i_iget5_block;
  	fh16[2] = (__u16)ei->i_iget5_offset;  /* fh16 [sic] */
+	fh16[3] = 0;  /* avoid leaking uninitialized data */
 	fh32[2] = inode->i_generation;
 	if (connectable && !S_ISDIR(inode->i_mode)) {
 		struct inode *parent;
diff -Naur a/fs/jbd/commit.c b/fs/jbd/commit.c
--- a/fs/jbd/commit.c	2013-11-01 20:18:05.473565598 +0200
+++ b/fs/jbd/commit.c	2013-11-01 18:44:55.849848158 +0200
@@ -85,7 +85,12 @@
 static void release_data_buffer(struct buffer_head *bh)
 {
 	if (buffer_freed(bh)) {
+		WARN_ON_ONCE(buffer_dirty(bh));
 		clear_buffer_freed(bh);
+		clear_buffer_mapped(bh);
+		clear_buffer_new(bh);
+		clear_buffer_req(bh);
+		bh->b_bdev = NULL;
 		release_buffer_page(bh);
 	} else
 		put_bh(bh);
@@ -864,17 +869,35 @@
 		 * there's no point in keeping a checkpoint record for
 		 * it. */
 
-		/* A buffer which has been freed while still being
-		 * journaled by a previous transaction may end up still
-		 * being dirty here, but we want to avoid writing back
-		 * that buffer in the future now that the last use has
-		 * been committed.  That's not only a performance gain,
-		 * it also stops aliasing problems if the buffer is left
-		 * behind for writeback and gets reallocated for another
-		 * use in a different page. */
+		/*
+		 * A buffer which has been freed while still being journaled by
+		 * a previous transaction.
+		 */
 		if (buffer_freed(bh)) {
-			clear_buffer_freed(bh);
-			clear_buffer_jbddirty(bh);
+			/*
+			 * If the running transaction is the one containing
+			 * "add to orphan" operation (b_next_transaction !=
+			 * NULL), we have to wait for that transaction to
+			 * commit before we can really get rid of the buffer.
+			 * So just clear b_modified to not confuse transaction
+			 * credit accounting and refile the buffer to
+			 * BJ_Forget of the running transaction. If the just
+			 * committed transaction contains "add to orphan"
+			 * operation, we can completely invalidate the buffer
+			 * now. We are rather throughout in that since the
+			 * buffer may be still accessible when blocksize <
+			 * pagesize and it is attached to the last partial
+			 * page.
+			 */
+			jh->b_modified = 0;
+			if (!jh->b_next_transaction) {
+				clear_buffer_freed(bh);
+				clear_buffer_jbddirty(bh);
+				clear_buffer_mapped(bh);
+				clear_buffer_new(bh);
+				clear_buffer_req(bh);
+				bh->b_bdev = NULL;
+			}
 		}
 
 		if (buffer_jbddirty(bh)) {
diff -Naur a/fs/jbd/transaction.c b/fs/jbd/transaction.c
--- a/fs/jbd/transaction.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/jbd/transaction.c	2013-11-01 18:44:55.853848171 +0200
@@ -1838,15 +1838,16 @@
  * We're outside-transaction here.  Either or both of j_running_transaction
  * and j_committing_transaction may be NULL.
  */
-static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh)
+static int journal_unmap_buffer(journal_t *journal, struct buffer_head *bh,
+				int partial_page)
 {
 	transaction_t *transaction;
 	struct journal_head *jh;
 	int may_free = 1;
-	int ret;
 
 	BUFFER_TRACE(bh, "entry");
 
+retry:
 	/*
 	 * It is safe to proceed here without the j_list_lock because the
 	 * buffers cannot be stolen by try_to_free_buffers as long as we are
@@ -1864,6 +1865,29 @@
 	if (!jh)
 		goto zap_buffer_no_jh;
 
+	/*
+	 * We cannot remove the buffer from checkpoint lists until the
+	 * transaction adding inode to orphan list (let's call it T)
+	 * is committed.  Otherwise if the transaction changing the
+	 * buffer would be cleaned from the journal before T is
+	 * committed, a crash will cause that the correct contents of
+	 * the buffer will be lost.  On the other hand we have to
+	 * clear the buffer dirty bit at latest at the moment when the
+	 * transaction marking the buffer as freed in the filesystem
+	 * structures is committed because from that moment on the
+	 * block can be reallocated and used by a different page.
+	 * Since the block hasn't been freed yet but the inode has
+	 * already been added to orphan list, it is safe for us to add
+	 * the buffer to BJ_Forget list of the newest transaction.
+	 *
+	 * Also we have to clear buffer_mapped flag of a truncated buffer
+	 * because the buffer_head may be attached to the page straddling
+	 * i_size (can happen only when blocksize < pagesize) and thus the
+	 * buffer_head can be reused when the file is extended again. So we end
+	 * up keeping around invalidated buffers attached to transactions'
+	 * BJ_Forget list just to stop checkpointing code from cleaning up
+	 * the transaction this buffer was modified in.
+	 */
 	transaction = jh->b_transaction;
 	if (transaction == NULL) {
 		/* First case: not on any transaction.  If it
@@ -1889,13 +1913,9 @@
 			 * committed, the buffer won't be needed any
 			 * longer. */
 			JBUFFER_TRACE(jh, "checkpointed: add to BJ_Forget");
-			ret = __dispose_buffer(jh,
+			may_free = __dispose_buffer(jh,
 					journal->j_running_transaction);
-			journal_put_journal_head(jh);
-			spin_unlock(&journal->j_list_lock);
-			jbd_unlock_bh_state(bh);
-			spin_unlock(&journal->j_state_lock);
-			return ret;
+			goto zap_buffer;
 		} else {
 			/* There is no currently-running transaction. So the
 			 * orphan record which we wrote for this file must have
@@ -1903,13 +1923,9 @@
 			 * the committing transaction, if it exists. */
 			if (journal->j_committing_transaction) {
 				JBUFFER_TRACE(jh, "give to committing trans");
-				ret = __dispose_buffer(jh,
+				may_free = __dispose_buffer(jh,
 					journal->j_committing_transaction);
-				journal_put_journal_head(jh);
-				spin_unlock(&journal->j_list_lock);
-				jbd_unlock_bh_state(bh);
-				spin_unlock(&journal->j_state_lock);
-				return ret;
+				goto zap_buffer;
 			} else {
 				/* The orphan record's transaction has
 				 * committed.  We can cleanse this buffer */
@@ -1929,16 +1945,31 @@
 			goto zap_buffer;
 		}
 		/*
-		 * If it is committing, we simply cannot touch it.  We
-		 * can remove it's next_transaction pointer from the
-		 * running transaction if that is set, but nothing
-		 * else. */
-		set_buffer_freed(bh);
-		if (jh->b_next_transaction) {
-			J_ASSERT(jh->b_next_transaction ==
-					journal->j_running_transaction);
-			jh->b_next_transaction = NULL;
+		 * The buffer is committing, we simply cannot touch
+		 * it. If the page is straddling i_size we have to wait
+		 * for commit and try again.
+		 */
+		if (partial_page) {
+			tid_t tid = journal->j_committing_transaction->t_tid;
+
+			journal_put_journal_head(jh);
+			spin_unlock(&journal->j_list_lock);
+			jbd_unlock_bh_state(bh);
+			spin_unlock(&journal->j_state_lock);
+			unlock_buffer(bh);
+			log_wait_commit(journal, tid);
+			lock_buffer(bh);
+			goto retry;
 		}
+		/*
+		 * OK, buffer won't be reachable after truncate. We just set
+		 * j_next_transaction to the running transaction (if there is
+		 * one) and mark buffer as freed so that commit code knows it
+		 * should clear dirty bits when it is done with the buffer.
+		 */
+		set_buffer_freed(bh);
+		if (journal->j_running_transaction && buffer_jbddirty(bh))
+			jh->b_next_transaction = journal->j_running_transaction;
 		journal_put_journal_head(jh);
 		spin_unlock(&journal->j_list_lock);
 		jbd_unlock_bh_state(bh);
@@ -1957,6 +1988,14 @@
 	}
 
 zap_buffer:
+	/*
+	 * This is tricky. Although the buffer is truncated, it may be reused
+	 * if blocksize < pagesize and it is attached to the page straddling
+	 * EOF. Since the buffer might have been added to BJ_Forget list of the
+	 * running transaction, journal_get_write_access() won't clear
+	 * b_modified and credit accounting gets confused. So clear b_modified
+	 * here. */
+	jh->b_modified = 0;
 	journal_put_journal_head(jh);
 zap_buffer_no_jh:
 	spin_unlock(&journal->j_list_lock);
@@ -2005,7 +2044,8 @@
 		if (offset <= curr_off) {
 			/* This block is wholly outside the truncation point */
 			lock_buffer(bh);
-			may_free &= journal_unmap_buffer(journal, bh);
+			may_free &= journal_unmap_buffer(journal, bh,
+							 offset > 0);
 			unlock_buffer(bh);
 		}
 		curr_off = next_off;
@@ -2120,7 +2160,7 @@
  */
 void __journal_refile_buffer(struct journal_head *jh)
 {
-	int was_dirty;
+	int was_dirty, jlist;
 	struct buffer_head *bh = jh2bh(jh);
 
 	J_ASSERT_JH(jh, jbd_is_locked_bh_state(bh));
@@ -2142,8 +2182,13 @@
 	__journal_temp_unlink_buffer(jh);
 	jh->b_transaction = jh->b_next_transaction;
 	jh->b_next_transaction = NULL;
-	__journal_file_buffer(jh, jh->b_transaction,
-				jh->b_modified ? BJ_Metadata : BJ_Reserved);
+	if (buffer_freed(bh))
+		jlist = BJ_Forget;
+	else if (jh->b_modified)
+		jlist = BJ_Metadata;
+	else
+		jlist = BJ_Reserved;
+	__journal_file_buffer(jh, jh->b_transaction, jlist);
 	J_ASSERT_JH(jh, jh->b_transaction->t_state == T_RUNNING);
 
 	if (was_dirty)
diff -Naur a/fs/jbd2/transaction.c b/fs/jbd2/transaction.c
--- a/fs/jbd2/transaction.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/jbd2/transaction.c	2013-11-01 18:44:55.857848188 +0200
@@ -1822,6 +1822,8 @@
 	clear_buffer_mapped(bh);
 	clear_buffer_req(bh);
 	clear_buffer_new(bh);
+	clear_buffer_delay(bh);
+	clear_buffer_unwritten(bh);
 	bh->b_bdev = NULL;
 	return may_free;
 }
diff -Naur a/fs/locks.c b/fs/locks.c
--- a/fs/locks.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/locks.c	2013-11-01 18:44:55.917848486 +0200
@@ -291,7 +291,7 @@
 	return 0;
 }
 
-static int assign_type(struct file_lock *fl, int type)
+static int assign_type(struct file_lock *fl, long type)
 {
 	switch (type) {
 	case F_RDLCK:
@@ -444,7 +444,7 @@
 /*
  * Initialize a lease, use the default lock manager operations
  */
-static int lease_init(struct file *filp, int type, struct file_lock *fl)
+static int lease_init(struct file *filp, long type, struct file_lock *fl)
  {
 	if (assign_type(fl, type) != 0)
 		return -EINVAL;
@@ -462,7 +462,7 @@
 }
 
 /* Allocate a file_lock initialised to this type of lease */
-static struct file_lock *lease_alloc(struct file *filp, int type)
+static struct file_lock *lease_alloc(struct file *filp, long type)
 {
 	struct file_lock *fl = locks_alloc_lock();
 	int error = -ENOMEM;
diff -Naur a/fs/nfs/nfs3proc.c b/fs/nfs/nfs3proc.c
--- a/fs/nfs/nfs3proc.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/nfs/nfs3proc.c	2013-11-01 18:44:56.033849070 +0200
@@ -66,7 +66,7 @@
 	nfs_fattr_init(info->fattr);
 	status = rpc_call_sync(client, &msg, 0);
 	dprintk("%s: reply fsinfo: %d\n", __func__, status);
-	if (!(info->fattr->valid & NFS_ATTR_FATTR)) {
+	if (status == 0 && !(info->fattr->valid & NFS_ATTR_FATTR)) {
 		msg.rpc_proc = &nfs3_procedures[NFS3PROC_GETATTR];
 		msg.rpc_resp = info->fattr;
 		status = rpc_call_sync(client, &msg, 0);
diff -Naur a/fs/nfs/nfs4proc.c b/fs/nfs/nfs4proc.c
--- a/fs/nfs/nfs4proc.c	2013-11-01 20:18:05.509565775 +0200
+++ b/fs/nfs/nfs4proc.c	2013-11-01 18:44:56.037849085 +0200
@@ -1586,6 +1586,7 @@
 		goto err_opendata_put;
 	if (server->caps & NFS_CAP_POSIX_LOCK)
 		set_bit(NFS_STATE_POSIX_LOCKS, &state->flags);
+	nfs_revalidate_inode(server, state->inode);
 	nfs4_opendata_put(opendata);
 	nfs4_put_state_owner(sp);
 	*res = state;
diff -Naur a/fs/nfs/super.c b/fs/nfs/super.c
--- a/fs/nfs/super.c	2013-11-01 20:18:05.521565836 +0200
+++ b/fs/nfs/super.c	2013-11-01 18:44:56.049849149 +0200
@@ -2934,4 +2934,6 @@
 	return error;
 }
 
+MODULE_ALIAS("nfs4");
+
 #endif /* CONFIG_NFS_V4 */
diff -Naur a/fs/nfsd/nfs4xdr.c b/fs/nfsd/nfs4xdr.c
--- a/fs/nfsd/nfs4xdr.c	2013-11-01 20:18:05.537565908 +0200
+++ b/fs/nfsd/nfs4xdr.c	2013-11-01 18:44:56.061849201 +0200
@@ -1955,7 +1955,7 @@
 	if (bmval0 & FATTR4_WORD0_CASE_INSENSITIVE) {
 		if ((buflen -= 4) < 0)
 			goto out_resource;
-		WRITE32(1);
+		WRITE32(0);
 	}
 	if (bmval0 & FATTR4_WORD0_CASE_PRESERVING) {
 		if ((buflen -= 4) < 0)
@@ -2610,11 +2610,16 @@
 	len = maxcount;
 	v = 0;
 	while (len > 0) {
-		pn = resp->rqstp->rq_resused++;
+		pn = resp->rqstp->rq_resused;
+		if (!resp->rqstp->rq_respages[pn]) { /* ran out of pages */
+			maxcount -= len;
+			break;
+		}
 		resp->rqstp->rq_vec[v].iov_base =
 			page_address(resp->rqstp->rq_respages[pn]);
 		resp->rqstp->rq_vec[v].iov_len =
 			len < PAGE_SIZE ? len : PAGE_SIZE;
+		resp->rqstp->rq_resused++;
 		v++;
 		len -= PAGE_SIZE;
 	}
@@ -2662,6 +2667,8 @@
 		return nfserr;
 	if (resp->xbuf->page_len)
 		return nfserr_resource;
+	if (!resp->rqstp->rq_respages[resp->rqstp->rq_resused])
+		return nfserr_resource;
 
 	page = page_address(resp->rqstp->rq_respages[resp->rqstp->rq_resused++]);
 
@@ -2711,6 +2718,8 @@
 		return nfserr;
 	if (resp->xbuf->page_len)
 		return nfserr_resource;
+	if (!resp->rqstp->rq_respages[resp->rqstp->rq_resused])
+		return nfserr_resource;
 
 	RESERVE_SPACE(8);  /* verifier */
 	savep = p;
diff -Naur a/fs/nilfs2/the_nilfs.c b/fs/nilfs2/the_nilfs.c
--- a/fs/nilfs2/the_nilfs.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/nilfs2/the_nilfs.c	2013-11-01 18:44:56.093849360 +0200
@@ -478,6 +478,7 @@
 		brelse(sbh[1]);
 		sbh[1] = NULL;
 		sbp[1] = NULL;
+		valid[1] = 0;
 		swp = 0;
 	}
 	if (!valid[swp]) {
diff -Naur a/fs/nls/nls_base.c b/fs/nls/nls_base.c
--- a/fs/nls/nls_base.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/nls/nls_base.c	2013-11-01 18:44:56.093849360 +0200
@@ -114,34 +114,57 @@
 }
 EXPORT_SYMBOL(utf32_to_utf8);
 
-int utf8s_to_utf16s(const u8 *s, int len, wchar_t *pwcs)
+static inline void put_utf16(wchar_t *s, unsigned c, enum utf16_endian endian)
+{
+	switch (endian) {
+	default:
+		*s = (wchar_t) c;
+		break;
+	case UTF16_LITTLE_ENDIAN:
+		*s = __cpu_to_le16(c);
+		break;
+	case UTF16_BIG_ENDIAN:
+		*s = __cpu_to_be16(c);
+		break;
+	}
+}
+
+int utf8s_to_utf16s(const u8 *s, int len, enum utf16_endian endian,
+		wchar_t *pwcs, int maxlen)
 {
 	u16 *op;
 	int size;
 	unicode_t u;
 
 	op = pwcs;
-	while (*s && len > 0) {
+	while (len > 0 && maxlen > 0 && *s) {
 		if (*s & 0x80) {
 			size = utf8_to_utf32(s, len, &u);
 			if (size < 0)
 				return -EINVAL;
+			s += size;
+			len -= size;
 
 			if (u >= PLANE_SIZE) {
+				if (maxlen < 2)
+					break;
 				u -= PLANE_SIZE;
-				*op++ = (wchar_t) (SURROGATE_PAIR |
-						((u >> 10) & SURROGATE_BITS));
-				*op++ = (wchar_t) (SURROGATE_PAIR |
+				put_utf16(op++, SURROGATE_PAIR |
+						((u >> 10) & SURROGATE_BITS),
+						endian);
+				put_utf16(op++, SURROGATE_PAIR |
 						SURROGATE_LOW |
-						(u & SURROGATE_BITS));
+						(u & SURROGATE_BITS),
+						endian);
+				maxlen -= 2;
 			} else {
-				*op++ = (wchar_t) u;
+				put_utf16(op++, u, endian);
+				maxlen--;
 			}
-			s += size;
-			len -= size;
 		} else {
-			*op++ = *s++;
+			put_utf16(op++, *s++, endian);
 			len--;
+			maxlen--;
 		}
 	}
 	return op - pwcs;
diff -Naur a/fs/signalfd.c b/fs/signalfd.c
--- a/fs/signalfd.c	2013-11-01 20:18:05.609566265 +0200
+++ b/fs/signalfd.c	2013-11-01 18:44:56.481851280 +0200
@@ -29,6 +29,21 @@
 #include <linux/signalfd.h>
 #include <linux/syscalls.h>
 
+void signalfd_cleanup(struct sighand_struct *sighand)
+{
+	wait_queue_head_t *wqh = &sighand->signalfd_wqh;
+	/*
+	 * The lockless check can race with remove_wait_queue() in progress,
+	 * but in this case its caller should run under rcu_read_lock() and
+	 * sighand_cachep is SLAB_DESTROY_BY_RCU, we can safely return.
+	 */
+	if (likely(!waitqueue_active(wqh)))
+		return;
+
+	/* wait_queue_t->func(POLLFREE) should do remove_wait_queue() */
+	wake_up_poll(wqh, POLLHUP | POLLFREE);
+}
+
 struct signalfd_ctx {
 	sigset_t sigmask;
 };
diff -Naur a/fs/sysfs/dir.c b/fs/sysfs/dir.c
--- a/fs/sysfs/dir.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/sysfs/dir.c	2013-11-01 18:44:56.509851417 +0200
@@ -440,20 +440,18 @@
 /**
  *	sysfs_pathname - return full path to sysfs dirent
  *	@sd: sysfs_dirent whose path we want
- *	@path: caller allocated buffer
+ *	@path: caller allocated buffer of size PATH_MAX
  *
  *	Gives the name "/" to the sysfs_root entry; any path returned
  *	is relative to wherever sysfs is mounted.
- *
- *	XXX: does no error checking on @path size
  */
 static char *sysfs_pathname(struct sysfs_dirent *sd, char *path)
 {
 	if (sd->s_parent) {
 		sysfs_pathname(sd->s_parent, path);
-		strcat(path, "/");
+		strlcat(path, "/", PATH_MAX);
 	}
-	strcat(path, sd->s_name);
+	strlcat(path, sd->s_name, PATH_MAX);
 	return path;
 }
 
@@ -486,9 +484,11 @@
 		char *path = kzalloc(PATH_MAX, GFP_KERNEL);
 		WARN(1, KERN_WARNING
 		     "sysfs: cannot create duplicate filename '%s'\n",
-		     (path == NULL) ? sd->s_name :
-		     strcat(strcat(sysfs_pathname(acxt->parent_sd, path), "/"),
-		            sd->s_name));
+		     (path == NULL) ? sd->s_name
+				    : (sysfs_pathname(acxt->parent_sd, path),
+				       strlcat(path, "/", PATH_MAX),
+				       strlcat(path, sd->s_name, PATH_MAX),
+				       path));
 		kfree(path);
 	}
 
diff -Naur a/fs/splice.c b/fs/splice.c
--- a/fs/splice.c	2013-11-01 20:18:05.609566265 +0200
+++ b/fs/splice.c	2013-11-01 18:44:56.489851326 +0200
@@ -30,6 +30,7 @@
 #include <linux/syscalls.h>
 #include <linux/uio.h>
 #include <linux/security.h>
+#include <linux/socket.h>
 
 /*
  * Attempt to steal a page from a pipe buffer. This should perhaps go into
@@ -637,7 +638,11 @@
 
 	ret = buf->ops->confirm(pipe, buf);
 	if (!ret) {
-		more = (sd->flags & SPLICE_F_MORE) || sd->len < sd->total_len;
+		more = (sd->flags & SPLICE_F_MORE) ? MSG_MORE : 0;
+
+		if (sd->len < sd->total_len && pipe->nrbufs > 1)
+			more |= MSG_SENDPAGE_NOTLAST;
+
 		if (file->f_op && file->f_op->sendpage)
 			ret = file->f_op->sendpage(file, buf->page, buf->offset,
 						   sd->len, &pos, more);
diff -Naur a/fs/udf/file.c b/fs/udf/file.c
--- a/fs/udf/file.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/udf/file.c	2013-11-01 18:44:56.557851664 +0200
@@ -40,20 +40,24 @@
 #include "udf_i.h"
 #include "udf_sb.h"
 
-static int udf_adinicb_readpage(struct file *file, struct page *page)
+static void __udf_adinicb_readpage(struct page *page)
 {
 	struct inode *inode = page->mapping->host;
 	char *kaddr;
 	struct udf_inode_info *iinfo = UDF_I(inode);
 
-	BUG_ON(!PageLocked(page));
-
 	kaddr = kmap(page);
-	memset(kaddr, 0, PAGE_CACHE_SIZE);
 	memcpy(kaddr, iinfo->i_ext.i_data + iinfo->i_lenEAttr, inode->i_size);
+	memset(kaddr + inode->i_size, 0, PAGE_CACHE_SIZE - inode->i_size);
 	flush_dcache_page(page);
 	SetPageUptodate(page);
 	kunmap(page);
+}
+
+static int udf_adinicb_readpage(struct file *file, struct page *page)
+{
+	BUG_ON(!PageLocked(page));
+	__udf_adinicb_readpage(page);
 	unlock_page(page);
 
 	return 0;
@@ -78,6 +82,25 @@
 	return 0;
 }
 
+static int udf_adinicb_write_begin(struct file *file,
+			struct address_space *mapping, loff_t pos,
+			unsigned len, unsigned flags, struct page **pagep,
+			void **fsdata)
+{
+	struct page *page;
+
+	if (WARN_ON_ONCE(pos >= PAGE_CACHE_SIZE))
+		return -EIO;
+	page = grab_cache_page_write_begin(mapping, 0, flags);
+	if (!page)
+		return -ENOMEM;
+	*pagep = page;
+
+	if (!PageUptodate(page) && len != PAGE_CACHE_SIZE)
+		__udf_adinicb_readpage(page);
+	return 0;
+}
+
 static int udf_adinicb_write_end(struct file *file,
 			struct address_space *mapping,
 			loff_t pos, unsigned len, unsigned copied,
@@ -100,8 +123,8 @@
 	.readpage	= udf_adinicb_readpage,
 	.writepage	= udf_adinicb_writepage,
 	.sync_page	= block_sync_page,
-	.write_begin = simple_write_begin,
-	.write_end = udf_adinicb_write_end,
+	.write_begin	= udf_adinicb_write_begin,
+	.write_end	= udf_adinicb_write_end,
 };
 
 static ssize_t udf_file_aio_write(struct kiocb *iocb, const struct iovec *iov,
diff -Naur a/fs/udf/inode.c b/fs/udf/inode.c
--- a/fs/udf/inode.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/udf/inode.c	2013-11-01 18:44:56.557851664 +0200
@@ -648,6 +648,8 @@
 				goal, err);
 		if (!newblocknum) {
 			brelse(prev_epos.bh);
+			brelse(cur_epos.bh);
+			brelse(next_epos.bh);
 			*err = -ENOSPC;
 			return NULL;
 		}
@@ -678,6 +680,8 @@
 	udf_update_extents(inode, laarr, startnum, endnum, &prev_epos);
 
 	brelse(prev_epos.bh);
+	brelse(cur_epos.bh);
+	brelse(next_epos.bh);
 
 	newblock = udf_get_pblock(inode->i_sb, newblocknum,
 				iinfo->i_location.partitionReferenceNum, 0);
diff -Naur a/fs/udf/namei.c b/fs/udf/namei.c
--- a/fs/udf/namei.c	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/udf/namei.c	2013-11-01 18:44:56.561851679 +0200
@@ -1331,6 +1331,7 @@
 	*lenp = 3;
 	fid->udf.block = location.logicalBlockNum;
 	fid->udf.partref = location.partitionReferenceNum;
+	fid->udf.parent_partref = 0;
 	fid->udf.generation = inode->i_generation;
 
 	if (connectable && !S_ISDIR(inode->i_mode)) {
diff -Naur a/fs/udf/super.c b/fs/udf/super.c
--- a/fs/udf/super.c	2013-11-01 20:18:05.633566384 +0200
+++ b/fs/udf/super.c	2013-11-01 18:44:56.561851679 +0200
@@ -57,6 +57,7 @@
 #include <linux/seq_file.h>
 #include <linux/bitmap.h>
 #include <linux/crc-itu-t.h>
+#include <linux/log2.h>
 #include <asm/byteorder.h>
 
 #include "udf_sb.h"
@@ -1239,16 +1240,65 @@
 	return ret;
 }
 
+static int udf_load_sparable_map(struct super_block *sb,
+				 struct udf_part_map *map,
+				 struct sparablePartitionMap *spm)
+{
+	uint32_t loc;
+	uint16_t ident;
+	struct sparingTable *st;
+	struct udf_sparing_data *sdata = &map->s_type_specific.s_sparing;
+	int i;
+	struct buffer_head *bh;
+
+	map->s_partition_type = UDF_SPARABLE_MAP15;
+	sdata->s_packet_len = le16_to_cpu(spm->packetLength);
+	if (!is_power_of_2(sdata->s_packet_len)) {
+		udf_error(sb, __func__, "error loading logical volume descriptor: "
+			"Invalid packet length %u\n",
+			(unsigned)sdata->s_packet_len);
+		return -EIO;
+	}
+	if (spm->numSparingTables > 4) {
+		udf_error(sb, __func__, "error loading logical volume descriptor: "
+			"Too many sparing tables (%d)\n",
+			(int)spm->numSparingTables);
+		return -EIO;
+	}
+
+	for (i = 0; i < spm->numSparingTables; i++) {
+		loc = le32_to_cpu(spm->locSparingTable[i]);
+		bh = udf_read_tagged(sb, loc, loc, &ident);
+		if (!bh)
+			continue;
+
+		st = (struct sparingTable *)bh->b_data;
+		if (ident != 0 ||
+		    strncmp(st->sparingIdent.ident, UDF_ID_SPARING,
+			    strlen(UDF_ID_SPARING)) ||
+		    sizeof(*st) + le16_to_cpu(st->reallocationTableLen) >
+							sb->s_blocksize) {
+			brelse(bh);
+			continue;
+		}
+
+		sdata->s_spar_map[i] = bh;
+	}
+	map->s_partition_func = udf_get_pblock_spar15;
+	return 0;
+}
+
 static int udf_load_logicalvol(struct super_block *sb, sector_t block,
 			       struct kernel_lb_addr *fileset)
 {
 	struct logicalVolDesc *lvd;
-	int i, j, offset;
+	int i, offset;
 	uint8_t type;
 	struct udf_sb_info *sbi = UDF_SB(sb);
 	struct genericPartitionMap *gpm;
 	uint16_t ident;
 	struct buffer_head *bh;
+	unsigned int table_len;
 	int ret = 0;
 
 	bh = udf_read_tagged(sb, block, block, &ident);
@@ -1257,6 +1307,15 @@
 	BUG_ON(ident != TAG_IDENT_LVD);
 	lvd = (struct logicalVolDesc *)bh->b_data;
 
+	table_len = le32_to_cpu(lvd->mapTableLength);
+	if (table_len > sb->s_blocksize - sizeof(*lvd)) {
+		udf_error(sb, __func__, "error loading logical volume descriptor: "
+		          "Partition table too long (%u > %lu)\n", table_len,
+		          sb->s_blocksize - sizeof(*lvd));
+		ret = 1;
+		goto out_bh;
+	}
+
 	i = udf_sb_alloc_partition_maps(sb, le32_to_cpu(lvd->numPartitionMaps));
 	if (i != 0) {
 		ret = i;
@@ -1264,7 +1323,7 @@
 	}
 
 	for (i = 0, offset = 0;
-	     i < sbi->s_partitions && offset < le32_to_cpu(lvd->mapTableLength);
+	     i < sbi->s_partitions && offset < table_len;
 	     i++, offset += gpm->partitionMapLength) {
 		struct udf_part_map *map = &sbi->s_partmaps[i];
 		gpm = (struct genericPartitionMap *)
@@ -1299,38 +1358,11 @@
 			} else if (!strncmp(upm2->partIdent.ident,
 						UDF_ID_SPARABLE,
 						strlen(UDF_ID_SPARABLE))) {
-				uint32_t loc;
-				struct sparingTable *st;
-				struct sparablePartitionMap *spm =
-					(struct sparablePartitionMap *)gpm;
-
-				map->s_partition_type = UDF_SPARABLE_MAP15;
-				map->s_type_specific.s_sparing.s_packet_len =
-						le16_to_cpu(spm->packetLength);
-				for (j = 0; j < spm->numSparingTables; j++) {
-					struct buffer_head *bh2;
-
-					loc = le32_to_cpu(
-						spm->locSparingTable[j]);
-					bh2 = udf_read_tagged(sb, loc, loc,
-							     &ident);
-					map->s_type_specific.s_sparing.
-							s_spar_map[j] = bh2;
-
-					if (bh2 == NULL)
-						continue;
-
-					st = (struct sparingTable *)bh2->b_data;
-					if (ident != 0 || strncmp(
-						st->sparingIdent.ident,
-						UDF_ID_SPARING,
-						strlen(UDF_ID_SPARING))) {
-						brelse(bh2);
-						map->s_type_specific.s_sparing.
-							s_spar_map[j] = NULL;
-					}
+				if (udf_load_sparable_map(sb, map,
+				    (struct sparablePartitionMap *)gpm) < 0) {
+					ret = 1;
+					goto out_bh;
 				}
-				map->s_partition_func = udf_get_pblock_spar15;
 			} else if (!strncmp(upm2->partIdent.ident,
 						UDF_ID_METADATA,
 						strlen(UDF_ID_METADATA))) {
diff -Naur a/fs/udf/udf_sb.h b/fs/udf/udf_sb.h
--- a/fs/udf/udf_sb.h	2009-12-03 05:51:21.000000000 +0200
+++ b/fs/udf/udf_sb.h	2013-11-01 18:44:56.561851679 +0200
@@ -78,7 +78,7 @@
 struct udf_bitmap {
 	__u32			s_extLength;
 	__u32			s_extPosition;
-	__u16			s_nr_groups;
+	int			s_nr_groups;
 	struct buffer_head 	**s_block_bitmap;
 };
 
diff -Naur a/fs/xfs/xfs_log_recover.c b/fs/xfs/xfs_log_recover.c
--- a/fs/xfs/xfs_log_recover.c	2013-11-01 20:18:05.669566569 +0200
+++ b/fs/xfs/xfs_log_recover.c	2013-11-01 18:44:56.717852460 +0200
@@ -3298,37 +3298,26 @@
 			 */
 			continue;
 		}
+		/*
+		 * Unlock the buffer so that it can be acquired in the normal
+		 * course of the transaction to truncate and free each inode.
+		 * Because we are not racing with anyone else here for the AGI
+		 * buffer, we don't even need to hold it locked to read the
+		 * initial unlinked bucket entries out of the buffer. We keep
+		 * buffer reference though, so that it stays pinned in memory
+		 * while we need the buffer.
+		 */
 		agi = XFS_BUF_TO_AGI(agibp);
+		xfs_buf_unlock(agibp);
 
 		for (bucket = 0; bucket < XFS_AGI_UNLINKED_BUCKETS; bucket++) {
 			agino = be32_to_cpu(agi->agi_unlinked[bucket]);
 			while (agino != NULLAGINO) {
-				/*
-				 * Release the agi buffer so that it can
-				 * be acquired in the normal course of the
-				 * transaction to truncate and free the inode.
-				 */
-				xfs_buf_relse(agibp);
-
 				agino = xlog_recover_process_one_iunlink(mp,
 							agno, agino, bucket);
-
-				/*
-				 * Reacquire the agibuffer and continue around
-				 * the loop. This should never fail as we know
-				 * the buffer was good earlier on.
-				 */
-				error = xfs_read_agi(mp, NULL, agno, &agibp);
-				ASSERT(error == 0);
-				agi = XFS_BUF_TO_AGI(agibp);
 			}
 		}
-
-		/*
-		 * Release the buffer for the current agi so we can
-		 * go on to the next one.
-		 */
-		xfs_buf_relse(agibp);
+		xfs_buf_rele(agibp);
 	}
 
 	mp->m_dmevmask = mp_dmevmask;
diff -Naur a/fs/xfs/xfs_vnodeops.c b/fs/xfs/xfs_vnodeops.c
--- a/fs/xfs/xfs_vnodeops.c	2013-11-01 20:18:05.677566608 +0200
+++ b/fs/xfs/xfs_vnodeops.c	2013-11-01 18:44:56.733852536 +0200
@@ -554,7 +554,7 @@
 	char		*link)
 {
 	xfs_mount_t	*mp = ip->i_mount;
-	int		pathlen;
+	xfs_fsize_t	pathlen;
 	int		error = 0;
 
 	xfs_itrace_entry(ip);
@@ -564,13 +564,21 @@
 
 	xfs_ilock(ip, XFS_ILOCK_SHARED);
 
-	ASSERT((ip->i_d.di_mode & S_IFMT) == S_IFLNK);
-	ASSERT(ip->i_d.di_size <= MAXPATHLEN);
-
 	pathlen = ip->i_d.di_size;
 	if (!pathlen)
 		goto out;
 
+	if (pathlen < 0 || pathlen > MAXPATHLEN) {
+		xfs_fs_cmn_err(CE_ALERT, mp,
+			 "%s: inode (%llu) bad symlink length (%lld)",
+			 __func__, (unsigned long long) ip->i_ino,
+			 (long long) pathlen);
+		ASSERT(0);
+		error = XFS_ERROR(EFSCORRUPTED);
+		goto out;
+	}
+
+
 	if (ip->i_df.if_flags & XFS_IFINLINE) {
 		memcpy(link, ip->i_df.if_u1.if_data, pathlen);
 		link[pathlen] = '\0';
diff -Naur a/include/asm-generic/poll.h b/include/asm-generic/poll.h
--- a/include/asm-generic/poll.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/asm-generic/poll.h	2013-11-01 18:44:57.009853898 +0200
@@ -28,6 +28,8 @@
 #define POLLRDHUP       0x2000
 #endif
 
+#define POLLFREE	0x4000	/* currently only for epoll */
+
 struct pollfd {
 	int fd;
 	short events;
diff -Naur a/include/asm-generic/signal.h b/include/asm-generic/signal.h
--- a/include/asm-generic/signal.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/asm-generic/signal.h	2013-11-01 18:44:57.009853898 +0200
@@ -99,6 +99,10 @@
 
 #include <asm-generic/signal-defs.h>
 
+#ifdef SA_RESTORER
+#define __ARCH_HAS_SA_RESTORER
+#endif
+
 struct sigaction {
 	__sighandler_t sa_handler;
 	unsigned long sa_flags;
diff -Naur a/include/linux/binfmts.h b/include/linux/binfmts.h
--- a/include/linux/binfmts.h	2013-11-01 20:18:05.689566669 +0200
+++ b/include/linux/binfmts.h	2013-11-01 18:44:57.093854325 +0200
@@ -71,8 +71,6 @@
 #define BINPRM_FLAGS_EXECFD_BIT 1
 #define BINPRM_FLAGS_EXECFD (1 << BINPRM_FLAGS_EXECFD_BIT)
 
-#define BINPRM_MAX_RECURSION 4
-
 /*
  * This structure defines the functions that are used to load the binary formats that
  * linux accepts.
@@ -122,6 +120,7 @@
 			   unsigned long stack_top,
 			   int executable_stack);
 extern int bprm_mm_init(struct linux_binprm *bprm);
+extern int bprm_change_interp(char *interp, struct linux_binprm *bprm);
 extern int copy_strings_kernel(int argc,char ** argv,struct linux_binprm *bprm);
 extern int prepare_bprm_creds(struct linux_binprm *bprm);
 extern void install_exec_creds(struct linux_binprm *bprm);
diff -Naur a/include/linux/blkdev.h b/include/linux/blkdev.h
--- a/include/linux/blkdev.h	2013-11-01 20:18:05.693566688 +0200
+++ b/include/linux/blkdev.h	2013-11-01 18:44:57.097854339 +0200
@@ -456,8 +456,7 @@
 #define QUEUE_FLAG_NONROT      14	/* non-rotational device (SSD) */
 #define QUEUE_FLAG_VIRT        QUEUE_FLAG_NONROT /* paravirt device */
 #define QUEUE_FLAG_IO_STAT     15	/* do IO stats */
-#define QUEUE_FLAG_CQ	       16	/* hardware does queuing */
-#define QUEUE_FLAG_DISCARD     17	/* supports DISCARD */
+#define QUEUE_FLAG_DISCARD     16	/* supports DISCARD */
 
 #define QUEUE_FLAG_DEFAULT	((1 << QUEUE_FLAG_IO_STAT) |		\
 				 (1 << QUEUE_FLAG_STACKABLE)	|	\
@@ -580,7 +579,6 @@
 
 #define blk_queue_plugged(q)	test_bit(QUEUE_FLAG_PLUGGED, &(q)->queue_flags)
 #define blk_queue_tagged(q)	test_bit(QUEUE_FLAG_QUEUED, &(q)->queue_flags)
-#define blk_queue_queuing(q)	test_bit(QUEUE_FLAG_CQ, &(q)->queue_flags)
 #define blk_queue_stopped(q)	test_bit(QUEUE_FLAG_STOPPED, &(q)->queue_flags)
 #define blk_queue_nomerges(q)	test_bit(QUEUE_FLAG_NOMERGES, &(q)->queue_flags)
 #define blk_queue_nonrot(q)	test_bit(QUEUE_FLAG_NONROT, &(q)->queue_flags)
diff -Naur a/include/linux/ethtool.h b/include/linux/ethtool.h
--- a/include/linux/ethtool.h	2013-11-01 20:19:19.277931573 +0200
+++ b/include/linux/ethtool.h	2013-11-01 18:44:57.141854554 +0200
@@ -33,7 +33,6 @@
 	__u8	eth_tp_mdix;
 	__u8	reserved2;
 	__u32	lp_advertising;	/* Features the link partner advertises */
-	__u32	eee;		/* Energy-Efficient Etehrnet */
 	__u32	reserved[2];
 };
 
@@ -668,6 +667,7 @@
 #define WAKE_ARP		(1 << 4)
 #define WAKE_MAGIC		(1 << 5)
 #define WAKE_MAGICSECURE	(1 << 6) /* only meaningful if WAKE_MAGIC */
+#define WAKE_DOWN_SPEED		(1 << 7)
 
 /* L3-L4 network traffic flow types */
 #define	TCP_V4_FLOW	0x01
diff -Naur a/include/linux/eventpoll.h b/include/linux/eventpoll.h
--- a/include/linux/eventpoll.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/eventpoll.h	2013-11-01 18:44:57.141854554 +0200
@@ -61,6 +61,7 @@
 static inline void eventpoll_init_file(struct file *file)
 {
 	INIT_LIST_HEAD(&file->f_ep_links);
+	INIT_LIST_HEAD(&file->f_tfile_llink);
 }
 
 
diff -Naur a/include/linux/fs.h b/include/linux/fs.h
--- a/include/linux/fs.h	2013-11-01 20:18:05.705566741 +0200
+++ b/include/linux/fs.h	2013-11-01 18:44:57.161854657 +0200
@@ -941,6 +941,7 @@
 #ifdef CONFIG_EPOLL
 	/* Used by fs/eventpoll.c to link all the hooks to this file */
 	struct list_head	f_ep_links;
+	struct list_head	f_tfile_llink;
 #endif /* #ifdef CONFIG_EPOLL */
 	struct address_space	*f_mapping;
 #ifdef CONFIG_DEBUG_WRITECOUNT
diff -Naur a/include/linux/hrtimer.h b/include/linux/hrtimer.h
--- a/include/linux/hrtimer.h	2013-11-01 20:18:05.709566771 +0200
+++ b/include/linux/hrtimer.h	2013-11-01 18:44:57.177854736 +0200
@@ -159,6 +159,7 @@
  *			and timers
  * @clock_base:		array of clock bases for this cpu
  * @curr_timer:		the timer which is executing a callback right now
+ * @clock_was_set:	Indicates that clock was set from irq context.
  * @expires_next:	absolute time of the next event which was scheduled
  *			via clock_set_next_event()
  * @hres_active:	State of high resolution mode
@@ -171,6 +172,7 @@
 struct hrtimer_cpu_base {
 	spinlock_t			lock;
 	struct hrtimer_clock_base	clock_base[HRTIMER_MAX_CLOCK_BASES];
+	unsigned int			clock_was_set;
 #ifdef CONFIG_HIGH_RES_TIMERS
 	ktime_t				expires_next;
 	int				hres_active;
@@ -280,6 +282,8 @@
 # define MONOTONIC_RES_NSEC	HIGH_RES_NSEC
 # define KTIME_MONOTONIC_RES	KTIME_HIGH_RES
 
+extern void clock_was_set_delayed(void);
+
 #else
 
 # define MONOTONIC_RES_NSEC	LOW_RES_NSEC
@@ -308,11 +312,14 @@
 {
 	return 0;
 }
+
+static inline void clock_was_set_delayed(void) { }
+
 #endif
 
 extern ktime_t ktime_get(void);
 extern ktime_t ktime_get_real(void);
-
+extern ktime_t ktime_get_update_offsets(ktime_t *offs_real);
 
 DECLARE_PER_CPU(struct tick_device, tick_cpu_device);
 
diff -Naur a/include/linux/hugetlb.h b/include/linux/hugetlb.h
--- a/include/linux/hugetlb.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/hugetlb.h	2013-11-01 18:44:57.177854736 +0200
@@ -12,6 +12,15 @@
 #include <linux/shm.h>
 #include <asm/tlbflush.h>
 
+struct hugepage_subpool {
+	spinlock_t lock;
+	long count;
+	long max_hpages, used_hpages;
+};
+
+struct hugepage_subpool *hugepage_new_subpool(long nr_blocks);
+void hugepage_put_subpool(struct hugepage_subpool *spool);
+
 int PageHuge(struct page *page);
 
 static inline int is_vm_hugetlb_page(struct vm_area_struct *vma)
@@ -138,12 +147,11 @@
 };
 
 struct hugetlbfs_sb_info {
-	long	max_blocks;   /* blocks allowed */
-	long	free_blocks;  /* blocks free */
 	long	max_inodes;   /* inodes allowed */
 	long	free_inodes;  /* inodes free */
 	spinlock_t	stat_lock;
 	struct hstate *hstate;
+	struct hugepage_subpool *spool;
 };
 
 
@@ -166,8 +174,6 @@
 extern const struct vm_operations_struct hugetlb_vm_ops;
 struct file *hugetlb_file_setup(const char *name, size_t size, int acct,
 				struct user_struct **user, int creat_flags);
-int hugetlb_get_quota(struct address_space *mapping, long delta);
-void hugetlb_put_quota(struct address_space *mapping, long delta);
 
 static inline int is_file_hugepages(struct file *file)
 {
diff -Naur a/include/linux/iocontext.h b/include/linux/iocontext.h
--- a/include/linux/iocontext.h	2013-11-01 20:18:05.717566807 +0200
+++ b/include/linux/iocontext.h	2013-11-01 18:44:57.213854920 +0200
@@ -94,14 +94,15 @@
 	return NULL;
 }
 
+struct task_struct;
 #ifdef CONFIG_BLOCK
 int put_io_context(struct io_context *ioc);
-void exit_io_context(void);
+void exit_io_context(struct task_struct *task);
 struct io_context *get_io_context(gfp_t gfp_flags, int node);
 struct io_context *alloc_io_context(gfp_t gfp_flags, int node);
 void copy_io_context(struct io_context **pdst, struct io_context **psrc);
 #else
-static inline void exit_io_context(void)
+static inline void exit_io_context(struct task_struct *task)
 {
 }
 
diff -Naur a/include/linux/irq.h b/include/linux/irq.h
--- a/include/linux/irq.h	2013-11-01 20:18:05.717566807 +0200
+++ b/include/linux/irq.h	2013-11-01 18:44:57.217854931 +0200
@@ -174,7 +174,6 @@
  */
 struct irq_desc {
 	unsigned int		irq;
-	struct timer_rand_state *timer_rand_state;
 	unsigned int            *kstat_irqs;
 #ifdef CONFIG_INTR_REMAP
 	struct irq_2_iommu      *irq_2_iommu;
diff -Naur a/include/linux/Kbuild b/include/linux/Kbuild
--- a/include/linux/Kbuild	2013-11-01 20:19:19.269931540 +0200
+++ b/include/linux/Kbuild	2013-11-01 18:44:57.037854039 +0200
@@ -7,6 +7,7 @@
 header-y += nfsd/
 header-y += raid/
 header-y += spi/
+header-y += stm/
 header-y += sunrpc/
 header-y += tc_act/
 header-y += tc_ematch/
diff -Naur a/include/linux/kernel.h b/include/linux/kernel.h
--- a/include/linux/kernel.h	2013-11-01 20:18:05.721566834 +0200
+++ b/include/linux/kernel.h	2013-11-01 18:44:57.233855013 +0200
@@ -55,6 +55,19 @@
 }							\
 )
 
+/*
+ * Multiplies an integer by a fraction, while avoiding unnecessary
+ * overflow or loss of precision.
+ */
+#define mult_frac(x, numer, denom)(			\
+{							\
+	typeof(x) quot = (x) / (denom);			\
+	typeof(x) rem  = (x) % (denom);			\
+	(quot * (numer)) + ((rem * (numer)) / (denom));	\
+}							\
+)
+
+
 #define _RET_IP_		(unsigned long)__builtin_return_address(0)
 #define _THIS_IP_  ({ __label__ __here; __here: (unsigned long)&&__here; })
 
diff -Naur a/include/linux/kmod.h b/include/linux/kmod.h
--- a/include/linux/kmod.h	2013-11-01 20:18:05.721566834 +0200
+++ b/include/linux/kmod.h	2013-11-01 18:44:57.237855039 +0200
@@ -64,6 +64,8 @@
 	UMH_WAIT_PROC = 1,	/* wait for the process to complete */
 };
 
+#define UMH_KILLABLE	4	/* wait for EXEC/PROC killable */
+
 /* Actually execute the sub-process */
 int call_usermodehelper_exec(struct subprocess_info *info, enum umh_wait wait);
 
diff -Naur a/include/linux/ktime.h b/include/linux/ktime.h
--- a/include/linux/ktime.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/ktime.h	2013-11-01 18:44:57.241855050 +0200
@@ -58,13 +58,6 @@
 
 typedef union ktime ktime_t;		/* Kill this */
 
-#define KTIME_MAX			((s64)~((u64)1 << 63))
-#if (BITS_PER_LONG == 64)
-# define KTIME_SEC_MAX			(KTIME_MAX / NSEC_PER_SEC)
-#else
-# define KTIME_SEC_MAX			LONG_MAX
-#endif
-
 /*
  * ktime_t definitions when using the 64-bit scalar representation:
  */
diff -Naur a/include/linux/kvm_host.h b/include/linux/kvm_host.h
--- a/include/linux/kvm_host.h	2013-11-01 20:18:05.721566834 +0200
+++ b/include/linux/kvm_host.h	2013-11-01 18:44:57.241855050 +0200
@@ -556,5 +556,12 @@
 {
 	return vcpu->kvm->bsp_vcpu_id == vcpu->vcpu_id;
 }
+
+bool kvm_vcpu_compatible(struct kvm_vcpu *vcpu);
+
+#else
+
+static inline bool kvm_vcpu_compatible(struct kvm_vcpu *vcpu) { return true; }
+
 #endif
 #endif
diff -Naur a/include/linux/mempolicy.h b/include/linux/mempolicy.h
--- a/include/linux/mempolicy.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/mempolicy.h	2013-11-01 18:44:57.257855132 +0200
@@ -180,7 +180,7 @@
 
 struct shared_policy {
 	struct rb_root root;
-	spinlock_t lock;
+	struct mutex mutex;
 };
 
 void mpol_shared_policy_init(struct shared_policy *sp, struct mempolicy *mpol);
diff -Naur a/include/linux/msdos_fs.h b/include/linux/msdos_fs.h
--- a/include/linux/msdos_fs.h	2013-11-01 20:19:19.309931729 +0200
+++ b/include/linux/msdos_fs.h	2013-11-01 18:44:57.289855288 +0200
@@ -15,6 +15,7 @@
 #define MSDOS_DPB_BITS	4		/* log2(MSDOS_DPB) */
 #define MSDOS_DPS	(SECTOR_SIZE / sizeof(struct msdos_dir_entry))
 #define MSDOS_DPS_BITS	4		/* log2(MSDOS_DPS) */
+#define MSDOS_LONGNAME	256		/* maximum name length */
 #define CF_LE_W(v)	le16_to_cpu(v)
 #define CF_LE_L(v)	le32_to_cpu(v)
 #define CT_LE_W(v)	cpu_to_le16(v)
@@ -48,8 +49,8 @@
 #define DELETED_FLAG	0xe5	/* marks file as deleted when in name[0] */
 #define IS_FREE(n)	(!*(n) || *(n) == DELETED_FLAG)
 
+#define FAT_LFN_LEN	255	/* maximum long name length */
 #define MSDOS_NAME	11	/* maximum name length */
-#define MSDOS_LONGNAME	256	/* maximum name length */
 #define MSDOS_SLOTS	21	/* max # of slots for short and long names */
 #define MSDOS_DOT	".          "	/* ".", padded to MSDOS_NAME chars */
 #define MSDOS_DOTDOT	"..         "	/* "..", padded to MSDOS_NAME chars */
diff -Naur a/include/linux/mtd/nand.h b/include/linux/mtd/nand.h
--- a/include/linux/mtd/nand.h	2013-11-01 20:19:19.309931729 +0200
+++ b/include/linux/mtd/nand.h	2013-11-01 18:44:57.293855309 +0200
@@ -191,6 +191,8 @@
 #define NAND_MULTIPLANE_PROG_ERASE	0x00004000
 /* Deivce supports multi-LUN operations */
 #define NAND_MULTILUN		0x00008000
+/* Micron '4-bit On-die ECC' device */
+#define NAND_MICRON_4BITONDIEECC	0x00080000
 
 
 /* Options valid for Samsung large page devices */
@@ -207,7 +209,8 @@
 					&& (chip->page_shift > 9))
 
 /* Mask to zero out the chip options, which come from the id table */
-#define NAND_CHIPOPTIONS_MSK	(0x0000ffff & ~NAND_NO_AUTOINCR)
+#define NAND_CHIPOPTIONS_MSK	(0x0000ffff & ~NAND_NO_AUTOINCR & \
+				 NAND_MICRON_4BITONDIEECC)
 
 /* Non chip related options */
 /* Use a flash based bad block table. This option is passed to the
@@ -320,6 +323,40 @@
 
 #define ONFI_CRC_BASE	0x4F4E
 
+/*
+ * NAND Device Timing Specification
+ *
+ * All values in nano seconds, except where specified.
+ */
+struct nand_timing_spec {
+	int	tR;		/* Max Page Read delay [us]*/
+	int	tCLS;		/* Min CLE setup time */
+	int	tCS;		/* Min CE setup time */
+	int	tALS;		/* Min ALE setup time */
+	int	tDS;		/* Min Data setup time */
+	int	tWP;		/* Min WE pulse width */
+	int	tCLH;		/* Min CLE hold time */
+	int	tCH;		/* Min CE hold time */
+	int	tALH;		/* Min ALE hold time */
+	int	tDH;		/* Min Data hold time */
+	int	tWB;		/* Max WE high to busy */
+	int	tWH;		/* Min WE hold time */
+	int	tWC;		/* Min Write cycle time */
+	int	tRP;		/* Min RE pulse width */
+	int	tREH;		/* Min RE high hold time */
+	int	tRC;		/* Min Read cycle time */
+	int	tREA;		/* Max Read access time */
+	int	tRHOH;		/* Min RE high to output hold */
+	int	tCEA;		/* Max CE access time */
+	int	tCOH;		/* Min CE high to output hold */
+	int	tCHZ;		/* Max CE high to output high Z */
+	int	tCSD;		/* Min CE high to ALE/CLE don't care */
+};
+
+/* ONFI define 6 timing modes */
+#define NAND_ONFI_TIMING_MODES		6
+extern struct nand_timing_spec nand_onfi_timing_specs[];
+
 /**
  * struct nand_hw_control - Control structure for hardware controller (e.g ECC generator) shared among independent devices
  * @lock:               protection lock
@@ -678,6 +715,13 @@
 extern int nand_suspend(struct mtd_info *mtd);
 extern void nand_resume(struct mtd_info *mtd);
 extern void nand_sync(struct mtd_info *mtd);
+extern uint8_t *nand_transfer_oob(struct nand_chip *chip, uint8_t *oob,
+				  struct mtd_oob_ops *ops, size_t len);
+extern int nand_check_wp(struct mtd_info *mtd);
+extern uint8_t *nand_fill_oob(struct nand_chip *chip, uint8_t *oob,
+			      struct mtd_oob_ops *ops);
+extern int nand_do_write_oob(struct mtd_info *mtd, loff_t to,
+			     struct mtd_oob_ops *ops);
 extern u8 nand_erasebb;
 
 /*
diff -Naur a/include/linux/mtd/partitions.h b/include/linux/mtd/partitions.h
--- a/include/linux/mtd/partitions.h	2013-11-01 20:19:19.309931729 +0200
+++ b/include/linux/mtd/partitions.h	2013-11-01 18:44:57.297855337 +0200
@@ -51,7 +51,8 @@
 
 int add_mtd_partitions(struct mtd_info *, const struct mtd_partition *, int);
 int del_mtd_partitions(struct mtd_info *);
-struct mtd_info *get_mtd_partition_slave(struct mtd_info *master, char *name);
+struct mtd_info *get_mtd_partition_slave(struct mtd_info *master, char *name,
+					 uint64_t *offset);
 
 /*
  * Functions dealing with the various ways of partitioning the space
diff -Naur a/include/linux/nls.h b/include/linux/nls.h
--- a/include/linux/nls.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/nls.h	2013-11-01 18:44:57.377855729 +0200
@@ -43,7 +43,7 @@
 	UTF16_BIG_ENDIAN
 };
 
-/* nls.c */
+/* nls_base.c */
 extern int register_nls(struct nls_table *);
 extern int unregister_nls(struct nls_table *);
 extern struct nls_table *load_nls(char *);
@@ -52,7 +52,8 @@
 
 extern int utf8_to_utf32(const u8 *s, int len, unicode_t *pu);
 extern int utf32_to_utf8(unicode_t u, u8 *s, int maxlen);
-extern int utf8s_to_utf16s(const u8 *s, int len, wchar_t *pwcs);
+extern int utf8s_to_utf16s(const u8 *s, int len,
+		enum utf16_endian endian, wchar_t *pwcs, int maxlen);
 extern int utf16s_to_utf8s(const wchar_t *pwcs, int len,
 		enum utf16_endian endian, u8 *s, int maxlen);
 
diff -Naur a/include/linux/page-flags.h b/include/linux/page-flags.h
--- a/include/linux/page-flags.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/page-flags.h	2013-11-01 18:44:57.381855755 +0200
@@ -362,7 +362,7 @@
  * pages on the LRU and/or pagecache.
  */
 TESTPAGEFLAG(Compound, compound)
-__PAGEFLAG(Head, compound)
+__SETPAGEFLAG(Head, compound)  __CLEARPAGEFLAG(Head, compound)
 
 /*
  * PG_reclaim is used in combination with PG_compound to mark the
@@ -374,8 +374,14 @@
  * PG_compound & PG_reclaim	=> Tail page
  * PG_compound & ~PG_reclaim	=> Head page
  */
+#define PG_head_mask ((1L << PG_compound))
 #define PG_head_tail_mask ((1L << PG_compound) | (1L << PG_reclaim))
 
+static inline int PageHead(struct page *page)
+{
+	return ((page->flags & PG_head_tail_mask) == PG_head_mask);
+}
+
 static inline int PageTail(struct page *page)
 {
 	return ((page->flags & PG_head_tail_mask) == PG_head_tail_mask);
diff -Naur a/include/linux/phy.h b/include/linux/phy.h
--- a/include/linux/phy.h	2013-11-01 20:19:19.313931750 +0200
+++ b/include/linux/phy.h	2013-11-01 18:44:57.393855805 +0200
@@ -248,6 +248,7 @@
  * changes in the link state.
  * adjust_state: Callback for the enet driver to respond to
  * changes in the state machine.
+ * wol: which WoL mode will be used to wake-up the system via ethtool.
  *
  * speed, duplex, pause, supported, advertising, and
  * autoneg are used like in mii_if_info
@@ -321,6 +322,7 @@
 	struct mutex lock;
 
 	struct net_device *attached_dev;
+	int wol;
 
 	void (*adjust_link)(struct net_device *dev);
 
@@ -339,6 +341,8 @@
  *   by this PHY
  * flags: A bitfield defining certain other features this PHY
  *   supports (like interrupts)
+ * wol: to define which Wake-up modes are supported (e.g. WoL
+ * via magic packet).
  *
  * The drivers must implement config_aneg and read_status.  All
  * other functions are optional. Note that none of these
@@ -354,6 +358,7 @@
 	unsigned int phy_id_mask;
 	u32 features;
 	u32 flags;
+	u32 wol_supported;
 
 	/*
 	 * Called to initialize the PHY,
@@ -442,6 +447,9 @@
 	return mdiobus_write(phydev->bus, phydev->addr, regnum, val);
 }
 
+int phy_read_page(struct phy_device *phydev, u16 regnum, int page);
+int phy_write_page(struct phy_device *phydev, u16 regnum, int page, int data);
+
 int get_phy_id(struct mii_bus *bus, int addr, u32 *phy_id);
 struct phy_device* get_phy_device(struct mii_bus *bus, int addr);
 int phy_device_register(struct phy_device *phy);
@@ -489,6 +497,9 @@
 void phy_stop_machine(struct phy_device *phydev);
 int phy_ethtool_sset(struct phy_device *phydev, struct ethtool_cmd *cmd);
 int phy_ethtool_gset(struct phy_device *phydev, struct ethtool_cmd *cmd);
+int phy_ethtool_set_wol(struct phy_device *phydev, struct ethtool_wolinfo *wol);
+int phy_ethtool_get_wol(struct phy_device *phydev, struct ethtool_wolinfo *wol);
+
 int phy_mii_ioctl(struct phy_device *phydev,
 		struct mii_ioctl_data *mii_data, int cmd);
 int phy_start_interrupts(struct phy_device *phydev);
diff -Naur a/include/linux/random.h b/include/linux/random.h
--- a/include/linux/random.h	2013-11-01 20:19:19.313931750 +0200
+++ b/include/linux/random.h	2013-11-01 18:44:57.409855887 +0200
@@ -44,15 +44,15 @@
 
 #ifdef __KERNEL__
 
-extern void rand_initialize_irq(int irq);
-
+extern void add_device_randomness(const void *, unsigned int);
 extern void add_input_randomness(unsigned int type, unsigned int code,
 				 unsigned int value);
-extern void add_interrupt_randomness(int irq);
+extern void add_interrupt_randomness(int irq, int irq_flags);
 
 extern void add_random_data(const char* rdata, int count);
 
 extern void get_random_bytes(void *buf, int nbytes);
+extern void get_random_bytes_arch(void *buf, int nbytes);
 void generate_random_uuid(unsigned char uuid_out[16]);
 
 #ifndef MODULE
@@ -65,6 +65,19 @@
 u32 random32(void);
 void srandom32(u32 seed);
 
+#ifdef CONFIG_ARCH_RANDOM
+# include <asm/archrandom.h>
+#else
+static inline int arch_get_random_long(unsigned long *v)
+{
+	return 0;
+}
+static inline int arch_get_random_int(unsigned int *v)
+{
+	return 0;
+}
+#endif
+
 #endif /* __KERNEL___ */
 
 #endif /* _LINUX_RANDOM_H */
diff -Naur a/include/linux/sched.h b/include/linux/sched.h
--- a/include/linux/sched.h	2013-11-01 20:18:05.757567009 +0200
+++ b/include/linux/sched.h	2013-11-01 18:44:57.425855965 +0200
@@ -2459,7 +2459,16 @@
 extern void recalc_sigpending_and_wake(struct task_struct *t);
 extern void recalc_sigpending(void);
 
-extern void signal_wake_up(struct task_struct *t, int resume_stopped);
+extern void signal_wake_up_state(struct task_struct *t, unsigned int state);
+
+static inline void signal_wake_up(struct task_struct *t, bool resume)
+{
+	signal_wake_up_state(t, resume ? TASK_WAKEKILL : 0);
+}
+static inline void ptrace_signal_wake_up(struct task_struct *t, bool resume)
+{
+	signal_wake_up_state(t, resume ? __TASK_TRACED : 0);
+}
 
 /*
  * Wrappers for p->thread_info->cpu access. No-op on UP.
diff -Naur a/include/linux/signalfd.h b/include/linux/signalfd.h
--- a/include/linux/signalfd.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/signalfd.h	2013-11-01 18:44:57.437856025 +0200
@@ -60,13 +60,16 @@
 		wake_up(&tsk->sighand->signalfd_wqh);
 }
 
+extern void signalfd_cleanup(struct sighand_struct *sighand);
+
 #else /* CONFIG_SIGNALFD */
 
 static inline void signalfd_notify(struct task_struct *tsk, int sig) { }
 
+static inline void signalfd_cleanup(struct sighand_struct *sighand) { }
+
 #endif /* CONFIG_SIGNALFD */
 
 #endif /* __KERNEL__ */
 
 #endif /* _LINUX_SIGNALFD_H */
-
diff -Naur a/include/linux/skbuff.h b/include/linux/skbuff.h
--- a/include/linux/skbuff.h	2013-11-01 20:19:19.317931778 +0200
+++ b/include/linux/skbuff.h	2013-11-01 18:44:57.437856025 +0200
@@ -1317,6 +1317,16 @@
 }
 #endif /* NET_SKBUFF_DATA_USES_OFFSET */
 
+static inline void skb_mac_header_rebuild(struct sk_buff *skb)
+{
+	if (skb_mac_header_was_set(skb)) {
+		const unsigned char *old_mac = skb_mac_header(skb);
+
+		skb_set_mac_header(skb, -skb->mac_len);
+		memmove(skb_mac_header(skb), old_mac, skb->mac_len);
+	}
+}
+
 static inline int skb_transport_offset(const struct sk_buff *skb)
 {
 	return skb_transport_header(skb) - skb->data;
diff -Naur a/include/linux/socket.h b/include/linux/socket.h
--- a/include/linux/socket.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/socket.h	2013-11-01 18:44:57.441856046 +0200
@@ -246,7 +246,7 @@
 #define MSG_ERRQUEUE	0x2000	/* Fetch message from error queue */
 #define MSG_NOSIGNAL	0x4000	/* Do not generate SIGPIPE */
 #define MSG_MORE	0x8000	/* Sender will send more */
-
+#define MSG_SENDPAGE_NOTLAST 0x20000 /* sendpage() internal : not the last page */
 #define MSG_EOF         MSG_FIN
 
 #define MSG_CMSG_CLOEXEC 0x40000000	/* Set close_on_exit for file
diff -Naur a/include/linux/stm/coprocessor.h b/include/linux/stm/coprocessor.h
--- a/include/linux/stm/coprocessor.h	2013-11-01 20:19:19.325931811 +0200
+++ b/include/linux/stm/coprocessor.h	2013-11-01 18:44:57.533856501 +0200
@@ -5,37 +5,15 @@
  * License.  See linux/COPYING for more information.
  */
 
+#ifndef __STM_COPROCESSOR_H__
+#define __STM_COPROCESSOR_H__
+
 #include <linux/ioctl.h>
+
+#ifdef __KERNEL__
 #include <linux/platform_device.h>
 #include <asm/addrspace.h>
 
-#define	MEGA			(1024 * 1024)
-typedef unsigned long kaddr_t;
-
-/* IOCTL parameters */
-
-typedef struct {
-	char	    name[16];		/* coprocessor name		    */
-	u_int	    flags;		/* control flags 		    */
-					/* Coprocessor region:              */
-	kaddr_t	    ram_start;		/*   Host effective address         */
-	u_int	    ram_size;		/*   region size (in bytes)         */
-	kaddr_t	    cp_ram_start;	/*   coprocessor effective address  */
-
-} cop_properties_t;
-
-#define ST_IOCTL_BASE		'l'
-#define STCOP_GRANT		_IOR(ST_IOCTL_BASE, 0, u_int)
-#define STCOP_RESET		_IOR(ST_IOCTL_BASE, 1, u_int)
-#define STCOP_START             STCOP_GRANT
-#define STCOP_PEEK		_IOR(ST_IOCTL_BASE, 2, void*)
-#define STCOP_POKE		_IOW(ST_IOCTL_BASE, 3, void*)
-#define STCOP_GET_PROPERTIES	_IOR(ST_IOCTL_BASE, 4, cop_properties_t*)
-#define STCOP_SET_PROPERTIES	_IOW(ST_IOCTL_BASE, 5, cop_properties_t*)
-
-#define NO_DATA		0xdeadbeef
-#define UNDEFINED_DATA	NO_DATA
-
 /* ---------------------------------------------------------------------------
  *     Generic macros
  * ------------------------------------------------------------------------ */
@@ -106,3 +84,32 @@
 extern int coproc_cpu_reset(coproc_t *);
 extern int coproc_check_area(u_long, u_long, int, coproc_t *);
 extern void coproc_proc_other_info(coproc_t *, struct seq_file *);
+#endif /* __KERNEL__ */
+
+/* IOCTL parameters */
+typedef unsigned long kaddr_t;
+typedef struct {
+	char	    name[16];		/* coprocessor name		    */
+	u_int	    flags;		/* control flags 		    */
+					/* Coprocessor region:              */
+	kaddr_t	    ram_start;		/*   Host effective address         */
+	u_int	    ram_size;		/*   region size (in bytes)         */
+	kaddr_t	    cp_ram_start;	/*   coprocessor effective address  */
+
+} cop_properties_t;
+
+#define	MEGA			(1024 * 1024)
+
+#define ST_IOCTL_BASE		'l'
+#define STCOP_GRANT		_IOR(ST_IOCTL_BASE, 0, u_int)
+#define STCOP_RESET		_IOR(ST_IOCTL_BASE, 1, u_int)
+#define STCOP_START             STCOP_GRANT
+#define STCOP_PEEK		_IOR(ST_IOCTL_BASE, 2, void*)
+#define STCOP_POKE		_IOW(ST_IOCTL_BASE, 3, void*)
+#define STCOP_GET_PROPERTIES	_IOR(ST_IOCTL_BASE, 4, cop_properties_t*)
+#define STCOP_SET_PROPERTIES	_IOW(ST_IOCTL_BASE, 5, cop_properties_t*)
+
+#define NO_DATA		0xdeadbeef
+#define UNDEFINED_DATA	NO_DATA
+
+#endif /* __STM_COPROCESSOR_H__ */
diff -Naur a/include/linux/stm/emi.h b/include/linux/stm/emi.h
--- a/include/linux/stm/emi.h	2013-11-01 20:19:19.325931811 +0200
+++ b/include/linux/stm/emi.h	2013-11-01 18:44:57.533856501 +0200
@@ -26,6 +26,46 @@
 };
 
 unsigned long emi_bank_base(int bank);
+
+/*
+ * EMI Config Data[0-3] bit fields definitions, as used by emi_bank_configure()
+ */
+#define EMI_CFG0_WE_USE_OE_CFG		(1 << 26)
+#define EMI_CGF0_WAIT_POLARITY_LOW	(1 << 25)
+#define EMI_CFG0_LATCH_POINT(v)		(((v) & 0x1f) << 20)
+#define EMI_CFG0_DRIVE_DELAY(v)		(((v) & 0x1f) << 15)
+#define EMI_CFG0_BUS_RELEASE(v)		(((v) & 0x0f) << 11)
+#define ACTIVE_CODE_OFF			0x0
+#define ACTIVE_CODE_RD			0x1
+#define ACTIVE_CODE_WR			0x2
+#define ACTIVE_CODE_RDWR		0x3
+#define EMI_CFG0_CS_ACTIVE(v)		(((v) & 0x3) << 9)
+#define EMI_CFG0_OE_ACTIVE(v)		(((v) & 0x3) << 7)
+#define EMI_CFG0_BE_ACTIVE(v)		(((v) & 0x3) << 5)
+#define EMI_CFG0_PORTSIZE_32BIT		(0x1 << 3)
+#define EMI_CFG0_PORTSIZE_16BIT		(0x2 << 3)
+#define EMI_CFG0_PORTSIZE_8BIT		(0x3 << 3)
+#define EMI_CFG0_DEVICE_NORMAL		0x1
+#define EMI_CFG0_DEVICE_BURST		0x4
+
+#define EMI_CFG1_READ_CYCLESNOTPHASE	(1 << 31)
+#define EMI_CFG1_READ_CYCLES(v)		(((v) & 0x7f) << 24)
+#define EMI_CFG1_READ_CSE1(v)		(((v) & 0x0f) << 20)
+#define EMI_CFG1_READ_CSE2(v)		(((v) & 0x0f) << 16)
+#define EMI_CFG1_READ_OEE1(v)		(((v) & 0x0f) << 12)
+#define EMI_CFG1_READ_OEE2(v)		(((v) & 0x0f) << 8)
+#define EMI_CFG1_READ_BEE1(v)		(((v) & 0x0f) << 4)
+#define EMI_CFG1_READ_BEE2(v)		((v) & 0x0f)
+
+#define EMI_CFG2_WRITE_CYCLESNOTPHASE	(1 << 31)
+#define EMI_CFG2_WRITE_CYCLES(v)	(((v) & 0x7f) << 24)
+#define EMI_CFG2_WRITW_CSE1(v)		(((v) & 0x0f) << 20)
+#define EMI_CFG2_WRITE_CSE2(v)		(((v) & 0x0f) << 16)
+#define EMI_CFG2_WRITE_OEE1(v)		(((v) & 0x0f) << 12)
+#define EMI_CFG2_WRITE_OEE2(v)		(((v) & 0x0f) << 8)
+#define EMI_CFG2_WRITE_BEE1(v)		(((v) & 0x0f) << 4)
+#define EMI_CFG2_WRITE_BEE2(v)		((v) & 0x0f)
+
 void emi_bank_configure(int bank, unsigned long data[4]);
 void emi_bank_write_cs_enable(int bank, int enable);
 void emi_config_pcmode(int bank, int pc_mode);
diff -Naur a/include/linux/stm/Kbuild b/include/linux/stm/Kbuild
--- a/include/linux/stm/Kbuild	1970-01-01 03:00:00.000000000 +0300
+++ b/include/linux/stm/Kbuild	2013-11-01 18:44:57.533856501 +0200
@@ -0,0 +1 @@
+header-y += coprocessor.h
diff -Naur a/include/linux/stm/lpm.h b/include/linux/stm/lpm.h
--- a/include/linux/stm/lpm.h	1970-01-01 03:00:00.000000000 +0300
+++ b/include/linux/stm/lpm.h	2013-11-01 18:44:57.533856501 +0200
@@ -0,0 +1,293 @@
+/*
+ * <root>/include/linux/stm/lpm.h
+ *
+ * Interface file for stm lpm driver
+ *
+ * Copyright (C) 2012 STMicroelectronics Limited
+ *
+ * Contributor:Francesco Virlinzi <francesco.virlinzi@st.com>
+ * Author:Pooja Agarwal <pooja.agarwal@st.com>
+ * Author:Udit Kumar <udit-dlh.kumar@st.com>
+ *
+ * May be copied or modified under the terms of the GNU General Public License.
+ * See linux/COPYING for more information.
+ */
+
+
+#ifndef __LPM_H
+#define __LPM_H
+
+#include <linux/rtc.h>
+
+/**
+ * enum stm_lpm_wakeup_devices- define wakeup devices
+ * One bit for each wakeup device
+ */
+
+enum stm_lpm_wakeup_devices{
+	STM_LPM_WAKEUP_IR = 1<<0,
+	STM_LPM_WAKEUP_CEC = 1<<1,
+	STM_LPM_WAKEUP_FRP = 1<<2,
+	STM_LPM_WAKEUP_WOL = 1<<3,
+	STM_LPM_WAKEUP_RTC = 1<<4,
+	STM_LPM_WAKEUP_ASC = 1<<5,
+	STM_LPM_WAKEUP_NMI = 1<<6,
+	STM_LPM_WAKEUP_HPD = 1<<7,
+	STM_LPM_WAKEUP_PIO = 1<<8,
+	STM_LPM_WAKEUP_EXT = 1<<9
+};
+
+/**
+ * enum stm_lpm_reset_type - define reset type
+ * @STM_LPM_SOC_RESET:	SOC reset
+ * @STM_LPM_SBC_RESET:	Only SBC reset
+ * @STM_LPM_BOOT_RESET:	reset SBC and stay in bootloader
+ */
+enum stm_lpm_reset_type{
+	STM_LPM_SOC_RESET = 0,
+	STM_LPM_SBC_RESET = 1<<0,
+	STM_LPM_BOOT_RESET = 1<<1
+};
+
+/**
+ * enum stm_lpm_sbc_state - defines SBC state
+ * @STM_LPM_SBC_BOOT:	SBC waiting in bootloader
+ * @STM_LPM_SBC_RUNNING:	SBC is running
+ * @STM_LPM_SBC_STANDBY:	Entering into standby
+ */
+
+enum stm_lpm_sbc_state{
+	STM_LPM_SBC_BOOT = 1,
+	STM_LPM_SBC_RUNNING = 4,
+	STM_LPM_SBC_STANDBY = 5
+};
+
+/**
+ * struct stm_lpm_version - define version information
+ * @major_comm_protocol:	Supported Major protocol version
+ * @minor_comm_protocol:	Supported Minor protocol version
+ * @major_soft:	Major software version
+ * @minor_soft:	Minor software version
+ * @patch_soft:	Software patch version
+ * @month:	Software build month version
+ * @day:	Software build day
+ * @year:	Software build year
+ *
+ * Same struct is used for firmware and driver version information
+ */
+
+struct stm_lpm_version{
+	char major_comm_protocol;
+	char minor_comm_protocol;
+	char major_soft;
+	char minor_soft;
+	char patch_soft;
+	char month;
+	char day;
+	char year;
+};
+
+/**
+ * struct stm_lpm_fp_setting - define front panel setting
+ * @owner:	Owner of front panel
+ * 		when 0 - SBC firmware will be owner in standby
+ *		when 1 - SBC firmware always own frontpanel display
+ *		when 2 - Host will always own front panel
+ * @am_pm:	AM/PM indicator, when 0 clock will be displayed in 24 hrs format
+ * @brightness:	brightness of display, [0-3] bits are used max value is 15
+ * This is to inform SBC how front panel display will be used
+ */
+struct stm_lpm_fp_setting{
+	char owner;
+	char am_pm;
+	char brightness;
+};
+
+/**
+ * enum stm_lpm_pio_use - to define how pio can be used
+ * @STM_LPM_PIO_POWER:	PIO used for power control
+ * @STM_LPM_PIO_ETH_MDINT:	PIO used for phy WOL
+ * @STM_LPM_PIO_WAKEUP:	PIO used as GPIO interrupt for wakeup
+ * @STM_LPM_PIO_EXT_IT:	PIO used as external interrupt
+ * @STM_LPM_PIO_OTHER:	Reserved
+ */
+
+enum stm_lpm_pio_use{
+	STM_LPM_PIO_POWER = 1,
+	STM_LPM_PIO_ETH_MDINT = 2,
+	STM_LPM_PIO_WAKEUP = 3,
+	STM_LPM_PIO_EXT_IT = 4,
+	STM_LPM_PIO_OTHER = 5,
+};
+
+/**
+ * struct stm_lpm_pio_setting - define PIO use
+ * @pio_bank:	pio bank number
+ * @pio_pin:	pio pin number, valid values [0-7]
+ * @pio_direction:	direction of PIO
+ *		0 means, pio is used as input.
+ *		1 means, pio is used as output.
+ * @interrupt_enabled:	If interrupt on this PIO is enabled
+ *		0 means, interrupts are disabled.
+ *		1 means, interrupt are enabled.
+ *		This must be set to 0 when pio is used as output.
+ * @pio_level:	PIO level high or low.
+ *		0 means, Interrupt/Power off will be done when PIO goes low.
+ *		1 means, Interrupt/Power off will be done when PIO goes high.
+ * @pio_use:	use of this pio
+ *
+ */
+
+struct stm_lpm_pio_setting{
+	char pio_bank;
+	char pio_pin;
+	bool pio_direction;
+	bool interrupt_enabled;
+	bool pio_level;
+	enum stm_lpm_pio_use  pio_use;
+};
+
+/**
+ * enum stm_lpm_adv_feature_name - Define name of advance feature of SBC
+ * @STM_LPM_USE_EXT_VCORE:	feature is external VCORE for SBC
+ * @STM_LPM_USE_INT_VOLT_DETECT:	internal low voltage detect
+ * @STM_LPM_EXT_CLOCK:	external clock
+ * @STM_LPM_RTC_SOURCE: RTC source for SBC
+ * @STM_LPM_WU_TRIGGERS: wakeup triggers
+ */
+
+enum stm_lpm_adv_feature_name{
+	STM_LPM_USE_EXT_VCORE = 1,
+	STM_LPM_USE_INT_VOLT_DETECT = 2,
+	STM_LPM_EXT_CLOCK = 3,
+	STM_LPM_RTC_SOURCE = 4,
+	STM_LPM_WU_TRIGGERS = 5,
+};
+
+/**
+ * struct stm_lpm_adv_feature - define advance feature struct
+ * @feature_name:	Name of feature
+ * @set_params:	Used to set feature on SBC
+ *
+ * 		when features is STM_LPM_USE_EXT_VCORE,
+ *		set_parmas[0] = 0 means Internal Vcore
+ *		set_parmas[0] = 1 means Internal Vcore
+ *		set_parmas[1] is unused
+ *
+ * 		when features is STM_LPM_USE_INT_VOLT_DETECT
+ *		set_parmas[0] is voltage value to detect low voltage
+ *		i..e for 3.3V use 33 and for 3.0V use 20
+ *		set_parmas[1] is unused
+ *
+ * 		when features is STM_LPM_EXT_CLOCK
+ *		set_parmas[0] = 1 means external
+ *		set_parmas[0] = 2 means external ACG
+ *		set_parmas[0] = 3 means Track_32K
+ *		set_parmas[1] is unused
+ *
+ * 		when features is STM_LPM_RTC_SOURCE
+ *		set_parmas[0] = 1 means RTC_32K_TCXO
+ *		set_parmas[0] = 2 means external ACG
+ *		set_parmas[0] = 3 means RTC_32K_OSC
+ *		set_parmas[1] is unused
+ *
+ * 		when features is STM_LPM_WU_TRIGGERS
+ *		set_parmas[0-1] is bit map for each wakeup trigger
+ *		as defined in enum stm_lpm_wakeup_devices
+ * @get_params: Used to get advance feature of SBC
+ *		get_params[0-3] is feature set supported by SBC , TBD
+ *		get_params[4-5] is wakeup triggers
+ *
+ */
+struct stm_lpm_adv_feature{
+	enum stm_lpm_adv_feature_name feature_name;
+	union {
+		unsigned char set_params[2];
+		unsigned char get_params[6];
+	} params;
+};
+
+/* defines  MAX depth for IR FIFO */
+#define MAX_IR_FIFO_DEPTH 64
+
+/**
+ * struct stm_lpm_ir_fifo - define one element of IR fifo
+ * @mark:	Mark time
+ * @symbol:	Symbol time
+ *
+ */
+struct stm_lpm_ir_fifo{
+	u16 mark;
+	u16 symbol;
+};
+
+/**
+ * sturct stm_lpm_ir_key - define raw data for IR key
+ * @key_index:	Key Index acts as key identifier
+ * @num_patterns:	Number of mark/symbol pattern define this key
+ * @fifo:	Place holder for mark/symbol data
+ *
+ * Max value of fifo is kept 64, which is max value of IR IP
+ */
+
+struct stm_lpm_ir_key{
+	u8 key_index;
+	u8 num_patterns;
+	struct stm_lpm_ir_fifo fifo[MAX_IR_FIFO_DEPTH];
+};
+
+
+/**
+ * struct stm_lpm_ir_keyinfo - define a IR key along with another info
+ * @ir_id:	Id of IR hardware, use id 0 for first IR, 1 for second IR
+ * 		use id 0x80 for first UHF and 0x81 for second so on
+ * @time_period:	Time period for this key , this is dependent on protocol
+ * @time_out:	Time out period for this key
+ * @tolerance:	Expected tolerance in IR key from standard value
+ * @ir_key:	IR key data
+ *
+ */
+
+struct stm_lpm_ir_keyinfo{
+	u8 ir_id;
+	u16 time_period;
+	u16 time_out;
+	u8 tolerance;
+	struct stm_lpm_ir_key ir_key;
+};
+
+int stm_lpm_configure_wdt(u16 time_in_ms);
+
+int stm_lpm_get_fw_state(enum stm_lpm_sbc_state *fw_state);
+
+int stm_lpm_get_wakeup_device(enum stm_lpm_wakeup_devices *wakeupdevice);
+
+int stm_lpm_get_wakeup_info(enum stm_lpm_wakeup_devices *wakeupdevice,
+	u16 *validsize, u16 datasize, char  *data) ;
+
+int stm_lpm_get_version(struct stm_lpm_version *drv_ver,
+	struct stm_lpm_version *fw_ver);
+
+int stm_lpm_reset(enum stm_lpm_reset_type reset_type);
+
+int stm_lpm_setup_fp(struct stm_lpm_fp_setting *fp_setting);
+
+
+int stm_lpm_setup_ir(u8 num_keys, struct stm_lpm_ir_keyinfo *keys);
+
+int stm_lpm_set_rtc(struct rtc_time *new_rtc);
+
+int stm_lpm_set_wakeup_device(u16  wakeup_devices);
+
+int stm_lpm_set_wakeup_time(u32 timeout);
+
+int stm_lpm_setup_pio(struct stm_lpm_pio_setting *pio_setting);
+
+int stm_lpm_setup_keyscan(u16 key_data);
+
+int stm_lpm_set_adv_feature(u8 enabled, struct stm_lpm_adv_feature *feature);
+
+int stm_lpm_get_adv_feature(unsigned char all_features,
+				struct stm_lpm_adv_feature *feature);
+
+#endif /*__LPM_H*/
diff -Naur a/include/linux/stm/nand_devices.h b/include/linux/stm/nand_devices.h
--- a/include/linux/stm/nand_devices.h	1970-01-01 03:00:00.000000000 +0300
+++ b/include/linux/stm/nand_devices.h	2013-11-01 18:44:57.533856501 +0200
@@ -0,0 +1,224 @@
+/*
+ * include/linux/stm/nand_devices.h
+ *
+ * Timing specifications for NAND devices found on ST Reference Boards.
+ *
+ * Author: Angus Clark <angus.clark@st.com>
+ *
+ * Copyright (C) 2012-2013 STMicroelectronics Limited
+ *
+ * May be copied or modified under the terms of the GNU General Public
+ * License.  See linux/COPYING for more information.
+ *
+ */
+#ifndef NAND_DEVICES_H
+#define NAND_DEVICES_H
+
+/* Hynix HY27UH08AG
+ * - tCEA not directly specified in datahseet: using tCEA = tREA + tCR.
+ * - tCSD not specified, assuming other constraints (i.e. tCOH, tCHZ) are
+ *   limiting factor.
+ */
+#define NAND_TSPEC_HYNIX_HY27UH08AG5B		\
+	((struct nand_timing_spec) {		\
+		.tR	= 25,			\
+		.tCLS	= 12,			\
+		.tCS	= 20,			\
+		.tALS	= 12,			\
+		.tDS	= 12,			\
+		.tWP	= 12,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 25,			\
+		.tRP	= 12,			\
+		.tREH	= 10,			\
+		.tRC	= 25,			\
+		.tREA	= 20,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 30,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 50,			\
+		.tCSD	= 0,			\
+	})
+
+/* Macronix MX30LF1G08AM
+ * - tRHOH and tCOH not specified in datahseet, but equivalent to tOH.
+ * - tCSD not specified, assuming other constraints (i.e. tCOH, tCHZ) are
+ *   limiting factor.
+ */
+#define NAND_TSPEC_MACRONIX_MX30LF1G08AM	\
+	((struct nand_timing_spec) {		\
+		.tR	= 25,			\
+		.tCLS	= 15,			\
+		.tCS	= 20,			\
+		.tALS	= 15,			\
+		.tDS	= 5,			\
+		.tWP	= 15,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 30,			\
+		.tRP	= 15,			\
+		.tREH	= 10,			\
+		.tRC	= 30,			\
+		.tREA	= 20,			\
+		.tRHOH	= 10,			\
+		.tCEA	= 25,			\
+		.tCOH	= 10,			\
+		.tCHZ	= 50,			\
+		.tCSD	= 0,			\
+	})
+
+/* Samsung K9F2G08U0C */
+#define NAND_TSPEC_SAMSUNG_K9F2G08U0C		\
+	((struct nand_timing_spec) {		\
+		.tR	= 40,			\
+		.tCLS	= 12,			\
+		.tCS	= 20,			\
+		.tALS	= 12,			\
+		.tDS	= 12,			\
+		.tWP	= 12,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 25,			\
+		.tRP	= 12,			\
+		.tREH	= 15,			\
+		.tRC	= 25,			\
+		.tREA	= 20,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 25,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 30,			\
+		.tCSD	= 10,			\
+	})
+
+/* Spansion S34ML0xG1
+ * - Spec in datasheet is more performant than advertised ONFI timing mode.
+ */
+#define NAND_TSPEC_SPANSION_S34ML01G1		\
+	((struct nand_timing_spec) {		\
+		.tR	= 25,			\
+		.tCLS	= 12,			\
+		.tCS	= 20,			\
+		.tALS	= 10,			\
+		.tDS	= 10,			\
+		.tWP	= 12,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 25,			\
+		.tRP	= 12,			\
+		.tREH	= 10,			\
+		.tRC	= 25,			\
+		.tREA	= 20,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 30,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 30,			\
+		.tCSD	= 10,			\
+	})
+
+#define NAND_TSPEC_SPANSION_S34ML02G1	NAND_TSPEC_SPANSION_S34ML01G1
+#define NAND_TSPEC_SPANSION_S34ML04G1	NAND_TSPEC_SPANSION_S34ML01G1
+
+/* Spansion S34ML0xG2
+ * - Spec in datasheet is more performant than advertised ONFI timing mode.
+ */
+#define NAND_TSPEC_SPANSION_S34ML01G2		\
+	((struct nand_timing_spec) {		\
+		.tR	= 25,			\
+		.tCLS	= 12,			\
+		.tCS	= 20,			\
+		.tALS	= 12,			\
+		.tDS	= 10,			\
+		.tWP	= 12,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 25,			\
+		.tRP	= 12,			\
+		.tREH	= 10,			\
+		.tRC	= 25,			\
+		.tREA	= 20,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 30,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 30,			\
+		.tCSD	= 10,			\
+	})
+
+/* ST NAND08GW3B2CN6
+ * - Spec in datasheet is more performant than advertised ONFI timing mode.
+ * - Now a Micron part
+ */
+#define NAND_TSPEC_ST_NAND08GW3B2CN6		\
+	((struct nand_timing_spec) {		\
+		.tR	= 25,			\
+		.tCLS	= 12,			\
+		.tCS	= 20,			\
+		.tALS	= 12,			\
+		.tDS	= 12,			\
+		.tWP	= 12,			\
+		.tCLH	= 5,			\
+		.tCH	= 5,			\
+		.tALH	= 5,			\
+		.tDH	= 5,			\
+		.tWB	= 100,			\
+		.tWH	= 10,			\
+		.tWC	= 25,			\
+		.tRP	= 12,			\
+		.tREH	= 10,			\
+		.tRC	= 25,			\
+		.tREA	= 20,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 25,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 30,			\
+		.tCSD	= 0,			\
+	})
+
+/* ST NAND256W3A2BN6 */
+#define NAND_TSPEC_ST_NAND256W3A2BN6		\
+	((struct nand_timing_spec) {		\
+		.tR	= 12,			\
+		.tCLS	= 0,			\
+		.tCS	= 0,			\
+		.tALS	= 0,			\
+		.tDS	= 20,			\
+		.tWP	= 25,			\
+		.tCLH	= 10,			\
+		.tCH	= 10,			\
+		.tALH	= 10,			\
+		.tDH	= 10,			\
+		.tWB	= 100,			\
+		.tWH	= 15,			\
+		.tWC	= 50,			\
+		.tRP	= 30,			\
+		.tREH	= 15,			\
+		.tRC	= 50,			\
+		.tREA	= 35,			\
+		.tRHOH	= 15,			\
+		.tCEA	= 45,			\
+		.tCOH	= 15,			\
+		.tCHZ	= 20,			\
+		.tCSD	= 0,			\
+	})
+
+#endif /* NAND_DEVICES_H */
diff -Naur a/include/linux/stm/nand.h b/include/linux/stm/nand.h
--- a/include/linux/stm/nand.h	2013-11-01 20:19:19.329931837 +0200
+++ b/include/linux/stm/nand.h	2013-11-01 18:44:57.533856501 +0200
@@ -9,8 +9,9 @@
 #ifndef __LINUX_STM_NAND_H
 #define __LINUX_STM_NAND_H
 
-/* Timing Paramters for NAND Controller.  See ADCS #7864584: "NAND Flash support
- * upgrades for FMI Functional Secification".
+/*
+ * Legacy specification for NAND timing parameters.  Deprecated in favour of
+ * include/mtd/nand.h:nand_timing_spec.
  */
 struct stm_nand_timing_data {
 	/* Times specified in ns.  (Will be rounded up to nearest multiple of
@@ -29,14 +30,43 @@
 	int chip_delay;		/* delay in us */
 };
 
+/*
+ * Board-level specification relating to a 'bank' of NAND Flash
+ */
 struct stm_nand_bank_data {
 	int			csn;
 	int			nr_partitions;
 	struct mtd_partition	*partitions;
 	unsigned int		options;
-	struct stm_nand_timing_data	*timing_data;
+	unsigned int		bbt_options;
+	unsigned int emi_withinbankoffset;
 
-	unsigned int		emi_withinbankoffset;
+	/*
+	 * The AC specification of the NAND device can be used to optimise how
+	 * the STM NAND drivers interact with the NAND device.  During
+	 * initialisation, NAND accesses are configured according to one of the
+	 * following methods, in order of precedence:
+	 *
+	 *   1. Using the data in 'struct nand_timing_spec', if supplied.
+	 *
+	 *   2. Using the data in 'struct stm_nand_timing_data', if supplied.
+	 *      Not supported by the stm-nand-bch driver, and deprecated in
+	 *      favour of method 1.
+	 *
+	 *   3. Using the ONFI timing mode, as advertised by the device during
+	 *      ONFI-probing (ONFI-compliant NAND only).
+	 *
+	 */
+	struct stm_nand_timing_data *timing_data; /* [DEPRECATED] */
+
+	struct nand_timing_spec *timing_spec;
+
+	/*
+	 * No. of IP clk cycles by which to 'relax' the timing configuration.
+	 * Required on some boards to to accommodate board-level limitations.
+	 * Used in conjunction with 'nand_timing_spec' and ONFI configuration.
+	 */
+	int			timing_relax;
 };
 
 #endif /* __LINUX_STM_NAND_H */
diff -Naur a/include/linux/stm/platform.h b/include/linux/stm/platform.h
--- a/include/linux/stm/platform.h	2013-11-01 20:19:19.333931848 +0200
+++ b/include/linux/stm/platform.h	2013-11-01 18:44:57.537856518 +0200
@@ -167,6 +167,7 @@
 	int calibration_value;
 	void (*custom_set_dcorrect)(void *priv);
 	unsigned long (*custom_get_data)(void *priv);
+	int correction_factor; /* add a signed correction to data read */
 	void *custom_priv;
 };
 
@@ -198,7 +199,24 @@
 	struct stm_device_config *device_config;
 };
 
-
+/**
+ * struct stm_lpm_i2c_data - i2c information for SBC
+ * @number_i2c : i2c number connected with external SBC
+ * @number_gpio: gpio which is connected with external SBC for power key.
+ *               This gpio will be controlled by SBC,
+ *		 Host will read status of it
+ * @status_gpio: status of gpio which is connected with SBC for power key
+ * @i2c_adap   : i2c_adapter which is connected with number_i2c
+ *
+ * This struct hold the parameters which are specific to external SBC.
+ * This external SBC is connected with SOC via i2c interface
+ */
+struct stm_lpm_i2c_data {
+	int number_i2c;
+	int number_gpio;
+	int status_gpio;
+	struct i2c_adapter *i2c_adap;
+};
 
 /*** TAP platform data ***/
 
@@ -312,6 +330,15 @@
 struct stm_plat_nand_bch_data {
 	struct stm_nand_bank_data *bank;
 	enum stm_nand_bch_ecc_config bch_ecc_cfg;
+
+	/* The threshold at which the number of corrected bit-flips per sector
+	 * is deemed to have reached an excessive level (triggers '-EUCLEAN' to
+	 * be returned to the caller).  The value should be in the range 1 to
+	 * <ecc-strength> where <ecc-strength> is 18 or 30, depending on the BCH
+	 * ECC mode in operation.  A value of 0 is interpreted by the driver as
+	 * <ecc-strength>.
+	 */
+	unsigned int bch_bitflip_threshold;
 };
 
 struct stm_plat_nand_emi_data {
@@ -334,6 +361,9 @@
 		int flex_connected;
 	} rbn;
 	enum stm_nand_bch_ecc_config bch_ecc_cfg;
+	unsigned int bch_bitflip_threshold; /* See description in
+					     * 'stm_plat_nand_bch_data'.
+					     */
 };
 
 
diff -Naur a/include/linux/stm/stx7108.h b/include/linux/stm/stx7108.h
--- a/include/linux/stm/stx7108.h	2013-11-01 20:19:19.341931897 +0200
+++ b/include/linux/stm/stx7108.h	2013-11-01 18:44:57.541856540 +0200
@@ -107,8 +107,15 @@
 	int tx_enabled;
 	int tx_od_enabled;
 };
+
+struct stx7108_lpm_i2c_config {
+	int number_i2c;
+	int number_gpio;
+};
+
 void stx7108_configure_lirc(struct stx7108_lirc_config *config);
 
+void stx7108_configure_lpm_i2c_interface(struct stx7108_lpm_i2c_config *conf);
 
 struct stx7108_pwm_config {
 	int out0_enabled;
diff -Naur a/include/linux/stm/wakeup_devices.h b/include/linux/stm/wakeup_devices.h
--- a/include/linux/stm/wakeup_devices.h	2013-11-01 20:19:19.345931913 +0200
+++ b/include/linux/stm/wakeup_devices.h	2013-11-01 18:44:57.749857555 +0200
@@ -29,8 +29,9 @@
 struct stm_wakeup_devices {
 	unsigned int lirc_can_wakeup:1;		/* lirc_scd_clk >= 1 MHz */
 	unsigned int hdmi_can_wakeup:1;		/* hdmi_clk == 100 MHz	 */
-	unsigned int eth_phy_can_wakeup:1;	/* eth_phy_clk ~= 25 MHz */
-	unsigned int eth1_phy_can_wakeup:1;
+	unsigned int stm_mac0_can_wakeup:1;	/* eth_phy_clk ~= 25 MHz */
+	unsigned int stm_mac1_can_wakeup:1;
+	unsigned int stm_phy_can_wakeup:1;
 	unsigned int hdmi_cec:1;
 	unsigned int hdmi_hotplug:1;
 	unsigned int kscan:1;
diff -Naur a/include/linux/time.h b/include/linux/time.h
--- a/include/linux/time.h	2013-11-01 20:18:05.773567084 +0200
+++ b/include/linux/time.h	2013-11-01 18:44:58.021858924 +0200
@@ -91,11 +91,36 @@
 	return ts_delta;
 }
 
+#define KTIME_MAX			((s64)~((u64)1 << 63))
+#if (BITS_PER_LONG == 64)
+# define KTIME_SEC_MAX			(KTIME_MAX / NSEC_PER_SEC)
+#else
+# define KTIME_SEC_MAX			LONG_MAX
+#endif
+
 /*
  * Returns true if the timespec is norm, false if denorm:
  */
-#define timespec_valid(ts) \
-	(((ts)->tv_sec >= 0) && (((unsigned long) (ts)->tv_nsec) < NSEC_PER_SEC))
+static inline bool timespec_valid(const struct timespec *ts)
+{
+	/* Dates before 1970 are bogus */
+	if (ts->tv_sec < 0)
+		return false;
+	/* Can't have more nanoseconds then a second */
+	if ((unsigned long)ts->tv_nsec >= NSEC_PER_SEC)
+		return false;
+	return true;
+}
+
+static inline bool timespec_valid_strict(const struct timespec *ts)
+{
+	if (!timespec_valid(ts))
+		return false;
+	/* Disallow values that could overflow ktime_t */
+	if ((unsigned long long)ts->tv_sec >= KTIME_SEC_MAX)
+		return false;
+	return true;
+}
 
 extern struct timespec xtime;
 extern struct timespec wall_to_monotonic;
diff -Naur a/include/linux/timex.h b/include/linux/timex.h
--- a/include/linux/timex.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/linux/timex.h	2013-11-01 18:44:58.021858924 +0200
@@ -271,7 +271,7 @@
 /* Returns how long ticks are at present, in ns / 2^NTP_SCALE_SHIFT. */
 extern u64 tick_length;
 
-extern void second_overflow(void);
+extern int second_overflow(unsigned long secs);
 extern void update_ntp_one_tick(void);
 extern int do_adjtimex(struct timex *);
 
diff -Naur a/include/mtd/mtd-abi.h b/include/mtd/mtd-abi.h
--- a/include/mtd/mtd-abi.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/mtd/mtd-abi.h	2013-11-01 18:44:58.085859244 +0200
@@ -42,6 +42,8 @@
 #define MTD_BIT_WRITEABLE	0x800	/* Single bits can be flipped */
 #define MTD_NO_ERASE		0x1000	/* No erase necessary */
 #define MTD_POWERUP_LOCK	0x2000	/* Always locked after reset */
+#define MTD_SLAVE_PARTITION	0x00010000	/* MTD Slave Partition */
+#define MTD_SPANS_MASTER	0x00020000	/* MTD spans entire master */
 
 // Some common devices / combinations of capabilities
 #define MTD_CAP_ROM		0
diff -Naur a/include/net/inet_sock.h b/include/net/inet_sock.h
--- a/include/net/inet_sock.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/net/inet_sock.h	2013-11-01 18:44:58.101859318 +0200
@@ -56,7 +56,15 @@
 	unsigned char	__data[0];
 };
 
-#define optlength(opt) (sizeof(struct ip_options) + opt->optlen)
+struct ip_options_rcu {
+	struct rcu_head rcu;
+	struct ip_options opt;
+};
+
+struct ip_options_data {
+	struct ip_options_rcu	opt;
+	char			data[40];
+};
 
 struct inet_request_sock {
 	struct request_sock	req;
@@ -77,7 +85,7 @@
 				acked	   : 1,
 				no_srccheck: 1;
 	kmemcheck_bitfield_end(flags);
-	struct ip_options	*opt;
+	struct ip_options_rcu	*opt;
 };
 
 static inline struct inet_request_sock *inet_rsk(const struct request_sock *sk)
@@ -122,7 +130,7 @@
 	__be32			saddr;
 	__s16			uc_ttl;
 	__u16			cmsg_flags;
-	struct ip_options	*opt;
+	struct ip_options_rcu	*inet_opt;
 	__be16			sport;
 	__u16			id;
 	__u8			tos;
diff -Naur a/include/net/ip.h b/include/net/ip.h
--- a/include/net/ip.h	2013-11-01 20:18:05.785567145 +0200
+++ b/include/net/ip.h	2013-11-01 18:44:58.101859318 +0200
@@ -54,7 +54,7 @@
 {
 	__be32			addr;
 	int			oif;
-	struct ip_options	*opt;
+	struct ip_options_rcu	*opt;
 	union skb_shared_tx	shtx;
 };
 
@@ -92,7 +92,7 @@
 
 extern int		ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
 					      __be32 saddr, __be32 daddr,
-					      struct ip_options *opt);
+					      struct ip_options_rcu *opt);
 extern int		ip_rcv(struct sk_buff *skb, struct net_device *dev,
 			       struct packet_type *pt, struct net_device *orig_dev);
 extern int		ip_local_deliver(struct sk_buff *skb);
@@ -362,14 +362,15 @@
  *	Functions provided by ip_options.c
  */
  
-extern void ip_options_build(struct sk_buff *skb, struct ip_options *opt, __be32 daddr, struct rtable *rt, int is_frag);
+extern void ip_options_build(struct sk_buff *skb, struct ip_options *opt,
+			     __be32 daddr, struct rtable *rt, int is_frag);
 extern int ip_options_echo(struct ip_options *dopt, struct sk_buff *skb);
 extern void ip_options_fragment(struct sk_buff *skb);
 extern int ip_options_compile(struct net *net,
 			      struct ip_options *opt, struct sk_buff *skb);
-extern int ip_options_get(struct net *net, struct ip_options **optp,
+extern int ip_options_get(struct net *net, struct ip_options_rcu **optp,
 			  unsigned char *data, int optlen);
-extern int ip_options_get_from_user(struct net *net, struct ip_options **optp,
+extern int ip_options_get_from_user(struct net *net, struct ip_options_rcu **optp,
 				    unsigned char __user *data, int optlen);
 extern void ip_options_undo(struct ip_options * opt);
 extern void ip_forward_options(struct sk_buff *skb);
diff -Naur a/include/net/ipv6.h b/include/net/ipv6.h
--- a/include/net/ipv6.h	2013-11-01 20:18:05.789567164 +0200
+++ b/include/net/ipv6.h	2013-11-01 18:44:58.105859337 +0200
@@ -449,17 +449,7 @@
 	return __ipv6_addr_diff(a1, a2, sizeof(struct in6_addr));
 }
 
-static __inline__ void ipv6_select_ident(struct frag_hdr *fhdr)
-{
-	static u32 ipv6_fragmentation_id = 1;
-	static DEFINE_SPINLOCK(ip6_id_lock);
-
-	spin_lock_bh(&ip6_id_lock);
-	fhdr->identification = htonl(ipv6_fragmentation_id);
-	if (++ipv6_fragmentation_id == 0)
-		ipv6_fragmentation_id = 1;
-	spin_unlock_bh(&ip6_id_lock);
-}
+extern void ipv6_select_ident(struct frag_hdr *fhdr, struct rt6_info *rt);
 
 /*
  *	Prototypes exported by ipv6
diff -Naur a/include/net/rose.h b/include/net/rose.h
--- a/include/net/rose.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/net/rose.h	2013-11-01 18:44:58.157859601 +0200
@@ -14,6 +14,12 @@
 
 #define	ROSE_MIN_LEN			3
 
+#define	ROSE_CALL_REQ_ADDR_LEN_OFF	3
+#define	ROSE_CALL_REQ_ADDR_LEN_VAL	0xAA	/* each address is 10 digits */
+#define	ROSE_CALL_REQ_DEST_ADDR_OFF	4
+#define	ROSE_CALL_REQ_SRC_ADDR_OFF	9
+#define	ROSE_CALL_REQ_FACILITIES_OFF	14
+
 #define	ROSE_GFI			0x10
 #define	ROSE_Q_BIT			0x80
 #define	ROSE_D_BIT			0x40
@@ -214,7 +220,7 @@
 extern int  rose_validate_nr(struct sock *, unsigned short);
 extern void rose_write_internal(struct sock *, int);
 extern int  rose_decode(struct sk_buff *, int *, int *, int *, int *, int *);
-extern int  rose_parse_facilities(unsigned char *, struct rose_facilities_struct *);
+extern int  rose_parse_facilities(unsigned char *, unsigned int, struct rose_facilities_struct *);
 extern void rose_disconnect(struct sock *, int, int, int);
 
 /* rose_timer.c */
diff -Naur a/include/net/transp_v6.h b/include/net/transp_v6.h
--- a/include/net/transp_v6.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/net/transp_v6.h	2013-11-01 18:44:58.173859675 +0200
@@ -16,6 +16,8 @@
 
 struct flowi;
 
+extern void initialize_hashidentrnd(void);
+
 /* extention headers */
 extern int				ipv6_exthdrs_init(void);
 extern void				ipv6_exthdrs_exit(void);
diff -Naur a/include/scsi/scsi.h b/include/scsi/scsi.h
--- a/include/scsi/scsi.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/scsi/scsi.h	2013-11-01 18:44:58.201859813 +0200
@@ -145,10 +145,10 @@
 
 /* defined in T10 SCSI Primary Commands-2 (SPC2) */
 struct scsi_varlen_cdb_hdr {
-	u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
-	u8 control;
-	u8 misc[5];
-	u8 additional_cdb_length;         /* total cdb length - 8 */
+	__u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
+	__u8 control;
+	__u8 misc[5];
+	__u8 additional_cdb_length;         /* total cdb length - 8 */
 	__be16 service_action;
 	/* service specific data follows */
 };
diff -Naur a/include/scsi/scsi_netlink.h b/include/scsi/scsi_netlink.h
--- a/include/scsi/scsi_netlink.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/scsi/scsi_netlink.h	2013-11-01 18:44:58.209859850 +0200
@@ -105,8 +105,8 @@
  *    PCI :  ID data is the 16 bit PCI Registered Vendor ID
  */
 #define SCSI_NL_VID_TYPE_SHIFT		56
-#define SCSI_NL_VID_TYPE_MASK		((u64)0xFF << SCSI_NL_VID_TYPE_SHIFT)
-#define SCSI_NL_VID_TYPE_PCI		((u64)0x01 << SCSI_NL_VID_TYPE_SHIFT)
+#define SCSI_NL_VID_TYPE_MASK		((__u64)0xFF << SCSI_NL_VID_TYPE_SHIFT)
+#define SCSI_NL_VID_TYPE_PCI		((__u64)0x01 << SCSI_NL_VID_TYPE_SHIFT)
 #define SCSI_NL_VID_ID_MASK		(~ SCSI_NL_VID_TYPE_MASK)
 
 
diff -Naur a/include/trace/events/kmem.h b/include/trace/events/kmem.h
--- a/include/trace/events/kmem.h	2009-12-03 05:51:21.000000000 +0200
+++ b/include/trace/events/kmem.h	2013-11-01 18:44:58.249860051 +0200
@@ -293,7 +293,7 @@
 
 	TP_printk("page=%p pfn=%lu order=%d migratetype=%d gfp_flags=%s",
 		__entry->page,
-		page_to_pfn(__entry->page),
+		__entry->page ? page_to_pfn(__entry->page) : 0,
 		__entry->order,
 		__entry->migratetype,
 		show_gfp_flags(__entry->gfp_flags))
@@ -319,7 +319,7 @@
 
 	TP_printk("page=%p pfn=%lu order=%u migratetype=%d percpu_refill=%d",
 		__entry->page,
-		page_to_pfn(__entry->page),
+		__entry->page ? page_to_pfn(__entry->page) : 0,
 		__entry->order,
 		__entry->migratetype,
 		__entry->order == 0)
diff -Naur a/kernel/async.c b/kernel/async.c
--- a/kernel/async.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/async.c	2013-11-01 18:44:58.293860270 +0200
@@ -93,6 +93,13 @@
 {
 	struct async_entry *entry;
 
+	if (!running) { /* just check the entry count */
+		if (atomic_read(&entry_count))
+			return 0; /* smaller than any cookie */
+		else
+			return next_cookie;
+	}
+
 	if (!list_empty(running)) {
 		entry = list_first_entry(running,
 			struct async_entry, list);
@@ -248,9 +255,7 @@
  */
 void async_synchronize_full(void)
 {
-	do {
-		async_synchronize_cookie(next_cookie);
-	} while (!list_empty(&async_running) || !list_empty(&async_pending));
+	async_synchronize_cookie_domain(next_cookie, NULL);
 }
 EXPORT_SYMBOL_GPL(async_synchronize_full);
 
@@ -270,7 +275,7 @@
 /**
  * async_synchronize_cookie_domain - synchronize asynchronous function calls within a certain domain with cookie checkpointing
  * @cookie: async_cookie_t to use as checkpoint
- * @running: running list to synchronize on
+ * @running: running list to synchronize on, NULL indicates all lists
  *
  * This function waits until all asynchronous function calls for the
  * synchronization domain specified by the running list @list submitted
diff -Naur a/kernel/cgroup.c b/kernel/cgroup.c
--- a/kernel/cgroup.c	2013-11-01 20:18:05.837567402 +0200
+++ b/kernel/cgroup.c	2013-11-01 18:44:58.305860326 +0200
@@ -1992,9 +1992,7 @@
 		dentry->d_fsdata = cgrp;
 		inc_nlink(parent->d_inode);
 		rcu_assign_pointer(cgrp->dentry, dentry);
-		dget(dentry);
 	}
-	dput(dentry);
 
 	return error;
 }
diff -Naur a/kernel/cred.c b/kernel/cred.c
--- a/kernel/cred.c	2013-11-01 20:18:05.849567455 +0200
+++ b/kernel/cred.c	2013-11-01 18:44:58.313860375 +0200
@@ -443,6 +443,8 @@
 
 	mutex_init(&p->cred_guard_mutex);
 
+	p->replacement_session_keyring = NULL;
+
 	if (
 #ifdef CONFIG_KEYS
 		!p->cred->thread_keyring &&
diff -Naur a/kernel/exit.c b/kernel/exit.c
--- a/kernel/exit.c	2013-11-01 20:18:05.849567455 +0200
+++ b/kernel/exit.c	2013-11-01 18:44:58.313860375 +0200
@@ -1020,7 +1020,7 @@
 	tsk->flags |= PF_EXITPIDONE;
 
 	if (tsk->io_context)
-		exit_io_context();
+		exit_io_context(tsk);
 
 	if (tsk->splice_pipe)
 		__free_pipe_info(tsk->splice_pipe);
diff -Naur a/kernel/fork.c b/kernel/fork.c
--- a/kernel/fork.c	2013-11-01 20:18:05.853567485 +0200
+++ b/kernel/fork.c	2013-11-01 18:44:58.317860389 +0200
@@ -64,6 +64,7 @@
 #include <linux/magic.h>
 #include <linux/perf_event.h>
 #include <linux/posix-timers.h>
+#include <linux/signalfd.h>
 
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
@@ -815,8 +816,10 @@
 
 void __cleanup_sighand(struct sighand_struct *sighand)
 {
-	if (atomic_dec_and_test(&sighand->count))
+	if (atomic_dec_and_test(&sighand->count)) {
+		signalfd_cleanup(sighand);
 		kmem_cache_free(sighand_cachep, sighand);
+	}
 }
 
 
@@ -1299,7 +1302,8 @@
 	if (pid != &init_struct_pid)
 		free_pid(pid);
 bad_fork_cleanup_io:
-	put_io_context(p->io_context);
+	if (p->io_context)
+		exit_io_context(p);
 bad_fork_cleanup_namespaces:
 	exit_task_namespaces(p);
 bad_fork_cleanup_mm:
diff -Naur a/kernel/futex.c b/kernel/futex.c
--- a/kernel/futex.c	2013-11-01 20:18:05.857567502 +0200
+++ b/kernel/futex.c	2013-11-01 18:44:58.321860408 +0200
@@ -264,17 +264,29 @@
 
 	page = compound_head(page);
 	lock_page(page);
+
+	/*
+	 * If page->mapping is NULL, then it cannot be a PageAnon
+	 * page; but it might be the ZERO_PAGE or in the gate area or
+	 * in a special mapping (all cases which we are happy to fail);
+	 * or it may have been a good file page when get_user_pages_fast
+	 * found it, but truncated or holepunched or subjected to
+	 * invalidate_complete_page2 before we got the page lock (also
+	 * cases which we are happy to fail).  And we hold a reference,
+	 * so refcount care in invalidate_complete_page's remove_mapping
+	 * prevents drop_caches from setting mapping to NULL beneath us.
+	 *
+	 * The case we do have to guard against is when memory pressure made
+	 * shmem_writepage move it from filecache to swapcache beneath us:
+	 * an unlikely race, but we do need to retry for page->mapping.
+	 */
 	if (!page->mapping) {
+		int shmem_swizzled = PageSwapCache(page);
 		unlock_page(page);
 		put_page(page);
-		/*
-		* ZERO_PAGE pages don't have a mapping. Avoid a busy loop
-		* trying to find one. RW mapping would have COW'd (and thus
-		* have a mapping) so this page is RO and won't ever change.
-		*/
-		if ((page == ZERO_PAGE(address)))
-			return -EFAULT;
-		goto again;
+		if (shmem_swizzled)
+			goto again;
+		return -EFAULT;
 	}
 
 	/*
@@ -2192,11 +2204,11 @@
  * @uaddr2:	the pi futex we will take prior to returning to user-space
  *
  * The caller will wait on uaddr and will be requeued by futex_requeue() to
- * uaddr2 which must be PI aware.  Normal wakeup will wake on uaddr2 and
- * complete the acquisition of the rt_mutex prior to returning to userspace.
- * This ensures the rt_mutex maintains an owner when it has waiters; without
- * one, the pi logic wouldn't know which task to boost/deboost, if there was a
- * need to.
+ * uaddr2 which must be PI aware and unique from uaddr.  Normal wakeup will wake
+ * on uaddr2 and complete the acquisition of the rt_mutex prior to returning to
+ * userspace.  This ensures the rt_mutex maintains an owner when it has waiters;
+ * without one, the pi logic would not know which task to boost/deboost, if
+ * there was a need to.
  *
  * We call schedule in futex_wait_queue_me() when we enqueue and return there
  * via the following:
@@ -2233,6 +2245,9 @@
 	struct futex_q q;
 	int res, ret;
 
+	if (uaddr == uaddr2)
+		return -EINVAL;
+
 	if (!bitset)
 		return -EINVAL;
 
@@ -2306,7 +2321,7 @@
 		 * signal.  futex_unlock_pi() will not destroy the lock_ptr nor
 		 * the pi_state.
 		 */
-		WARN_ON(!&q.pi_state);
+		WARN_ON(!q.pi_state);
 		pi_mutex = &q.pi_state->pi_mutex;
 		ret = rt_mutex_finish_proxy_lock(pi_mutex, to, &rt_waiter, 1);
 		debug_rt_mutex_free_waiter(&rt_waiter);
@@ -2333,7 +2348,7 @@
 	 * fault, unlock the rt_mutex and return the fault to userspace.
 	 */
 	if (ret == -EFAULT) {
-		if (rt_mutex_owner(pi_mutex) == current)
+		if (pi_mutex && rt_mutex_owner(pi_mutex) == current)
 			rt_mutex_unlock(pi_mutex);
 	} else if (ret == -EINTR) {
 		/*
diff -Naur a/kernel/hrtimer.c b/kernel/hrtimer.c
--- a/kernel/hrtimer.c	2013-11-01 20:18:05.861567521 +0200
+++ b/kernel/hrtimer.c	2013-11-01 18:44:58.325860434 +0200
@@ -603,6 +603,12 @@
 	return res;
 }
 
+static inline ktime_t hrtimer_update_base(struct hrtimer_cpu_base *base)
+{
+	ktime_t *offs_real = &base->clock_base[CLOCK_REALTIME].offset;
+
+	return ktime_get_update_offsets(offs_real);
+}
 
 /*
  * Retrigger next event is called after clock was set
@@ -612,26 +618,15 @@
 static void retrigger_next_event(void *arg)
 {
 	struct hrtimer_cpu_base *base;
-	struct timespec realtime_offset;
-	unsigned long seq;
 
 	if (!hrtimer_hres_active())
 		return;
 
-	do {
-		seq = read_seqbegin(&xtime_lock);
-		set_normalized_timespec(&realtime_offset,
-					-wall_to_monotonic.tv_sec,
-					-wall_to_monotonic.tv_nsec);
-	} while (read_seqretry(&xtime_lock, seq));
-
 	base = &__get_cpu_var(hrtimer_bases);
 
 	/* Adjust CLOCK_REALTIME offset */
 	spin_lock(&base->lock);
-	base->clock_base[CLOCK_REALTIME].offset =
-		timespec_to_ktime(realtime_offset);
-
+	hrtimer_update_base(base);
 	hrtimer_force_reprogram(base, 0);
 	spin_unlock(&base->lock);
 }
@@ -731,13 +726,25 @@
 	base->clock_base[CLOCK_MONOTONIC].resolution = KTIME_HIGH_RES;
 
 	tick_setup_sched_timer();
-
 	/* "Retrigger" the interrupt to get things going */
 	retrigger_next_event(NULL);
 	local_irq_restore(flags);
 	return 1;
 }
 
+/*
+ * Called from timekeeping code to reprogramm the hrtimer interrupt
+ * device. If called from the timer interrupt context we defer it to
+ * softirq context.
+ */
+void clock_was_set_delayed(void)
+{
+	struct hrtimer_cpu_base *cpu_base = &__get_cpu_var(hrtimer_bases);
+
+	cpu_base->clock_was_set = 1;
+	__raise_softirq_irqoff(HRTIMER_SOFTIRQ);
+}
+
 #else
 
 static inline int hrtimer_hres_active(void) { return 0; }
@@ -1250,11 +1257,10 @@
 	cpu_base->nr_events++;
 	dev->next_event.tv64 = KTIME_MAX;
 
-	entry_time = now = ktime_get();
+	spin_lock(&cpu_base->lock);
+	entry_time = now = hrtimer_update_base(cpu_base);
 retry:
 	expires_next.tv64 = KTIME_MAX;
-
-	spin_lock(&cpu_base->lock);
 	/*
 	 * We set expires_next to KTIME_MAX here with cpu_base->lock
 	 * held to prevent that a timer is enqueued in our queue via
@@ -1328,8 +1334,12 @@
 	 * We need to prevent that we loop forever in the hrtimer
 	 * interrupt routine. We give it 3 attempts to avoid
 	 * overreacting on some spurious event.
+	 *
+	 * Acquire base lock for updating the offsets and retrieving
+	 * the current time.
 	 */
-	now = ktime_get();
+	spin_lock(&cpu_base->lock);
+	now = hrtimer_update_base(cpu_base);
 	cpu_base->nr_retries++;
 	if (++retries < 3)
 		goto retry;
@@ -1341,6 +1351,7 @@
 	 */
 	cpu_base->nr_hangs++;
 	cpu_base->hang_detected = 1;
+	spin_unlock(&cpu_base->lock);
 	delta = ktime_sub(now, entry_time);
 	if (delta.tv64 > cpu_base->max_hang_time.tv64)
 		cpu_base->max_hang_time = delta;
@@ -1393,6 +1404,13 @@
 
 static void run_hrtimer_softirq(struct softirq_action *h)
 {
+	struct hrtimer_cpu_base *cpu_base = &__get_cpu_var(hrtimer_bases);
+
+	if (cpu_base->clock_was_set) {
+		cpu_base->clock_was_set = 0;
+		clock_was_set();
+	}
+
 	hrtimer_peek_ahead_timers();
 }
 
diff -Naur a/kernel/irq/handle.c b/kernel/irq/handle.c
--- a/kernel/irq/handle.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/irq/handle.c	2013-11-01 18:44:58.329860445 +0200
@@ -370,7 +370,7 @@
 irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action)
 {
 	irqreturn_t ret, retval = IRQ_NONE;
-	unsigned int status = 0;
+	unsigned int flags = 0;
 
 	if (!(action->flags & IRQF_DISABLED))
 		local_irq_enable_in_hardirq();
@@ -413,7 +413,7 @@
 
 			/* Fall through to add to randomness */
 		case IRQ_HANDLED:
-			status |= action->flags;
+			flags |= action->flags;
 			break;
 
 		default:
@@ -424,8 +424,7 @@
 		action = action->next;
 	} while (action);
 
-	if (status & IRQF_SAMPLE_RANDOM)
-		add_interrupt_randomness(irq);
+	add_interrupt_randomness(irq, flags);
 	local_irq_disable();
 
 	return retval;
diff -Naur a/kernel/irq/manage.c b/kernel/irq/manage.c
--- a/kernel/irq/manage.c	2013-11-01 20:18:05.865567548 +0200
+++ b/kernel/irq/manage.c	2013-11-01 18:44:58.329860445 +0200
@@ -633,22 +633,6 @@
 
 	if (desc->chip == &no_irq_chip)
 		return -ENOSYS;
-	/*
-	 * Some drivers like serial.c use request_irq() heavily,
-	 * so we have to be careful not to interfere with a
-	 * running system.
-	 */
-	if (new->flags & IRQF_SAMPLE_RANDOM) {
-		/*
-		 * This function might sleep, we want to call it first,
-		 * outside of the atomic block.
-		 * Yes, this might clear the entropy pool if the wrong
-		 * driver is attempted to be loaded, without actually
-		 * installing a new handler, but is this really a problem,
-		 * only the sysadmin is able to do this.
-		 */
-		rand_initialize_irq(irq);
-	}
 
 	/* Oneshot interrupts are not allowed with shared */
 	if ((new->flags & IRQF_ONESHOT) && (new->flags & IRQF_SHARED))
@@ -1021,7 +1005,6 @@
  *
  *	IRQF_SHARED		Interrupt is shared
  *	IRQF_DISABLED	Disable local interrupts while processing
- *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy
  *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
  */
diff -Naur a/kernel/kmod.c b/kernel/kmod.c
--- a/kernel/kmod.c	2013-11-01 20:18:05.869567560 +0200
+++ b/kernel/kmod.c	2013-11-01 18:44:58.337860494 +0200
@@ -53,6 +53,50 @@
 */
 char modprobe_path[KMOD_PATH_LEN] = "/sbin/modprobe";
 
+static void free_modprobe_argv(char **argv, char **envp)
+{
+	kfree(argv[3]); /* check call_modprobe() */
+	kfree(argv);
+}
+
+static int call_modprobe(char *module_name, int wait)
+{
+	static char *envp[] = { "HOME=/",
+				"TERM=linux",
+				"PATH=/sbin:/usr/sbin:/bin:/usr/bin",
+				NULL };
+	struct subprocess_info *info;
+
+	char **argv = kmalloc(sizeof(char *[5]), GFP_KERNEL);
+	if (!argv)
+		goto out;
+
+	module_name = kstrdup(module_name, GFP_KERNEL);
+	if (!module_name)
+		goto free_argv;
+
+	argv[0] = modprobe_path;
+	argv[1] = "-q";
+	argv[2] = "--";
+	argv[3] = module_name;	/* check free_modprobe_argv() */
+	argv[4] = NULL;
+
+	info = call_usermodehelper_setup(argv[0], argv, envp, GFP_ATOMIC);
+	if (!info)
+		goto free_module_name;
+
+	call_usermodehelper_setcleanup(info, free_modprobe_argv);
+
+	return call_usermodehelper_exec(info, wait | UMH_KILLABLE);
+
+free_module_name:
+	kfree(module_name);
+free_argv:
+	kfree(argv);
+out:
+	return -ENOMEM;
+}
+
 /**
  * __request_module - try to load a kernel module
  * @wait: wait (or not) for the operation to complete
@@ -74,11 +118,6 @@
 	char module_name[MODULE_NAME_LEN];
 	unsigned int max_modprobes;
 	int ret;
-	char *argv[] = { modprobe_path, "-q", "--", module_name, NULL };
-	static char *envp[] = { "HOME=/",
-				"TERM=linux",
-				"PATH=/sbin:/usr/sbin:/bin:/usr/bin",
-				NULL };
 	static atomic_t kmod_concurrent = ATOMIC_INIT(0);
 #define MAX_KMOD_CONCURRENT 50	/* Completely arbitrary value - KAO */
 	static int kmod_loop_msg;
@@ -121,8 +160,8 @@
 
 	trace_module_request(module_name, wait, _RET_IP_);
 
-	ret = call_usermodehelper(modprobe_path, argv, envp,
-			wait ? UMH_WAIT_PROC : UMH_WAIT_EXEC);
+	ret = call_modprobe(module_name, wait ? UMH_WAIT_PROC : UMH_WAIT_EXEC);
+
 	atomic_dec(&kmod_concurrent);
 	return ret;
 }
@@ -193,7 +232,7 @@
 
 	/* Exec failed? */
 	sub_info->retval = retval;
-	do_exit(0);
+	return 0;
 }
 
 void call_usermodehelper_freeinfo(struct subprocess_info *info)
@@ -206,6 +245,19 @@
 }
 EXPORT_SYMBOL(call_usermodehelper_freeinfo);
 
+static void umh_complete(struct subprocess_info *sub_info)
+{
+	struct completion *comp = xchg(&sub_info->complete, NULL);
+	/*
+	 * See call_usermodehelper_exec(). If xchg() returns NULL
+	 * we own sub_info, the UMH_KILLABLE caller has gone away.
+	 */
+	if (comp)
+		complete(comp);
+	else
+		call_usermodehelper_freeinfo(sub_info);
+}
+
 /* Keventd can't block, but this (a child) can. */
 static int wait_for_helper(void *data)
 {
@@ -245,7 +297,7 @@
 	if (sub_info->wait == UMH_NO_WAIT)
 		call_usermodehelper_freeinfo(sub_info);
 	else
-		complete(sub_info->complete);
+		umh_complete(sub_info);
 	return 0;
 }
 
@@ -259,6 +311,9 @@
 
 	BUG_ON(atomic_read(&sub_info->cred->usage) != 1);
 
+	if (wait != UMH_NO_WAIT)
+		wait &= ~UMH_KILLABLE;
+
 	/* CLONE_VFORK: wait until the usermode helper has execve'd
 	 * successfully We need the data structures to stay around
 	 * until that is done.  */
@@ -280,7 +335,7 @@
 		/* FALLTHROUGH */
 
 	case UMH_WAIT_EXEC:
-		complete(sub_info->complete);
+		umh_complete(sub_info);
 	}
 }
 
@@ -520,9 +575,21 @@
 	queue_work(khelper_wq, &sub_info->work);
 	if (wait == UMH_NO_WAIT)	/* task has freed sub_info */
 		goto unlock;
+
+	if (wait & UMH_KILLABLE) {
+		retval = wait_for_completion_killable(&done);
+		if (!retval)
+			goto wait_done;
+
+		/* umh_complete() will see NULL and free sub_info */
+		if (xchg(&sub_info->complete, NULL))
+			goto unlock;
+		/* fallthrough, umh_complete() was already called */
+	}
+
 	wait_for_completion(&done);
+wait_done:
 	retval = sub_info->retval;
-
 out:
 	call_usermodehelper_freeinfo(sub_info);
 unlock:
diff -Naur a/kernel/posix-cpu-timers.c b/kernel/posix-cpu-timers.c
--- a/kernel/posix-cpu-timers.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/posix-cpu-timers.c	2013-11-01 18:44:58.365860627 +0200
@@ -1537,8 +1537,10 @@
 		while (!signal_pending(current)) {
 			if (timer.it.cpu.expires.sched == 0) {
 				/*
-				 * Our timer fired and was reset.
+				 * Our timer fired and was reset, below
+				 * deletion can not fail.
 				 */
+				posix_cpu_timer_del(&timer);
 				spin_unlock_irq(&timer.it_lock);
 				return 0;
 			}
@@ -1556,9 +1558,26 @@
 		 * We were interrupted by a signal.
 		 */
 		sample_to_timespec(which_clock, timer.it.cpu.expires, rqtp);
-		posix_cpu_timer_set(&timer, 0, &zero_it, it);
+		error = posix_cpu_timer_set(&timer, 0, &zero_it, it);
+		if (!error) {
+			/*
+			 * Timer is now unarmed, deletion can not fail.
+			 */
+			posix_cpu_timer_del(&timer);
+		}
 		spin_unlock_irq(&timer.it_lock);
 
+		while (error == TIMER_RETRY) {
+			/*
+			 * We need to handle case when timer was or is in the
+			 * middle of firing. In other cases we already freed
+			 * resources.
+			 */
+			spin_lock_irq(&timer.it_lock);
+			error = posix_cpu_timer_del(&timer);
+			spin_unlock_irq(&timer.it_lock);
+		}
+
 		if ((it->it_value.tv_sec | it->it_value.tv_nsec) == 0) {
 			/*
 			 * It actually did fire already.
diff -Naur a/kernel/ptrace.c b/kernel/ptrace.c
--- a/kernel/ptrace.c	2013-11-01 20:18:05.893567679 +0200
+++ b/kernel/ptrace.c	2013-11-01 18:44:58.377860683 +0200
@@ -56,7 +56,7 @@
 		    child->signal->group_stop_count)
 			__set_task_state(child, TASK_STOPPED);
 		else
-			signal_wake_up(child, 1);
+			ptrace_signal_wake_up(child, true);
 	}
 	spin_unlock(&child->sighand->siglock);
 }
@@ -80,6 +80,40 @@
 		ptrace_untrace(child);
 }
 
+/* Ensure that nothing can wake it up, even SIGKILL */
+static bool ptrace_freeze_traced(struct task_struct *task, int kill)
+{
+	bool ret = true;
+
+	spin_lock_irq(&task->sighand->siglock);
+	if (task_is_stopped(task) && !__fatal_signal_pending(task))
+		task->state = __TASK_TRACED;
+	else if (!kill) {
+		if (task_is_traced(task) && !__fatal_signal_pending(task))
+			task->state = __TASK_TRACED;
+		else
+			ret = false;
+	}
+	spin_unlock_irq(&task->sighand->siglock);
+
+	return ret;
+}
+
+static void ptrace_unfreeze_traced(struct task_struct *task)
+{
+	if (task->state != __TASK_TRACED)
+		return;
+
+	WARN_ON(!task->ptrace || task->parent != current);
+
+	spin_lock_irq(&task->sighand->siglock);
+	if (__fatal_signal_pending(task))
+		wake_up_state(task, __TASK_TRACED);
+	else
+		task->state = TASK_TRACED;
+	spin_unlock_irq(&task->sighand->siglock);
+}
+
 /*
  * Check that we have indeed attached to the thing..
  */
@@ -95,25 +129,29 @@
 	 * be changed by us so it's not changing right after this.
 	 */
 	read_lock(&tasklist_lock);
-	if ((child->ptrace & PT_PTRACED) && child->parent == current) {
-		ret = 0;
+	if (child->ptrace && child->parent == current) {
+		WARN_ON(child->state == __TASK_TRACED);
 		/*
 		 * child->sighand can't be NULL, release_task()
 		 * does ptrace_unlink() before __exit_signal().
 		 */
-		spin_lock_irq(&child->sighand->siglock);
-		if (task_is_stopped(child))
-			child->state = TASK_TRACED;
-		else if (!task_is_traced(child) && !kill)
-			ret = -ESRCH;
-		spin_unlock_irq(&child->sighand->siglock);
+		if (ptrace_freeze_traced(child, kill))
+			ret = 0;
 	}
 	read_unlock(&tasklist_lock);
 
-	if (!ret && !kill)
-		ret = wait_task_inactive(child, TASK_TRACED) ? 0 : -ESRCH;
+	if (!ret && !kill) {
+		if (!wait_task_inactive(child, __TASK_TRACED)) {
+			/*
+			 * This can only happen if may_ptrace_stop() fails and
+			 * ptrace_stop() changes ->state back to TASK_RUNNING,
+			 * so we should not worry about leaking __TASK_TRACED.
+			 */
+			WARN_ON(child->state == __TASK_TRACED);
+			ret = -ESRCH;
+		}
+	}
 
-	/* All systems go.. */
 	return ret;
 }
 
@@ -506,7 +544,7 @@
 	}
 
 	child->exit_code = data;
-	wake_up_process(child);
+	wake_up_state(child, __TASK_TRACED);
 
 	return 0;
 }
@@ -637,6 +675,8 @@
 		goto out_put_task_struct;
 
 	ret = arch_ptrace(child, request, addr, data);
+	if (ret || request != PTRACE_DETACH)
+		ptrace_unfreeze_traced(child);
 
  out_put_task_struct:
 	put_task_struct(child);
@@ -752,8 +792,11 @@
 	}
 
 	ret = ptrace_check_attach(child, request == PTRACE_KILL);
-	if (!ret)
+	if (!ret) {
 		ret = compat_arch_ptrace(child, request, addr, data);
+		if (ret || request != PTRACE_DETACH)
+			ptrace_unfreeze_traced(child);
+	}
 
  out_put_task_struct:
 	put_task_struct(child);
diff -Naur a/kernel/resource.c b/kernel/resource.c
--- a/kernel/resource.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/resource.c	2013-11-01 18:44:58.385860732 +0200
@@ -533,6 +533,7 @@
 	struct resource *parent = root;
 	struct resource *conflict;
 	struct resource *res = kzalloc(sizeof(*res), GFP_ATOMIC);
+	struct resource *next_res = NULL;
 
 	if (!res)
 		return;
@@ -542,21 +543,46 @@
 	res->end = end;
 	res->flags = IORESOURCE_BUSY;
 
-	conflict = __request_resource(parent, res);
-	if (!conflict)
-		return;
-
-	/* failed, split and try again */
-	kfree(res);
+	while (1) {
 
-	/* conflict covered whole area */
-	if (conflict->start <= start && conflict->end >= end)
-		return;
+		conflict = __request_resource(parent, res);
+		if (!conflict) {
+			if (!next_res)
+				break;
+			res = next_res;
+			next_res = NULL;
+			continue;
+		}
+
+		/* conflict covered whole area */
+		if (conflict->start <= res->start &&
+				conflict->end >= res->end) {
+			kfree(res);
+			WARN_ON(next_res);
+			break;
+		}
+
+		/* failed, split and try again */
+		if (conflict->start > res->start) {
+			end = res->end;
+			res->end = conflict->start - 1;
+			if (conflict->end < end) {
+				next_res = kzalloc(sizeof(*next_res),
+						GFP_ATOMIC);
+				if (!next_res) {
+					kfree(res);
+					break;
+				}
+				next_res->name = name;
+				next_res->start = conflict->end + 1;
+				next_res->end = end;
+				next_res->flags = IORESOURCE_BUSY;
+			}
+		} else {
+			res->start = conflict->end + 1;
+		}
+	}
 
-	if (conflict->start > start)
-		__reserve_region_with_split(root, start, conflict->start-1, name);
-	if (conflict->end < end)
-		__reserve_region_with_split(root, conflict->end+1, end, name);
 }
 
 void __init reserve_region_with_split(struct resource *root,
diff -Naur a/kernel/sched.c b/kernel/sched.c
--- a/kernel/sched.c	2013-11-01 20:18:05.913567786 +0200
+++ b/kernel/sched.c	2013-11-01 18:44:58.393860765 +0200
@@ -2618,7 +2618,8 @@
  */
 int wake_up_process(struct task_struct *p)
 {
-	return try_to_wake_up(p, TASK_ALL, 0);
+	WARN_ON(task_is_stopped_or_traced(p));
+	return try_to_wake_up(p, TASK_NORMAL, 0);
 }
 EXPORT_SYMBOL(wake_up_process);
 
diff -Naur a/kernel/sched_fair.c b/kernel/sched_fair.c
--- a/kernel/sched_fair.c	2013-11-01 20:18:05.921567812 +0200
+++ b/kernel/sched_fair.c	2013-11-01 18:44:58.393860765 +0200
@@ -862,6 +862,9 @@
 		struct sched_entity *se = __pick_next_entity(cfs_rq);
 		s64 delta = curr->vruntime - se->vruntime;
 
+		if (delta < 0)
+			return;
+
 		if (delta > ideal_runtime)
 			resched_task(rq_of(cfs_rq)->curr);
 	}
diff -Naur a/kernel/signal.c b/kernel/signal.c
--- a/kernel/signal.c	2013-11-01 20:18:05.925567842 +0200
+++ b/kernel/signal.c	2013-11-01 18:44:58.397860791 +0200
@@ -320,6 +320,9 @@
 		if (force_default || ka->sa.sa_handler != SIG_IGN)
 			ka->sa.sa_handler = SIG_DFL;
 		ka->sa.sa_flags = 0;
+#ifdef __ARCH_HAS_SA_RESTORER
+		ka->sa.sa_restorer = NULL;
+#endif
 		sigemptyset(&ka->sa.sa_mask);
 		ka++;
 	}
@@ -513,23 +516,17 @@
  * No need to set need_resched since signal event passing
  * goes through ->blocked
  */
-void signal_wake_up(struct task_struct *t, int resume)
+void signal_wake_up_state(struct task_struct *t, unsigned int state)
 {
-	unsigned int mask;
-
 	set_tsk_thread_flag(t, TIF_SIGPENDING);
-
 	/*
-	 * For SIGKILL, we want to wake it up in the stopped/traced/killable
+	 * TASK_WAKEKILL also means wake it up in the stopped/traced/killable
 	 * case. We don't check t->state here because there is a race with it
 	 * executing another processor and just now entering stopped state.
 	 * By using wake_up_state, we ensure the process will wake up and
 	 * handle its death signal.
 	 */
-	mask = TASK_INTERRUPTIBLE;
-	if (resume)
-		mask |= TASK_WAKEKILL;
-	if (!wake_up_state(t, mask))
+	if (!wake_up_state(t, state | TASK_INTERRUPTIBLE))
 		kick_process(t);
 }
 
@@ -1530,6 +1527,10 @@
 	 * If SIGKILL was already sent before the caller unlocked
 	 * ->siglock we must see ->core_state != NULL. Otherwise it
 	 * is safe to enter schedule().
+	 *
+	 * This is almost outdated, a task with the pending SIGKILL can't
+	 * block in TASK_TRACED. But PTRACE_EVENT_EXIT can be reported
+	 * after SIGKILL was already dequeued.
 	 */
 	if (unlikely(current->mm->core_state) &&
 	    unlikely(current->mm == current->parent->mm))
@@ -2300,7 +2301,7 @@
 
 static int do_tkill(pid_t tgid, pid_t pid, int sig)
 {
-	struct siginfo info;
+	struct siginfo info = {};
 
 	info.si_signo = sig;
 	info.si_errno = 0;
diff -Naur a/kernel/sys.c b/kernel/sys.c
--- a/kernel/sys.c	2013-11-01 20:18:05.933567878 +0200
+++ b/kernel/sys.c	2013-11-01 18:44:58.405860823 +0200
@@ -303,6 +303,7 @@
 void kernel_restart(char *cmd)
 {
 	kernel_restart_prepare(cmd);
+	disable_nonboot_cpus();
 	if (!cmd)
 		printk(KERN_EMERG "Restarting system.\n");
 	else
diff -Naur a/kernel/softirq.c b/kernel/softirq.c
--- a/kernel/softirq.c	2013-11-01 20:19:19.361931988 +0200
+++ b/kernel/softirq.c	2013-11-01 18:44:58.401860802 +0200
@@ -194,21 +194,21 @@
 EXPORT_SYMBOL(local_bh_enable_ip);
 
 /*
- * We restart softirq processing MAX_SOFTIRQ_RESTART times,
- * and we fall back to softirqd after that.
+ * We restart softirq processing for at most 2 ms,
+ * and if need_resched() is not set.
  *
- * This number has been established via experimentation.
+ * These limits have been established via experimentation.
  * The two things to balance is latency against fairness -
  * we want to handle softirqs as soon as possible, but they
  * should not be able to lock up the box.
  */
-#define MAX_SOFTIRQ_RESTART 10
+#define MAX_SOFTIRQ_TIME  msecs_to_jiffies(2)
 
 asmlinkage void __do_softirq(void)
 {
 	struct softirq_action *h;
 	__u32 pending;
-	int max_restart = MAX_SOFTIRQ_RESTART;
+	unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
 	int cpu;
 
 	pending = local_softirq_pending();
@@ -257,11 +257,12 @@
 	local_irq_disable();
 
 	pending = local_softirq_pending();
-	if (pending && --max_restart)
-		goto restart;
+	if (pending) {
+		if (time_before(jiffies, end) && !need_resched())
+			goto restart;
 
-	if (pending)
 		wakeup_softirqd();
+	}
 
 	lockdep_softirq_exit();
 
diff -Naur a/kernel/time/ntp.c b/kernel/time/ntp.c
--- a/kernel/time/ntp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/time/ntp.c	2013-11-01 18:44:58.409860851 +0200
@@ -28,8 +28,6 @@
 u64				tick_length;
 static u64			tick_length_base;
 
-static struct hrtimer		leap_timer;
-
 #define MAX_TICKADJ		500LL		/* usecs */
 #define MAX_TICKADJ_SCALED \
 	(((MAX_TICKADJ * NSEC_PER_USEC) << NTP_SCALE_SHIFT) / NTP_INTERVAL_FREQ)
@@ -108,7 +106,7 @@
 {
 	time_status &= ~STA_MODE;
 
-	if (secs < MINSEC)
+	if ((s32)secs < MINSEC)
 		return 0;
 
 	if (!(time_status & STA_FLL) && (secs <= MAXSEC))
@@ -180,60 +178,64 @@
 }
 
 /*
- * Leap second processing. If in leap-insert state at the end of the
- * day, the system clock is set back one second; if in leap-delete
- * state, the system clock is set ahead one second.
+ * this routine handles the overflow of the microsecond field
+ *
+ * The tricky bits of code to handle the accurate clock support
+ * were provided by Dave Mills (Mills@UDEL.EDU) of NTP fame.
+ * They were originally developed for SUN and DEC kernels.
+ * All the kudos should go to Dave for this stuff.
+ *
+ * Also handles leap second processing, and returns leap offset
  */
-static enum hrtimer_restart ntp_leap_second(struct hrtimer *timer)
+int second_overflow(unsigned long secs)
 {
-	enum hrtimer_restart res = HRTIMER_NORESTART;
-
-	write_seqlock(&xtime_lock);
+	int leap = 0;
+	s64 delta;
 
+	/*
+	 * Leap second processing. If in leap-insert state at the end of the
+	 * day, the system clock is set back one second; if in leap-delete
+	 * state, the system clock is set ahead one second.
+	 */
 	switch (time_state) {
 	case TIME_OK:
+		if (time_status & STA_INS)
+			time_state = TIME_INS;
+		else if (time_status & STA_DEL)
+			time_state = TIME_DEL;
 		break;
 	case TIME_INS:
-		timekeeping_leap_insert(-1);
-		time_state = TIME_OOP;
-		printk(KERN_NOTICE
-			"Clock: inserting leap second 23:59:60 UTC\n");
-		hrtimer_add_expires_ns(&leap_timer, NSEC_PER_SEC);
-		res = HRTIMER_RESTART;
+		if (!(time_status & STA_INS))
+			time_state = TIME_OK;
+		else if (secs % 86400 == 0) {
+			leap = -1;
+			time_state = TIME_OOP;
+			time_tai++;
+			printk(KERN_NOTICE
+				"Clock: inserting leap second 23:59:60 UTC\n");
+		}
 		break;
 	case TIME_DEL:
-		timekeeping_leap_insert(1);
-		time_tai--;
-		time_state = TIME_WAIT;
-		printk(KERN_NOTICE
-			"Clock: deleting leap second 23:59:59 UTC\n");
+		if (!(time_status & STA_DEL))
+			time_state = TIME_OK;
+		else if ((secs + 1) % 86400 == 0) {
+			leap = 1;
+			time_tai--;
+			time_state = TIME_WAIT;
+			printk(KERN_NOTICE
+				"Clock: deleting leap second 23:59:59 UTC\n");
+		}
 		break;
 	case TIME_OOP:
-		time_tai++;
 		time_state = TIME_WAIT;
-		/* fall through */
+		break;
+
 	case TIME_WAIT:
 		if (!(time_status & (STA_INS | STA_DEL)))
 			time_state = TIME_OK;
 		break;
 	}
 
-	write_sequnlock(&xtime_lock);
-
-	return res;
-}
-
-/*
- * this routine handles the overflow of the microsecond field
- *
- * The tricky bits of code to handle the accurate clock support
- * were provided by Dave Mills (Mills@UDEL.EDU) of NTP fame.
- * They were originally developed for SUN and DEC kernels.
- * All the kudos should go to Dave for this stuff.
- */
-void second_overflow(void)
-{
-	s64 delta;
 
 	/* Bump the maxerror field */
 	time_maxerror += MAXFREQ / NSEC_PER_USEC;
@@ -253,23 +255,25 @@
 	tick_length	+= delta;
 
 	if (!time_adjust)
-		return;
+		goto out;
 
 	if (time_adjust > MAX_TICKADJ) {
 		time_adjust -= MAX_TICKADJ;
 		tick_length += MAX_TICKADJ_SCALED;
-		return;
+		goto out;
 	}
 
 	if (time_adjust < -MAX_TICKADJ) {
 		time_adjust += MAX_TICKADJ;
 		tick_length -= MAX_TICKADJ_SCALED;
-		return;
+		goto out;
 	}
 
 	tick_length += (s64)(time_adjust * NSEC_PER_USEC / NTP_INTERVAL_FREQ)
 							 << NTP_SCALE_SHIFT;
 	time_adjust = 0;
+out:
+	return leap;
 }
 
 #ifdef CONFIG_GENERIC_CMOS_UPDATE
@@ -331,27 +335,6 @@
 static inline void notify_cmos_timer(void) { }
 #endif
 
-/*
- * Start the leap seconds timer:
- */
-static inline void ntp_start_leap_timer(struct timespec *ts)
-{
-	long now = ts->tv_sec;
-
-	if (time_status & STA_INS) {
-		time_state = TIME_INS;
-		now += 86400 - now % 86400;
-		hrtimer_start(&leap_timer, ktime_set(now, 0), HRTIMER_MODE_ABS);
-
-		return;
-	}
-
-	if (time_status & STA_DEL) {
-		time_state = TIME_DEL;
-		now += 86400 - (now + 1) % 86400;
-		hrtimer_start(&leap_timer, ktime_set(now, 0), HRTIMER_MODE_ABS);
-	}
-}
 
 /*
  * Propagate a new txc->status value into the NTP state:
@@ -374,22 +357,6 @@
 	time_status &= STA_RONLY;
 	time_status |= txc->status & ~STA_RONLY;
 
-	switch (time_state) {
-	case TIME_OK:
-		ntp_start_leap_timer(ts);
-		break;
-	case TIME_INS:
-	case TIME_DEL:
-		time_state = TIME_OK;
-		ntp_start_leap_timer(ts);
-	case TIME_WAIT:
-		if (!(time_status & (STA_INS | STA_DEL)))
-			time_state = TIME_OK;
-		break;
-	case TIME_OOP:
-		hrtimer_restart(&leap_timer);
-		break;
-	}
 }
 /*
  * Called with the xtime lock held, so we can access and modify
@@ -469,9 +436,6 @@
 		    (txc->tick <  900000/USER_HZ ||
 		     txc->tick > 1100000/USER_HZ))
 			return -EINVAL;
-
-		if (txc->modes & ADJ_STATUS && time_state != TIME_OK)
-			hrtimer_cancel(&leap_timer);
 	}
 
 	getnstimeofday(&ts);
@@ -549,6 +513,4 @@
 void __init ntp_init(void)
 {
 	ntp_clear();
-	hrtimer_init(&leap_timer, CLOCK_REALTIME, HRTIMER_MODE_ABS);
-	leap_timer.function = ntp_leap_second;
 }
diff -Naur a/kernel/time/tick-broadcast.c b/kernel/time/tick-broadcast.c
--- a/kernel/time/tick-broadcast.c	2013-11-01 20:18:05.941567927 +0200
+++ b/kernel/time/tick-broadcast.c	2013-11-01 18:44:58.409860851 +0200
@@ -67,7 +67,8 @@
  */
 int tick_check_broadcast_device(struct clock_event_device *dev)
 {
-	if ((tick_broadcast_device.evtdev &&
+	if ((dev->features & CLOCK_EVT_FEAT_DUMMY) ||
+	    (tick_broadcast_device.evtdev &&
 	     tick_broadcast_device.evtdev->rating >= dev->rating) ||
 	     (dev->features & CLOCK_EVT_FEAT_C3STOP))
 		return 0;
diff -Naur a/kernel/time/tick-sched.c b/kernel/time/tick-sched.c
--- a/kernel/time/tick-sched.c	2013-11-01 20:18:05.949567955 +0200
+++ b/kernel/time/tick-sched.c	2013-11-01 18:44:58.413860865 +0200
@@ -765,7 +765,7 @@
 		hrtimer_cancel(&ts->sched_timer);
 # endif
 
-	ts->nohz_mode = NOHZ_MODE_INACTIVE;
+	memset(ts, 0, sizeof(*ts));
 }
 #endif
 
diff -Naur a/kernel/time/timekeeping.c b/kernel/time/timekeeping.c
--- a/kernel/time/timekeeping.c	2013-11-01 20:18:05.949567955 +0200
+++ b/kernel/time/timekeeping.c	2013-11-01 18:44:58.413860865 +0200
@@ -161,11 +161,39 @@
 struct timespec wall_to_monotonic __attribute__ ((aligned (16)));
 static struct timespec total_sleep_time;
 
+/* Offset clock monotonic -> clock realtime */
+static ktime_t offs_real;
+
+/* Offset clock monotonic -> clock boottime */
+static ktime_t offs_boot;
+
 /*
  * The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock.
  */
 struct timespec raw_time;
 
+/* must hold write on xtime_lock */
+static void update_rt_offset(void)
+{
+	struct timespec tmp, *wtm = &wall_to_monotonic;
+
+	set_normalized_timespec(&tmp, -wtm->tv_sec, -wtm->tv_nsec);
+	offs_real = timespec_to_ktime(tmp);
+}
+
+/* must hold write on xtime_lock */
+static void timekeeping_update(bool clearntp)
+{
+	if (clearntp) {
+		timekeeper.ntp_error = 0;
+		ntp_clear();
+	}
+	update_rt_offset();
+	update_vsyscall(&xtime, timekeeper.clock, timekeeper.mult);
+}
+
+
+
 /* flag for if timekeeping is suspended */
 int __read_mostly timekeeping_suspended;
 
@@ -183,14 +211,6 @@
 	ACCESS_ONCE(xtime_cache) = ts;
 }
 
-/* must hold xtime_lock */
-void timekeeping_leap_insert(int leapsecond)
-{
-	xtime.tv_sec += leapsecond;
-	wall_to_monotonic.tv_sec -= leapsecond;
-	update_vsyscall(&xtime, timekeeper.clock, timekeeper.mult);
-}
-
 #ifdef CONFIG_GENERIC_TIME
 
 /**
@@ -334,7 +354,7 @@
 	struct timespec ts_delta;
 	unsigned long flags;
 
-	if ((unsigned long)tv->tv_nsec >= NSEC_PER_SEC)
+	if (!timespec_valid_strict(tv))
 		return -EINVAL;
 
 	write_seqlock_irqsave(&xtime_lock, flags);
@@ -349,10 +369,7 @@
 
 	update_xtime_cache(0);
 
-	timekeeper.ntp_error = 0;
-	ntp_clear();
-
-	update_vsyscall(&xtime, timekeeper.clock, timekeeper.mult);
+	timekeeping_update(true);
 
 	write_sequnlock_irqrestore(&xtime_lock, flags);
 
@@ -553,7 +570,20 @@
 	struct timespec now, boot;
 
 	read_persistent_clock(&now);
+	if (!timespec_valid_strict(&now)) {
+		printk("WARNING: Persistent clock returned invalid value!\n"
+			"         Check your CMOS/BIOS settings.\n");
+		now.tv_sec = 0;
+		now.tv_nsec = 0;
+	}
+
 	read_boot_clock(&boot);
+	if (!timespec_valid_strict(&boot)) {
+		printk("WARNING: Boot clock returned invalid value!\n"
+			"         Check your CMOS/BIOS settings.\n");
+		boot.tv_sec = 0;
+		boot.tv_nsec = 0;
+	}
 
 	write_seqlock_irqsave(&xtime_lock, flags);
 
@@ -575,6 +605,7 @@
 	set_normalized_timespec(&wall_to_monotonic,
 				-boot.tv_sec, -boot.tv_nsec);
 	update_xtime_cache(0);
+	update_rt_offset();
 	total_sleep_time.tv_sec = 0;
 	total_sleep_time.tv_nsec = 0;
 	write_sequnlock_irqrestore(&xtime_lock, flags);
@@ -583,6 +614,12 @@
 /* time in seconds when suspend began */
 static struct timespec timekeeping_suspend_time;
 
+static void update_sleep_time(struct timespec t)
+{
+	total_sleep_time = t;
+	offs_boot = timespec_to_ktime(t);
+}
+
 /**
  * timekeeping_resume - Resumes the generic timekeeping subsystem.
  * @dev:	unused
@@ -606,13 +643,14 @@
 		ts = timespec_sub(ts, timekeeping_suspend_time);
 		xtime = timespec_add_safe(xtime, ts);
 		wall_to_monotonic = timespec_sub(wall_to_monotonic, ts);
-		total_sleep_time = timespec_add_safe(total_sleep_time, ts);
+		update_sleep_time(timespec_add_safe(total_sleep_time, ts));
 	}
 	update_xtime_cache(0);
 	/* re-base the last cycle value */
 	timekeeper.clock->cycle_last = timekeeper.clock->read(timekeeper.clock);
 	timekeeper.ntp_error = 0;
 	timekeeping_suspended = 0;
+	timekeeping_update(false);
 	write_sequnlock_irqrestore(&xtime_lock, flags);
 
 	touch_softlockup_watchdog();
@@ -769,6 +807,10 @@
 #else
 	offset = timekeeper.cycle_interval;
 #endif
+	/* Check if there's really nothing to do */
+	if (offset < timekeeper.cycle_interval)
+		goto out;
+
 	timekeeper.xtime_nsec = (s64)xtime.tv_nsec << timekeeper.shift;
 
 	/* normally this loop will run just once, however in the
@@ -783,9 +825,14 @@
 
 		timekeeper.xtime_nsec += timekeeper.xtime_interval;
 		if (timekeeper.xtime_nsec >= nsecps) {
+			int leap;
 			timekeeper.xtime_nsec -= nsecps;
 			xtime.tv_sec++;
-			second_overflow();
+			leap = second_overflow(xtime.tv_sec);
+			xtime.tv_sec += leap;
+			wall_to_monotonic.tv_sec -= leap;
+			if (leap)
+				clock_was_set_delayed();
 		}
 
 		raw_time.tv_nsec += timekeeper.raw_interval;
@@ -834,11 +881,11 @@
 	timekeeper.ntp_error +=	timekeeper.xtime_nsec <<
 				timekeeper.ntp_error_shift;
 
+out:
 	nsecs = clocksource_cyc2ns(offset, timekeeper.mult, timekeeper.shift);
 	update_xtime_cache(nsecs);
 
-	/* check to see if there is a new clocksource to use */
-	update_vsyscall(&xtime, timekeeper.clock, timekeeper.mult);
+	timekeeping_update(false);
 }
 
 /**
@@ -915,3 +962,35 @@
 				now.tv_nsec + mono.tv_nsec);
 	return now;
 }
+
+#ifdef CONFIG_HIGH_RES_TIMERS
+/**
+ * ktime_get_update_offsets - hrtimer helper
+ * @real:	pointer to storage for monotonic -> realtime offset
+ *
+ * Returns current monotonic time and updates the offsets
+ * Called from hrtimer_interupt() or retrigger_next_event()
+ */
+ktime_t ktime_get_update_offsets(ktime_t *real)
+{
+	ktime_t now;
+	unsigned int seq;
+	u64 secs, nsecs;
+
+	do {
+		seq = read_seqbegin(&xtime_lock);
+
+		secs = xtime.tv_sec;
+		nsecs = xtime.tv_nsec;
+		nsecs += timekeeping_get_ns();
+		/* If arch requires, add in gettimeoffset() */
+		nsecs += arch_gettimeoffset();
+
+		*real = offs_real;
+	} while (read_seqretry(&xtime_lock, seq));
+
+	now = ktime_add_ns(ktime_set(secs, 0), nsecs);
+	now = ktime_sub(now, *real);
+	return now;
+}
+#endif
diff -Naur a/kernel/timer.c b/kernel/timer.c
--- a/kernel/timer.c	2013-11-01 20:19:19.365932016 +0200
+++ b/kernel/timer.c	2013-11-01 18:44:58.417860884 +0200
@@ -1553,12 +1553,12 @@
 			boot_done = 1;
 			base = &boot_tvec_bases;
 		}
+		spin_lock_init(&base->lock);
 		tvec_base_done[cpu] = 1;
 	} else {
 		base = per_cpu(tvec_bases, cpu);
 	}
 
-	spin_lock_init(&base->lock);
 
 	for (j = 0; j < TVN_SIZE; j++) {
 		INIT_LIST_HEAD(base->tv5.vec + j);
diff -Naur a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c
--- a/kernel/trace/ftrace.c	2013-11-01 20:18:05.957568004 +0200
+++ b/kernel/trace/ftrace.c	2013-11-01 18:44:58.417860884 +0200
@@ -469,7 +469,6 @@
 		free_page(tmp);
 	}
 
-	free_page((unsigned long)stat->pages);
 	stat->pages = NULL;
 	stat->start = NULL;
 
diff -Naur a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c
--- a/kernel/trace/ring_buffer.c	2013-11-01 20:18:05.957568004 +0200
+++ b/kernel/trace/ring_buffer.c	2013-11-01 18:44:58.421860910 +0200
@@ -2876,6 +2876,8 @@
 	 * Splice the empty reader page into the list around the head.
 	 */
 	reader = rb_set_head_page(cpu_buffer);
+	if (!reader)
+		goto out;
 	cpu_buffer->reader_page->list.next = reader->list.next;
 	cpu_buffer->reader_page->list.prev = reader->list.prev;
 
diff -Naur a/kernel/workqueue.c b/kernel/workqueue.c
--- a/kernel/workqueue.c	2009-12-03 05:51:21.000000000 +0200
+++ b/kernel/workqueue.c	2013-11-01 18:44:58.437860984 +0200
@@ -772,6 +772,7 @@
 	return ret;
 
 }
+EXPORT_SYMBOL_GPL(current_is_keventd);
 
 static struct cpu_workqueue_struct *
 init_cpu_workqueue(struct workqueue_struct *wq, int cpu)
diff -Naur a/lib/genalloc.c b/lib/genalloc.c
--- a/lib/genalloc.c	2009-12-03 05:51:21.000000000 +0200
+++ b/lib/genalloc.c	2013-11-01 18:44:58.449861040 +0200
@@ -52,7 +52,7 @@
 	struct gen_pool_chunk *chunk;
 	int nbits = size >> pool->min_alloc_order;
 	int nbytes = sizeof(struct gen_pool_chunk) +
-				(nbits + BITS_PER_BYTE - 1) / BITS_PER_BYTE;
+				BITS_TO_LONGS(nbits) * sizeof(long);
 
 	chunk = kmalloc_node(nbytes, GFP_KERNEL | __GFP_ZERO, nid);
 	if (unlikely(chunk == NULL))
diff -Naur a/localversion-stm b/localversion-stm
--- a/localversion-stm	2013-11-01 20:19:19.373932049 +0200
+++ b/localversion-stm	2013-11-01 18:44:58.477861180 +0200
@@ -1 +1 @@
-_stm24_0211
+_stm24_0212-rc1
diff -Naur a/MAINTAINERS b/MAINTAINERS
--- a/MAINTAINERS	2013-11-01 20:18:03.177554212 +0200
+++ b/MAINTAINERS	2013-11-01 18:44:42.381781367 +0200
@@ -4379,7 +4379,7 @@
 F:	drivers/block/brd.c
 
 RANDOM NUMBER DRIVER
-M:	Matt Mackall <mpm@selenic.com>
+M:	Theodore Ts'o" <tytso@mit.edu>
 S:	Maintained
 F:	drivers/char/random.c
 
diff -Naur a/mm/hugetlb.c b/mm/hugetlb.c
--- a/mm/hugetlb.c	2013-11-01 20:18:05.981568113 +0200
+++ b/mm/hugetlb.c	2013-11-01 18:44:58.485861222 +0200
@@ -49,6 +49,84 @@
  */
 static DEFINE_SPINLOCK(hugetlb_lock);
 
+static inline void unlock_or_release_subpool(struct hugepage_subpool *spool)
+{
+	bool free = (spool->count == 0) && (spool->used_hpages == 0);
+
+	spin_unlock(&spool->lock);
+
+	/* If no pages are used, and no other handles to the subpool
+	 * remain, free the subpool the subpool remain */
+	if (free)
+		kfree(spool);
+}
+
+struct hugepage_subpool *hugepage_new_subpool(long nr_blocks)
+{
+	struct hugepage_subpool *spool;
+
+	spool = kmalloc(sizeof(*spool), GFP_KERNEL);
+	if (!spool)
+		return NULL;
+
+	spin_lock_init(&spool->lock);
+	spool->count = 1;
+	spool->max_hpages = nr_blocks;
+	spool->used_hpages = 0;
+
+	return spool;
+}
+
+void hugepage_put_subpool(struct hugepage_subpool *spool)
+{
+	spin_lock(&spool->lock);
+	BUG_ON(!spool->count);
+	spool->count--;
+	unlock_or_release_subpool(spool);
+}
+
+static int hugepage_subpool_get_pages(struct hugepage_subpool *spool,
+				      long delta)
+{
+	int ret = 0;
+
+	if (!spool)
+		return 0;
+
+	spin_lock(&spool->lock);
+	if ((spool->used_hpages + delta) <= spool->max_hpages) {
+		spool->used_hpages += delta;
+	} else {
+		ret = -ENOMEM;
+	}
+	spin_unlock(&spool->lock);
+
+	return ret;
+}
+
+static void hugepage_subpool_put_pages(struct hugepage_subpool *spool,
+				       long delta)
+{
+	if (!spool)
+		return;
+
+	spin_lock(&spool->lock);
+	spool->used_hpages -= delta;
+	/* If hugetlbfs_put_super couldn't free spool due to
+	* an outstanding quota reference, free it now. */
+	unlock_or_release_subpool(spool);
+}
+
+static inline struct hugepage_subpool *subpool_inode(struct inode *inode)
+{
+	return HUGETLBFS_SB(inode->i_sb)->spool;
+}
+
+static inline struct hugepage_subpool *subpool_vma(struct vm_area_struct *vma)
+{
+	return subpool_inode(vma->vm_file->f_dentry->d_inode);
+}
+
 /*
  * Region tracking -- allows tracking of reservations and instantiated pages
  *                    across the pages in a mapping.
@@ -541,9 +619,9 @@
 	 */
 	struct hstate *h = page_hstate(page);
 	int nid = page_to_nid(page);
-	struct address_space *mapping;
+	struct hugepage_subpool *spool =
+		(struct hugepage_subpool *)page_private(page);
 
-	mapping = (struct address_space *) page_private(page);
 	set_page_private(page, 0);
 	page->mapping = NULL;
 	BUG_ON(page_count(page));
@@ -558,8 +636,7 @@
 		enqueue_huge_page(h, page);
 	}
 	spin_unlock(&hugetlb_lock);
-	if (mapping)
-		hugetlb_put_quota(mapping, 1);
+	hugepage_subpool_put_pages(spool, 1);
 }
 
 static void prep_new_huge_page(struct hstate *h, struct page *page, int nid)
@@ -927,11 +1004,12 @@
 /*
  * Determine if the huge page at addr within the vma has an associated
  * reservation.  Where it does not we will need to logically increase
- * reservation and actually increase quota before an allocation can occur.
- * Where any new reservation would be required the reservation change is
- * prepared, but not committed.  Once the page has been quota'd allocated
- * an instantiated the change should be committed via vma_commit_reservation.
- * No action is required on failure.
+ * reservation and actually increase subpool usage before an allocation
+ * can occur.  Where any new reservation would be required the
+ * reservation change is prepared, but not committed.  Once the page
+ * has been allocated from the subpool and instantiated the change should
+ * be committed via vma_commit_reservation.  No action is required on
+ * failure.
  */
 static long vma_needs_reservation(struct hstate *h,
 			struct vm_area_struct *vma, unsigned long addr)
@@ -980,24 +1058,24 @@
 static struct page *alloc_huge_page(struct vm_area_struct *vma,
 				    unsigned long addr, int avoid_reserve)
 {
+	struct hugepage_subpool *spool = subpool_vma(vma);
 	struct hstate *h = hstate_vma(vma);
 	struct page *page;
-	struct address_space *mapping = vma->vm_file->f_mapping;
-	struct inode *inode = mapping->host;
 	long chg;
 
 	/*
-	 * Processes that did not create the mapping will have no reserves and
-	 * will not have accounted against quota. Check that the quota can be
-	 * made before satisfying the allocation
-	 * MAP_NORESERVE mappings may also need pages and quota allocated
-	 * if no reserve mapping overlaps.
+	 * Processes that did not create the mapping will have no
+	 * reserves and will not have accounted against subpool
+	 * limit. Check that the subpool limit can be made before
+	 * satisfying the allocation MAP_NORESERVE mappings may also
+	 * need pages and subpool limit allocated allocated if no reserve
+	 * mapping overlaps.
 	 */
 	chg = vma_needs_reservation(h, vma, addr);
 	if (chg < 0)
 		return ERR_PTR(-VM_FAULT_OOM);
 	if (chg)
-		if (hugetlb_get_quota(inode->i_mapping, chg))
+		if (hugepage_subpool_get_pages(spool, chg))
 			return ERR_PTR(-VM_FAULT_SIGBUS);
 
 	spin_lock(&hugetlb_lock);
@@ -1007,13 +1085,13 @@
 	if (!page) {
 		page = alloc_buddy_huge_page(h, vma, addr);
 		if (!page) {
-			hugetlb_put_quota(inode->i_mapping, chg);
+			hugepage_subpool_put_pages(spool, chg);
 			return ERR_PTR(-VM_FAULT_SIGBUS);
 		}
 	}
 
 	set_page_refcounted(page);
-	set_page_private(page, (unsigned long) mapping);
+	set_page_private(page, (unsigned long)spool);
 
 	vma_commit_reservation(h, vma, addr);
 
@@ -1694,10 +1772,20 @@
 		kref_get(&reservations->refs);
 }
 
+static void resv_map_put(struct vm_area_struct *vma)
+{
+	struct resv_map *reservations = vma_resv_map(vma);
+
+	if (!reservations)
+		return;
+	kref_put(&reservations->refs, resv_map_release);
+}
+
 static void hugetlb_vm_op_close(struct vm_area_struct *vma)
 {
 	struct hstate *h = hstate_vma(vma);
 	struct resv_map *reservations = vma_resv_map(vma);
+	struct hugepage_subpool *spool = subpool_vma(vma);
 	unsigned long reserve;
 	unsigned long start;
 	unsigned long end;
@@ -1709,11 +1797,11 @@
 		reserve = (end - start) -
 			region_count(&reservations->regions, start, end);
 
-		kref_put(&reservations->refs, resv_map_release);
+		resv_map_put(vma);
 
 		if (reserve) {
 			hugetlb_acct_memory(h, -reserve);
-			hugetlb_put_quota(vma->vm_file->f_mapping, reserve);
+			hugepage_subpool_put_pages(spool, reserve);
 		}
 	}
 }
@@ -1910,7 +1998,7 @@
 	address = address & huge_page_mask(h);
 	pgoff = ((address - vma->vm_start) >> PAGE_SHIFT)
 		+ (vma->vm_pgoff >> PAGE_SHIFT);
-	mapping = (struct address_space *)page_private(page);
+	mapping = vma->vm_file->f_dentry->d_inode->i_mapping;
 
 	vma_prio_tree_foreach(iter_vma, &iter, &mapping->i_mmap, pgoff, pgoff) {
 		/* Do not unmap the current VMA */
@@ -2364,11 +2452,12 @@
 {
 	long ret, chg;
 	struct hstate *h = hstate_inode(inode);
+	struct hugepage_subpool *spool = subpool_inode(inode);
 
 	/*
 	 * Only apply hugepage reservation if asked. At fault time, an
 	 * attempt will be made for VM_NORESERVE to allocate a page
-	 * and filesystem quota without using reserves
+	 * without using reserves
 	 */
 	if (acctflag & VM_NORESERVE)
 		return 0;
@@ -2392,21 +2481,25 @@
 		set_vma_resv_flags(vma, HPAGE_RESV_OWNER);
 	}
 
-	if (chg < 0)
-		return chg;
+	if (chg < 0) {
+		ret = chg;
+		goto out_err;
+	}
 
-	/* There must be enough filesystem quota for the mapping */
-	if (hugetlb_get_quota(inode->i_mapping, chg))
-		return -ENOSPC;
+	/* There must be enough pages in the subpool for the mapping */
+	if (hugepage_subpool_get_pages(spool, chg)) {
+		ret = -ENOSPC;
+		goto out_err;
+	}
 
 	/*
 	 * Check enough hugepages are available for the reservation.
-	 * Hand back the quota if there are not
+	 * Hand the pages back to the subpool if there are not
 	 */
 	ret = hugetlb_acct_memory(h, chg);
 	if (ret < 0) {
-		hugetlb_put_quota(inode->i_mapping, chg);
-		return ret;
+		hugepage_subpool_put_pages(spool, chg);
+		goto out_err;
 	}
 
 	/*
@@ -2423,17 +2516,22 @@
 	if (!vma || vma->vm_flags & VM_MAYSHARE)
 		region_add(&inode->i_mapping->private_list, from, to);
 	return 0;
+out_err:
+	if (vma)
+		resv_map_put(vma);
+	return ret;
 }
 
 void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)
 {
 	struct hstate *h = hstate_inode(inode);
 	long chg = region_truncate(&inode->i_mapping->private_list, offset);
+	struct hugepage_subpool *spool = subpool_inode(inode);
 
 	spin_lock(&inode->i_lock);
 	inode->i_blocks -= (blocks_per_huge_page(h) * freed);
 	spin_unlock(&inode->i_lock);
 
-	hugetlb_put_quota(inode->i_mapping, (chg - freed));
+	hugepage_subpool_put_pages(spool, (chg - freed));
 	hugetlb_acct_memory(h, -(chg - freed));
 }
diff -Naur a/mm/madvise.c b/mm/madvise.c
--- a/mm/madvise.c	2009-12-03 05:51:21.000000000 +0200
+++ b/mm/madvise.c	2013-11-01 18:44:58.489861241 +0200
@@ -12,6 +12,7 @@
 #include <linux/hugetlb.h>
 #include <linux/sched.h>
 #include <linux/ksm.h>
+#include <linux/file.h>
 
 /*
  * Any behaviour which results in changes to the vma->vm_flags needs to
@@ -190,14 +191,16 @@
 	struct address_space *mapping;
 	loff_t offset, endoff;
 	int error;
+	struct file *f;
 
 	*prev = NULL;	/* tell sys_madvise we drop mmap_sem */
 
 	if (vma->vm_flags & (VM_LOCKED|VM_NONLINEAR|VM_HUGETLB))
 		return -EINVAL;
 
-	if (!vma->vm_file || !vma->vm_file->f_mapping
-		|| !vma->vm_file->f_mapping->host) {
+	f = vma->vm_file;
+
+	if (!f || !f->f_mapping || !f->f_mapping->host) {
 			return -EINVAL;
 	}
 
@@ -211,9 +214,16 @@
 	endoff = (loff_t)(end - vma->vm_start - 1)
 			+ ((loff_t)vma->vm_pgoff << PAGE_SHIFT);
 
-	/* vmtruncate_range needs to take i_mutex and i_alloc_sem */
+	/*
+	 * vmtruncate_range may need to take i_mutex and i_alloc_sem.
+	 * We need to explicitly grab a reference because the vma (and
+	 * hence the vma's reference to the file) can go away as soon as
+	 * we drop mmap_sem.
+	 */
+	get_file(f);
 	up_read(&current->mm->mmap_sem);
 	error = vmtruncate_range(mapping->host, offset, endoff);
+	fput(f);
 	down_read(&current->mm->mmap_sem);
 	return error;
 }
diff -Naur a/mm/mempolicy.c b/mm/mempolicy.c
--- a/mm/mempolicy.c	2013-11-01 20:18:05.993568178 +0200
+++ b/mm/mempolicy.c	2013-11-01 18:44:58.497861278 +0200
@@ -1759,7 +1759,7 @@
  */
 
 /* lookup first element intersecting start-end */
-/* Caller holds sp->lock */
+/* Caller holds sp->mutex */
 static struct sp_node *
 sp_lookup(struct shared_policy *sp, unsigned long start, unsigned long end)
 {
@@ -1823,13 +1823,13 @@
 
 	if (!sp->root.rb_node)
 		return NULL;
-	spin_lock(&sp->lock);
+	mutex_lock(&sp->mutex);
 	sn = sp_lookup(sp, idx, idx+1);
 	if (sn) {
 		mpol_get(sn->policy);
 		pol = sn->policy;
 	}
-	spin_unlock(&sp->lock);
+	mutex_unlock(&sp->mutex);
 	return pol;
 }
 
@@ -1860,10 +1860,10 @@
 static int shared_policy_replace(struct shared_policy *sp, unsigned long start,
 				 unsigned long end, struct sp_node *new)
 {
-	struct sp_node *n, *new2 = NULL;
+	struct sp_node *n;
+	int ret = 0;
 
-restart:
-	spin_lock(&sp->lock);
+	mutex_lock(&sp->mutex);
 	n = sp_lookup(sp, start, end);
 	/* Take care of old policies in the same range. */
 	while (n && n->start < end) {
@@ -1876,16 +1876,14 @@
 		} else {
 			/* Old policy spanning whole new range. */
 			if (n->end > end) {
+				struct sp_node *new2;
+				new2 = sp_alloc(end, n->end, n->policy);
 				if (!new2) {
-					spin_unlock(&sp->lock);
-					new2 = sp_alloc(end, n->end, n->policy);
-					if (!new2)
-						return -ENOMEM;
-					goto restart;
+					ret = -ENOMEM;
+					goto out;
 				}
 				n->end = start;
 				sp_insert(sp, new2);
-				new2 = NULL;
 				break;
 			} else
 				n->end = start;
@@ -1896,12 +1894,9 @@
 	}
 	if (new)
 		sp_insert(sp, new);
-	spin_unlock(&sp->lock);
-	if (new2) {
-		mpol_put(new2->policy);
-		kmem_cache_free(sn_cache, new2);
-	}
-	return 0;
+out:
+	mutex_unlock(&sp->mutex);
+	return ret;
 }
 
 /**
@@ -1919,7 +1914,7 @@
 	int ret;
 
 	sp->root = RB_ROOT;		/* empty tree == default mempolicy */
-	spin_lock_init(&sp->lock);
+	mutex_init(&sp->mutex);
 
 	if (mpol) {
 		struct vm_area_struct pvma;
@@ -1987,7 +1982,7 @@
 
 	if (!p->root.rb_node)
 		return;
-	spin_lock(&p->lock);
+	mutex_lock(&p->mutex);
 	next = rb_first(&p->root);
 	while (next) {
 		n = rb_entry(next, struct sp_node, nd);
@@ -1996,7 +1991,7 @@
 		mpol_put(n->policy);
 		kmem_cache_free(sn_cache, n);
 	}
-	spin_unlock(&p->lock);
+	mutex_unlock(&p->mutex);
 }
 
 /* assumes fs == KERNEL_DS */
@@ -2259,7 +2254,7 @@
 		break;
 
 	default:
-		BUG();
+		return -EINVAL;
 	}
 
 	l = strlen(policy_types[mode]);
diff -Naur a/mm/mmu_notifier.c b/mm/mmu_notifier.c
--- a/mm/mmu_notifier.c	2009-12-03 05:51:21.000000000 +0200
+++ b/mm/mmu_notifier.c	2013-11-01 18:44:58.501861299 +0200
@@ -32,6 +32,24 @@
 void __mmu_notifier_release(struct mm_struct *mm)
 {
 	struct mmu_notifier *mn;
+	struct hlist_node *n;
+
+	/*
+	 * RCU here will block mmu_notifier_unregister until
+	 * ->release returns.
+	 */
+	rcu_read_lock();
+	hlist_for_each_entry_rcu(mn, n, &mm->mmu_notifier_mm->list, hlist)
+		/*
+		 * if ->release runs before mmu_notifier_unregister it
+		 * must be handled as it's the only way for the driver
+		 * to flush all existing sptes and stop the driver
+		 * from establishing any more sptes before all the
+		 * pages in the mm are freed.
+		 */
+		if (mn->ops->release)
+			mn->ops->release(mn, mm);
+	rcu_read_unlock();
 
 	spin_lock(&mm->mmu_notifier_mm->lock);
 	while (unlikely(!hlist_empty(&mm->mmu_notifier_mm->list))) {
@@ -45,23 +63,6 @@
 		 * mmu_notifier_unregister to return.
 		 */
 		hlist_del_init_rcu(&mn->hlist);
-		/*
-		 * RCU here will block mmu_notifier_unregister until
-		 * ->release returns.
-		 */
-		rcu_read_lock();
-		spin_unlock(&mm->mmu_notifier_mm->lock);
-		/*
-		 * if ->release runs before mmu_notifier_unregister it
-		 * must be handled as it's the only way for the driver
-		 * to flush all existing sptes and stop the driver
-		 * from establishing any more sptes before all the
-		 * pages in the mm are freed.
-		 */
-		if (mn->ops->release)
-			mn->ops->release(mn, mm);
-		rcu_read_unlock();
-		spin_lock(&mm->mmu_notifier_mm->lock);
 	}
 	spin_unlock(&mm->mmu_notifier_mm->lock);
 
@@ -263,16 +264,13 @@
 {
 	BUG_ON(atomic_read(&mm->mm_count) <= 0);
 
-	spin_lock(&mm->mmu_notifier_mm->lock);
 	if (!hlist_unhashed(&mn->hlist)) {
-		hlist_del_rcu(&mn->hlist);
-
 		/*
 		 * RCU here will force exit_mmap to wait ->release to finish
 		 * before freeing the pages.
 		 */
 		rcu_read_lock();
-		spin_unlock(&mm->mmu_notifier_mm->lock);
+
 		/*
 		 * exit_mmap will block in mmu_notifier_release to
 		 * guarantee ->release is called before freeing the
@@ -281,8 +279,11 @@
 		if (mn->ops->release)
 			mn->ops->release(mn, mm);
 		rcu_read_unlock();
-	} else
+
+		spin_lock(&mm->mmu_notifier_mm->lock);
+		hlist_del_rcu(&mn->hlist);
 		spin_unlock(&mm->mmu_notifier_mm->lock);
+	}
 
 	/*
 	 * Wait any running method to finish, of course including
diff -Naur a/mm/shmem.c b/mm/shmem.c
--- a/mm/shmem.c	2013-11-01 20:18:06.017568294 +0200
+++ b/mm/shmem.c	2013-11-01 18:44:58.517861386 +0200
@@ -2242,6 +2242,7 @@
 	unsigned long inodes;
 	int error = -EINVAL;
 
+	config.mpol = NULL;
 	if (shmem_parse_options(data, &config, true))
 		return error;
 
@@ -2269,8 +2270,13 @@
 	sbinfo->max_inodes  = config.max_inodes;
 	sbinfo->free_inodes = config.max_inodes - inodes;
 
-	mpol_put(sbinfo->mpol);
-	sbinfo->mpol        = config.mpol;	/* transfers initial ref */
+	/*
+	 * Preserve previous mempolicy unless mpol remount option was specified.
+	 */
+	if (config.mpol) {
+		mpol_put(sbinfo->mpol);
+		sbinfo->mpol = config.mpol;	/* transfers initial ref */
+	}
 out:
 	spin_unlock(&sbinfo->stat_lock);
 	return error;
diff -Naur a/mm/truncate.c b/mm/truncate.c
--- a/mm/truncate.c	2013-11-01 20:18:06.021568322 +0200
+++ b/mm/truncate.c	2013-11-01 18:44:58.525861418 +0200
@@ -376,11 +376,12 @@
 	if (page_has_private(page) && !try_to_release_page(page, GFP_KERNEL))
 		return 0;
 
+	clear_page_mlock(page);
+
 	spin_lock_irq(&mapping->tree_lock);
 	if (PageDirty(page))
 		goto failed;
 
-	clear_page_mlock(page);
 	BUG_ON(page_has_private(page));
 	__remove_from_page_cache(page);
 	spin_unlock_irq(&mapping->tree_lock);
diff -Naur a/mm/vmscan.c b/mm/vmscan.c
--- a/mm/vmscan.c	2013-11-01 20:18:06.029568353 +0200
+++ b/mm/vmscan.c	2013-11-01 18:44:58.529861446 +0200
@@ -2241,6 +2241,8 @@
 			balance_pgdat(pgdat, order);
 		}
 	}
+
+	current->reclaim_state = NULL;
 	return 0;
 }
 
diff -Naur a/net/atm/common.c b/net/atm/common.c
--- a/net/atm/common.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/atm/common.c	2013-11-01 18:44:58.545861516 +0200
@@ -473,6 +473,8 @@
 	struct sk_buff *skb;
 	int copied, error = -EINVAL;
 
+	msg->msg_namelen = 0;
+
 	if (sock->state != SS_CONNECTED)
 		return -ENOTCONN;
 	if (flags & ~MSG_DONTWAIT)		/* only handle MSG_DONTWAIT */
@@ -749,6 +751,7 @@
 				if (!vcc->dev ||
 				    !test_bit(ATM_VF_ADDR,&vcc->flags))
 					return -ENOTCONN;
+				memset(&pvc, 0, sizeof(pvc));
 				pvc.sap_family = AF_ATMPVC;
 				pvc.sap_addr.itf = vcc->dev->number;
 				pvc.sap_addr.vpi = vcc->vpi;
diff -Naur a/net/atm/pvc.c b/net/atm/pvc.c
--- a/net/atm/pvc.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/atm/pvc.c	2013-11-01 18:44:58.573861656 +0200
@@ -93,6 +93,7 @@
 	if (!vcc->dev || !test_bit(ATM_VF_ADDR,&vcc->flags)) return -ENOTCONN;
 	*sockaddr_len = sizeof(struct sockaddr_atmpvc);
 	addr = (struct sockaddr_atmpvc *) sockaddr;
+	memset(addr, 0, sizeof(*addr));
 	addr->sap_family = AF_ATMPVC;
 	addr->sap_addr.itf = vcc->dev->number;
 	addr->sap_addr.vpi = vcc->vpi;
diff -Naur a/net/ax25/af_ax25.c b/net/ax25/af_ax25.c
--- a/net/ax25/af_ax25.c	2013-11-01 20:18:06.037568401 +0200
+++ b/net/ax25/af_ax25.c	2013-11-01 18:44:58.577861684 +0200
@@ -1654,6 +1654,7 @@
 		ax25_address src;
 		const unsigned char *mac = skb_mac_header(skb);
 
+		memset(sax, 0, sizeof(struct full_sockaddr_ax25));
 		ax25_addr_parse(mac + 1, skb->data - mac - 1, &src, NULL,
 				&digi, NULL, NULL);
 		sax->sax25_family = AF_AX25;
diff -Naur a/net/bluetooth/af_bluetooth.c b/net/bluetooth/af_bluetooth.c
--- a/net/bluetooth/af_bluetooth.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/bluetooth/af_bluetooth.c	2013-11-01 18:44:58.597861775 +0200
@@ -240,14 +240,14 @@
 	if (flags & (MSG_OOB))
 		return -EOPNOTSUPP;
 
+	msg->msg_namelen = 0;
+
 	if (!(skb = skb_recv_datagram(sk, flags, noblock, &err))) {
 		if (sk->sk_shutdown & RCV_SHUTDOWN)
 			return 0;
 		return err;
 	}
 
-	msg->msg_namelen = 0;
-
 	copied = skb->len;
 	if (len < copied) {
 		msg->msg_flags |= MSG_TRUNC;
diff -Naur a/net/bluetooth/hci_sock.c b/net/bluetooth/hci_sock.c
--- a/net/bluetooth/hci_sock.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/bluetooth/hci_sock.c	2013-11-01 18:44:58.605861817 +0200
@@ -576,6 +576,7 @@
 		{
 			struct hci_filter *f = &hci_pi(sk)->filter;
 
+			memset(&uf, 0, sizeof(uf));
 			uf.type_mask = f->type_mask;
 			uf.opcode    = f->opcode;
 			uf.event_mask[0] = *((u32 *) f->event_mask + 0);
diff -Naur a/net/bluetooth/hidp/core.c b/net/bluetooth/hidp/core.c
--- a/net/bluetooth/hidp/core.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/bluetooth/hidp/core.c	2013-11-01 18:44:58.605861817 +0200
@@ -778,7 +778,7 @@
 	hid->version = req->version;
 	hid->country = req->country;
 
-	strncpy(hid->name, req->name, 128);
+	strncpy(hid->name, req->name, sizeof(req->name) - 1);
 	strncpy(hid->phys, batostr(&src), 64);
 	strncpy(hid->uniq, batostr(&dst), 64);
 
diff -Naur a/net/bluetooth/l2cap.c b/net/bluetooth/l2cap.c
--- a/net/bluetooth/l2cap.c	2013-11-01 20:18:06.041568414 +0200
+++ b/net/bluetooth/l2cap.c	2013-11-01 18:44:58.609861836 +0200
@@ -1184,6 +1184,7 @@
 
 	BT_DBG("sock %p, sk %p", sock, sk);
 
+	memset(la, 0, sizeof(struct sockaddr_l2));
 	addr->sa_family = AF_BLUETOOTH;
 	*len = sizeof(struct sockaddr_l2);
 
diff -Naur a/net/bluetooth/rfcomm/sock.c b/net/bluetooth/rfcomm/sock.c
--- a/net/bluetooth/rfcomm/sock.c	2013-11-01 20:18:06.045568431 +0200
+++ b/net/bluetooth/rfcomm/sock.c	2013-11-01 18:44:58.609861836 +0200
@@ -543,6 +543,7 @@
 
 	BT_DBG("sock %p, sk %p", sock, sk);
 
+	memset(sa, 0, sizeof(*sa));
 	sa->rc_family  = AF_BLUETOOTH;
 	sa->rc_channel = rfcomm_pi(sk)->channel;
 	if (peer)
@@ -651,6 +652,7 @@
 
 	if (test_and_clear_bit(RFCOMM_DEFER_SETUP, &d->flags)) {
 		rfcomm_dlc_accept(d);
+		msg->msg_namelen = 0;
 		return 0;
 	}
 
diff -Naur a/net/bridge/br_stp_bpdu.c b/net/bridge/br_stp_bpdu.c
--- a/net/bridge/br_stp_bpdu.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/bridge/br_stp_bpdu.c	2013-11-01 18:44:58.617861873 +0200
@@ -15,6 +15,7 @@
 #include <linux/netfilter_bridge.h>
 #include <linux/etherdevice.h>
 #include <linux/llc.h>
+#include <linux/pkt_sched.h>
 #include <net/net_namespace.h>
 #include <net/llc.h>
 #include <net/llc_pdu.h>
@@ -39,6 +40,7 @@
 
 	skb->dev = p->dev;
 	skb->protocol = htons(ETH_P_802_2);
+	skb->priority = TC_PRIO_CONTROL;
 
 	skb_reserve(skb, LLC_RESERVE);
 	memcpy(__skb_put(skb, length), data, length);
diff -Naur a/net/core/dev.c b/net/core/dev.c
--- a/net/core/dev.c	2013-11-01 20:19:19.385932107 +0200
+++ b/net/core/dev.c	2013-11-01 18:44:58.681862195 +0200
@@ -967,6 +967,8 @@
  */
 int dev_set_alias(struct net_device *dev, const char *alias, size_t len)
 {
+	char *new_ifalias;
+
 	ASSERT_RTNL();
 
 	if (len >= IFALIASZ)
@@ -980,9 +982,10 @@
 		return 0;
 	}
 
-	dev->ifalias = krealloc(dev->ifalias, len + 1, GFP_KERNEL);
-	if (!dev->ifalias)
+	new_ifalias = krealloc(dev->ifalias, len + 1, GFP_KERNEL);
+	if (!new_ifalias)
 		return -ENOMEM;
+	dev->ifalias = new_ifalias;
 
 	strlcpy(dev->ifalias, alias, len+1);
 	return len;
@@ -1133,6 +1136,7 @@
 		/*
 		 *	... and announce new interface.
 		 */
+		add_device_randomness(dev->dev_addr, dev->addr_len);
 		call_netdevice_notifiers(NETDEV_UP, dev);
 	}
 
@@ -2844,7 +2848,7 @@
 		 * Allow this to run for 2 jiffies since which will allow
 		 * an average latency of 1.5/HZ.
 		 */
-		if (unlikely(budget <= 0 || time_after(jiffies, time_limit)))
+		if (unlikely(budget <= 0 || time_after_eq(jiffies, time_limit)))
 			goto softnet_break;
 
 		local_irq_enable();
@@ -4268,6 +4272,7 @@
 	err = ops->ndo_set_mac_address(dev, sa);
 	if (!err)
 		call_netdevice_notifiers(NETDEV_CHANGEADDR, dev);
+	add_device_randomness(dev->dev_addr, dev->addr_len);
 	return err;
 }
 EXPORT_SYMBOL(dev_set_mac_address);
@@ -4874,6 +4879,7 @@
 	dev_init_scheduler(dev);
 	dev_hold(dev);
 	list_netdevice(dev);
+	add_device_randomness(dev->dev_addr, dev->addr_len);
 
 	/* Notify protocols, that a new device appeared. */
 	ret = call_netdevice_notifiers(NETDEV_REGISTER, dev);
diff -Naur a/net/core/rtnetlink.c b/net/core/rtnetlink.c
--- a/net/core/rtnetlink.c	2013-11-01 20:18:06.073568573 +0200
+++ b/net/core/rtnetlink.c	2013-11-01 18:44:58.697862269 +0200
@@ -817,6 +817,7 @@
 			goto errout;
 		send_addr_notify = 1;
 		modified = 1;
+		add_device_randomness(dev->dev_addr, dev->addr_len);
 	}
 
 	if (tb[IFLA_MTU]) {
diff -Naur a/net/core/skbuff.c b/net/core/skbuff.c
--- a/net/core/skbuff.c	2013-11-01 20:19:19.393932151 +0200
+++ b/net/core/skbuff.c	2013-11-01 18:44:58.701862298 +0200
@@ -2978,6 +2978,8 @@
  */
 int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb)
 {
+	int len = skb->len;
+
 	if (atomic_read(&sk->sk_rmem_alloc) + skb->truesize >=
 	    (unsigned)sk->sk_rcvbuf)
 		return -ENOMEM;
@@ -2989,7 +2991,7 @@
 
 	skb_queue_tail(&sk->sk_error_queue, skb);
 	if (!sock_flag(sk, SOCK_DEAD))
-		sk->sk_data_ready(sk, skb->len);
+		sk->sk_data_ready(sk, len);
 	return 0;
 }
 EXPORT_SYMBOL(sock_queue_err_skb);
diff -Naur a/net/core/sock.c b/net/core/sock.c
--- a/net/core/sock.c	2013-11-01 20:18:06.081568610 +0200
+++ b/net/core/sock.c	2013-11-01 18:44:58.701862298 +0200
@@ -562,7 +562,8 @@
 
 	case SO_KEEPALIVE:
 #ifdef CONFIG_INET
-		if (sk->sk_protocol == IPPROTO_TCP)
+		if (sk->sk_protocol == IPPROTO_TCP &&
+		    sk->sk_type == SOCK_STREAM)
 			tcp_set_keepalive(sk, valbool);
 #endif
 		sock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);
@@ -1391,6 +1392,11 @@
 	gfp_t gfp_mask;
 	long timeo;
 	int err;
+	int npages = (data_len + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+
+	err = -EMSGSIZE;
+	if (npages > MAX_SKB_FRAGS)
+		goto failure;
 
 	gfp_mask = sk->sk_allocation;
 	if (gfp_mask & __GFP_WAIT)
@@ -1409,14 +1415,12 @@
 		if (atomic_read(&sk->sk_wmem_alloc) < sk->sk_sndbuf) {
 			skb = alloc_skb(header_len, gfp_mask);
 			if (skb) {
-				int npages;
 				int i;
 
 				/* No pages, we're done... */
 				if (!data_len)
 					break;
 
-				npages = (data_len + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 				skb->truesize += data_len;
 				skb_shinfo(skb)->nr_frags = npages;
 				for (i = 0; i < npages; i++) {
diff -Naur a/net/dcb/dcbnl.c b/net/dcb/dcbnl.c
--- a/net/dcb/dcbnl.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/dcb/dcbnl.c	2013-11-01 18:44:58.937863468 +0200
@@ -307,6 +307,7 @@
 	dcb->dcb_family = AF_UNSPEC;
 	dcb->cmd = DCB_CMD_GPERM_HWADDR;
 
+	memset(perm_addr, 0, sizeof(perm_addr));
 	netdev->dcbnl_ops->getpermhwaddr(netdev, perm_addr);
 
 	ret = nla_put(dcbnl_skb, DCB_ATTR_PERM_HWADDR, sizeof(perm_addr),
diff -Naur a/net/dccp/ccid.h b/net/dccp/ccid.h
--- a/net/dccp/ccid.h	2009-12-03 05:51:21.000000000 +0200
+++ b/net/dccp/ccid.h	2013-11-01 18:44:58.937863468 +0200
@@ -214,7 +214,7 @@
 					u32 __user *optval, int __user *optlen)
 {
 	int rc = -ENOPROTOOPT;
-	if (ccid->ccid_ops->ccid_hc_rx_getsockopt != NULL)
+	if (ccid != NULL && ccid->ccid_ops->ccid_hc_rx_getsockopt != NULL)
 		rc = ccid->ccid_ops->ccid_hc_rx_getsockopt(sk, optname, len,
 						 optval, optlen);
 	return rc;
@@ -225,7 +225,7 @@
 					u32 __user *optval, int __user *optlen)
 {
 	int rc = -ENOPROTOOPT;
-	if (ccid->ccid_ops->ccid_hc_tx_getsockopt != NULL)
+	if (ccid != NULL && ccid->ccid_ops->ccid_hc_tx_getsockopt != NULL)
 		rc = ccid->ccid_ops->ccid_hc_tx_getsockopt(sk, optname, len,
 						 optval, optlen);
 	return rc;
diff -Naur a/net/dccp/ipv4.c b/net/dccp/ipv4.c
--- a/net/dccp/ipv4.c	2013-11-01 20:18:06.081568610 +0200
+++ b/net/dccp/ipv4.c	2013-11-01 18:44:58.945863500 +0200
@@ -47,6 +47,7 @@
 	__be32 daddr, nexthop;
 	int tmp;
 	int err;
+	struct ip_options_rcu *inet_opt;
 
 	dp->dccps_role = DCCP_ROLE_CLIENT;
 
@@ -57,10 +58,12 @@
 		return -EAFNOSUPPORT;
 
 	nexthop = daddr = usin->sin_addr.s_addr;
-	if (inet->opt != NULL && inet->opt->srr) {
+
+	inet_opt = inet->inet_opt;
+	if (inet_opt != NULL && inet_opt->opt.srr) {
 		if (daddr == 0)
 			return -EINVAL;
-		nexthop = inet->opt->faddr;
+		nexthop = inet_opt->opt.faddr;
 	}
 
 	tmp = ip_route_connect(&rt, nexthop, inet->saddr,
@@ -75,7 +78,7 @@
 		return -ENETUNREACH;
 	}
 
-	if (inet->opt == NULL || !inet->opt->srr)
+	if (inet_opt == NULL || !inet_opt->opt.srr)
 		daddr = rt->rt_dst;
 
 	if (inet->saddr == 0)
@@ -86,8 +89,8 @@
 	inet->daddr = daddr;
 
 	inet_csk(sk)->icsk_ext_hdr_len = 0;
-	if (inet->opt != NULL)
-		inet_csk(sk)->icsk_ext_hdr_len = inet->opt->optlen;
+	if (inet_opt)
+		inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
 	/*
 	 * Socket identity is still unknown (sport may be zero).
 	 * However we set state to DCCP_REQUESTING and not releasing socket
@@ -397,7 +400,7 @@
 	newinet->daddr	   = ireq->rmt_addr;
 	newinet->rcv_saddr = ireq->loc_addr;
 	newinet->saddr	   = ireq->loc_addr;
-	newinet->opt	   = ireq->opt;
+	newinet->inet_opt	= ireq->opt;
 	ireq->opt	   = NULL;
 	newinet->mc_index  = inet_iif(skb);
 	newinet->mc_ttl	   = ip_hdr(skb)->ttl;
diff -Naur a/net/dccp/ipv6.c b/net/dccp/ipv6.c
--- a/net/dccp/ipv6.c	2013-11-01 20:18:06.085568639 +0200
+++ b/net/dccp/ipv6.c	2013-11-01 18:44:58.949863528 +0200
@@ -600,7 +600,7 @@
 
 	   First: no IPv4 options.
 	 */
-	newinet->opt = NULL;
+	newinet->inet_opt = NULL;
 
 	/* Clone RX bits */
 	newnp->rxopt.all = np->rxopt.all;
diff -Naur a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
--- a/net/ipv4/af_inet.c	2013-11-01 20:18:06.089568655 +0200
+++ b/net/ipv4/af_inet.c	2013-11-01 18:44:59.073864134 +0200
@@ -152,7 +152,7 @@
 	WARN_ON(sk->sk_wmem_queued);
 	WARN_ON(sk->sk_forward_alloc);
 
-	kfree(inet->opt);
+	kfree(inet->inet_opt);
 	dst_release(sk->sk_dst_cache);
 	sk_refcnt_debug_dec(sk);
 }
@@ -1065,9 +1065,11 @@
 	__be32 old_saddr = inet->saddr;
 	__be32 new_saddr;
 	__be32 daddr = inet->daddr;
+	struct ip_options_rcu *inet_opt;
 
-	if (inet->opt && inet->opt->srr)
-		daddr = inet->opt->faddr;
+	inet_opt = inet->inet_opt;
+	if (inet_opt && inet_opt->opt.srr)
+		daddr = inet_opt->opt.faddr;
 
 	/* Query new route. */
 	err = ip_route_connect(&rt, daddr, 0,
@@ -1109,6 +1111,7 @@
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = (struct rtable *)__sk_dst_check(sk, 0);
 	__be32 daddr;
+	struct ip_options_rcu *inet_opt;
 	int err;
 
 	/* Route is OK, nothing to do. */
@@ -1116,9 +1119,12 @@
 		return 0;
 
 	/* Reroute. */
+	rcu_read_lock();
+	inet_opt = rcu_dereference(inet->inet_opt);
 	daddr = inet->daddr;
-	if (inet->opt && inet->opt->srr)
-		daddr = inet->opt->faddr;
+	if (inet_opt && inet_opt->opt.srr)
+		daddr = inet_opt->opt.faddr;
+	rcu_read_unlock();
 {
 	struct flowi fl = {
 		.oif = sk->sk_bound_dev_if,
diff -Naur a/net/ipv4/cipso_ipv4.c b/net/ipv4/cipso_ipv4.c
--- a/net/ipv4/cipso_ipv4.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/cipso_ipv4.c	2013-11-01 18:44:59.077864155 +0200
@@ -1726,8 +1726,10 @@
 		case CIPSO_V4_TAG_LOCAL:
 			/* This is a non-standard tag that we only allow for
 			 * local connections, so if the incoming interface is
-			 * not the loopback device drop the packet. */
-			if (!(skb->dev->flags & IFF_LOOPBACK)) {
+			 * not the loopback device drop the packet. Further,
+			 * there is no legitimate reason for setting this from
+			 * userspace so reject it if skb is NULL. */
+			if (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {
 				err_offset = opt_iter;
 				goto validate_return_locked;
 			}
@@ -1858,6 +1860,11 @@
 	return CIPSO_V4_HDR_LEN + ret_val;
 }
 
+static void opt_kfree_rcu(struct rcu_head *head)
+{
+	kfree(container_of(head, struct ip_options_rcu, rcu));
+}
+
 /**
  * cipso_v4_sock_setattr - Add a CIPSO option to a socket
  * @sk: the socket
@@ -1880,7 +1887,7 @@
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
-	struct ip_options *opt = NULL;
+	struct ip_options_rcu *old, *opt = NULL;
 	struct inet_sock *sk_inet;
 	struct inet_connection_sock *sk_conn;
 
@@ -1916,22 +1923,25 @@
 		ret_val = -ENOMEM;
 		goto socket_setattr_failure;
 	}
-	memcpy(opt->__data, buf, buf_len);
-	opt->optlen = opt_len;
-	opt->cipso = sizeof(struct iphdr);
+	memcpy(opt->opt.__data, buf, buf_len);
+	opt->opt.optlen = opt_len;
+	opt->opt.cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	sk_inet = inet_sk(sk);
+
+	old = sk_inet->inet_opt;
 	if (sk_inet->is_icsk) {
 		sk_conn = inet_csk(sk);
-		if (sk_inet->opt)
-			sk_conn->icsk_ext_hdr_len -= sk_inet->opt->optlen;
-		sk_conn->icsk_ext_hdr_len += opt->optlen;
+		if (old)
+			sk_conn->icsk_ext_hdr_len -= old->opt.optlen;
+		sk_conn->icsk_ext_hdr_len += opt->opt.optlen;
 		sk_conn->icsk_sync_mss(sk, sk_conn->icsk_pmtu_cookie);
 	}
-	opt = xchg(&sk_inet->opt, opt);
-	kfree(opt);
+	rcu_assign_pointer(sk_inet->inet_opt, opt);
+	if (old)
+		call_rcu(&old->rcu, opt_kfree_rcu);
 
 	return 0;
 
@@ -1961,7 +1971,7 @@
 	unsigned char *buf = NULL;
 	u32 buf_len;
 	u32 opt_len;
-	struct ip_options *opt = NULL;
+	struct ip_options_rcu *opt = NULL;
 	struct inet_request_sock *req_inet;
 
 	/* We allocate the maximum CIPSO option size here so we are probably
@@ -1989,15 +1999,16 @@
 		ret_val = -ENOMEM;
 		goto req_setattr_failure;
 	}
-	memcpy(opt->__data, buf, buf_len);
-	opt->optlen = opt_len;
-	opt->cipso = sizeof(struct iphdr);
+	memcpy(opt->opt.__data, buf, buf_len);
+	opt->opt.optlen = opt_len;
+	opt->opt.cipso = sizeof(struct iphdr);
 	kfree(buf);
 	buf = NULL;
 
 	req_inet = inet_rsk(req);
 	opt = xchg(&req_inet->opt, opt);
-	kfree(opt);
+	if (opt)
+		call_rcu(&opt->rcu, opt_kfree_rcu);
 
 	return 0;
 
@@ -2017,34 +2028,34 @@
  * values on failure.
  *
  */
-int cipso_v4_delopt(struct ip_options **opt_ptr)
+int cipso_v4_delopt(struct ip_options_rcu **opt_ptr)
 {
 	int hdr_delta = 0;
-	struct ip_options *opt = *opt_ptr;
+	struct ip_options_rcu *opt = *opt_ptr;
 
-	if (opt->srr || opt->rr || opt->ts || opt->router_alert) {
+	if (opt->opt.srr || opt->opt.rr || opt->opt.ts || opt->opt.router_alert) {
 		u8 cipso_len;
 		u8 cipso_off;
 		unsigned char *cipso_ptr;
 		int iter;
 		int optlen_new;
 
-		cipso_off = opt->cipso - sizeof(struct iphdr);
-		cipso_ptr = &opt->__data[cipso_off];
+		cipso_off = opt->opt.cipso - sizeof(struct iphdr);
+		cipso_ptr = &opt->opt.__data[cipso_off];
 		cipso_len = cipso_ptr[1];
 
-		if (opt->srr > opt->cipso)
-			opt->srr -= cipso_len;
-		if (opt->rr > opt->cipso)
-			opt->rr -= cipso_len;
-		if (opt->ts > opt->cipso)
-			opt->ts -= cipso_len;
-		if (opt->router_alert > opt->cipso)
-			opt->router_alert -= cipso_len;
-		opt->cipso = 0;
+		if (opt->opt.srr > opt->opt.cipso)
+			opt->opt.srr -= cipso_len;
+		if (opt->opt.rr > opt->opt.cipso)
+			opt->opt.rr -= cipso_len;
+		if (opt->opt.ts > opt->opt.cipso)
+			opt->opt.ts -= cipso_len;
+		if (opt->opt.router_alert > opt->opt.cipso)
+			opt->opt.router_alert -= cipso_len;
+		opt->opt.cipso = 0;
 
 		memmove(cipso_ptr, cipso_ptr + cipso_len,
-			opt->optlen - cipso_off - cipso_len);
+			opt->opt.optlen - cipso_off - cipso_len);
 
 		/* determining the new total option length is tricky because of
 		 * the padding necessary, the only thing i can think to do at
@@ -2053,21 +2064,21 @@
 		 * from there we can determine the new total option length */
 		iter = 0;
 		optlen_new = 0;
-		while (iter < opt->optlen)
-			if (opt->__data[iter] != IPOPT_NOP) {
-				iter += opt->__data[iter + 1];
+		while (iter < opt->opt.optlen)
+			if (opt->opt.__data[iter] != IPOPT_NOP) {
+				iter += opt->opt.__data[iter + 1];
 				optlen_new = iter;
 			} else
 				iter++;
-		hdr_delta = opt->optlen;
-		opt->optlen = (optlen_new + 3) & ~3;
-		hdr_delta -= opt->optlen;
+		hdr_delta = opt->opt.optlen;
+		opt->opt.optlen = (optlen_new + 3) & ~3;
+		hdr_delta -= opt->opt.optlen;
 	} else {
 		/* only the cipso option was present on the socket so we can
 		 * remove the entire option struct */
 		*opt_ptr = NULL;
-		hdr_delta = opt->optlen;
-		kfree(opt);
+		hdr_delta = opt->opt.optlen;
+		call_rcu(&opt->rcu, opt_kfree_rcu);
 	}
 
 	return hdr_delta;
@@ -2084,15 +2095,15 @@
 void cipso_v4_sock_delattr(struct sock *sk)
 {
 	int hdr_delta;
-	struct ip_options *opt;
+	struct ip_options_rcu *opt;
 	struct inet_sock *sk_inet;
 
 	sk_inet = inet_sk(sk);
-	opt = sk_inet->opt;
-	if (opt == NULL || opt->cipso == 0)
+	opt = sk_inet->inet_opt;
+	if (opt == NULL || opt->opt.cipso == 0)
 		return;
 
-	hdr_delta = cipso_v4_delopt(&sk_inet->opt);
+	hdr_delta = cipso_v4_delopt(&sk_inet->inet_opt);
 	if (sk_inet->is_icsk && hdr_delta > 0) {
 		struct inet_connection_sock *sk_conn = inet_csk(sk);
 		sk_conn->icsk_ext_hdr_len -= hdr_delta;
@@ -2110,12 +2121,12 @@
  */
 void cipso_v4_req_delattr(struct request_sock *req)
 {
-	struct ip_options *opt;
+	struct ip_options_rcu *opt;
 	struct inet_request_sock *req_inet;
 
 	req_inet = inet_rsk(req);
 	opt = req_inet->opt;
-	if (opt == NULL || opt->cipso == 0)
+	if (opt == NULL || opt->opt.cipso == 0)
 		return;
 
 	cipso_v4_delopt(&req_inet->opt);
@@ -2185,14 +2196,18 @@
  */
 int cipso_v4_sock_getattr(struct sock *sk, struct netlbl_lsm_secattr *secattr)
 {
-	struct ip_options *opt;
-
-	opt = inet_sk(sk)->opt;
-	if (opt == NULL || opt->cipso == 0)
-		return -ENOMSG;
+	struct ip_options_rcu *opt;
+	int res = -ENOMSG;
 
-	return cipso_v4_getattr(opt->__data + opt->cipso - sizeof(struct iphdr),
-				secattr);
+	rcu_read_lock();
+	opt = rcu_dereference(inet_sk(sk)->inet_opt);
+	if (opt && opt->opt.cipso)
+		res = cipso_v4_getattr(opt->opt.__data +
+						opt->opt.cipso -
+						sizeof(struct iphdr),
+				       secattr);
+	rcu_read_unlock();
+	return res;
 }
 
 /**
diff -Naur a/net/ipv4/icmp.c b/net/ipv4/icmp.c
--- a/net/ipv4/icmp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/icmp.c	2013-11-01 18:44:59.085864199 +0200
@@ -107,8 +107,7 @@
 		__be32	       times[3];
 	} data;
 	int head_len;
-	struct ip_options replyopts;
-	unsigned char  optbuf[40];
+	struct ip_options_data replyopts;
 };
 
 /* An array of errno for error messages from dest unreach. */
@@ -362,7 +361,7 @@
 	struct inet_sock *inet;
 	__be32 daddr;
 
-	if (ip_options_echo(&icmp_param->replyopts, skb))
+	if (ip_options_echo(&icmp_param->replyopts.opt.opt, skb))
 		return;
 
 	sk = icmp_xmit_lock(net);
@@ -376,10 +375,10 @@
 	daddr = ipc.addr = rt->rt_src;
 	ipc.opt = NULL;
 	ipc.shtx.flags = 0;
-	if (icmp_param->replyopts.optlen) {
-		ipc.opt = &icmp_param->replyopts;
-		if (ipc.opt->srr)
-			daddr = icmp_param->replyopts.faddr;
+	if (icmp_param->replyopts.opt.opt.optlen) {
+		ipc.opt = &icmp_param->replyopts.opt;
+		if (ipc.opt->opt.srr)
+			daddr = icmp_param->replyopts.opt.opt.faddr;
 	}
 	{
 		struct flowi fl = { .nl_u = { .ip4_u =
@@ -516,7 +515,7 @@
 					   IPTOS_PREC_INTERNETCONTROL) :
 					  iph->tos;
 
-	if (ip_options_echo(&icmp_param.replyopts, skb_in))
+	if (ip_options_echo(&icmp_param.replyopts.opt.opt, skb_in))
 		goto out_unlock;
 
 
@@ -532,15 +531,15 @@
 	icmp_param.offset = skb_network_offset(skb_in);
 	inet_sk(sk)->tos = tos;
 	ipc.addr = iph->saddr;
-	ipc.opt = &icmp_param.replyopts;
+	ipc.opt = &icmp_param.replyopts.opt;
 	ipc.shtx.flags = 0;
 
 	{
 		struct flowi fl = {
 			.nl_u = {
 				.ip4_u = {
-					.daddr = icmp_param.replyopts.srr ?
-						icmp_param.replyopts.faddr :
+					.daddr = icmp_param.replyopts.opt.opt.srr ?
+						icmp_param.replyopts.opt.opt.faddr :
 						iph->saddr,
 					.saddr = saddr,
 					.tos = RT_TOS(tos)
@@ -629,7 +628,7 @@
 	room = dst_mtu(&rt->u.dst);
 	if (room > 576)
 		room = 576;
-	room -= sizeof(struct iphdr) + icmp_param.replyopts.optlen;
+	room -= sizeof(struct iphdr) + icmp_param.replyopts.opt.opt.optlen;
 	room -= sizeof(struct icmphdr);
 
 	icmp_param.data_len = skb_in->len - icmp_param.offset;
diff -Naur a/net/ipv4/inet_connection_sock.c b/net/ipv4/inet_connection_sock.c
--- a/net/ipv4/inet_connection_sock.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/inet_connection_sock.c	2013-11-01 18:44:59.085864199 +0200
@@ -356,11 +356,11 @@
 {
 	struct rtable *rt;
 	const struct inet_request_sock *ireq = inet_rsk(req);
-	struct ip_options *opt = inet_rsk(req)->opt;
+	struct ip_options_rcu *opt = inet_rsk(req)->opt;
 	struct flowi fl = { .oif = sk->sk_bound_dev_if,
 			    .nl_u = { .ip4_u =
-				      { .daddr = ((opt && opt->srr) ?
-						  opt->faddr :
+				      { .daddr = ((opt && opt->opt.srr) ?
+						  opt->opt.faddr :
 						  ireq->rmt_addr),
 					.saddr = ireq->loc_addr,
 					.tos = RT_CONN_FLAGS(sk) } },
@@ -374,7 +374,7 @@
 	security_req_classify_flow(req, &fl);
 	if (ip_route_output_flow(net, &rt, &fl, sk, 0))
 		goto no_route;
-	if (opt && opt->is_strictroute && rt->rt_dst != rt->rt_gateway)
+	if (opt && opt->opt.is_strictroute && rt->rt_dst != rt->rt_gateway)
 		goto route_err;
 	return &rt->u.dst;
 
diff -Naur a/net/ipv4/ip_options.c b/net/ipv4/ip_options.c
--- a/net/ipv4/ip_options.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/ip_options.c	2013-11-01 18:44:59.093864236 +0200
@@ -35,7 +35,7 @@
  * saddr is address of outgoing interface.
  */
 
-void ip_options_build(struct sk_buff * skb, struct ip_options * opt,
+void ip_options_build(struct sk_buff *skb, struct ip_options *opt,
 			    __be32 daddr, struct rtable *rt, int is_frag)
 {
 	unsigned char *iph = skb_network_header(skb);
@@ -82,9 +82,9 @@
  * NOTE: dopt cannot point to skb.
  */
 
-int ip_options_echo(struct ip_options * dopt, struct sk_buff * skb)
+int ip_options_echo(struct ip_options *dopt, struct sk_buff *skb)
 {
-	struct ip_options *sopt;
+	const struct ip_options *sopt;
 	unsigned char *sptr, *dptr;
 	int soffset, doffset;
 	int	optlen;
@@ -94,10 +94,8 @@
 
 	sopt = &(IPCB(skb)->opt);
 
-	if (sopt->optlen == 0) {
-		dopt->optlen = 0;
+	if (sopt->optlen == 0)
 		return 0;
-	}
 
 	sptr = skb_network_header(skb);
 	dptr = dopt->__data;
@@ -156,7 +154,7 @@
 		dopt->optlen += optlen;
 	}
 	if (sopt->srr) {
-		unsigned char * start = sptr+sopt->srr;
+		unsigned char *start = sptr+sopt->srr;
 		__be32 faddr;
 
 		optlen  = start[1];
@@ -499,19 +497,19 @@
 	}
 }
 
-static struct ip_options *ip_options_get_alloc(const int optlen)
+static struct ip_options_rcu *ip_options_get_alloc(const int optlen)
 {
-	return kzalloc(sizeof(struct ip_options) + ((optlen + 3) & ~3),
+	return kzalloc(sizeof(struct ip_options_rcu) + ((optlen + 3) & ~3),
 		       GFP_KERNEL);
 }
 
-static int ip_options_get_finish(struct net *net, struct ip_options **optp,
-				 struct ip_options *opt, int optlen)
+static int ip_options_get_finish(struct net *net, struct ip_options_rcu **optp,
+				 struct ip_options_rcu *opt, int optlen)
 {
 	while (optlen & 3)
-		opt->__data[optlen++] = IPOPT_END;
-	opt->optlen = optlen;
-	if (optlen && ip_options_compile(net, opt, NULL)) {
+		opt->opt.__data[optlen++] = IPOPT_END;
+	opt->opt.optlen = optlen;
+	if (optlen && ip_options_compile(net, &opt->opt, NULL)) {
 		kfree(opt);
 		return -EINVAL;
 	}
@@ -520,29 +518,29 @@
 	return 0;
 }
 
-int ip_options_get_from_user(struct net *net, struct ip_options **optp,
+int ip_options_get_from_user(struct net *net, struct ip_options_rcu **optp,
 			     unsigned char __user *data, int optlen)
 {
-	struct ip_options *opt = ip_options_get_alloc(optlen);
+	struct ip_options_rcu *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return -ENOMEM;
-	if (optlen && copy_from_user(opt->__data, data, optlen)) {
+	if (optlen && copy_from_user(opt->opt.__data, data, optlen)) {
 		kfree(opt);
 		return -EFAULT;
 	}
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
-int ip_options_get(struct net *net, struct ip_options **optp,
+int ip_options_get(struct net *net, struct ip_options_rcu **optp,
 		   unsigned char *data, int optlen)
 {
-	struct ip_options *opt = ip_options_get_alloc(optlen);
+	struct ip_options_rcu *opt = ip_options_get_alloc(optlen);
 
 	if (!opt)
 		return -ENOMEM;
 	if (optlen)
-		memcpy(opt->__data, data, optlen);
+		memcpy(opt->opt.__data, data, optlen);
 	return ip_options_get_finish(net, optp, opt, optlen);
 }
 
diff -Naur a/net/ipv4/ip_output.c b/net/ipv4/ip_output.c
--- a/net/ipv4/ip_output.c	2013-11-01 20:18:06.101568719 +0200
+++ b/net/ipv4/ip_output.c	2013-11-01 18:44:59.093864236 +0200
@@ -137,14 +137,14 @@
  *
  */
 int ip_build_and_send_pkt(struct sk_buff *skb, struct sock *sk,
-			  __be32 saddr, __be32 daddr, struct ip_options *opt)
+			  __be32 saddr, __be32 daddr, struct ip_options_rcu *opt)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct rtable *rt = skb_rtable(skb);
 	struct iphdr *iph;
 
 	/* Build the IP header. */
-	skb_push(skb, sizeof(struct iphdr) + (opt ? opt->optlen : 0));
+	skb_push(skb, sizeof(struct iphdr) + (opt ? opt->opt.optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	iph->version  = 4;
@@ -160,9 +160,9 @@
 	iph->protocol = sk->sk_protocol;
 	ip_select_ident(iph, &rt->u.dst, sk);
 
-	if (opt && opt->optlen) {
-		iph->ihl += opt->optlen>>2;
-		ip_options_build(skb, opt, daddr, rt, 0);
+	if (opt && opt->opt.optlen) {
+		iph->ihl += opt->opt.optlen>>2;
+		ip_options_build(skb, &opt->opt, daddr, rt, 0);
 	}
 
 	skb->priority = sk->sk_priority;
@@ -312,9 +312,10 @@
 {
 	struct sock *sk = skb->sk;
 	struct inet_sock *inet = inet_sk(sk);
-	struct ip_options *opt = inet->opt;
+	struct ip_options_rcu *inet_opt = NULL;
 	struct rtable *rt;
 	struct iphdr *iph;
+	int res;
 
 	/* Skip all of this if the packet is already routed,
 	 * f.e. by something like SCTP.
@@ -325,13 +326,15 @@
 
 	/* Make sure we can route this packet. */
 	rt = (struct rtable *)__sk_dst_check(sk, 0);
+	rcu_read_lock();
+	inet_opt = rcu_dereference(inet->inet_opt);
 	if (rt == NULL) {
 		__be32 daddr;
 
 		/* Use correct destination address if we have options. */
 		daddr = inet->daddr;
-		if(opt && opt->srr)
-			daddr = opt->faddr;
+		if (inet_opt && inet_opt->opt.srr)
+			daddr = inet_opt->opt.faddr;
 
 		{
 			struct flowi fl = { .oif = sk->sk_bound_dev_if,
@@ -359,11 +362,11 @@
 	skb_dst_set(skb, dst_clone(&rt->u.dst));
 
 packet_routed:
-	if (opt && opt->is_strictroute && rt->rt_dst != rt->rt_gateway)
+	if (inet_opt && inet_opt->opt.is_strictroute && rt->rt_dst != rt->rt_gateway)
 		goto no_route;
 
 	/* OK, we know where to send it, allocate and build IP header. */
-	skb_push(skb, sizeof(struct iphdr) + (opt ? opt->optlen : 0));
+	skb_push(skb, sizeof(struct iphdr) + (inet_opt ? inet_opt->opt.optlen : 0));
 	skb_reset_network_header(skb);
 	iph = ip_hdr(skb);
 	*((__be16 *)iph) = htons((4 << 12) | (5 << 8) | (inet->tos & 0xff));
@@ -377,9 +380,9 @@
 	iph->daddr    = rt->rt_dst;
 	/* Transport layer set skb->h.foo itself. */
 
-	if (opt && opt->optlen) {
-		iph->ihl += opt->optlen >> 2;
-		ip_options_build(skb, opt, inet->daddr, rt, 0);
+	if (inet_opt && inet_opt->opt.optlen) {
+		iph->ihl += inet_opt->opt.optlen >> 2;
+		ip_options_build(skb, &inet_opt->opt, inet->daddr, rt, 0);
 	}
 
 	ip_select_ident_more(iph, &rt->u.dst, sk,
@@ -387,10 +390,12 @@
 
 	skb->priority = sk->sk_priority;
 	skb->mark = sk->sk_mark;
-
-	return ip_local_out(skb);
+	res = ip_local_out(skb);
+	rcu_read_unlock();
+	return res;
 
 no_route:
+	rcu_read_unlock();
 	IP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);
 	kfree_skb(skb);
 	return -EHOSTUNREACH;
@@ -809,7 +814,7 @@
 		/*
 		 * setup for corking.
 		 */
-		opt = ipc->opt;
+		opt = ipc->opt ? &ipc->opt->opt : NULL;
 		if (opt) {
 			if (inet->cork.opt == NULL) {
 				inet->cork.opt = kmalloc(sizeof(struct ip_options) + 40, sk->sk_allocation);
@@ -1367,26 +1372,23 @@
 		   unsigned int len)
 {
 	struct inet_sock *inet = inet_sk(sk);
-	struct {
-		struct ip_options	opt;
-		char			data[40];
-	} replyopts;
+	struct ip_options_data replyopts;
 	struct ipcm_cookie ipc;
 	__be32 daddr;
 	struct rtable *rt = skb_rtable(skb);
 
-	if (ip_options_echo(&replyopts.opt, skb))
+	if (ip_options_echo(&replyopts.opt.opt, skb))
 		return;
 
 	daddr = ipc.addr = rt->rt_src;
 	ipc.opt = NULL;
 	ipc.shtx.flags = 0;
 
-	if (replyopts.opt.optlen) {
+	if (replyopts.opt.opt.optlen) {
 		ipc.opt = &replyopts.opt;
 
-		if (ipc.opt->srr)
-			daddr = replyopts.opt.faddr;
+		if (replyopts.opt.opt.srr)
+			daddr = replyopts.opt.opt.faddr;
 	}
 
 	{
diff -Naur a/net/ipv4/ip_sockglue.c b/net/ipv4/ip_sockglue.c
--- a/net/ipv4/ip_sockglue.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/ip_sockglue.c	2013-11-01 18:44:59.093864236 +0200
@@ -434,6 +434,11 @@
 }
 
 
+static void opt_kfree_rcu(struct rcu_head *head)
+{
+	kfree(container_of(head, struct ip_options_rcu, rcu));
+}
+
 /*
  *	Socket option code for IP. This is the end of the line after any
  *	TCP,UDP etc options on an IP socket.
@@ -479,13 +484,15 @@
 	switch (optname) {
 	case IP_OPTIONS:
 	{
-		struct ip_options *opt = NULL;
+		struct ip_options_rcu *old, *opt = NULL;
+
 		if (optlen > 40 || optlen < 0)
 			goto e_inval;
 		err = ip_options_get_from_user(sock_net(sk), &opt,
 					       optval, optlen);
 		if (err)
 			break;
+		old = inet->inet_opt;
 		if (inet->is_icsk) {
 			struct inet_connection_sock *icsk = inet_csk(sk);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
@@ -494,17 +501,18 @@
 			       (TCPF_LISTEN | TCPF_CLOSE)) &&
 			     inet->daddr != LOOPBACK4_IPV6)) {
 #endif
-				if (inet->opt)
-					icsk->icsk_ext_hdr_len -= inet->opt->optlen;
+				if (old)
+					icsk->icsk_ext_hdr_len -= old->opt.optlen;
 				if (opt)
-					icsk->icsk_ext_hdr_len += opt->optlen;
+					icsk->icsk_ext_hdr_len += opt->opt.optlen;
 				icsk->icsk_sync_mss(sk, icsk->icsk_pmtu_cookie);
 #if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
 			}
 #endif
 		}
-		opt = xchg(&inet->opt, opt);
-		kfree(opt);
+		rcu_assign_pointer(inet->inet_opt, opt);
+		if (old)
+			call_rcu(&old->rcu, opt_kfree_rcu);
 		break;
 	}
 	case IP_PKTINFO:
@@ -563,7 +571,7 @@
 	case IP_TTL:
 		if (optlen < 1)
 			goto e_inval;
-		if (val != -1 && (val < 0 || val > 255))
+		if (val != -1 && (val < 1 || val > 255))
 			goto e_inval;
 		inet->uc_ttl = val;
 		break;
@@ -1032,12 +1040,15 @@
 	case IP_OPTIONS:
 	{
 		unsigned char optbuf[sizeof(struct ip_options)+40];
-		struct ip_options * opt = (struct ip_options *)optbuf;
+		struct ip_options *opt = (struct ip_options *)optbuf;
+		struct ip_options_rcu *inet_opt;
+
+		inet_opt = inet->inet_opt;
 		opt->optlen = 0;
-		if (inet->opt)
-			memcpy(optbuf, inet->opt,
-			       sizeof(struct ip_options)+
-			       inet->opt->optlen);
+		if (inet_opt)
+			memcpy(optbuf, &inet_opt->opt,
+			       sizeof(struct ip_options) +
+			       inet_opt->opt.optlen);
 		release_sock(sk);
 
 		if (opt->optlen == 0)
diff -Naur a/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c b/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c
--- a/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2013-11-01 20:18:06.109568744 +0200
+++ b/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2013-11-01 18:44:59.109864313 +0200
@@ -83,6 +83,14 @@
 	*dataoff = nhoff + (iph->ihl << 2);
 	*protonum = iph->protocol;
 
+	/* Check bogus IP headers */
+	if (*dataoff > skb->len) {
+		pr_debug("nf_conntrack_ipv4: bogus IPv4 packet: "
+			 "nhoff %u, ihl %u, skblen %u\n",
+			 nhoff, iph->ihl << 2, skb->len);
+		return -NF_ACCEPT;
+	}
+
 	return NF_ACCEPT;
 }
 
diff -Naur a/net/ipv4/raw.c b/net/ipv4/raw.c
--- a/net/ipv4/raw.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/raw.c	2013-11-01 18:44:59.121864376 +0200
@@ -459,6 +459,7 @@
 	__be32 saddr;
 	u8  tos;
 	int err;
+	struct ip_options_data opt_copy;
 
 	err = -EMSGSIZE;
 	if (len > 0xFFFF)
@@ -519,8 +520,18 @@
 	saddr = ipc.addr;
 	ipc.addr = daddr;
 
-	if (!ipc.opt)
-		ipc.opt = inet->opt;
+	if (!ipc.opt) {
+		struct ip_options_rcu *inet_opt;
+
+		rcu_read_lock();
+		inet_opt = rcu_dereference(inet->inet_opt);
+		if (inet_opt) {
+			memcpy(&opt_copy, inet_opt,
+			       sizeof(*inet_opt) + inet_opt->opt.optlen);
+			ipc.opt = &opt_copy.opt;
+		}
+		rcu_read_unlock();
+	}
 
 	if (ipc.opt) {
 		err = -EINVAL;
@@ -529,10 +540,10 @@
 		 */
 		if (inet->hdrincl)
 			goto done;
-		if (ipc.opt->srr) {
+		if (ipc.opt->opt.srr) {
 			if (!daddr)
 				goto done;
-			daddr = ipc.opt->faddr;
+			daddr = ipc.opt->opt.faddr;
 		}
 	}
 	tos = RT_CONN_FLAGS(sk);
diff -Naur a/net/ipv4/route.c b/net/ipv4/route.c
--- a/net/ipv4/route.c	2013-11-01 20:18:06.113568769 +0200
+++ b/net/ipv4/route.c	2013-11-01 18:44:59.121864376 +0200
@@ -1412,7 +1412,7 @@
 					dev_hold(rt->u.dst.dev);
 				if (rt->idev)
 					in_dev_hold(rt->idev);
-				rt->u.dst.obsolete	= 0;
+				rt->u.dst.obsolete	= -1;
 				rt->u.dst.lastuse	= jiffies;
 				rt->u.dst.path		= &rt->u.dst;
 				rt->u.dst.neighbour	= NULL;
@@ -1477,7 +1477,7 @@
 	struct dst_entry *ret = dst;
 
 	if (rt) {
-		if (dst->obsolete) {
+		if (dst->obsolete > 0) {
 			ip_rt_put(rt);
 			ret = NULL;
 		} else if ((rt->rt_flags & RTCF_REDIRECTED) ||
@@ -1700,7 +1700,9 @@
 
 static struct dst_entry *ipv4_dst_check(struct dst_entry *dst, u32 cookie)
 {
-	return NULL;
+	if (rt_is_expired((struct rtable *)dst))
+		return NULL;
+	return dst;
 }
 
 static void ipv4_dst_destroy(struct dst_entry *dst)
@@ -1862,7 +1864,8 @@
 	if (!rth)
 		goto e_nobufs;
 
-	rth->u.dst.output= ip_rt_bug;
+	rth->u.dst.output = ip_rt_bug;
+	rth->u.dst.obsolete = -1;
 
 	atomic_set(&rth->u.dst.__refcnt, 1);
 	rth->u.dst.flags= DST_HOST;
@@ -2023,6 +2026,7 @@
 	rth->fl.oif 	= 0;
 	rth->rt_spec_dst= spec_dst;
 
+	rth->u.dst.obsolete = -1;
 	rth->u.dst.input = ip_forward;
 	rth->u.dst.output = ip_output;
 	rth->rt_genid = rt_genid(dev_net(rth->u.dst.dev));
@@ -2187,6 +2191,7 @@
 		goto e_nobufs;
 
 	rth->u.dst.output= ip_rt_bug;
+	rth->u.dst.obsolete = -1;
 	rth->rt_genid = rt_genid(net);
 
 	atomic_set(&rth->u.dst.__refcnt, 1);
@@ -2411,7 +2416,8 @@
 	rth->rt_gateway = fl->fl4_dst;
 	rth->rt_spec_dst= fl->fl4_src;
 
-	rth->u.dst.output=ip_output;
+	rth->u.dst.output = ip_output;
+	rth->u.dst.obsolete = -1;
 	rth->rt_genid = rt_genid(dev_net(dev_out));
 
 	RT_CACHE_STAT_INC(out_slow_tot);
@@ -2741,6 +2747,7 @@
 	if (rt) {
 		struct dst_entry *new = &rt->u.dst;
 
+		new->obsolete = -1;
 		atomic_set(&new->__refcnt, 1);
 		new->__use = 1;
 		new->input = dst_discard;
diff -Naur a/net/ipv4/syncookies.c b/net/ipv4/syncookies.c
--- a/net/ipv4/syncookies.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/syncookies.c	2013-11-01 18:44:59.121864376 +0200
@@ -309,10 +309,10 @@
 	 * the ACK carries the same options again (see RFC1122 4.2.3.8)
 	 */
 	if (opt && opt->optlen) {
-		int opt_size = sizeof(struct ip_options) + opt->optlen;
+		int opt_size = sizeof(struct ip_options_rcu) + opt->optlen;
 
 		ireq->opt = kmalloc(opt_size, GFP_ATOMIC);
-		if (ireq->opt != NULL && ip_options_echo(ireq->opt, skb)) {
+		if (ireq->opt != NULL && ip_options_echo(&ireq->opt->opt, skb)) {
 			kfree(ireq->opt);
 			ireq->opt = NULL;
 		}
diff -Naur a/net/ipv4/tcp.c b/net/ipv4/tcp.c
--- a/net/ipv4/tcp.c	2013-11-01 20:18:06.117568804 +0200
+++ b/net/ipv4/tcp.c	2013-11-01 18:44:59.125864402 +0200
@@ -838,8 +838,7 @@
 wait_for_sndbuf:
 		set_bit(SOCK_NOSPACE, &sk->sk_socket->flags);
 wait_for_memory:
-		if (copied)
-			tcp_push(sk, flags & ~MSG_MORE, mss_now, TCP_NAGLE_PUSH);
+		tcp_push(sk, flags & ~MSG_MORE, mss_now, TCP_NAGLE_PUSH);
 
 		if ((err = sk_stream_wait_memory(sk, &timeo)) != 0)
 			goto do_error;
@@ -848,7 +847,7 @@
 	}
 
 out:
-	if (copied)
+	if (copied && !(flags & MSG_SENDPAGE_NOTLAST))
 		tcp_push(sk, flags, mss_now, tp->nonagle);
 	return copied;
 
diff -Naur a/net/ipv4/tcp_illinois.c b/net/ipv4/tcp_illinois.c
--- a/net/ipv4/tcp_illinois.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/tcp_illinois.c	2013-11-01 18:44:59.125864402 +0200
@@ -313,11 +313,13 @@
 			.tcpv_rttcnt = ca->cnt_rtt,
 			.tcpv_minrtt = ca->base_rtt,
 		};
-		u64 t = ca->sum_rtt;
 
-		do_div(t, ca->cnt_rtt);
-		info.tcpv_rtt = t;
+		if (info.tcpv_rttcnt > 0) {
+			u64 t = ca->sum_rtt;
 
+			do_div(t, info.tcpv_rttcnt);
+			info.tcpv_rtt = t;
+		}
 		nla_put(skb, INET_DIAG_VEGASINFO, sizeof(info), &info);
 	}
 }
diff -Naur a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
--- a/net/ipv4/tcp_input.c	2013-11-01 20:18:06.121568811 +0200
+++ b/net/ipv4/tcp_input.c	2013-11-01 18:44:59.129864412 +0200
@@ -5239,7 +5239,9 @@
 			if (tp->copied_seq == tp->rcv_nxt &&
 			    len - tcp_header_len <= tp->ucopy.len) {
 #ifdef CONFIG_NET_DMA
-				if (tcp_dma_try_early_copy(sk, skb, tcp_header_len)) {
+				if (tp->ucopy.task == current &&
+				    sock_owned_by_user(sk) &&
+				    tcp_dma_try_early_copy(sk, skb, tcp_header_len)) {
 					copied_early = 1;
 					eaten = 1;
 				}
@@ -5632,6 +5634,8 @@
 			goto discard;
 
 		if (th->syn) {
+			if (th->fin)
+				goto discard;
 			if (icsk->icsk_af_ops->conn_request(sk, skb) < 0)
 				return 1;
 
diff -Naur a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c
--- a/net/ipv4/tcp_ipv4.c	2013-11-01 20:18:06.121568811 +0200
+++ b/net/ipv4/tcp_ipv4.c	2013-11-01 18:44:59.133864432 +0200
@@ -152,6 +152,7 @@
 	__be32 daddr, nexthop;
 	int tmp;
 	int err;
+	struct ip_options_rcu *inet_opt;
 
 	if (addr_len < sizeof(struct sockaddr_in))
 		return -EINVAL;
@@ -160,10 +161,11 @@
 		return -EAFNOSUPPORT;
 
 	nexthop = daddr = usin->sin_addr.s_addr;
-	if (inet->opt && inet->opt->srr) {
+	inet_opt = inet->inet_opt;
+	if (inet_opt && inet_opt->opt.srr) {
 		if (!daddr)
 			return -EINVAL;
-		nexthop = inet->opt->faddr;
+		nexthop = inet_opt->opt.faddr;
 	}
 
 	tmp = ip_route_connect(&rt, nexthop, inet->saddr,
@@ -181,7 +183,7 @@
 		return -ENETUNREACH;
 	}
 
-	if (!inet->opt || !inet->opt->srr)
+	if (!inet_opt || !inet_opt->opt.srr)
 		daddr = rt->rt_dst;
 
 	if (!inet->saddr)
@@ -215,8 +217,8 @@
 	inet->daddr = daddr;
 
 	inet_csk(sk)->icsk_ext_hdr_len = 0;
-	if (inet->opt)
-		inet_csk(sk)->icsk_ext_hdr_len = inet->opt->optlen;
+	if (inet_opt)
+		inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
 
 	tp->rx_opt.mss_clamp = 536;
 
@@ -406,6 +408,9 @@
 		    !icsk->icsk_backoff)
 			break;
 
+		if (sock_owned_by_user(sk))
+			break;
+
 		icsk->icsk_backoff--;
 		inet_csk(sk)->icsk_rto = __tcp_set_rto(tp) <<
 					 icsk->icsk_backoff;
@@ -420,11 +425,6 @@
 		if (remaining) {
 			inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
 						  remaining, TCP_RTO_MAX);
-		} else if (sock_owned_by_user(sk)) {
-			/* RTO revert clocked out retransmission,
-			 * but socket is locked. Will defer. */
-			inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
-						  HZ/20, TCP_RTO_MAX);
 		} else {
 			/* RTO revert clocked out retransmission.
 			 * Will retransmit now */
@@ -804,17 +804,18 @@
 /*
  * Save and compile IPv4 options into the request_sock if needed.
  */
-static struct ip_options *tcp_v4_save_options(struct sock *sk,
-					      struct sk_buff *skb)
+static struct ip_options_rcu *tcp_v4_save_options(struct sock *sk,
+						  struct sk_buff *skb)
 {
-	struct ip_options *opt = &(IPCB(skb)->opt);
-	struct ip_options *dopt = NULL;
+	const struct ip_options *opt = &(IPCB(skb)->opt);
+	struct ip_options_rcu *dopt = NULL;
 
 	if (opt && opt->optlen) {
-		int opt_size = optlength(opt);
+		int opt_size = sizeof(*dopt) + opt->optlen;
+
 		dopt = kmalloc(opt_size, GFP_ATOMIC);
 		if (dopt) {
-			if (ip_options_echo(dopt, skb)) {
+			if (ip_options_echo(&dopt->opt, skb)) {
 				kfree(dopt);
 				dopt = NULL;
 			}
@@ -1364,6 +1365,7 @@
 #ifdef CONFIG_TCP_MD5SIG
 	struct tcp_md5sig_key *key;
 #endif
+	struct ip_options_rcu *inet_opt;
 
 	if (sk_acceptq_is_full(sk))
 		goto exit_overflow;
@@ -1384,13 +1386,14 @@
 	newinet->daddr	      = ireq->rmt_addr;
 	newinet->rcv_saddr    = ireq->loc_addr;
 	newinet->saddr	      = ireq->loc_addr;
-	newinet->opt	      = ireq->opt;
+	inet_opt	      = ireq->opt;
+	rcu_assign_pointer(newinet->inet_opt, inet_opt);
 	ireq->opt	      = NULL;
 	newinet->mc_index     = inet_iif(skb);
 	newinet->mc_ttl	      = ip_hdr(skb)->ttl;
 	inet_csk(newsk)->icsk_ext_hdr_len = 0;
-	if (newinet->opt)
-		inet_csk(newsk)->icsk_ext_hdr_len = newinet->opt->optlen;
+	if (inet_opt)
+		inet_csk(newsk)->icsk_ext_hdr_len = inet_opt->opt.optlen;
 	newinet->id = newtp->write_seq ^ jiffies;
 
 	tcp_mtup_init(newsk);
diff -Naur a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
--- a/net/ipv4/tcp_output.c	2013-11-01 20:18:06.125568827 +0200
+++ b/net/ipv4/tcp_output.c	2013-11-01 18:44:59.137864459 +0200
@@ -1391,8 +1391,11 @@
 			goto send_now;
 	}
 
-	/* Ok, it looks like it is advisable to defer.  */
-	tp->tso_deferred = 1 | (jiffies << 1);
+	/* Ok, it looks like it is advisable to defer.
+	 * Do not rearm the timer if already set to not break TCP ACK clocking.
+	 */
+	if (!tp->tso_deferred)
+		tp->tso_deferred = 1 | (jiffies << 1);
 
 	return 1;
 
diff -Naur a/net/ipv4/udp.c b/net/ipv4/udp.c
--- a/net/ipv4/udp.c	2013-11-01 20:18:06.129568848 +0200
+++ b/net/ipv4/udp.c	2013-11-01 18:44:59.141864473 +0200
@@ -592,6 +592,7 @@
 	int err, is_udplite = IS_UDPLITE(sk);
 	int corkreq = up->corkflag || msg->msg_flags&MSG_MORE;
 	int (*getfrag)(void *, char *, int, int, int, struct sk_buff *);
+	struct ip_options_data opt_copy;
 
 	if (len > 0xFFFF)
 		return -EMSGSIZE;
@@ -663,22 +664,32 @@
 			free = 1;
 		connected = 0;
 	}
-	if (!ipc.opt)
-		ipc.opt = inet->opt;
+	if (!ipc.opt) {
+		struct ip_options_rcu *inet_opt;
+
+		rcu_read_lock();
+		inet_opt = rcu_dereference(inet->inet_opt);
+		if (inet_opt) {
+			memcpy(&opt_copy, inet_opt,
+			       sizeof(*inet_opt) + inet_opt->opt.optlen);
+			ipc.opt = &opt_copy.opt;
+		}
+		rcu_read_unlock();
+	}
 
 	saddr = ipc.addr;
 	ipc.addr = faddr = daddr;
 
-	if (ipc.opt && ipc.opt->srr) {
+	if (ipc.opt && ipc.opt->opt.srr) {
 		if (!daddr)
 			return -EINVAL;
-		faddr = ipc.opt->faddr;
+		faddr = ipc.opt->opt.faddr;
 		connected = 0;
 	}
 	tos = RT_TOS(inet->tos);
 	if (sock_flag(sk, SOCK_LOCALROUTE) ||
 	    (msg->msg_flags & MSG_DONTROUTE) ||
-	    (ipc.opt && ipc.opt->is_strictroute)) {
+	    (ipc.opt && ipc.opt->opt.is_strictroute)) {
 		tos |= RTO_ONLINK;
 		connected = 0;
 	}
diff -Naur a/net/ipv4/xfrm4_mode_beet.c b/net/ipv4/xfrm4_mode_beet.c
--- a/net/ipv4/xfrm4_mode_beet.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/xfrm4_mode_beet.c	2013-11-01 18:44:59.145864491 +0200
@@ -110,10 +110,7 @@
 
 	skb_push(skb, sizeof(*iph));
 	skb_reset_network_header(skb);
-
-	memmove(skb->data - skb->mac_len, skb_mac_header(skb),
-		skb->mac_len);
-	skb_set_mac_header(skb, -skb->mac_len);
+	skb_mac_header_rebuild(skb);
 
 	xfrm4_beet_make_header(skb);
 
diff -Naur a/net/ipv4/xfrm4_mode_tunnel.c b/net/ipv4/xfrm4_mode_tunnel.c
--- a/net/ipv4/xfrm4_mode_tunnel.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv4/xfrm4_mode_tunnel.c	2013-11-01 18:44:59.149864514 +0200
@@ -65,7 +65,6 @@
 
 static int xfrm4_mode_tunnel_input(struct xfrm_state *x, struct sk_buff *skb)
 {
-	const unsigned char *old_mac;
 	int err = -EINVAL;
 
 	if (XFRM_MODE_SKB_CB(skb)->protocol != IPPROTO_IPIP)
@@ -83,10 +82,9 @@
 	if (!(x->props.flags & XFRM_STATE_NOECN))
 		ipip_ecn_decapsulate(skb);
 
-	old_mac = skb_mac_header(skb);
-	skb_set_mac_header(skb, -skb->mac_len);
-	memmove(skb_mac_header(skb), old_mac, skb->mac_len);
 	skb_reset_network_header(skb);
+	skb_mac_header_rebuild(skb);
+
 	err = 0;
 
 out:
diff -Naur a/net/ipv6/af_inet6.c b/net/ipv6/af_inet6.c
--- a/net/ipv6/af_inet6.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv6/af_inet6.c	2013-11-01 18:44:59.245864986 +0200
@@ -1073,6 +1073,8 @@
 		goto out;
 	}
 
+	initialize_hashidentrnd();
+
 	err = proto_register(&tcpv6_prot, 1);
 	if (err)
 		goto out;
diff -Naur a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c
--- a/net/ipv6/ip6_output.c	2013-11-01 20:18:06.137568890 +0200
+++ b/net/ipv6/ip6_output.c	2013-11-01 18:44:59.253865035 +0200
@@ -604,6 +604,35 @@
 	return offset;
 }
 
+static u32 hashidentrnd __read_mostly;
+#define FID_HASH_SZ 16
+static u32 ipv6_fragmentation_id[FID_HASH_SZ];
+
+void __init initialize_hashidentrnd(void)
+{
+	get_random_bytes(&hashidentrnd, sizeof(hashidentrnd));
+}
+
+static u32 __ipv6_select_ident(const struct in6_addr *addr)
+{
+	u32 newid, oldid, hash = jhash2((u32 *)addr, 4, hashidentrnd);
+	u32 *pid = &ipv6_fragmentation_id[hash % FID_HASH_SZ];
+
+	do {
+		oldid = *pid;
+		newid = oldid + 1;
+		if (!(hash + newid))
+			newid++;
+	} while (cmpxchg(pid, oldid, newid) != oldid);
+
+	return hash + newid;
+}
+
+void ipv6_select_ident(struct frag_hdr *fhdr, struct rt6_info *rt)
+{
+	fhdr->identification = htonl(__ipv6_select_ident(&rt->rt6i_dst.addr));
+}
+
 static int ip6_fragment(struct sk_buff *skb, int (*output)(struct sk_buff *))
 {
 	struct sk_buff *frag;
@@ -689,7 +718,7 @@
 		skb_reset_network_header(skb);
 		memcpy(skb_network_header(skb), tmp_hdr, hlen);
 
-		ipv6_select_ident(fh);
+		ipv6_select_ident(fh, rt);
 		fh->nexthdr = nexthdr;
 		fh->reserved = 0;
 		fh->frag_off = htons(IP6_MF);
@@ -835,7 +864,7 @@
 		fh->nexthdr = nexthdr;
 		fh->reserved = 0;
 		if (!frag_id) {
-			ipv6_select_ident(fh);
+			ipv6_select_ident(fh, rt);
 			frag_id = fh->identification;
 		} else
 			fh->identification = frag_id;
@@ -1039,7 +1068,8 @@
 			int getfrag(void *from, char *to, int offset, int len,
 			int odd, struct sk_buff *skb),
 			void *from, int length, int hh_len, int fragheaderlen,
-			int transhdrlen, int mtu,unsigned int flags)
+			int transhdrlen, int mtu,unsigned int flags,
+			struct rt6_info *rt)
 
 {
 	struct sk_buff *skb;
@@ -1084,7 +1114,7 @@
 		skb_shinfo(skb)->gso_size = (mtu - fragheaderlen -
 					     sizeof(struct frag_hdr)) & ~7;
 		skb_shinfo(skb)->gso_type = SKB_GSO_UDP;
-		ipv6_select_ident(&fhdr);
+		ipv6_select_ident(&fhdr, rt);
 		skb_shinfo(skb)->ip6_frag_id = fhdr.identification;
 		__skb_queue_tail(&sk->sk_write_queue, skb);
 
@@ -1233,7 +1263,7 @@
 
 		err = ip6_ufo_append_data(sk, getfrag, from, length, hh_len,
 					  fragheaderlen, transhdrlen, mtu,
-					  flags);
+					  flags, rt);
 		if (err)
 			goto error;
 		return 0;
diff -Naur a/net/ipv6/reassembly.c b/net/ipv6/reassembly.c
--- a/net/ipv6/reassembly.c	2013-11-01 20:18:06.153568971 +0200
+++ b/net/ipv6/reassembly.c	2013-11-01 18:44:59.273865127 +0200
@@ -148,16 +148,6 @@
 }
 EXPORT_SYMBOL(ip6_frag_match);
 
-/* Memory Tracking Functions. */
-static inline void frag_kfree_skb(struct netns_frags *nf,
-		struct sk_buff *skb, int *work)
-{
-	if (work)
-		*work -= skb->truesize;
-	atomic_sub(skb->truesize, &nf->mem);
-	kfree_skb(skb);
-}
-
 void ip6_frag_init(struct inet_frag_queue *q, void *a)
 {
 	struct frag_queue *fq = container_of(q, struct frag_queue, q);
@@ -348,58 +338,22 @@
 		prev = next;
 	}
 
-	/* We found where to put this one.  Check for overlap with
-	 * preceding fragment, and, if needed, align things so that
-	 * any overlaps are eliminated.
+	/* RFC5722, Section 4:
+	 *                                  When reassembling an IPv6 datagram, if
+	 *   one or more its constituent fragments is determined to be an
+	 *   overlapping fragment, the entire datagram (and any constituent
+	 *   fragments, including those not yet received) MUST be silently
+	 *   discarded.
 	 */
-	if (prev) {
-		int i = (FRAG6_CB(prev)->offset + prev->len) - offset;
-
-		if (i > 0) {
-			offset += i;
-			if (end <= offset)
-				goto err;
-			if (!pskb_pull(skb, i))
-				goto err;
-			if (skb->ip_summed != CHECKSUM_UNNECESSARY)
-				skb->ip_summed = CHECKSUM_NONE;
-		}
-	}
 
-	/* Look for overlap with succeeding segments.
-	 * If we can merge fragments, do it.
-	 */
-	while (next && FRAG6_CB(next)->offset < end) {
-		int i = end - FRAG6_CB(next)->offset; /* overlap is 'i' bytes */
-
-		if (i < next->len) {
-			/* Eat head of the next overlapped fragment
-			 * and leave the loop. The next ones cannot overlap.
-			 */
-			if (!pskb_pull(next, i))
-				goto err;
-			FRAG6_CB(next)->offset += i;	/* next fragment */
-			fq->q.meat -= i;
-			if (next->ip_summed != CHECKSUM_UNNECESSARY)
-				next->ip_summed = CHECKSUM_NONE;
-			break;
-		} else {
-			struct sk_buff *free_it = next;
-
-			/* Old fragment is completely overridden with
-			 * new one drop it.
-			 */
-			next = next->next;
-
-			if (prev)
-				prev->next = next;
-			else
-				fq->q.fragments = next;
-
-			fq->q.meat -= free_it->len;
-			frag_kfree_skb(fq->q.net, free_it, NULL);
-		}
-	}
+	/* Check for overlap with preceding fragment. */
+	if (prev &&
+	    (FRAG6_CB(prev)->offset + prev->len) - offset > 0)
+		goto discard_fq;
+
+	/* Look for overlap with succeeding segment. */
+	if (next && FRAG6_CB(next)->offset < end)
+		goto discard_fq;
 
 	FRAG6_CB(skb)->offset = offset;
 
@@ -436,6 +390,8 @@
 	write_unlock(&ip6_frags.lock);
 	return -1;
 
+discard_fq:
+	fq_kill(fq);
 err:
 	IP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),
 		      IPSTATS_MIB_REASMFAILS);
diff -Naur a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c
--- a/net/ipv6/tcp_ipv6.c	2013-11-01 20:18:06.161569008 +0200
+++ b/net/ipv6/tcp_ipv6.c	2013-11-01 18:44:59.277865155 +0200
@@ -1391,7 +1391,7 @@
 
 	   First: no IPv4 options.
 	 */
-	newinet->opt = NULL;
+	newinet->inet_opt = NULL;
 	newnp->ipv6_fl_list = NULL;
 
 	/* Clone RX bits */
diff -Naur a/net/ipv6/udp.c b/net/ipv6/udp.c
--- a/net/ipv6/udp.c	2013-11-01 20:18:06.161569008 +0200
+++ b/net/ipv6/udp.c	2013-11-01 18:44:59.277865155 +0200
@@ -1162,7 +1162,7 @@
 	fptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);
 	fptr->nexthdr = nexthdr;
 	fptr->reserved = 0;
-	ipv6_select_ident(fptr);
+	ipv6_select_ident(fptr, (struct rt6_info *)skb_dst(skb));
 
 	/* Fragment the skb. ipv6 header and the remaining fields of the
 	 * fragment header are updated in ipv6_gso_segment()
diff -Naur a/net/ipv6/xfrm6_mode_beet.c b/net/ipv6/xfrm6_mode_beet.c
--- a/net/ipv6/xfrm6_mode_beet.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv6/xfrm6_mode_beet.c	2013-11-01 18:44:59.277865155 +0200
@@ -82,7 +82,6 @@
 static int xfrm6_beet_input(struct xfrm_state *x, struct sk_buff *skb)
 {
 	struct ipv6hdr *ip6h;
-	const unsigned char *old_mac;
 	int size = sizeof(struct ipv6hdr);
 	int err;
 
@@ -92,10 +91,7 @@
 
 	__skb_push(skb, size);
 	skb_reset_network_header(skb);
-
-	old_mac = skb_mac_header(skb);
-	skb_set_mac_header(skb, -skb->mac_len);
-	memmove(skb_mac_header(skb), old_mac, skb->mac_len);
+	skb_mac_header_rebuild(skb);
 
 	xfrm6_beet_make_header(skb);
 
diff -Naur a/net/ipv6/xfrm6_mode_tunnel.c b/net/ipv6/xfrm6_mode_tunnel.c
--- a/net/ipv6/xfrm6_mode_tunnel.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/ipv6/xfrm6_mode_tunnel.c	2013-11-01 18:44:59.277865155 +0200
@@ -61,7 +61,6 @@
 static int xfrm6_mode_tunnel_input(struct xfrm_state *x, struct sk_buff *skb)
 {
 	int err = -EINVAL;
-	const unsigned char *old_mac;
 
 	if (XFRM_MODE_SKB_CB(skb)->protocol != IPPROTO_IPV6)
 		goto out;
@@ -78,10 +77,9 @@
 	if (!(x->props.flags & XFRM_STATE_NOECN))
 		ipip6_ecn_decapsulate(skb);
 
-	old_mac = skb_mac_header(skb);
-	skb_set_mac_header(skb, -skb->mac_len);
-	memmove(skb_mac_header(skb), old_mac, skb->mac_len);
 	skb_reset_network_header(skb);
+	skb_mac_header_rebuild(skb);
+
 	err = 0;
 
 out:
diff -Naur a/net/irda/af_irda.c b/net/irda/af_irda.c
--- a/net/irda/af_irda.c	2013-11-01 20:18:06.169569050 +0200
+++ b/net/irda/af_irda.c	2013-11-01 18:44:59.441865987 +0200
@@ -1338,6 +1338,8 @@
 	if ((err = sock_error(sk)) < 0)
 		return err;
 
+	msg->msg_namelen = 0;
+
 	skb = skb_recv_datagram(sk, flags & ~MSG_DONTWAIT,
 				flags & MSG_DONTWAIT, &err);
 	if (!skb)
diff -Naur a/net/iucv/af_iucv.c b/net/iucv/af_iucv.c
--- a/net/iucv/af_iucv.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/iucv/af_iucv.c	2013-11-01 18:44:59.469866108 +0200
@@ -1160,6 +1160,8 @@
 	struct sk_buff *skb, *rskb, *cskb;
 	int err = 0;
 
+	msg->msg_namelen = 0;
+
 	if ((sk->sk_state == IUCV_DISCONN || sk->sk_state == IUCV_SEVERED) &&
 	    skb_queue_empty(&iucv->backlog_skb_q) &&
 	    skb_queue_empty(&sk->sk_receive_queue) &&
diff -Naur a/net/llc/af_llc.c b/net/llc/af_llc.c
--- a/net/llc/af_llc.c	2013-11-01 20:18:06.177569089 +0200
+++ b/net/llc/af_llc.c	2013-11-01 18:44:59.821867841 +0200
@@ -674,6 +674,8 @@
 	int target;	/* Read at least this many bytes */
 	long timeo;
 
+	msg->msg_namelen = 0;
+
 	lock_sock(sk);
 	copied = -ENOTCONN;
 	if (unlikely(sk->sk_type == SOCK_STREAM && sk->sk_state == TCP_LISTEN))
@@ -912,14 +914,13 @@
 	struct sockaddr_llc sllc;
 	struct sock *sk = sock->sk;
 	struct llc_sock *llc = llc_sk(sk);
-	int rc = 0;
+	int rc = -EBADF;
 
 	memset(&sllc, 0, sizeof(sllc));
 	lock_sock(sk);
 	if (sock_flag(sk, SOCK_ZAPPED))
 		goto out;
 	*uaddrlen = sizeof(sllc);
-	memset(uaddr, 0, *uaddrlen);
 	if (peer) {
 		rc = -ENOTCONN;
 		if (sk->sk_state != TCP_ESTABLISHED)
diff -Naur a/net/netfilter/ipvs/ip_vs_ctl.c b/net/netfilter/ipvs/ip_vs_ctl.c
--- a/net/netfilter/ipvs/ip_vs_ctl.c	2013-11-01 20:18:06.205569228 +0200
+++ b/net/netfilter/ipvs/ip_vs_ctl.c	2013-11-01 18:44:59.881868138 +0200
@@ -2455,6 +2455,7 @@
 	{
 		struct ip_vs_timeout_user t;
 
+		memset(&t, 0, sizeof(t));
 		__ip_vs_get_timeouts(&t);
 		if (copy_to_user(user, &t, sizeof(t)) != 0)
 			ret = -EFAULT;
diff -Naur a/net/netfilter/ipvs/ip_vs_xmit.c b/net/netfilter/ipvs/ip_vs_xmit.c
--- a/net/netfilter/ipvs/ip_vs_xmit.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/netfilter/ipvs/ip_vs_xmit.c	2013-11-01 18:44:59.885868167 +0200
@@ -64,6 +64,15 @@
 	return dst;
 }
 
+static inline bool
+__mtu_check_toobig_v6(const struct sk_buff *skb, u32 mtu)
+{
+	if (skb->len > mtu && !skb_is_gso(skb)) {
+		return true; /* Packet size violate MTU size */
+	}
+	return false;
+}
+
 static struct rtable *
 __ip_vs_get_out_rt(struct ip_vs_conn *cp, u32 rtos)
 {
@@ -245,7 +254,8 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF))) {
+	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF)) &&
+	    !skb_is_gso(skb)) {
 		ip_rt_put(rt);
 		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -309,7 +319,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if (skb->len > mtu) {
+	if (__mtu_check_toobig_v6(skb, mtu)) {
 		dst_release(&rt->u.dst);
 		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -376,7 +386,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF))) {
+	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF)) && !skb_is_gso(skb)) {
 		ip_rt_put(rt);
 		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
 		IP_VS_DBG_RL_PKT(0, pp, skb, 0, "ip_vs_nat_xmit(): frag needed for");
@@ -452,7 +462,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if (skb->len > mtu) {
+	if (__mtu_check_toobig_v6(skb, mtu)) {
 		dst_release(&rt->u.dst);
 		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
 		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
@@ -561,8 +571,8 @@
 
 	df |= (old_iph->frag_off & htons(IP_DF));
 
-	if ((old_iph->frag_off & htons(IP_DF))
-	    && mtu < ntohs(old_iph->tot_len)) {
+	if ((old_iph->frag_off & htons(IP_DF) &&
+	    mtu < ntohs(old_iph->tot_len) && !skb_is_gso(skb))) {
 		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
 		ip_rt_put(rt);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -671,7 +681,8 @@
 	if (skb_dst(skb))
 		skb_dst(skb)->ops->update_pmtu(skb_dst(skb), mtu);
 
-	if (mtu < ntohs(old_iph->payload_len) + sizeof(struct ipv6hdr)) {
+	/* MTU checking: Notice that 'mtu' have been adjusted before hand */
+	if (__mtu_check_toobig_v6(skb, mtu)) {
 		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
 		dst_release(&rt->u.dst);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -760,7 +771,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if ((iph->frag_off & htons(IP_DF)) && skb->len > mtu) {
+	if ((iph->frag_off & htons(IP_DF)) && skb->len > mtu && !skb_is_gso(skb)) {
 		icmp_send(skb, ICMP_DEST_UNREACH,ICMP_FRAG_NEEDED, htonl(mtu));
 		ip_rt_put(rt);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -813,7 +824,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if (skb->len > mtu) {
+	if (__mtu_check_toobig_v6(skb, mtu)) {
 		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
 		dst_release(&rt->u.dst);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -888,7 +899,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if ((skb->len > mtu) && (ip_hdr(skb)->frag_off & htons(IP_DF))) {
+	if ((skb->len > mtu) && (ip_hdr(skb)->frag_off & htons(IP_DF)) && !skb_is_gso(skb)) {
 		ip_rt_put(rt);
 		icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
@@ -963,7 +974,7 @@
 
 	/* MTU checking */
 	mtu = dst_mtu(&rt->u.dst);
-	if (skb->len > mtu) {
+	if (__mtu_check_toobig_v6(skb, mtu)) {
 		dst_release(&rt->u.dst);
 		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
 		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
diff -Naur a/net/netlink/af_netlink.c b/net/netlink/af_netlink.c
--- a/net/netlink/af_netlink.c	2013-11-01 20:18:06.221569303 +0200
+++ b/net/netlink/af_netlink.c	2013-11-01 18:45:00.065869057 +0200
@@ -821,12 +821,19 @@
 	return 0;
 }
 
-int netlink_sendskb(struct sock *sk, struct sk_buff *skb)
+static int __netlink_sendskb(struct sock *sk, struct sk_buff *skb)
 {
 	int len = skb->len;
 
 	skb_queue_tail(&sk->sk_receive_queue, skb);
 	sk->sk_data_ready(sk, len);
+	return len;
+}
+
+int netlink_sendskb(struct sock *sk, struct sk_buff *skb)
+{
+	int len = __netlink_sendskb(sk, skb);
+
 	sock_put(sk);
 	return len;
 }
@@ -951,8 +958,7 @@
 	if (atomic_read(&sk->sk_rmem_alloc) <= sk->sk_rcvbuf &&
 	    !test_bit(0, &nlk->state)) {
 		skb_set_owner_r(skb, sk);
-		skb_queue_tail(&sk->sk_receive_queue, skb);
-		sk->sk_data_ready(sk, skb->len);
+		__netlink_sendskb(sk, skb);
 		return atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf;
 	}
 	return -1;
@@ -1665,10 +1671,8 @@
 
 		if (sk_filter(sk, skb))
 			kfree_skb(skb);
-		else {
-			skb_queue_tail(&sk->sk_receive_queue, skb);
-			sk->sk_data_ready(sk, skb->len);
-		}
+		else
+			__netlink_sendskb(sk, skb);
 		return 0;
 	}
 
@@ -1680,10 +1684,8 @@
 
 	if (sk_filter(sk, skb))
 		kfree_skb(skb);
-	else {
-		skb_queue_tail(&sk->sk_receive_queue, skb);
-		sk->sk_data_ready(sk, skb->len);
-	}
+	else
+		__netlink_sendskb(sk, skb);
 
 	if (cb->done)
 		cb->done(cb);
diff -Naur a/net/packet/af_packet.c b/net/packet/af_packet.c
--- a/net/packet/af_packet.c	2013-11-01 20:18:06.221569303 +0200
+++ b/net/packet/af_packet.c	2013-11-01 18:45:00.089869176 +0200
@@ -828,7 +828,6 @@
 
 	if (likely(po->tx_ring.pg_vec)) {
 		ph = skb_shinfo(skb)->destructor_arg;
-		BUG_ON(__packet_get_status(po, ph) != TP_STATUS_SENDING);
 		BUG_ON(atomic_read(&po->tx_ring.pending) == 0);
 		atomic_dec(&po->tx_ring.pending);
 		__packet_set_status(po, ph, TP_STATUS_AVAILABLE);
diff -Naur a/net/phonet/pep.c b/net/phonet/pep.c
--- a/net/phonet/pep.c	2013-11-01 20:18:06.225569324 +0200
+++ b/net/phonet/pep.c	2013-11-01 18:45:00.093869202 +0200
@@ -851,6 +851,9 @@
 	int flags = msg->msg_flags;
 	int err, done;
 
+	if (len > 65535)
+		return -EMSGSIZE;
+
 	if (msg->msg_flags & MSG_OOB || !(msg->msg_flags & MSG_EOR))
 		return -EOPNOTSUPP;
 
diff -Naur a/net/rds/recv.c b/net/rds/recv.c
--- a/net/rds/recv.c	2013-11-01 20:18:06.229569353 +0200
+++ b/net/rds/recv.c	2013-11-01 18:45:00.113869295 +0200
@@ -410,6 +410,8 @@
 
 	rdsdebug("size %zu flags 0x%x timeo %ld\n", size, msg_flags, timeo);
 
+	msg->msg_namelen = 0;
+
 	if (msg_flags & MSG_OOB)
 		goto out;
 
@@ -486,6 +488,7 @@
 			sin->sin_port = inc->i_hdr.h_sport;
 			sin->sin_addr.s_addr = inc->i_saddr;
 			memset(sin->sin_zero, 0, sizeof(sin->sin_zero));
+			msg->msg_namelen = sizeof(*sin);
 		}
 		break;
 	}
diff -Naur a/net/rose/af_rose.c b/net/rose/af_rose.c
--- a/net/rose/af_rose.c	2013-11-01 20:18:06.229569353 +0200
+++ b/net/rose/af_rose.c	2013-11-01 18:45:00.117869314 +0200
@@ -983,7 +983,7 @@
 	struct sock *make;
 	struct rose_sock *make_rose;
 	struct rose_facilities_struct facilities;
-	int n, len;
+	int n;
 
 	skb->sk = NULL;		/* Initially we don't know who it's for */
 
@@ -992,9 +992,9 @@
 	 */
 	memset(&facilities, 0x00, sizeof(struct rose_facilities_struct));
 
-	len  = (((skb->data[3] >> 4) & 0x0F) + 1) >> 1;
-	len += (((skb->data[3] >> 0) & 0x0F) + 1) >> 1;
-	if (!rose_parse_facilities(skb->data + len + 4, &facilities)) {
+	if (!rose_parse_facilities(skb->data + ROSE_CALL_REQ_FACILITIES_OFF,
+				   skb->len - ROSE_CALL_REQ_FACILITIES_OFF,
+				   &facilities)) {
 		rose_transmit_clear_request(neigh, lci, ROSE_INVALID_FACILITY, 76);
 		return 0;
 	}
@@ -1275,6 +1275,7 @@
 	skb_copy_datagram_iovec(skb, 0, msg->msg_iov, copied);
 
 	if (srose != NULL) {
+		memset(srose, 0, msg->msg_namelen);
 		srose->srose_family = AF_ROSE;
 		srose->srose_addr   = rose->dest_addr;
 		srose->srose_call   = rose->dest_call;
diff -Naur a/net/rose/rose_loopback.c b/net/rose/rose_loopback.c
--- a/net/rose/rose_loopback.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/rose/rose_loopback.c	2013-11-01 18:45:00.117869314 +0200
@@ -72,9 +72,20 @@
 	unsigned int lci_i, lci_o;
 
 	while ((skb = skb_dequeue(&loopback_queue)) != NULL) {
+		if (skb->len < ROSE_MIN_LEN) {
+			kfree_skb(skb);
+			continue;
+		}
 		lci_i     = ((skb->data[0] << 8) & 0xF00) + ((skb->data[1] << 0) & 0x0FF);
 		frametype = skb->data[2];
-		dest      = (rose_address *)(skb->data + 4);
+		if (frametype == ROSE_CALL_REQUEST &&
+		    (skb->len <= ROSE_CALL_REQ_FACILITIES_OFF ||
+		     skb->data[ROSE_CALL_REQ_ADDR_LEN_OFF] !=
+		     ROSE_CALL_REQ_ADDR_LEN_VAL)) {
+			kfree_skb(skb);
+			continue;
+		}
+		dest      = (rose_address *)(skb->data + ROSE_CALL_REQ_DEST_ADDR_OFF);
 		lci_o     = 0xFFF - lci_i;
 
 		skb_reset_transport_header(skb);
diff -Naur a/net/rose/rose_route.c b/net/rose/rose_route.c
--- a/net/rose/rose_route.c	2013-11-01 20:18:06.233569369 +0200
+++ b/net/rose/rose_route.c	2013-11-01 18:45:00.117869314 +0200
@@ -852,7 +852,7 @@
 	unsigned int lci, new_lci;
 	unsigned char cause, diagnostic;
 	struct net_device *dev;
-	int len, res = 0;
+	int res = 0;
 	char buf[11];
 
 #if 0
@@ -860,10 +860,17 @@
 		return res;
 #endif
 
+	if (skb->len < ROSE_MIN_LEN)
+		return res;
 	frametype = skb->data[2];
 	lci = ((skb->data[0] << 8) & 0xF00) + ((skb->data[1] << 0) & 0x0FF);
-	src_addr  = (rose_address *)(skb->data + 9);
-	dest_addr = (rose_address *)(skb->data + 4);
+	if (frametype == ROSE_CALL_REQUEST &&
+	    (skb->len <= ROSE_CALL_REQ_FACILITIES_OFF ||
+	     skb->data[ROSE_CALL_REQ_ADDR_LEN_OFF] !=
+	     ROSE_CALL_REQ_ADDR_LEN_VAL))
+		return res;
+	src_addr  = (rose_address *)(skb->data + ROSE_CALL_REQ_SRC_ADDR_OFF);
+	dest_addr = (rose_address *)(skb->data + ROSE_CALL_REQ_DEST_ADDR_OFF);
 
 	spin_lock_bh(&rose_neigh_list_lock);
 	spin_lock_bh(&rose_route_list_lock);
@@ -1001,12 +1008,11 @@
 		goto out;
 	}
 
-	len  = (((skb->data[3] >> 4) & 0x0F) + 1) >> 1;
-	len += (((skb->data[3] >> 0) & 0x0F) + 1) >> 1;
-
 	memset(&facilities, 0x00, sizeof(struct rose_facilities_struct));
 
-	if (!rose_parse_facilities(skb->data + len + 4, &facilities)) {
+	if (!rose_parse_facilities(skb->data + ROSE_CALL_REQ_FACILITIES_OFF,
+				   skb->len - ROSE_CALL_REQ_FACILITIES_OFF,
+				   &facilities)) {
 		rose_transmit_clear_request(rose_neigh, lci, ROSE_INVALID_FACILITY, 76);
 		goto out;
 	}
diff -Naur a/net/rose/rose_subr.c b/net/rose/rose_subr.c
--- a/net/rose/rose_subr.c	2013-11-01 20:18:06.233569369 +0200
+++ b/net/rose/rose_subr.c	2013-11-01 18:45:00.117869314 +0200
@@ -141,7 +141,7 @@
 		*dptr++ = ROSE_GFI | lci1;
 		*dptr++ = lci2;
 		*dptr++ = frametype;
-		*dptr++ = 0xAA;
+		*dptr++ = ROSE_CALL_REQ_ADDR_LEN_VAL;
 		memcpy(dptr, &rose->dest_addr,  ROSE_ADDR_LEN);
 		dptr   += ROSE_ADDR_LEN;
 		memcpy(dptr, &rose->source_addr, ROSE_ADDR_LEN);
@@ -245,12 +245,16 @@
 	do {
 		switch (*p & 0xC0) {
 		case 0x00:
+			if (len < 2)
+				return -1;
 			p   += 2;
 			n   += 2;
 			len -= 2;
 			break;
 
 		case 0x40:
+			if (len < 3)
+				return -1;
 			if (*p == FAC_NATIONAL_RAND)
 				facilities->rand = ((p[1] << 8) & 0xFF00) + ((p[2] << 0) & 0x00FF);
 			p   += 3;
@@ -259,32 +263,48 @@
 			break;
 
 		case 0x80:
+			if (len < 4)
+				return -1;
 			p   += 4;
 			n   += 4;
 			len -= 4;
 			break;
 
 		case 0xC0:
+			if (len < 2)
+				return -1;
 			l = p[1];
+			if (len < 2 + l)
+				return -1;
 			if (*p == FAC_NATIONAL_DEST_DIGI) {
 				if (!fac_national_digis_received) {
+					if (l < AX25_ADDR_LEN)
+						return -1;
 					memcpy(&facilities->source_digis[0], p + 2, AX25_ADDR_LEN);
 					facilities->source_ndigis = 1;
 				}
 			}
 			else if (*p == FAC_NATIONAL_SRC_DIGI) {
 				if (!fac_national_digis_received) {
+					if (l < AX25_ADDR_LEN)
+						return -1;
 					memcpy(&facilities->dest_digis[0], p + 2, AX25_ADDR_LEN);
 					facilities->dest_ndigis = 1;
 				}
 			}
 			else if (*p == FAC_NATIONAL_FAIL_CALL) {
+				if (l < AX25_ADDR_LEN)
+					return -1;
 				memcpy(&facilities->fail_call, p + 2, AX25_ADDR_LEN);
 			}
 			else if (*p == FAC_NATIONAL_FAIL_ADD) {
+				if (l < 1 + ROSE_ADDR_LEN)
+					return -1;
 				memcpy(&facilities->fail_addr, p + 3, ROSE_ADDR_LEN);
 			}
 			else if (*p == FAC_NATIONAL_DIGIS) {
+				if (l % AX25_ADDR_LEN)
+					return -1;
 				fac_national_digis_received = 1;
 				facilities->source_ndigis = 0;
 				facilities->dest_ndigis   = 0;
@@ -318,24 +338,32 @@
 	do {
 		switch (*p & 0xC0) {
 		case 0x00:
+			if (len < 2)
+				return -1;
 			p   += 2;
 			n   += 2;
 			len -= 2;
 			break;
 
 		case 0x40:
+			if (len < 3)
+				return -1;
 			p   += 3;
 			n   += 3;
 			len -= 3;
 			break;
 
 		case 0x80:
+			if (len < 4)
+				return -1;
 			p   += 4;
 			n   += 4;
 			len -= 4;
 			break;
 
 		case 0xC0:
+			if (len < 2)
+				return -1;
 			l = p[1];
 
 			/* Prevent overflows*/
@@ -364,49 +392,44 @@
 	return n;
 }
 
-int rose_parse_facilities(unsigned char *p,
+int rose_parse_facilities(unsigned char *p, unsigned packet_len,
 	struct rose_facilities_struct *facilities)
 {
 	int facilities_len, len;
 
 	facilities_len = *p++;
 
-	if (facilities_len == 0)
+	if (facilities_len == 0 || (unsigned)facilities_len > packet_len)
 		return 0;
 
-	while (facilities_len > 0) {
-		if (*p == 0x00) {
-			facilities_len--;
-			p++;
-
-			switch (*p) {
-			case FAC_NATIONAL:		/* National */
-				len = rose_parse_national(p + 1, facilities, facilities_len - 1);
-				if (len < 0)
-					return 0;
-				facilities_len -= len + 1;
-				p += len + 1;
-				break;
-
-			case FAC_CCITT:		/* CCITT */
-				len = rose_parse_ccitt(p + 1, facilities, facilities_len - 1);
-				if (len < 0)
-					return 0;
-				facilities_len -= len + 1;
-				p += len + 1;
-				break;
-
-			default:
-				printk(KERN_DEBUG "ROSE: rose_parse_facilities - unknown facilities family %02X\n", *p);
-				facilities_len--;
-				p++;
-				break;
-			}
-		} else
-			break;	/* Error in facilities format */
+	while (facilities_len >= 3 && *p == 0x00) {
+		facilities_len--;
+		p++;
+
+		switch (*p) {
+		case FAC_NATIONAL:		/* National */
+			len = rose_parse_national(p + 1, facilities, facilities_len - 1);
+			break;
+
+		case FAC_CCITT:		/* CCITT */
+			len = rose_parse_ccitt(p + 1, facilities, facilities_len - 1);
+			break;
+
+		default:
+			printk(KERN_DEBUG "ROSE: rose_parse_facilities - unknown facilities family %02X\n", *p);
+			len = 1;
+			break;
+		}
+
+		if (len < 0)
+			return 0;
+		if (WARN_ON(len >= facilities_len))
+			return 0;
+		facilities_len -= len + 1;
+		p += len + 1;
 	}
 
-	return 1;
+	return facilities_len == 0;
 }
 
 static int rose_create_facilities(unsigned char *buffer, struct rose_sock *rose)
diff -Naur a/net/sched/act_gact.c b/net/sched/act_gact.c
--- a/net/sched/act_gact.c	2013-11-01 20:18:06.233569369 +0200
+++ b/net/sched/act_gact.c	2013-11-01 18:45:00.129869372 +0200
@@ -67,6 +67,9 @@
 	struct tcf_common *pc;
 	int ret = 0;
 	int err;
+#ifdef CONFIG_GACT_PROB
+	struct tc_gact_p *p_parm = NULL;
+#endif
 
 	if (nla == NULL)
 		return -EINVAL;
@@ -82,6 +85,12 @@
 #ifndef CONFIG_GACT_PROB
 	if (tb[TCA_GACT_PROB] != NULL)
 		return -EOPNOTSUPP;
+#else
+	if (tb[TCA_GACT_PROB]) {
+		p_parm = nla_data(tb[TCA_GACT_PROB]);
+		if (p_parm->ptype >= MAX_RAND)
+			return -EINVAL;
+	}
 #endif
 
 	pc = tcf_hash_check(parm->index, a, bind, &gact_hash_info);
@@ -103,8 +112,7 @@
 	spin_lock_bh(&gact->tcf_lock);
 	gact->tcf_action = parm->action;
 #ifdef CONFIG_GACT_PROB
-	if (tb[TCA_GACT_PROB] != NULL) {
-		struct tc_gact_p *p_parm = nla_data(tb[TCA_GACT_PROB]);
+	if (p_parm) {
 		gact->tcfg_paction = p_parm->paction;
 		gact->tcfg_pval    = p_parm->pval;
 		gact->tcfg_ptype   = p_parm->ptype;
@@ -132,7 +140,7 @@
 
 	spin_lock(&gact->tcf_lock);
 #ifdef CONFIG_GACT_PROB
-	if (gact->tcfg_ptype && gact_rand[gact->tcfg_ptype] != NULL)
+	if (gact->tcfg_ptype)
 		action = gact_rand[gact->tcfg_ptype](gact);
 	else
 		action = gact->tcf_action;
diff -Naur a/net/sched/sch_gred.c b/net/sched/sch_gred.c
--- a/net/sched/sch_gred.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sched/sch_gred.c	2013-11-01 18:45:00.153869494 +0200
@@ -544,11 +544,8 @@
 		opt.packets	= q->packetsin;
 		opt.bytesin	= q->bytesin;
 
-		if (gred_wred_mode(table)) {
-			q->parms.qidlestart =
-				table->tab[table->def]->parms.qidlestart;
-			q->parms.qavg = table->tab[table->def]->parms.qavg;
-		}
+		if (gred_wred_mode(table))
+			gred_load_wred_set(table, q);
 
 		opt.qave = red_calc_qavg(&q->parms, q->parms.qavg);
 
diff -Naur a/net/sched/sch_htb.c b/net/sched/sch_htb.c
--- a/net/sched/sch_htb.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sched/sch_htb.c	2013-11-01 18:45:00.153869494 +0200
@@ -865,7 +865,7 @@
 	q->now = psched_get_time();
 	start_at = jiffies;
 
-	next_event = q->now + 5 * PSCHED_TICKS_PER_SEC;
+	next_event = q->now + 5LLU * PSCHED_TICKS_PER_SEC;
 
 	for (level = 0; level < TC_HTB_MAXDEPTH; level++) {
 		/* common case optimization - skip event handler quickly */
diff -Naur a/net/sched/sch_netem.c b/net/sched/sch_netem.c
--- a/net/sched/sch_netem.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sched/sch_netem.c	2013-11-01 18:45:00.157869511 +0200
@@ -199,12 +199,10 @@
 	 * do it now in software before we mangle it.
 	 */
 	if (q->corrupt && q->corrupt >= get_crandom(&q->corrupt_cor)) {
-		if (!(skb = skb_unshare(skb, GFP_ATOMIC))
-		    || (skb->ip_summed == CHECKSUM_PARTIAL
-			&& skb_checksum_help(skb))) {
-			sch->qstats.drops++;
-			return NET_XMIT_DROP;
-		}
+		if (!(skb = skb_unshare(skb, GFP_ATOMIC)) ||
+		    (skb->ip_summed == CHECKSUM_PARTIAL &&
+		     skb_checksum_help(skb)))
+			return qdisc_drop(skb, sch);
 
 		skb->data[net_random() % skb_headlen(skb)] ^= 1<<(net_random() % 8);
 	}
diff -Naur a/net/sctp/auth.c b/net/sctp/auth.c
--- a/net/sctp/auth.c	2013-11-01 20:18:06.241569405 +0200
+++ b/net/sctp/auth.c	2013-11-01 18:45:00.161869538 +0200
@@ -70,7 +70,7 @@
 		return;
 
 	if (atomic_dec_and_test(&key->refcnt)) {
-		kfree(key);
+		kzfree(key);
 		SCTP_DBG_OBJCNT_DEC(keys);
 	}
 }
diff -Naur a/net/sctp/chunk.c b/net/sctp/chunk.c
--- a/net/sctp/chunk.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sctp/chunk.c	2013-11-01 18:45:00.161869538 +0200
@@ -272,7 +272,7 @@
 			goto errout;
 		err = sctp_user_addto_chunk(chunk, offset, len, msgh->msg_iov);
 		if (err < 0)
-			goto errout;
+			goto errout_chunk_free;
 
 		offset += len;
 
@@ -308,7 +308,7 @@
 		__skb_pull(chunk->skb, (__u8 *)chunk->chunk_hdr
 			   - (__u8 *)chunk->skb->data);
 		if (err < 0)
-			goto errout;
+			goto errout_chunk_free;
 
 		sctp_datamsg_assign(msg, chunk);
 		list_add_tail(&chunk->frag_list, &msg->chunks);
@@ -316,6 +316,9 @@
 
 	return msg;
 
+errout_chunk_free:
+	sctp_chunk_free(chunk);
+
 errout:
 	list_for_each_safe(pos, temp, &msg->chunks) {
 		list_del_init(pos);
diff -Naur a/net/sctp/endpointola.c b/net/sctp/endpointola.c
--- a/net/sctp/endpointola.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sctp/endpointola.c	2013-11-01 18:45:00.161869538 +0200
@@ -249,6 +249,8 @@
 /* Final destructor for endpoint.  */
 static void sctp_endpoint_destroy(struct sctp_endpoint *ep)
 {
+	int i;
+
 	SCTP_ASSERT(ep->base.dead, "Endpoint is not dead", return);
 
 	/* Free up the HMAC transform. */
@@ -271,6 +273,9 @@
 	sctp_inq_free(&ep->base.inqueue);
 	sctp_bind_addr_free(&ep->base.bind_addr);
 
+	for (i = 0; i < SCTP_HOW_MANY_SECRETS; ++i)
+		memset(&ep->secret_key[i], 0, SCTP_SECRET_SIZE);
+
 	/* Remove and free the port */
 	if (sctp_sk(ep->base.sk)->bind_hash)
 		sctp_put_port(ep->base.sk);
diff -Naur a/net/sctp/input.c b/net/sctp/input.c
--- a/net/sctp/input.c	2013-11-01 20:18:06.245569432 +0200
+++ b/net/sctp/input.c	2013-11-01 18:45:00.161869538 +0200
@@ -739,15 +739,12 @@
 
 	epb = &ep->base;
 
-	if (hlist_unhashed(&epb->node))
-		return;
-
 	epb->hashent = sctp_ep_hashfn(epb->bind_addr.port);
 
 	head = &sctp_ep_hashtable[epb->hashent];
 
 	sctp_write_lock(&head->lock);
-	__hlist_del(&epb->node);
+	hlist_del_init(&epb->node);
 	sctp_write_unlock(&head->lock);
 }
 
@@ -828,7 +825,7 @@
 	head = &sctp_assoc_hashtable[epb->hashent];
 
 	sctp_write_lock(&head->lock);
-	__hlist_del(&epb->node);
+	hlist_del_init(&epb->node);
 	sctp_write_unlock(&head->lock);
 }
 
diff -Naur a/net/sctp/socket.c b/net/sctp/socket.c
--- a/net/sctp/socket.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/sctp/socket.c	2013-11-01 18:45:00.181869632 +0200
@@ -1142,8 +1142,14 @@
 	SCTP_DEBUG_PRINTK("About to exit __sctp_connect() free asoc: %p"
 			  " kaddrs: %p err: %d\n",
 			  asoc, kaddrs, err);
-	if (asoc)
+	if (asoc) {
+		/* sctp_primitive_ASSOCIATE may have added this association
+		 * To the hash table, try to unhash it, just in case, its a noop
+		 * if it wasn't hashed so we're safe
+		 */
+		sctp_unhash_established(asoc);
 		sctp_association_free(asoc);
+	}
 	return err;
 }
 
@@ -1851,8 +1857,10 @@
 	goto out_unlock;
 
 out_free:
-	if (new_asoc)
+	if (new_asoc) {
+		sctp_unhash_established(asoc);
 		sctp_association_free(asoc);
+	}
 out_unlock:
 	sctp_release_sock(sk);
 
@@ -3263,7 +3271,7 @@
 
 	ret = sctp_auth_set_key(sctp_sk(sk)->ep, asoc, authkey);
 out:
-	kfree(authkey);
+	kzfree(authkey);
 	return ret;
 }
 
diff -Naur a/net/socket.c b/net/socket.c
--- a/net/socket.c	2013-11-01 20:18:06.261569511 +0200
+++ b/net/socket.c	2013-11-01 18:45:00.185869652 +0200
@@ -732,9 +732,9 @@
 
 	sock = file->private_data;
 
-	flags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;
-	if (more)
-		flags |= MSG_MORE;
+	flags = (file->f_flags & O_NONBLOCK) ? MSG_DONTWAIT : 0;
+	/* more is a combination of MSG_MORE and MSG_SENDPAGE_NOTLAST */
+	flags |= more;
 
 	return kernel_sendpage(sock, page, offset, size, flags);
 }
diff -Naur a/net/sunrpc/cache.c b/net/sunrpc/cache.c
--- a/net/sunrpc/cache.c	2013-11-01 20:18:06.265569525 +0200
+++ b/net/sunrpc/cache.c	2013-11-01 18:45:00.233869889 +0200
@@ -719,6 +719,8 @@
 {
 	ssize_t ret;
 
+	if (count == 0)
+		return -EINVAL;
 	if (copy_from_user(kaddr, buf, count))
 		return -EFAULT;
 	kaddr[count] = '\0';
diff -Naur a/net/sunrpc/rpc_pipe.c b/net/sunrpc/rpc_pipe.c
--- a/net/sunrpc/rpc_pipe.c	2013-11-01 20:18:06.269569544 +0200
+++ b/net/sunrpc/rpc_pipe.c	2013-11-01 18:45:00.237869910 +0200
@@ -459,7 +459,7 @@
 {
 	struct inode *inode;
 
-	BUG_ON(!d_unhashed(dentry));
+	d_drop(dentry);
 	inode = rpc_get_inode(dir->i_sb, mode);
 	if (!inode)
 		goto out_err;
diff -Naur a/net/sunrpc/sched.c b/net/sunrpc/sched.c
--- a/net/sunrpc/sched.c	2013-11-01 20:18:06.273569571 +0200
+++ b/net/sunrpc/sched.c	2013-11-01 18:45:00.237869910 +0200
@@ -485,14 +485,18 @@
  */
 void rpc_wake_up(struct rpc_wait_queue *queue)
 {
-	struct rpc_task *task, *next;
 	struct list_head *head;
 
 	spin_lock_bh(&queue->lock);
 	head = &queue->tasks[queue->maxpriority];
 	for (;;) {
-		list_for_each_entry_safe(task, next, head, u.tk_wait.list)
+		while (!list_empty(head)) {
+			struct rpc_task *task;
+			task = list_first_entry(head,
+					struct rpc_task,
+					u.tk_wait.list);
 			rpc_wake_up_task_queue_locked(queue, task);
+		}
 		if (head == &queue->tasks[0])
 			break;
 		head--;
@@ -510,13 +514,16 @@
  */
 void rpc_wake_up_status(struct rpc_wait_queue *queue, int status)
 {
-	struct rpc_task *task, *next;
 	struct list_head *head;
 
 	spin_lock_bh(&queue->lock);
 	head = &queue->tasks[queue->maxpriority];
 	for (;;) {
-		list_for_each_entry_safe(task, next, head, u.tk_wait.list) {
+		while (!list_empty(head)) {
+			struct rpc_task *task;
+			task = list_first_entry(head,
+					struct rpc_task,
+					u.tk_wait.list);
 			task->tk_status = status;
 			rpc_wake_up_task_queue_locked(queue, task);
 		}
diff -Naur a/net/sunrpc/svc_xprt.c b/net/sunrpc/svc_xprt.c
--- a/net/sunrpc/svc_xprt.c	2013-11-01 20:18:06.277569584 +0200
+++ b/net/sunrpc/svc_xprt.c	2013-11-01 18:45:00.241869936 +0200
@@ -304,7 +304,6 @@
  */
 void svc_xprt_enqueue(struct svc_xprt *xprt)
 {
-	struct svc_serv	*serv = xprt->xpt_server;
 	struct svc_pool *pool;
 	struct svc_rqst	*rqstp;
 	int cpu;
@@ -381,8 +380,6 @@
 				rqstp, rqstp->rq_xprt);
 		rqstp->rq_xprt = xprt;
 		svc_xprt_get(xprt);
-		rqstp->rq_reserved = serv->sv_max_mesg;
-		atomic_add(rqstp->rq_reserved, &xprt->xpt_reserved);
 		rqstp->rq_waking = 1;
 		pool->sp_nwaking++;
 		pool->sp_stats.threads_woken++;
@@ -667,8 +664,6 @@
 	if (xprt) {
 		rqstp->rq_xprt = xprt;
 		svc_xprt_get(xprt);
-		rqstp->rq_reserved = serv->sv_max_mesg;
-		atomic_add(rqstp->rq_reserved, &xprt->xpt_reserved);
 	} else {
 		/* No data pending. Go to sleep */
 		svc_thread_enqueue(pool, rqstp);
@@ -758,6 +753,8 @@
 		} else
 			len = xprt->xpt_ops->xpo_recvfrom(rqstp);
 		dprintk("svc: got len=%d\n", len);
+		rqstp->rq_reserved = serv->sv_max_mesg;
+		atomic_add(rqstp->rq_reserved, &xprt->xpt_reserved);
 	}
 
 	/* No data, incomplete (TCP) read, or accept() */
@@ -811,7 +808,8 @@
 
 	/* Grab mutex to serialize outgoing data. */
 	mutex_lock(&xprt->xpt_mutex);
-	if (test_bit(XPT_DEAD, &xprt->xpt_flags))
+	if (test_bit(XPT_DEAD, &xprt->xpt_flags)
+			|| test_bit(XPT_CLOSE, &xprt->xpt_flags))
 		len = -ENOTCONN;
 	else
 		len = xprt->xpt_ops->xpo_sendto(rqstp);
diff -Naur a/net/tipc/socket.c b/net/tipc/socket.c
--- a/net/tipc/socket.c	2013-11-01 20:18:06.285569621 +0200
+++ b/net/tipc/socket.c	2013-11-01 18:45:00.285870150 +0200
@@ -800,6 +800,7 @@
 	if (addr) {
 		addr->family = AF_TIPC;
 		addr->addrtype = TIPC_ADDR_ID;
+		memset(&addr->addr, 0, sizeof(addr->addr));
 		addr->addr.id.ref = msg_origport(msg);
 		addr->addr.id.node = msg_orignode(msg);
 		addr->addr.name.domain = 0;   	/* could leave uninitialized */
@@ -916,6 +917,9 @@
 		goto exit;
 	}
 
+	/* will be updated in set_orig_addr() if needed */
+	m->msg_namelen = 0;
+
 restart:
 
 	/* Look for a message in receive queue; wait if necessary */
@@ -1049,6 +1053,9 @@
 		goto exit;
 	}
 
+	/* will be updated in set_orig_addr() if needed */
+	m->msg_namelen = 0;
+
 restart:
 
 	/* Look for a message in receive queue; wait if necessary */
diff -Naur a/net/unix/af_unix.c b/net/unix/af_unix.c
--- a/net/unix/af_unix.c	2013-11-01 20:18:06.289569650 +0200
+++ b/net/unix/af_unix.c	2013-11-01 18:45:00.289870166 +0200
@@ -370,7 +370,7 @@
 #endif
 }
 
-static int unix_release_sock(struct sock *sk, int embrion)
+static void unix_release_sock(struct sock *sk, int embrion)
 {
 	struct unix_sock *u = unix_sk(sk);
 	struct dentry *dentry;
@@ -445,8 +445,6 @@
 
 	if (unix_tot_inflight)
 		unix_gc();		/* Garbage collect fds */
-
-	return 0;
 }
 
 static int unix_listen(struct socket *sock, int backlog)
@@ -660,9 +658,10 @@
 	if (!sk)
 		return 0;
 
+	unix_release_sock(sk, 0);
 	sock->sk = NULL;
 
-	return unix_release_sock(sk, 0);
+	return 0;
 }
 
 static int unix_autobind(struct socket *sock)
diff -Naur a/net/wanrouter/wanmain.c b/net/wanrouter/wanmain.c
--- a/net/wanrouter/wanmain.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/wanrouter/wanmain.c	2013-11-01 18:45:00.293870188 +0200
@@ -603,36 +603,31 @@
 		 * successfully, add it to the interface list.
 		 */
 
-		if (dev->name == NULL) {
-			err = -EINVAL;
-		} else {
-
-			#ifdef WANDEBUG
-			printk(KERN_INFO "%s: registering interface %s...\n",
-				wanrouter_modname, dev->name);
-			#endif
-
-			err = register_netdev(dev);
-			if (!err) {
-				struct net_device *slave = NULL;
-				unsigned long smp_flags=0;
-
-				lock_adapter_irq(&wandev->lock, &smp_flags);
-
-				if (wandev->dev == NULL) {
-					wandev->dev = dev;
-				} else {
-					for (slave=wandev->dev;
-					     DEV_TO_SLAVE(slave);
-					     slave = DEV_TO_SLAVE(slave))
-						DEV_TO_SLAVE(slave) = dev;
-				}
-				++wandev->ndev;
-
-				unlock_adapter_irq(&wandev->lock, &smp_flags);
-				err = 0;	/* done !!! */
-				goto out;
+#ifdef WANDEBUG
+		printk(KERN_INFO "%s: registering interface %s...\n",
+		       wanrouter_modname, dev->name);
+#endif
+
+		err = register_netdev(dev);
+		if (!err) {
+			struct net_device *slave = NULL;
+			unsigned long smp_flags=0;
+
+			lock_adapter_irq(&wandev->lock, &smp_flags);
+
+			if (wandev->dev == NULL) {
+				wandev->dev = dev;
+			} else {
+				for (slave=wandev->dev;
+				     DEV_TO_SLAVE(slave);
+				     slave = DEV_TO_SLAVE(slave))
+					DEV_TO_SLAVE(slave) = dev;
 			}
+			++wandev->ndev;
+
+			unlock_adapter_irq(&wandev->lock, &smp_flags);
+			err = 0;	/* done !!! */
+			goto out;
 		}
 		if (wandev->del_if)
 			wandev->del_if(wandev, dev);
diff -Naur a/net/xfrm/xfrm_user.c b/net/xfrm/xfrm_user.c
--- a/net/xfrm/xfrm_user.c	2009-12-03 05:51:21.000000000 +0200
+++ b/net/xfrm/xfrm_user.c	2013-11-01 18:45:00.337870399 +0200
@@ -506,6 +506,7 @@
 
 static void copy_to_user_state(struct xfrm_state *x, struct xfrm_usersa_info *p)
 {
+	memset(p, 0, sizeof(*p));
 	memcpy(&p->id, &x->id, sizeof(p->id));
 	memcpy(&p->sel, &x->sel, sizeof(p->sel));
 	memcpy(&p->lft, &x->lft, sizeof(p->lft));
@@ -646,6 +647,7 @@
 {
 	struct xfrm_dump_info info;
 	struct sk_buff *skb;
+	int err;
 
 	skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_ATOMIC);
 	if (!skb)
@@ -656,9 +658,10 @@
 	info.nlmsg_seq = seq;
 	info.nlmsg_flags = 0;
 
-	if (dump_one_state(x, 0, &info)) {
+	err = dump_one_state(x, 0, &info);
+	if (err) {
 		kfree_skb(skb);
-		return NULL;
+		return ERR_PTR(err);
 	}
 
 	return skb;
@@ -1075,6 +1078,7 @@
 
 static void copy_to_user_policy(struct xfrm_policy *xp, struct xfrm_userpolicy_info *p, int dir)
 {
+	memset(p, 0, sizeof(*p));
 	memcpy(&p->sel, &xp->selector, sizeof(p->sel));
 	memcpy(&p->lft, &xp->lft, sizeof(p->lft));
 	memcpy(&p->curlft, &xp->curlft, sizeof(p->curlft));
@@ -1176,6 +1180,7 @@
 		struct xfrm_user_tmpl *up = &vec[i];
 		struct xfrm_tmpl *kp = &xp->xfrm_vec[i];
 
+		memset(up, 0, sizeof(*up));
 		memcpy(&up->id, &kp->id, sizeof(up->id));
 		up->family = kp->encap_family;
 		memcpy(&up->saddr, &kp->saddr, sizeof(up->saddr));
@@ -1301,6 +1306,7 @@
 {
 	struct xfrm_dump_info info;
 	struct sk_buff *skb;
+	int err;
 
 	skb = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
 	if (!skb)
@@ -1311,9 +1317,10 @@
 	info.nlmsg_seq = seq;
 	info.nlmsg_flags = 0;
 
-	if (dump_one_policy(xp, dir, 0, &info) < 0) {
+	err = dump_one_policy(xp, dir, 0, &info);
+	if (err) {
 		kfree_skb(skb);
-		return NULL;
+		return ERR_PTR(err);
 	}
 
 	return skb;
diff -Naur a/scripts/gcc-version.sh b/scripts/gcc-version.sh
--- a/scripts/gcc-version.sh	2009-12-03 05:51:21.000000000 +0200
+++ b/scripts/gcc-version.sh	2013-11-01 18:45:00.409870762 +0200
@@ -22,10 +22,10 @@
 	exit 1
 fi
 
-MAJOR=$(echo __GNUC__ | $compiler -E -xc - | tail -n 1)
-MINOR=$(echo __GNUC_MINOR__ | $compiler -E -xc - | tail -n 1)
+MAJOR=$(echo __GNUC__ | $compiler -E -x c - | tail -n 1)
+MINOR=$(echo __GNUC_MINOR__ | $compiler -E -x c - | tail -n 1)
 if [ "x$with_patchlevel" != "x" ] ; then
-	PATCHLEVEL=$(echo __GNUC_PATCHLEVEL__ | $compiler -E -xc - | tail -n 1)
+	PATCHLEVEL=$(echo __GNUC_PATCHLEVEL__ | $compiler -E -x c - | tail -n 1)
 	printf "%02d%02d%02d\\n" $MAJOR $MINOR $PATCHLEVEL
 else
 	printf "%02d%02d\\n" $MAJOR $MINOR
diff -Naur a/scripts/gcc-x86_32-has-stack-protector.sh b/scripts/gcc-x86_32-has-stack-protector.sh
--- a/scripts/gcc-x86_32-has-stack-protector.sh	2009-12-03 05:51:21.000000000 +0200
+++ b/scripts/gcc-x86_32-has-stack-protector.sh	2013-11-01 18:45:00.409870762 +0200
@@ -1,6 +1,6 @@
 #!/bin/sh
 
-echo "int foo(void) { char X[200]; return 3; }" | $* -S -xc -c -O0 -fstack-protector - -o - 2> /dev/null | grep -q "%gs"
+echo "int foo(void) { char X[200]; return 3; }" | $* -S -x c -c -O0 -fstack-protector - -o - 2> /dev/null | grep -q "%gs"
 if [ "$?" -eq "0" ] ; then
 	echo y
 else
diff -Naur a/scripts/gcc-x86_64-has-stack-protector.sh b/scripts/gcc-x86_64-has-stack-protector.sh
--- a/scripts/gcc-x86_64-has-stack-protector.sh	2009-12-03 05:51:21.000000000 +0200
+++ b/scripts/gcc-x86_64-has-stack-protector.sh	2013-11-01 18:45:00.409870762 +0200
@@ -1,6 +1,6 @@
 #!/bin/sh
 
-echo "int foo(void) { char X[200]; return 3; }" | $* -S -xc -c -O0 -mcmodel=kernel -fstack-protector - -o - 2> /dev/null | grep -q "%gs"
+echo "int foo(void) { char X[200]; return 3; }" | $* -S -x c -c -O0 -mcmodel=kernel -fstack-protector - -o - 2> /dev/null | grep -q "%gs"
 if [ "$?" -eq "0" ] ; then
 	echo y
 else
diff -Naur a/scripts/Kbuild.include b/scripts/Kbuild.include
--- a/scripts/Kbuild.include	2013-11-01 20:18:06.317569784 +0200
+++ b/scripts/Kbuild.include	2013-11-01 18:45:00.341870428 +0200
@@ -94,24 +94,24 @@
 # Usage: cflags-y += $(call as-option,-Wa$(comma)-isa=foo,)
 
 as-option = $(call try-run,\
-	$(CC) $(KBUILD_CFLAGS) $(1) -c -xassembler /dev/null -o "$$TMP",$(1),$(2))
+	$(CC) $(KBUILD_CFLAGS) $(1) -c -x assembler /dev/null -o "$$TMP",$(1),$(2))
 
 # as-instr
 # Usage: cflags-y += $(call as-instr,instr,option1,option2)
 
 as-instr = $(call try-run,\
-	/bin/echo -e "$(1)" | $(CC) $(KBUILD_AFLAGS) -c -xassembler -o "$$TMP" -,$(2),$(3))
+	/bin/echo -e "$(1)" | $(CC) $(KBUILD_AFLAGS) -c -x assembler -o "$$TMP" -,$(2),$(3))
 
 # cc-option
 # Usage: cflags-y += $(call cc-option,-march=winchip-c6,-march=i586)
 
 cc-option = $(call try-run,\
-	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) $(1) -c -xc /dev/null -o "$$TMP",$(1),$(2))
+	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) $(1) -c -x c /dev/null -o "$$TMP",$(1),$(2))
 
 # cc-option-yn
 # Usage: flag := $(call cc-option-yn,-march=winchip-c6)
 cc-option-yn = $(call try-run,\
-	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) $(1) -c -xc /dev/null -o "$$TMP",y,n)
+	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) $(1) -c -x c /dev/null -o "$$TMP",y,n)
 
 # cc-option-align
 # Prefix align with either -falign or -malign
@@ -121,7 +121,7 @@
 # cc-disable-warning
 # Usage: cflags-y += $(call cc-disable-warning,unused-but-set-variable)
 cc-disable-warning = $(call try-run,\
-	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) -W$(strip $(1)) -c -xc /dev/null -o "$$TMP",-Wno-$(strip $(1)))
+	$(CC) $(KBUILD_CPPFLAGS) $(KBUILD_CFLAGS) -W$(strip $(1)) -c -x c /dev/null -o "$$TMP",-Wno-$(strip $(1)))
 
 # cc-version
 # Usage gcc-ver := $(call cc-version)
@@ -139,7 +139,7 @@
 # cc-ldoption
 # Usage: ldflags += $(call cc-ldoption, -Wl$(comma)--hash-style=both)
 cc-ldoption = $(call try-run,\
-	$(CC) $(1) -nostdlib -xc /dev/null -o "$$TMP",$(1),$(2))
+	$(CC) $(1) -nostdlib -x c /dev/null -o "$$TMP",$(1),$(2))
 
 # ld-option
 # Usage: LDFLAGS += $(call ld-option, -X)
diff -Naur a/scripts/kconfig/check.sh b/scripts/kconfig/check.sh
--- a/scripts/kconfig/check.sh	2009-12-03 05:51:21.000000000 +0200
+++ b/scripts/kconfig/check.sh	2013-11-01 18:45:00.417870799 +0200
@@ -1,6 +1,6 @@
 #!/bin/sh
 # Needed for systems without gettext
-$* -xc -o /dev/null - > /dev/null 2>&1 << EOF
+$* -x c -o /dev/null - > /dev/null 2>&1 << EOF
 #include <libintl.h>
 int main()
 {
diff -Naur a/scripts/kconfig/lxdialog/check-lxdialog.sh b/scripts/kconfig/lxdialog/check-lxdialog.sh
--- a/scripts/kconfig/lxdialog/check-lxdialog.sh	2009-12-03 05:51:21.000000000 +0200
+++ b/scripts/kconfig/lxdialog/check-lxdialog.sh	2013-11-01 18:45:00.425870848 +0200
@@ -36,7 +36,7 @@
 
 # Check if we can link to ncurses
 check() {
-        $cc -xc - -o $tmp 2>/dev/null <<'EOF'
+        $cc -x c - -o $tmp 2>/dev/null <<'EOF'
 #include CURSES_LOC
 main() {}
 EOF
diff -Naur a/security/commoncap.c b/security/commoncap.c
--- a/security/commoncap.c	2009-12-03 05:51:21.000000000 +0200
+++ b/security/commoncap.c	2013-11-01 18:45:00.449870958 +0200
@@ -27,6 +27,7 @@
 #include <linux/sched.h>
 #include <linux/prctl.h>
 #include <linux/securebits.h>
+#include <linux/personality.h>
 
 /*
  * If a non-root user executes a setuid-root binary in
@@ -511,6 +512,11 @@
 	}
 skip:
 
+	/* if we have fs caps, clear dangerous personality flags */
+	if (!cap_issubset(new->cap_permitted, old->cap_permitted))
+		bprm->per_clear |= PER_CLEAR_ON_SETID;
+
+
 	/* Don't let someone trace a set[ug]id/setpcap binary with the revised
 	 * credentials unless they have the appropriate permit
 	 */
diff -Naur a/security/keys/process_keys.c b/security/keys/process_keys.c
--- a/security/keys/process_keys.c	2013-11-01 20:18:06.329569842 +0200
+++ b/security/keys/process_keys.c	2013-11-01 18:45:00.461871021 +0200
@@ -56,7 +56,7 @@
 
 	kenter("%p{%u}", user, user->uid);
 
-	if (user->uid_keyring) {
+	if (user->uid_keyring && user->session_keyring) {
 		kleave(" = 0 [exist]");
 		return 0;
 	}
diff -Naur a/sound/core/seq/seq_timer.c b/sound/core/seq/seq_timer.c
--- a/sound/core/seq/seq_timer.c	2009-12-03 05:51:21.000000000 +0200
+++ b/sound/core/seq/seq_timer.c	2013-11-01 18:45:00.577871602 +0200
@@ -291,10 +291,10 @@
 			tid.device = SNDRV_TIMER_GLOBAL_SYSTEM;
 			err = snd_timer_open(&t, str, &tid, q->queue);
 		}
-		if (err < 0) {
-			snd_printk(KERN_ERR "seq fatal error: cannot create timer (%i)\n", err);
-			return err;
-		}
+	}
+	if (err < 0) {
+		snd_printk(KERN_ERR "seq fatal error: cannot create timer (%i)\n", err);
+		return err;
 	}
 	t->callback = snd_seq_timer_interrupt;
 	t->callback_data = q;
diff -Naur a/sound/drivers/mpu401/mpu401_uart.c b/sound/drivers/mpu401/mpu401_uart.c
--- a/sound/drivers/mpu401/mpu401_uart.c	2009-12-03 05:51:21.000000000 +0200
+++ b/sound/drivers/mpu401/mpu401_uart.c	2013-11-01 18:45:00.925873313 +0200
@@ -554,6 +554,7 @@
 	spin_lock_init(&mpu->output_lock);
 	spin_lock_init(&mpu->timer_lock);
 	mpu->hardware = hardware;
+	mpu->irq = -1;
 	if (! (info_flags & MPU401_INFO_INTEGRATED)) {
 		int res_size = hardware == MPU401_HW_PC98II ? 4 : 2;
 		mpu->res = request_region(port, res_size, "MPU401 UART");
diff -Naur a/sound/pci/ac97/ac97_codec.c b/sound/pci/ac97/ac97_codec.c
--- a/sound/pci/ac97/ac97_codec.c	2009-12-03 05:51:21.000000000 +0200
+++ b/sound/pci/ac97/ac97_codec.c	2013-11-01 18:45:01.029873836 +0200
@@ -1252,6 +1252,8 @@
 		tmp.index = ac97->num;
 		kctl = snd_ctl_new1(&tmp, ac97);
 	}
+	if (!kctl)
+		return -ENOMEM;
 	if (reg >= AC97_PHONE && reg <= AC97_PCM)
 		set_tlv_db_scale(kctl, db_scale_5bit_12db_max);
 	else
diff -Naur a/sound/pci/echoaudio/echoaudio_dsp.c b/sound/pci/echoaudio/echoaudio_dsp.c
--- a/sound/pci/echoaudio/echoaudio_dsp.c	2009-12-03 05:51:21.000000000 +0200
+++ b/sound/pci/echoaudio/echoaudio_dsp.c	2013-11-01 18:45:01.097874176 +0200
@@ -474,7 +474,7 @@
 	const struct firmware *fw;
 	int box_type, err;
 
-	if (snd_BUG_ON(!chip->dsp_code_to_load || !chip->comm_page))
+	if (snd_BUG_ON(!chip->comm_page))
 		return -EPERM;
 
 	/* See if the ASIC is present and working - only if the DSP is already loaded */
diff -Naur a/sound/pci/hda/hda_proc.c b/sound/pci/hda/hda_proc.c
--- a/sound/pci/hda/hda_proc.c	2013-11-01 20:18:06.385570120 +0200
+++ b/sound/pci/hda/hda_proc.c	2013-11-01 18:45:01.129874338 +0200
@@ -340,7 +340,7 @@
 	if (digi1 & AC_DIG1_EMPHASIS)
 		snd_iprintf(buffer, " Preemphasis");
 	if (digi1 & AC_DIG1_COPYRIGHT)
-		snd_iprintf(buffer, " Copyright");
+		snd_iprintf(buffer, " Non-Copyright");
 	if (digi1 & AC_DIG1_NONAUDIO)
 		snd_iprintf(buffer, " Non-Audio");
 	if (digi1 & AC_DIG1_PROFESSIONAL)
diff -Naur a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c
--- a/sound/pci/hda/patch_realtek.c	2013-11-01 20:18:06.409570247 +0200
+++ b/sound/pci/hda/patch_realtek.c	2013-11-01 18:45:01.153874457 +0200
@@ -131,8 +131,8 @@
 enum {
 	ALC269_BASIC,
 	ALC269_QUANTA_FL1,
-	ALC269_ASUS_EEEPC_P703,
-	ALC269_ASUS_EEEPC_P901,
+	ALC269_ASUS_AMIC,
+	ALC269_ASUS_DMIC,
 	ALC269_FUJITSU,
 	ALC269_LIFEBOOK,
 	ALC269_AUTO,
@@ -188,6 +188,8 @@
 	ALC663_ASUS_MODE4,
 	ALC663_ASUS_MODE5,
 	ALC663_ASUS_MODE6,
+	ALC663_ASUS_MODE7,
+	ALC663_ASUS_MODE8,
 	ALC272_DELL,
 	ALC272_DELL_ZM1,
 	ALC272_SAMSUNG_NC10,
@@ -13234,10 +13236,12 @@
 /* toggle speaker-output according to the hp-jack state */
 static void alc269_speaker_automute(struct hda_codec *codec)
 {
+	struct alc_spec *spec = codec->spec;
+	unsigned int nid = spec->autocfg.hp_pins[0];
 	unsigned int present;
 	unsigned char bits;
 
-	present = snd_hda_codec_read(codec, 0x15, 0,
+	present = snd_hda_codec_read(codec, nid, 0,
 				AC_VERB_GET_PIN_SENSE, 0) & 0x80000000;
 	bits = present ? AMP_IN_MUTE(0) : 0;
 	snd_hda_codec_amp_stereo(codec, 0x0c, HDA_INPUT, 0,
@@ -13463,8 +13467,8 @@
 static const char *alc269_models[ALC269_MODEL_LAST] = {
 	[ALC269_BASIC]			= "basic",
 	[ALC269_QUANTA_FL1]		= "quanta",
-	[ALC269_ASUS_EEEPC_P703]	= "eeepc-p703",
-	[ALC269_ASUS_EEEPC_P901]	= "eeepc-p901",
+	[ALC269_ASUS_AMIC]		= "asus-amic",
+	[ALC269_ASUS_DMIC]		= "asus-dmic",
 	[ALC269_FUJITSU]		= "fujitsu",
 	[ALC269_LIFEBOOK]		= "lifebook",
 	[ALC269_AUTO]			= "auto",
@@ -13473,18 +13477,41 @@
 static struct snd_pci_quirk alc269_cfg_tbl[] = {
 	SND_PCI_QUIRK(0x17aa, 0x3bf8, "Quanta FL1", ALC269_QUANTA_FL1),
 	SND_PCI_QUIRK(0x1043, 0x8330, "ASUS Eeepc P703 P900A",
-		      ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x1883, "ASUS F81Se", ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x16a3, "ASUS F5Q", ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x1723, "ASUS P80", ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x1773, "ASUS U20A", ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x1743, "ASUS U80", ALC269_ASUS_EEEPC_P703),
-        SND_PCI_QUIRK(0x1043, 0x1653, "ASUS U50", ALC269_ASUS_EEEPC_P703),
+		      ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1133, "ASUS UJ20ft", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1273, "ASUS UL80JT", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1283, "ASUS U53Jc", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x12b3, "ASUS N82Jv", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x13a3, "ASUS UL30Vt", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1373, "ASUS G73JX", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1383, "ASUS UJ30Jc", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x13d3, "ASUS N61JA", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1413, "ASUS UL50", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1443, "ASUS UL30", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1453, "ASUS M60Jv", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1483, "ASUS UL80", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x14f3, "ASUS F83Vf", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x14e3, "ASUS UL20", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1513, "ASUS UX30", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x15a3, "ASUS N60Jv", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x15b3, "ASUS N60Dp", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x15c3, "ASUS N70De", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x15e3, "ASUS F83T", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1643, "ASUS M60J", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1653, "ASUS U50", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1693, "ASUS F50N", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x16a3, "ASUS F5Q", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x16e3, "ASUS UX50", ALC269_ASUS_DMIC),
+	SND_PCI_QUIRK(0x1043, 0x1723, "ASUS P80", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1743, "ASUS U80", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1773, "ASUS U20A", ALC269_ASUS_AMIC),
+	SND_PCI_QUIRK(0x1043, 0x1883, "ASUS F81Se", ALC269_ASUS_AMIC),
 	SND_PCI_QUIRK(0x1043, 0x831a, "ASUS Eeepc P901",
-		      ALC269_ASUS_EEEPC_P901),
+		      ALC269_ASUS_DMIC),
 	SND_PCI_QUIRK(0x1043, 0x834a, "ASUS Eeepc S101",
-		      ALC269_ASUS_EEEPC_P901),
-        SND_PCI_QUIRK(0x1043, 0x16e3, "ASUS UX50", ALC269_ASUS_EEEPC_P901),
+		      ALC269_ASUS_DMIC),
+	SND_PCI_QUIRK(0x1043, 0x8398, "ASUS P1005HA", ALC269_ASUS_DMIC),
+	SND_PCI_QUIRK(0x1043, 0x83ce, "ASUS P1005HA", ALC269_ASUS_DMIC),
 	SND_PCI_QUIRK(0x1734, 0x115d, "FSC Amilo", ALC269_FUJITSU),
 	SND_PCI_QUIRK(0x10cf, 0x1475, "Lifebook ICH9M-based", ALC269_LIFEBOOK),
 	{}
@@ -13514,7 +13541,7 @@
 		.setup = alc269_quanta_fl1_setup,
 		.init_hook = alc269_quanta_fl1_init_hook,
 	},
-	[ALC269_ASUS_EEEPC_P703] = {
+	[ALC269_ASUS_AMIC] = {
 		.mixers = { alc269_eeepc_mixer },
 		.cap_mixer = alc269_epc_capture_mixer,
 		.init_verbs = { alc269_init_verbs,
@@ -13528,7 +13555,7 @@
 		.setup = alc269_eeepc_amic_setup,
 		.init_hook = alc269_eeepc_inithook,
 	},
-	[ALC269_ASUS_EEEPC_P901] = {
+	[ALC269_ASUS_DMIC] = {
 		.mixers = { alc269_eeepc_mixer },
 		.cap_mixer = alc269_epc_capture_mixer,
 		.init_verbs = { alc269_init_verbs,
@@ -14686,6 +14713,27 @@
 	},
 };
 
+/* Pin config fixes */
+enum {
+	PINFIX_FSC_AMILO_PI1505,
+};
+
+static struct alc_pincfg alc861_fsc_amilo_pi1505_pinfix[] = {
+	{ 0x0b, 0x0221101f }, /* HP */
+	{ 0x0f, 0x90170310 }, /* speaker */
+	{ }
+};
+
+static const struct alc_fixup alc861_fixups[] = {
+	[PINFIX_FSC_AMILO_PI1505] = {
+		.pins = alc861_fsc_amilo_pi1505_pinfix
+	},
+};
+
+static struct snd_pci_quirk alc861_fixup_tbl[] = {
+	SND_PCI_QUIRK(0x1734, 0x10c7, "FSC Amilo Pi1505", PINFIX_FSC_AMILO_PI1505),
+	{}
+};
 
 static int patch_alc861(struct hda_codec *codec)
 {
@@ -14709,6 +14757,8 @@
 		board_config = ALC861_AUTO;
 	}
 
+	alc_pick_fixup(codec, alc861_fixup_tbl, alc861_fixups);
+
 	if (board_config == ALC861_AUTO) {
 		/* automatic parse from the BIOS config */
 		err = alc861_parse_auto_config(codec);
@@ -16144,6 +16194,52 @@
 	{ } /* end */
 };
 
+static struct hda_bind_ctls alc663_asus_mode7_8_all_bind_switch = {
+	.ops = &snd_hda_bind_sw,
+	.values = {
+		HDA_COMPOSE_AMP_VAL(0x14, 3, 0, HDA_OUTPUT),
+		HDA_COMPOSE_AMP_VAL(0x15, 3, 0, HDA_OUTPUT),
+		HDA_COMPOSE_AMP_VAL(0x17, 3, 0, HDA_OUTPUT),
+		HDA_COMPOSE_AMP_VAL(0x1b, 3, 0, HDA_OUTPUT),
+		HDA_COMPOSE_AMP_VAL(0x21, 3, 0, HDA_OUTPUT),
+		0
+	},
+};
+
+static struct hda_bind_ctls alc663_asus_mode7_8_sp_bind_switch = {
+	.ops = &snd_hda_bind_sw,
+	.values = {
+		HDA_COMPOSE_AMP_VAL(0x14, 3, 0, HDA_OUTPUT),
+		HDA_COMPOSE_AMP_VAL(0x17, 3, 0, HDA_OUTPUT),
+		0
+	},
+};
+
+static struct snd_kcontrol_new alc663_mode7_mixer[] = {
+	HDA_BIND_SW("Master Playback Switch", &alc663_asus_mode7_8_all_bind_switch),
+	HDA_BIND_VOL("Speaker Playback Volume", &alc663_asus_bind_master_vol),
+	HDA_BIND_SW("Speaker Playback Switch", &alc663_asus_mode7_8_sp_bind_switch),
+	HDA_CODEC_MUTE("Headphone1 Playback Switch", 0x1b, 0x0, HDA_OUTPUT),
+	HDA_CODEC_MUTE("Headphone2 Playback Switch", 0x21, 0x0, HDA_OUTPUT),
+	HDA_CODEC_VOLUME("IntMic Playback Volume", 0x0b, 0x0, HDA_INPUT),
+	HDA_CODEC_MUTE("IntMic Playback Switch", 0x0b, 0x0, HDA_INPUT),
+	HDA_CODEC_VOLUME("Mic Playback Volume", 0x0b, 0x1, HDA_INPUT),
+	HDA_CODEC_MUTE("Mic Playback Switch", 0x0b, 0x1, HDA_INPUT),
+	{ } /* end */
+};
+
+static struct snd_kcontrol_new alc663_mode8_mixer[] = {
+	HDA_BIND_SW("Master Playback Switch", &alc663_asus_mode7_8_all_bind_switch),
+	HDA_BIND_VOL("Speaker Playback Volume", &alc663_asus_bind_master_vol),
+	HDA_BIND_SW("Speaker Playback Switch", &alc663_asus_mode7_8_sp_bind_switch),
+	HDA_CODEC_MUTE("Headphone1 Playback Switch", 0x15, 0x0, HDA_OUTPUT),
+	HDA_CODEC_MUTE("Headphone2 Playback Switch", 0x21, 0x0, HDA_OUTPUT),
+	HDA_CODEC_VOLUME("Mic Playback Volume", 0x0b, 0x0, HDA_INPUT),
+	HDA_CODEC_MUTE("Mic Playback Switch", 0x0b, 0x0, HDA_INPUT),
+	{ } /* end */
+};
+
+
 static struct snd_kcontrol_new alc662_chmode_mixer[] = {
 	{
 		.iface = SNDRV_CTL_ELEM_IFACE_MIXER,
@@ -16431,6 +16527,45 @@
 	{}
 };
 
+static struct hda_verb alc663_mode7_init_verbs[] = {
+	{0x15, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_IN},
+	{0x16, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_IN},
+	{0x17, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT},
+	{0x17, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x1b, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_HP},
+	{0x1b, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x1b, AC_VERB_SET_CONNECT_SEL, 0x01},
+	{0x21, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_HP},
+	{0x21, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x21, AC_VERB_SET_CONNECT_SEL, 0x01},	/* Headphone */
+	{0x22, AC_VERB_SET_AMP_GAIN_MUTE, AMP_IN_MUTE(0)},
+	{0x22, AC_VERB_SET_AMP_GAIN_MUTE, AMP_IN_UNMUTE(9)},
+	{0x19, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_MIC_EVENT},
+	{0x1b, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_HP_EVENT},
+	{0x21, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_HP_EVENT},
+	{}
+};
+
+static struct hda_verb alc663_mode8_init_verbs[] = {
+	{0x12, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_IN},
+	{0x15, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_HP},
+	{0x15, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x15, AC_VERB_SET_CONNECT_SEL, 0x01},
+	{0x16, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_IN},
+	{0x17, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT},
+	{0x17, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x1b, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_IN},
+	{0x21, AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_HP},
+	{0x21, AC_VERB_SET_AMP_GAIN_MUTE, AMP_OUT_UNMUTE},
+	{0x21, AC_VERB_SET_CONNECT_SEL, 0x01},	/* Headphone */
+	{0x22, AC_VERB_SET_AMP_GAIN_MUTE, AMP_IN_MUTE(0)},
+	{0x22, AC_VERB_SET_AMP_GAIN_MUTE, AMP_IN_UNMUTE(9)},
+	{0x15, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_HP_EVENT},
+	{0x18, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_MIC_EVENT},
+	{0x21, AC_VERB_SET_UNSOLICITED_ENABLE, AC_USRSP_EN | ALC880_HP_EVENT},
+	{}
+};
+
 static struct snd_kcontrol_new alc662_auto_capture_mixer[] = {
 	HDA_CODEC_VOLUME("Capture Volume", 0x09, 0x0, HDA_INPUT),
 	HDA_CODEC_MUTE("Capture Switch", 0x09, 0x0, HDA_INPUT),
@@ -16626,6 +16761,54 @@
 	}
 }
 
+static void alc663_two_hp_m7_speaker_automute(struct hda_codec *codec)
+{
+	unsigned int present1, present2;
+
+	present1 = snd_hda_codec_read(codec, 0x1b, 0,
+			AC_VERB_GET_PIN_SENSE, 0)
+			& AC_PINSENSE_PRESENCE;
+	present2 = snd_hda_codec_read(codec, 0x21, 0,
+			AC_VERB_GET_PIN_SENSE, 0)
+			& AC_PINSENSE_PRESENCE;
+
+	if (present1 || present2) {
+		snd_hda_codec_write_cache(codec, 0x14, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, 0);
+		snd_hda_codec_write_cache(codec, 0x17, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, 0);
+	} else {
+		snd_hda_codec_write_cache(codec, 0x14, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT);
+		snd_hda_codec_write_cache(codec, 0x17, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT);
+	}
+}
+
+static void alc663_two_hp_m8_speaker_automute(struct hda_codec *codec)
+{
+	unsigned int present1, present2;
+
+	present1 = snd_hda_codec_read(codec, 0x21, 0,
+			AC_VERB_GET_PIN_SENSE, 0)
+			& AC_PINSENSE_PRESENCE;
+	present2 = snd_hda_codec_read(codec, 0x15, 0,
+			AC_VERB_GET_PIN_SENSE, 0)
+			& AC_PINSENSE_PRESENCE;
+
+	if (present1 || present2) {
+		snd_hda_codec_write_cache(codec, 0x14, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, 0);
+		snd_hda_codec_write_cache(codec, 0x17, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, 0);
+	} else {
+		snd_hda_codec_write_cache(codec, 0x14, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT);
+		snd_hda_codec_write_cache(codec, 0x17, 0,
+			AC_VERB_SET_PIN_WIDGET_CONTROL, PIN_OUT);
+	}
+}
+
 static void alc663_m51va_unsol_event(struct hda_codec *codec,
 					   unsigned int res)
 {
@@ -16645,7 +16828,7 @@
 	spec->ext_mic.pin = 0x18;
 	spec->ext_mic.mux_idx = 0;
 	spec->int_mic.pin = 0x12;
-	spec->int_mic.mux_idx = 1;
+	spec->int_mic.mux_idx = 9;
 	spec->auto_mic = 1;
 }
 
@@ -16657,7 +16840,17 @@
 
 /* ***************** Mode1 ******************************/
 #define alc663_mode1_unsol_event	alc663_m51va_unsol_event
-#define alc663_mode1_setup		alc663_m51va_setup
+
+static void alc663_mode1_setup(struct hda_codec *codec)
+{
+	struct alc_spec *spec = codec->spec;
+	spec->ext_mic.pin = 0x18;
+	spec->ext_mic.mux_idx = 0;
+	spec->int_mic.pin = 0x19;
+	spec->int_mic.mux_idx = 1;
+	spec->auto_mic = 1;
+}
+
 #define alc663_mode1_inithook		alc663_m51va_inithook
 
 /* ***************** Mode2 ******************************/
@@ -16674,7 +16867,7 @@
 	}
 }
 
-#define alc662_mode2_setup	alc663_m51va_setup
+#define alc662_mode2_setup	alc663_mode1_setup
 
 static void alc662_mode2_inithook(struct hda_codec *codec)
 {
@@ -16695,7 +16888,7 @@
 	}
 }
 
-#define alc663_mode3_setup	alc663_m51va_setup
+#define alc663_mode3_setup	alc663_mode1_setup
 
 static void alc663_mode3_inithook(struct hda_codec *codec)
 {
@@ -16716,7 +16909,7 @@
 	}
 }
 
-#define alc663_mode4_setup	alc663_m51va_setup
+#define alc663_mode4_setup	alc663_mode1_setup
 
 static void alc663_mode4_inithook(struct hda_codec *codec)
 {
@@ -16737,7 +16930,7 @@
 	}
 }
 
-#define alc663_mode5_setup	alc663_m51va_setup
+#define alc663_mode5_setup	alc663_mode1_setup
 
 static void alc663_mode5_inithook(struct hda_codec *codec)
 {
@@ -16758,7 +16951,7 @@
 	}
 }
 
-#define alc663_mode6_setup	alc663_m51va_setup
+#define alc663_mode6_setup	alc663_mode1_setup
 
 static void alc663_mode6_inithook(struct hda_codec *codec)
 {
@@ -16766,6 +16959,50 @@
 	alc_mic_automute(codec);
 }
 
+/* ***************** Mode7 ******************************/
+static void alc663_mode7_unsol_event(struct hda_codec *codec,
+					   unsigned int res)
+{
+	switch (res >> 26) {
+	case ALC880_HP_EVENT:
+		alc663_two_hp_m7_speaker_automute(codec);
+		break;
+	case ALC880_MIC_EVENT:
+		alc_mic_automute(codec);
+		break;
+	}
+}
+
+#define alc663_mode7_setup	alc663_mode1_setup
+
+static void alc663_mode7_inithook(struct hda_codec *codec)
+{
+	alc663_two_hp_m7_speaker_automute(codec);
+	alc_mic_automute(codec);
+}
+
+/* ***************** Mode8 ******************************/
+static void alc663_mode8_unsol_event(struct hda_codec *codec,
+					   unsigned int res)
+{
+	switch (res >> 26) {
+	case ALC880_HP_EVENT:
+		alc663_two_hp_m8_speaker_automute(codec);
+		break;
+	case ALC880_MIC_EVENT:
+		alc_mic_automute(codec);
+		break;
+	}
+}
+
+#define alc663_mode8_setup	alc663_m51va_setup
+
+static void alc663_mode8_inithook(struct hda_codec *codec)
+{
+	alc663_two_hp_m8_speaker_automute(codec);
+	alc_mic_automute(codec);
+}
+
 static void alc663_g71v_hp_automute(struct hda_codec *codec)
 {
 	unsigned int present;
@@ -16904,6 +17141,8 @@
 	[ALC663_ASUS_MODE4] = "asus-mode4",
 	[ALC663_ASUS_MODE5] = "asus-mode5",
 	[ALC663_ASUS_MODE6] = "asus-mode6",
+	[ALC663_ASUS_MODE7] = "asus-mode7",
+	[ALC663_ASUS_MODE8] = "asus-mode8",
 	[ALC272_DELL]		= "dell",
 	[ALC272_DELL_ZM1]	= "dell-zm1",
 	[ALC272_SAMSUNG_NC10]	= "samsung-nc10",
@@ -16920,12 +17159,22 @@
 	SND_PCI_QUIRK(0x1043, 0x11d3, "ASUS NB", ALC663_ASUS_MODE1),
 	SND_PCI_QUIRK(0x1043, 0x11f3, "ASUS NB", ALC662_ASUS_MODE2),
 	SND_PCI_QUIRK(0x1043, 0x1203, "ASUS NB", ALC663_ASUS_MODE1),
+	SND_PCI_QUIRK(0x1043, 0x1303, "ASUS G60J", ALC663_ASUS_MODE1),
+	SND_PCI_QUIRK(0x1043, 0x1333, "ASUS G60Jx", ALC663_ASUS_MODE1),
 	SND_PCI_QUIRK(0x1043, 0x1339, "ASUS NB", ALC662_ASUS_MODE2),
+	SND_PCI_QUIRK(0x1043, 0x13e3, "ASUS N71JA", ALC663_ASUS_MODE7),
+	SND_PCI_QUIRK(0x1043, 0x1463, "ASUS N71", ALC663_ASUS_MODE7),
+	SND_PCI_QUIRK(0x1043, 0x14d3, "ASUS G72", ALC663_ASUS_MODE8),
+	SND_PCI_QUIRK(0x1043, 0x1563, "ASUS N90", ALC663_ASUS_MODE3),
+	SND_PCI_QUIRK(0x1043, 0x15d3, "ASUS N50SF F50SF", ALC663_ASUS_MODE1),
 	SND_PCI_QUIRK(0x1043, 0x16c3, "ASUS NB", ALC662_ASUS_MODE2),
+	SND_PCI_QUIRK(0x1043, 0x16f3, "ASUS K40C K50C", ALC662_ASUS_MODE2),
+	SND_PCI_QUIRK(0x1043, 0x1733, "ASUS N81De", ALC663_ASUS_MODE1),
 	SND_PCI_QUIRK(0x1043, 0x1753, "ASUS NB", ALC662_ASUS_MODE2),
 	SND_PCI_QUIRK(0x1043, 0x1763, "ASUS NB", ALC663_ASUS_MODE6),
 	SND_PCI_QUIRK(0x1043, 0x1765, "ASUS NB", ALC663_ASUS_MODE6),
 	SND_PCI_QUIRK(0x1043, 0x1783, "ASUS NB", ALC662_ASUS_MODE2),
+	SND_PCI_QUIRK(0x1043, 0x1793, "ASUS F50GX", ALC663_ASUS_MODE1),
 	SND_PCI_QUIRK(0x1043, 0x17b3, "ASUS F70SL", ALC663_ASUS_MODE3),
 	SND_PCI_QUIRK(0x1043, 0x17c3, "ASUS UX20", ALC663_ASUS_M51VA),
 	SND_PCI_QUIRK(0x1043, 0x17f3, "ASUS X58LE", ALC662_ASUS_MODE2),
@@ -17208,6 +17457,36 @@
 		.setup = alc663_mode6_setup,
 		.init_hook = alc663_mode6_inithook,
 	},
+	[ALC663_ASUS_MODE7] = {
+		.mixers = { alc663_mode7_mixer },
+		.cap_mixer = alc662_auto_capture_mixer,
+		.init_verbs = { alc662_init_verbs,
+				alc663_mode7_init_verbs },
+		.num_dacs = ARRAY_SIZE(alc662_dac_nids),
+		.hp_nid = 0x03,
+		.dac_nids = alc662_dac_nids,
+		.dig_out_nid = ALC662_DIGOUT_NID,
+		.num_channel_mode = ARRAY_SIZE(alc662_3ST_2ch_modes),
+		.channel_mode = alc662_3ST_2ch_modes,
+		.unsol_event = alc663_mode7_unsol_event,
+		.setup = alc663_mode7_setup,
+		.init_hook = alc663_mode7_inithook,
+	},
+	[ALC663_ASUS_MODE8] = {
+		.mixers = { alc663_mode8_mixer },
+		.cap_mixer = alc662_auto_capture_mixer,
+		.init_verbs = { alc662_init_verbs,
+				alc663_mode8_init_verbs },
+		.num_dacs = ARRAY_SIZE(alc662_dac_nids),
+		.hp_nid = 0x03,
+		.dac_nids = alc662_dac_nids,
+		.dig_out_nid = ALC662_DIGOUT_NID,
+		.num_channel_mode = ARRAY_SIZE(alc662_3ST_2ch_modes),
+		.channel_mode = alc662_3ST_2ch_modes,
+		.unsol_event = alc663_mode8_unsol_event,
+		.setup = alc663_mode8_setup,
+		.init_hook = alc663_mode8_inithook,
+	},
 	[ALC272_DELL] = {
 		.mixers = { alc663_m51va_mixer },
 		.cap_mixer = alc272_auto_capture_mixer,
@@ -17676,7 +17955,9 @@
 	{ .id = 0x10ec0267, .name = "ALC267", .patch = patch_alc268 },
 	{ .id = 0x10ec0268, .name = "ALC268", .patch = patch_alc268 },
 	{ .id = 0x10ec0269, .name = "ALC269", .patch = patch_alc269 },
+	{ .id = 0x10ec0270, .name = "ALC270", .patch = patch_alc269 },
 	{ .id = 0x10ec0272, .name = "ALC272", .patch = patch_alc662 },
+	{ .id = 0x10ec0275, .name = "ALC275", .patch = patch_alc269 },
 	{ .id = 0x10ec0861, .rev = 0x100340, .name = "ALC660",
 	  .patch = patch_alc861 },
 	{ .id = 0x10ec0660, .name = "ALC660-VD", .patch = patch_alc861vd },
diff -Naur a/sound/stm/conv_i2sspdif.c b/sound/stm/conv_i2sspdif.c
--- a/sound/stm/conv_i2sspdif.c	2013-11-01 20:19:19.429932324 +0200
+++ b/sound/stm/conv_i2sspdif.c	2013-11-01 18:45:01.345875405 +0200
@@ -89,6 +89,27 @@
 
 #define CHA_STA_TRIES 50000
 
+static int snd_stm_conv_i2sspdif_set_cha_sta(struct snd_stm_conv_i2sspdif
+		*conv_i2sspdif, unsigned long *status)
+{
+	int j;
+
+	/* Clear the channel status update bit (only IP v4 or later) */
+	if (conv_i2sspdif->ver >= 4)
+		set__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(conv_i2sspdif, 1);
+
+	/* Set the channel status */
+	for (j = 0; j < 6; j++)
+		set__AUD_SPDIFPC_CHA_STA(conv_i2sspdif, j, status[j]);
+
+	/* Verify the channel status is set */
+	for (j = 0; j < 6; j++)
+		if (get__AUD_SPDIFPC_CHA_STA(conv_i2sspdif, j) != status[j])
+			return 0;
+
+	return 1;
+}
+
 static int snd_stm_conv_i2sspdif_iec958_set(struct snd_stm_conv_i2sspdif
 		*conv_i2sspdif, struct snd_aes_iec958 *iec958)
 {
@@ -142,6 +163,26 @@
 
 			status[i] = word | (word << 1);
 		}
+
+		/* Set converter's channel status registers - they are realised
+		 * in such a ridiculous way that write to them is enabled only
+		 * in (about) 300us time window after CHL_STS_BUFF_EMPTY bit
+		 * is asserted... And this happens once every 2ms (only when
+		 * converter is enabled and gets data...) */
+
+		for (i = 0; i < CHA_STA_TRIES; i++) {
+
+			if (get__AUD_SPDIFPC_STA__CHL_STS_BUFF_EMPTY(
+							conv_i2sspdif)) {
+
+				ok = snd_stm_conv_i2sspdif_set_cha_sta(
+								conv_i2sspdif,
+								status);
+
+				if (ok)
+					break;
+			}
+		}
 	} else {
 		/* Fortunately in some hardware there is a "sane" mode
 		 * of channel status registers operation... :-) */
@@ -151,31 +192,12 @@
 					iec958->status[i * 4 + 1] << 8 |
 					iec958->status[i * 4 + 2] << 16 |
 					iec958->status[i * 4 + 3] << 24;
-	}
 
-	/* Set converter's channel status registers - they are realised
-	 * in such a ridiculous way that write to them is enabled only
-	 * in (about) 300us time window after CHL_STS_BUFF_EMPTY bit
-	 * is asserted... And this happens once every 2ms (only when
-	 * converter is enabled and gets data...) */
-
-	ok = 0;
-	for (i = 0; i < CHA_STA_TRIES; i++) {
-		if (get__AUD_SPDIFPC_STA__CHL_STS_BUFF_EMPTY(conv_i2sspdif)) {
-			for (j = 0; j < 6; j++)
-				set__AUD_SPDIFPC_CHA_STA(conv_i2sspdif, j,
-						status[j]);
-			ok = 1;
-			for (j = 0; j < 6; j++)
-				if (get__AUD_SPDIFPC_CHA_STA(conv_i2sspdif,
-						j) != status[j]) {
-					ok = 0;
-					break;
-				}
-			if (ok)
-				break;
-		}
+		/* Set converter's channel status registers */
+		ok = snd_stm_conv_i2sspdif_set_cha_sta(conv_i2sspdif, status);
 	}
+
+
 	if (!ok) {
 		snd_stm_printe("WARNING! Failed to set channel status registers"
 				" for converter %s! (tried %d times)\n",
diff -Naur a/sound/stm/reg_aud_spdifpc.h b/sound/stm/reg_aud_spdifpc.h
--- a/sound/stm/reg_aud_spdifpc.h	2013-11-01 20:19:19.465932508 +0200
+++ b/sound/stm/reg_aud_spdifpc.h	2013-11-01 18:45:01.353875444 +0200
@@ -177,6 +177,16 @@
 	value__AUD_SPDIFPC_CFG__REQ_ACK_EN__ENABLED(ip))
 
 /* CHA_STA_BITS */
+#define shift__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip) 9
+#define mask__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip) 0x1
+
+#define set__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip, value) \
+	writel((readl(ip->base + offset__AUD_SPDIFPC_CFG(ip)) & \
+	~(mask__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip) << \
+	shift__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip))) | (((value) & \
+	mask__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip)) << \
+	shift__AUD_SPDIFPC_CFG__CHL_STS_UPDATE_CLR(ip)), ip->base + \
+	offset__AUD_SPDIFPC_CFG(ip))
 
 #define shift__AUD_SPDIFPC_CFG__CHA_STA_BITS(ip) (ip->ver < \
 	4 ? -1 : 6)
diff -Naur a/usr/gen_init_cpio.c b/usr/gen_init_cpio.c
--- a/usr/gen_init_cpio.c	2009-12-03 05:51:21.000000000 +0200
+++ b/usr/gen_init_cpio.c	2013-11-01 18:45:01.405875700 +0200
@@ -299,7 +299,7 @@
 	int retval;
 	int rc = -1;
 	int namesize;
-	int i;
+	unsigned int i;
 
 	mode |= S_IFREG;
 
@@ -372,25 +372,28 @@
 
 static char *cpio_replace_env(char *new_location)
 {
-       char expanded[PATH_MAX + 1];
-       char env_var[PATH_MAX + 1];
-       char *start;
-       char *end;
-
-       for (start = NULL; (start = strstr(new_location, "${")); ) {
-               end = strchr(start, '}');
-               if (start < end) {
-                       *env_var = *expanded = '\0';
-                       strncat(env_var, start + 2, end - start - 2);
-                       strncat(expanded, new_location, start - new_location);
-                       strncat(expanded, getenv(env_var), PATH_MAX);
-                       strncat(expanded, end + 1, PATH_MAX);
-                       strncpy(new_location, expanded, PATH_MAX);
-               } else
-                       break;
-       }
+	char expanded[PATH_MAX + 1];
+	char env_var[PATH_MAX + 1];
+	char *start;
+	char *end;
+
+	for (start = NULL; (start = strstr(new_location, "${")); ) {
+		end = strchr(start, '}');
+		if (start < end) {
+			*env_var = *expanded = '\0';
+			strncat(env_var, start + 2, end - start - 2);
+			strncat(expanded, new_location, start - new_location);
+			strncat(expanded, getenv(env_var),
+				PATH_MAX - strlen(expanded));
+			strncat(expanded, end + 1,
+				PATH_MAX - strlen(expanded));
+			strncpy(new_location, expanded, PATH_MAX);
+			new_location[PATH_MAX] = 0;
+		} else
+			break;
+	}
 
-       return new_location;
+	return new_location;
 }
 
 
diff -Naur a/virt/kvm/ioapic.c b/virt/kvm/ioapic.c
--- a/virt/kvm/ioapic.c	2009-12-03 05:51:21.000000000 +0200
+++ b/virt/kvm/ioapic.c	2013-11-01 18:45:01.405875700 +0200
@@ -71,9 +71,12 @@
 			u32 redir_index = (ioapic->ioregsel - 0x10) >> 1;
 			u64 redir_content;
 
-			ASSERT(redir_index < IOAPIC_NUM_PINS);
+			if (redir_index < IOAPIC_NUM_PINS)
+				redir_content =
+					ioapic->redirtbl[redir_index].bits;
+			else
+				redir_content = ~0ULL;
 
-			redir_content = ioapic->redirtbl[redir_index].bits;
 			result = (ioapic->ioregsel & 0x1) ?
 			    (redir_content >> 32) & 0xffffffff :
 			    redir_content & 0xffffffff;
diff -Naur a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
--- a/virt/kvm/kvm_main.c	2013-11-01 20:18:06.489570635 +0200
+++ b/virt/kvm/kvm_main.c	2013-11-01 18:45:01.409875722 +0200
@@ -43,6 +43,8 @@
 #include <linux/swap.h>
 #include <linux/bitops.h>
 #include <linux/spinlock.h>
+#include <linux/namei.h>
+#include <linux/fs.h>
 
 #include <asm/processor.h>
 #include <asm/io.h>
@@ -575,12 +577,76 @@
 	return r;
 }
 
+/*
+ * We want to test whether the caller has been granted permissions to
+ * use this device.  To be able to configure and control the device,
+ * the user needs access to PCI configuration space and BAR resources.
+ * These are accessed through PCI sysfs.  PCI config space is often
+ * passed to the process calling this ioctl via file descriptor, so we
+ * can't rely on access to that file.  We can check for permissions
+ * on each of the BAR resource files, which is a pretty clear
+ * indicator that the user has been granted access to the device.
+ */
+static int probe_sysfs_permissions(struct pci_dev *dev)
+{
+#ifdef CONFIG_SYSFS
+	int i;
+	bool bar_found = false;
+
+	for (i = PCI_STD_RESOURCES; i <= PCI_STD_RESOURCE_END; i++) {
+		char *kpath, *syspath;
+		struct path path;
+		struct inode *inode;
+		int r;
+
+		if (!pci_resource_len(dev, i))
+			continue;
+
+		kpath = kobject_get_path(&dev->dev.kobj, GFP_KERNEL);
+		if (!kpath)
+			return -ENOMEM;
+
+		/* Per sysfs-rules, sysfs is always at /sys */
+		syspath = kasprintf(GFP_KERNEL, "/sys%s/resource%d", kpath, i);
+		kfree(kpath);
+		if (!syspath)
+			return -ENOMEM;
+
+		r = kern_path(syspath, LOOKUP_FOLLOW, &path);
+		kfree(syspath);
+		if (r)
+			return r;
+
+		inode = path.dentry->d_inode;
+
+		r = inode_permission(inode, MAY_READ | MAY_WRITE | MAY_ACCESS);
+		path_put(&path);
+		if (r)
+			return r;
+
+		bar_found = true;
+	}
+
+	/* If no resources, probably something special */
+	if (!bar_found)
+		return -EPERM;
+
+	return 0;
+#else
+	return -EINVAL; /* No way to control the device without sysfs */
+#endif
+}
+
 static int kvm_vm_ioctl_assign_device(struct kvm *kvm,
 				      struct kvm_assigned_pci_dev *assigned_dev)
 {
 	int r = 0;
 	struct kvm_assigned_dev_kernel *match;
 	struct pci_dev *dev;
+	u8 header_type;
+
+	if (!(assigned_dev->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU))
+		return -EINVAL;
 
 	down_read(&kvm->slots_lock);
 	mutex_lock(&kvm->lock);
@@ -607,6 +673,18 @@
 		r = -EINVAL;
 		goto out_free;
 	}
+
+	/* Don't allow bridges to be assigned */
+	pci_read_config_byte(dev, PCI_HEADER_TYPE, &header_type);
+	if ((header_type & PCI_HEADER_TYPE) != PCI_HEADER_TYPE_NORMAL) {
+		r = -EPERM;
+		goto out_put;
+	}
+
+	r = probe_sysfs_permissions(dev);
+	if (r)
+		goto out_put;
+
 	if (pci_enable_device(dev)) {
 		printk(KERN_INFO "%s: Could not enable PCI device\n", __func__);
 		r = -EBUSY;
@@ -635,16 +713,14 @@
 
 	list_add(&match->list, &kvm->arch.assigned_dev_head);
 
-	if (assigned_dev->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU) {
-		if (!kvm->arch.iommu_domain) {
-			r = kvm_iommu_map_guest(kvm);
-			if (r)
-				goto out_list_del;
-		}
-		r = kvm_assign_device(kvm, match);
+	if (!kvm->arch.iommu_domain) {
+		r = kvm_iommu_map_guest(kvm);
 		if (r)
 			goto out_list_del;
 	}
+	r = kvm_assign_device(kvm, match);
+	if (r)
+		goto out_list_del;
 
 out:
 	mutex_unlock(&kvm->lock);
@@ -683,8 +759,7 @@
 		goto out;
 	}
 
-	if (match->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU)
-		kvm_deassign_device(kvm, match);
+	kvm_deassign_device(kvm, match);
 
 	kvm_free_assigned_device(kvm, match);
 
@@ -1782,6 +1857,10 @@
 		return r;
 
 	mutex_lock(&kvm->lock);
+	if (!kvm_vcpu_compatible(vcpu)) {
+		r = -EINVAL;
+		goto vcpu_destroy;
+	}
 	if (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {
 		r = -EINVAL;
 		goto vcpu_destroy;
